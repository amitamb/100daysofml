{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amit/anaconda3/envs/tf/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "        \n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        \n",
    "        self.D = None\n",
    "        self.G = None\n",
    "        self.AM = None\n",
    "        self.DM = None\n",
    "    \n",
    "    def discriminator(self):\n",
    "        \n",
    "        if self.D:\n",
    "            return self.D\n",
    "        \n",
    "        self.D = Sequential()\n",
    "        depth = 64\n",
    "        dropout = 0.4\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.D.add(Conv2D(depth * 1, 5, strides=2, padding='same', input_shape=input_shape))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        self.D.add(Conv2D(depth * 2, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        self.D.add(Conv2D(depth * 4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        self.D.add(Conv2D(depth * 4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "        \n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1, activation='sigmoid'))\n",
    "        self.D.summary()\n",
    "        \n",
    "        return self.D\n",
    "    \n",
    "    def generator(self):\n",
    "        \n",
    "        if self.G:\n",
    "            return self.G\n",
    "        \n",
    "        self.G = Sequential()\n",
    "        \n",
    "        depth = 64+64+64+64\n",
    "        dim = 7\n",
    "        \n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Reshape((dim, dim, depth)))\n",
    "        \n",
    "        self.G.add(UpSampling2D()) # doubles the row and columns\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), kernel_size=5, padding='same'))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        \n",
    "        self.G.add(UpSampling2D()) # doubles the row and columns\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), kernel_size=5, padding='same'))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(int(depth/8), kernel_size=5, padding='same'))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        \n",
    "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "\n",
    "        return self.G\n",
    "    \n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        \n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.DM\n",
    "    \n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        \n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        \n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_DCGAN(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "        \n",
    "        self.x_train = input_data.read_data_sets('mnist', one_hot=True).train.images\n",
    "        self.x_train = self.x_train.reshape(-1, self.img_rows, self.img_cols, 1).astype(np.float32)\n",
    "        \n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator = self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "        \n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        node_input = None\n",
    "        if save_interval > 0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        \n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0, self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            \n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            \n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([batch_size * 2, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "            \n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            \n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s: [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            \n",
    "            print(log_mesg)\n",
    "            \n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval == 0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "    \n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 2,665,729\n",
      "Trainable params: 2,665,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12544)             1266944   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 14, 14, 128)       819328    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 2,394,241\n",
      "Trainable params: 2,368,705\n",
      "Non-trainable params: 25,536\n",
      "_________________________________________________________________\n",
      "0: [D loss: 0.693571, acc: 0.468750]: [A loss: 0.863926, acc: 0.000000]\n",
      "1: [D loss: 0.674432, acc: 0.500000]: [A loss: 0.859994, acc: 0.000000]\n",
      "2: [D loss: 0.637056, acc: 0.982422]: [A loss: 0.879674, acc: 0.000000]\n",
      "3: [D loss: 0.615504, acc: 0.501953]: [A loss: 1.055648, acc: 0.000000]\n",
      "4: [D loss: 0.575242, acc: 0.972656]: [A loss: 0.987882, acc: 0.000000]\n",
      "5: [D loss: 0.527793, acc: 0.628906]: [A loss: 1.271954, acc: 0.000000]\n",
      "6: [D loss: 0.456028, acc: 0.996094]: [A loss: 1.159890, acc: 0.011719]\n",
      "7: [D loss: 0.600594, acc: 0.529297]: [A loss: 1.629862, acc: 0.000000]\n",
      "8: [D loss: 0.444763, acc: 0.939453]: [A loss: 1.331612, acc: 0.000000]\n",
      "9: [D loss: 0.374569, acc: 0.968750]: [A loss: 1.354169, acc: 0.003906]\n",
      "10: [D loss: 0.392469, acc: 0.814453]: [A loss: 1.770170, acc: 0.000000]\n",
      "11: [D loss: 0.291066, acc: 0.980469]: [A loss: 1.618327, acc: 0.000000]\n",
      "12: [D loss: 0.376329, acc: 0.798828]: [A loss: 2.244699, acc: 0.000000]\n",
      "13: [D loss: 0.277863, acc: 0.964844]: [A loss: 1.516870, acc: 0.000000]\n",
      "14: [D loss: 0.366763, acc: 0.800781]: [A loss: 2.180262, acc: 0.000000]\n",
      "15: [D loss: 0.229952, acc: 0.996094]: [A loss: 1.616211, acc: 0.003906]\n",
      "16: [D loss: 0.329435, acc: 0.816406]: [A loss: 2.303061, acc: 0.000000]\n",
      "17: [D loss: 0.193515, acc: 0.994141]: [A loss: 1.748004, acc: 0.000000]\n",
      "18: [D loss: 0.255827, acc: 0.894531]: [A loss: 2.242331, acc: 0.000000]\n",
      "19: [D loss: 0.162708, acc: 0.994141]: [A loss: 2.000895, acc: 0.000000]\n",
      "20: [D loss: 0.214221, acc: 0.935547]: [A loss: 2.417259, acc: 0.000000]\n",
      "21: [D loss: 0.143205, acc: 0.996094]: [A loss: 2.093533, acc: 0.000000]\n",
      "22: [D loss: 0.209296, acc: 0.919922]: [A loss: 2.646472, acc: 0.000000]\n",
      "23: [D loss: 0.135329, acc: 0.988281]: [A loss: 2.042869, acc: 0.015625]\n",
      "24: [D loss: 0.293160, acc: 0.845703]: [A loss: 2.934528, acc: 0.000000]\n",
      "25: [D loss: 0.184044, acc: 0.970703]: [A loss: 1.803026, acc: 0.031250]\n",
      "26: [D loss: 0.350490, acc: 0.802734]: [A loss: 2.785892, acc: 0.000000]\n",
      "27: [D loss: 0.184987, acc: 0.955078]: [A loss: 1.860608, acc: 0.023438]\n",
      "28: [D loss: 0.259388, acc: 0.875000]: [A loss: 2.460236, acc: 0.000000]\n",
      "29: [D loss: 0.138408, acc: 0.982422]: [A loss: 2.183992, acc: 0.011719]\n",
      "30: [D loss: 0.199379, acc: 0.929688]: [A loss: 2.549030, acc: 0.000000]\n",
      "31: [D loss: 0.141288, acc: 0.974609]: [A loss: 2.354323, acc: 0.003906]\n",
      "32: [D loss: 0.182676, acc: 0.935547]: [A loss: 2.667024, acc: 0.007812]\n",
      "33: [D loss: 0.146790, acc: 0.970703]: [A loss: 2.375834, acc: 0.007812]\n",
      "34: [D loss: 0.210676, acc: 0.906250]: [A loss: 3.051568, acc: 0.000000]\n",
      "35: [D loss: 0.150458, acc: 0.968750]: [A loss: 2.160528, acc: 0.019531]\n",
      "36: [D loss: 0.315181, acc: 0.841797]: [A loss: 3.177001, acc: 0.000000]\n",
      "37: [D loss: 0.190105, acc: 0.951172]: [A loss: 1.879238, acc: 0.078125]\n",
      "38: [D loss: 0.362631, acc: 0.796875]: [A loss: 3.016403, acc: 0.000000]\n",
      "39: [D loss: 0.155086, acc: 0.970703]: [A loss: 2.248673, acc: 0.015625]\n",
      "40: [D loss: 0.240754, acc: 0.888672]: [A loss: 2.757345, acc: 0.000000]\n",
      "41: [D loss: 0.141105, acc: 0.962891]: [A loss: 2.497173, acc: 0.019531]\n",
      "42: [D loss: 0.159425, acc: 0.945312]: [A loss: 2.630643, acc: 0.000000]\n",
      "43: [D loss: 0.177940, acc: 0.923828]: [A loss: 2.762230, acc: 0.015625]\n",
      "44: [D loss: 0.182858, acc: 0.941406]: [A loss: 2.634701, acc: 0.019531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45: [D loss: 0.191040, acc: 0.917969]: [A loss: 3.050746, acc: 0.007812]\n",
      "46: [D loss: 0.145881, acc: 0.960938]: [A loss: 2.618855, acc: 0.011719]\n",
      "47: [D loss: 0.221764, acc: 0.888672]: [A loss: 3.237328, acc: 0.000000]\n",
      "48: [D loss: 0.160286, acc: 0.962891]: [A loss: 2.243748, acc: 0.089844]\n",
      "49: [D loss: 0.364757, acc: 0.804688]: [A loss: 3.633828, acc: 0.000000]\n",
      "50: [D loss: 0.218793, acc: 0.933594]: [A loss: 1.933405, acc: 0.101562]\n",
      "51: [D loss: 0.383091, acc: 0.792969]: [A loss: 3.180440, acc: 0.007812]\n",
      "52: [D loss: 0.169719, acc: 0.966797]: [A loss: 2.498710, acc: 0.042969]\n",
      "53: [D loss: 0.205075, acc: 0.908203]: [A loss: 2.831325, acc: 0.011719]\n",
      "54: [D loss: 0.167009, acc: 0.943359]: [A loss: 2.805378, acc: 0.003906]\n",
      "55: [D loss: 0.177703, acc: 0.923828]: [A loss: 2.923305, acc: 0.023438]\n",
      "56: [D loss: 0.137749, acc: 0.972656]: [A loss: 2.924636, acc: 0.027344]\n",
      "57: [D loss: 0.197427, acc: 0.917969]: [A loss: 3.257019, acc: 0.003906]\n",
      "58: [D loss: 0.172878, acc: 0.939453]: [A loss: 2.701957, acc: 0.019531]\n",
      "59: [D loss: 0.249599, acc: 0.865234]: [A loss: 3.481541, acc: 0.000000]\n",
      "60: [D loss: 0.168590, acc: 0.964844]: [A loss: 2.305671, acc: 0.101562]\n",
      "61: [D loss: 0.348487, acc: 0.808594]: [A loss: 3.551773, acc: 0.000000]\n",
      "62: [D loss: 0.208458, acc: 0.947266]: [A loss: 1.977678, acc: 0.187500]\n",
      "63: [D loss: 0.436145, acc: 0.773438]: [A loss: 3.404583, acc: 0.000000]\n",
      "64: [D loss: 0.173959, acc: 0.962891]: [A loss: 2.374396, acc: 0.101562]\n",
      "65: [D loss: 0.267882, acc: 0.857422]: [A loss: 3.072327, acc: 0.007812]\n",
      "66: [D loss: 0.174015, acc: 0.949219]: [A loss: 2.794468, acc: 0.011719]\n",
      "67: [D loss: 0.191211, acc: 0.919922]: [A loss: 3.032982, acc: 0.015625]\n",
      "68: [D loss: 0.174011, acc: 0.945312]: [A loss: 3.049514, acc: 0.015625]\n",
      "69: [D loss: 0.195136, acc: 0.917969]: [A loss: 3.286090, acc: 0.011719]\n",
      "70: [D loss: 0.183691, acc: 0.935547]: [A loss: 3.074197, acc: 0.019531]\n",
      "71: [D loss: 0.225920, acc: 0.884766]: [A loss: 3.593804, acc: 0.007812]\n",
      "72: [D loss: 0.164908, acc: 0.960938]: [A loss: 2.189616, acc: 0.167969]\n",
      "73: [D loss: 0.471111, acc: 0.761719]: [A loss: 4.043414, acc: 0.000000]\n",
      "74: [D loss: 0.257379, acc: 0.902344]: [A loss: 1.936255, acc: 0.250000]\n",
      "75: [D loss: 0.457849, acc: 0.769531]: [A loss: 3.151510, acc: 0.003906]\n",
      "76: [D loss: 0.211411, acc: 0.941406]: [A loss: 2.404984, acc: 0.117188]\n",
      "77: [D loss: 0.239504, acc: 0.869141]: [A loss: 2.984350, acc: 0.015625]\n",
      "78: [D loss: 0.200254, acc: 0.929688]: [A loss: 2.872121, acc: 0.050781]\n",
      "79: [D loss: 0.193921, acc: 0.919922]: [A loss: 3.137154, acc: 0.003906]\n",
      "80: [D loss: 0.186875, acc: 0.925781]: [A loss: 2.837880, acc: 0.058594]\n",
      "81: [D loss: 0.221861, acc: 0.886719]: [A loss: 3.326698, acc: 0.003906]\n",
      "82: [D loss: 0.206323, acc: 0.910156]: [A loss: 3.156632, acc: 0.019531]\n",
      "83: [D loss: 0.184883, acc: 0.919922]: [A loss: 3.248623, acc: 0.019531]\n",
      "84: [D loss: 0.233253, acc: 0.878906]: [A loss: 3.742349, acc: 0.003906]\n",
      "85: [D loss: 0.182196, acc: 0.962891]: [A loss: 2.371845, acc: 0.167969]\n",
      "86: [D loss: 0.421495, acc: 0.789062]: [A loss: 4.174712, acc: 0.000000]\n",
      "87: [D loss: 0.311415, acc: 0.873047]: [A loss: 1.722561, acc: 0.351562]\n",
      "88: [D loss: 0.471357, acc: 0.783203]: [A loss: 3.013679, acc: 0.011719]\n",
      "89: [D loss: 0.219977, acc: 0.908203]: [A loss: 2.823515, acc: 0.039062]\n",
      "90: [D loss: 0.214924, acc: 0.896484]: [A loss: 2.983567, acc: 0.019531]\n",
      "91: [D loss: 0.219187, acc: 0.894531]: [A loss: 2.972711, acc: 0.019531]\n",
      "92: [D loss: 0.219287, acc: 0.904297]: [A loss: 3.006689, acc: 0.019531]\n",
      "93: [D loss: 0.228286, acc: 0.888672]: [A loss: 3.301207, acc: 0.019531]\n",
      "94: [D loss: 0.184405, acc: 0.949219]: [A loss: 2.893106, acc: 0.070312]\n",
      "95: [D loss: 0.290705, acc: 0.837891]: [A loss: 3.813688, acc: 0.000000]\n",
      "96: [D loss: 0.224517, acc: 0.931641]: [A loss: 1.971852, acc: 0.277344]\n",
      "97: [D loss: 0.532265, acc: 0.769531]: [A loss: 3.783924, acc: 0.000000]\n",
      "98: [D loss: 0.258197, acc: 0.919922]: [A loss: 1.986578, acc: 0.277344]\n",
      "99: [D loss: 0.403000, acc: 0.798828]: [A loss: 3.146007, acc: 0.011719]\n",
      "100: [D loss: 0.201980, acc: 0.933594]: [A loss: 2.488044, acc: 0.125000]\n",
      "101: [D loss: 0.315530, acc: 0.822266]: [A loss: 3.156868, acc: 0.039062]\n",
      "102: [D loss: 0.222335, acc: 0.923828]: [A loss: 2.406096, acc: 0.167969]\n",
      "103: [D loss: 0.313970, acc: 0.820312]: [A loss: 3.290156, acc: 0.011719]\n",
      "104: [D loss: 0.237012, acc: 0.906250]: [A loss: 2.607500, acc: 0.097656]\n",
      "105: [D loss: 0.305847, acc: 0.828125]: [A loss: 3.348180, acc: 0.015625]\n",
      "106: [D loss: 0.235726, acc: 0.912109]: [A loss: 2.674891, acc: 0.058594]\n",
      "107: [D loss: 0.359433, acc: 0.775391]: [A loss: 3.862024, acc: 0.011719]\n",
      "108: [D loss: 0.272889, acc: 0.912109]: [A loss: 1.709307, acc: 0.406250]\n",
      "109: [D loss: 0.552306, acc: 0.757812]: [A loss: 3.282080, acc: 0.007812]\n",
      "110: [D loss: 0.268103, acc: 0.892578]: [A loss: 2.414810, acc: 0.113281]\n",
      "111: [D loss: 0.359374, acc: 0.800781]: [A loss: 3.224931, acc: 0.015625]\n",
      "112: [D loss: 0.235171, acc: 0.921875]: [A loss: 2.125069, acc: 0.207031]\n",
      "113: [D loss: 0.393384, acc: 0.791016]: [A loss: 3.286792, acc: 0.003906]\n",
      "114: [D loss: 0.266766, acc: 0.914062]: [A loss: 2.145249, acc: 0.242188]\n",
      "115: [D loss: 0.391141, acc: 0.779297]: [A loss: 3.065570, acc: 0.015625]\n",
      "116: [D loss: 0.252632, acc: 0.925781]: [A loss: 2.333494, acc: 0.148438]\n",
      "117: [D loss: 0.396743, acc: 0.792969]: [A loss: 3.274209, acc: 0.011719]\n",
      "118: [D loss: 0.246506, acc: 0.951172]: [A loss: 2.224952, acc: 0.187500]\n",
      "119: [D loss: 0.425614, acc: 0.777344]: [A loss: 3.449776, acc: 0.003906]\n",
      "120: [D loss: 0.288069, acc: 0.902344]: [A loss: 1.929574, acc: 0.355469]\n",
      "121: [D loss: 0.433523, acc: 0.773438]: [A loss: 3.040139, acc: 0.011719]\n",
      "122: [D loss: 0.285357, acc: 0.886719]: [A loss: 2.106281, acc: 0.226562]\n",
      "123: [D loss: 0.412791, acc: 0.742188]: [A loss: 3.300463, acc: 0.007812]\n",
      "124: [D loss: 0.340431, acc: 0.847656]: [A loss: 2.031154, acc: 0.265625]\n",
      "125: [D loss: 0.372195, acc: 0.771484]: [A loss: 3.035865, acc: 0.003906]\n",
      "126: [D loss: 0.278667, acc: 0.902344]: [A loss: 2.227781, acc: 0.183594]\n",
      "127: [D loss: 0.349566, acc: 0.783203]: [A loss: 3.229740, acc: 0.000000]\n",
      "128: [D loss: 0.273702, acc: 0.902344]: [A loss: 2.172724, acc: 0.250000]\n",
      "129: [D loss: 0.408947, acc: 0.771484]: [A loss: 3.470117, acc: 0.000000]\n",
      "130: [D loss: 0.311680, acc: 0.898438]: [A loss: 1.782454, acc: 0.394531]\n",
      "131: [D loss: 0.501433, acc: 0.746094]: [A loss: 2.961138, acc: 0.003906]\n",
      "132: [D loss: 0.268520, acc: 0.935547]: [A loss: 2.048271, acc: 0.175781]\n",
      "133: [D loss: 0.398462, acc: 0.785156]: [A loss: 2.972844, acc: 0.011719]\n",
      "134: [D loss: 0.260048, acc: 0.929688]: [A loss: 2.098314, acc: 0.207031]\n",
      "135: [D loss: 0.451072, acc: 0.748047]: [A loss: 3.203843, acc: 0.007812]\n",
      "136: [D loss: 0.289974, acc: 0.906250]: [A loss: 1.710281, acc: 0.398438]\n",
      "137: [D loss: 0.483212, acc: 0.775391]: [A loss: 2.903773, acc: 0.011719]\n",
      "138: [D loss: 0.331489, acc: 0.839844]: [A loss: 1.962400, acc: 0.246094]\n",
      "139: [D loss: 0.399842, acc: 0.785156]: [A loss: 2.658155, acc: 0.023438]\n",
      "140: [D loss: 0.298006, acc: 0.884766]: [A loss: 2.185805, acc: 0.140625]\n",
      "141: [D loss: 0.370972, acc: 0.781250]: [A loss: 2.955616, acc: 0.019531]\n",
      "142: [D loss: 0.279726, acc: 0.888672]: [A loss: 2.044653, acc: 0.285156]\n",
      "143: [D loss: 0.395570, acc: 0.767578]: [A loss: 3.143986, acc: 0.011719]\n",
      "144: [D loss: 0.312944, acc: 0.886719]: [A loss: 2.015150, acc: 0.273438]\n",
      "145: [D loss: 0.457085, acc: 0.759766]: [A loss: 3.214966, acc: 0.000000]\n",
      "146: [D loss: 0.321516, acc: 0.886719]: [A loss: 1.957368, acc: 0.253906]\n",
      "147: [D loss: 0.363471, acc: 0.792969]: [A loss: 2.922455, acc: 0.015625]\n",
      "148: [D loss: 0.325311, acc: 0.843750]: [A loss: 2.095866, acc: 0.273438]\n",
      "149: [D loss: 0.333404, acc: 0.787109]: [A loss: 3.068955, acc: 0.019531]\n",
      "150: [D loss: 0.334234, acc: 0.826172]: [A loss: 2.519719, acc: 0.109375]\n",
      "151: [D loss: 0.268199, acc: 0.871094]: [A loss: 2.669940, acc: 0.050781]\n",
      "152: [D loss: 0.391731, acc: 0.794922]: [A loss: 3.158788, acc: 0.019531]\n",
      "153: [D loss: 0.297085, acc: 0.914062]: [A loss: 1.808357, acc: 0.343750]\n",
      "154: [D loss: 0.563859, acc: 0.726562]: [A loss: 3.853246, acc: 0.000000]\n",
      "155: [D loss: 0.412560, acc: 0.814453]: [A loss: 1.363181, acc: 0.503906]\n",
      "156: [D loss: 0.615139, acc: 0.701172]: [A loss: 2.681863, acc: 0.007812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157: [D loss: 0.329564, acc: 0.878906]: [A loss: 1.806152, acc: 0.308594]\n",
      "158: [D loss: 0.392298, acc: 0.769531]: [A loss: 2.462632, acc: 0.054688]\n",
      "159: [D loss: 0.336219, acc: 0.818359]: [A loss: 2.189805, acc: 0.062500]\n",
      "160: [D loss: 0.379840, acc: 0.773438]: [A loss: 2.583929, acc: 0.031250]\n",
      "161: [D loss: 0.312745, acc: 0.855469]: [A loss: 2.357210, acc: 0.074219]\n",
      "162: [D loss: 0.403998, acc: 0.769531]: [A loss: 2.884290, acc: 0.031250]\n",
      "163: [D loss: 0.281996, acc: 0.929688]: [A loss: 1.789711, acc: 0.296875]\n",
      "164: [D loss: 0.543694, acc: 0.712891]: [A loss: 3.451839, acc: 0.003906]\n",
      "165: [D loss: 0.416533, acc: 0.832031]: [A loss: 1.216222, acc: 0.531250]\n",
      "166: [D loss: 0.632195, acc: 0.714844]: [A loss: 2.465833, acc: 0.039062]\n",
      "167: [D loss: 0.356450, acc: 0.818359]: [A loss: 2.062494, acc: 0.117188]\n",
      "168: [D loss: 0.376227, acc: 0.775391]: [A loss: 2.355415, acc: 0.042969]\n",
      "169: [D loss: 0.377977, acc: 0.802734]: [A loss: 2.336967, acc: 0.101562]\n",
      "170: [D loss: 0.274617, acc: 0.869141]: [A loss: 2.173501, acc: 0.132812]\n",
      "171: [D loss: 0.417000, acc: 0.759766]: [A loss: 3.016516, acc: 0.035156]\n",
      "172: [D loss: 0.309762, acc: 0.902344]: [A loss: 1.794083, acc: 0.300781]\n",
      "173: [D loss: 0.519861, acc: 0.748047]: [A loss: 3.247401, acc: 0.000000]\n",
      "174: [D loss: 0.340760, acc: 0.888672]: [A loss: 1.646958, acc: 0.328125]\n",
      "175: [D loss: 0.511835, acc: 0.742188]: [A loss: 2.923362, acc: 0.007812]\n",
      "176: [D loss: 0.342056, acc: 0.876953]: [A loss: 1.713552, acc: 0.355469]\n",
      "177: [D loss: 0.414240, acc: 0.753906]: [A loss: 2.948765, acc: 0.023438]\n",
      "178: [D loss: 0.346452, acc: 0.847656]: [A loss: 1.977692, acc: 0.191406]\n",
      "179: [D loss: 0.348110, acc: 0.792969]: [A loss: 2.757656, acc: 0.042969]\n",
      "180: [D loss: 0.324383, acc: 0.855469]: [A loss: 2.017303, acc: 0.230469]\n",
      "181: [D loss: 0.328141, acc: 0.820312]: [A loss: 2.912573, acc: 0.007812]\n",
      "182: [D loss: 0.359231, acc: 0.830078]: [A loss: 2.402184, acc: 0.082031]\n",
      "183: [D loss: 0.290855, acc: 0.853516]: [A loss: 2.747769, acc: 0.023438]\n",
      "184: [D loss: 0.395694, acc: 0.792969]: [A loss: 3.073244, acc: 0.023438]\n",
      "185: [D loss: 0.298356, acc: 0.904297]: [A loss: 1.542889, acc: 0.414062]\n",
      "186: [D loss: 0.655907, acc: 0.681641]: [A loss: 4.189281, acc: 0.000000]\n",
      "187: [D loss: 0.488371, acc: 0.751953]: [A loss: 1.253330, acc: 0.500000]\n",
      "188: [D loss: 0.524805, acc: 0.751953]: [A loss: 2.114884, acc: 0.128906]\n",
      "189: [D loss: 0.367185, acc: 0.792969]: [A loss: 2.360877, acc: 0.074219]\n",
      "190: [D loss: 0.325437, acc: 0.849609]: [A loss: 2.228011, acc: 0.097656]\n",
      "191: [D loss: 0.377549, acc: 0.771484]: [A loss: 2.440214, acc: 0.046875]\n",
      "192: [D loss: 0.306882, acc: 0.867188]: [A loss: 2.033596, acc: 0.171875]\n",
      "193: [D loss: 0.411660, acc: 0.769531]: [A loss: 2.807681, acc: 0.031250]\n",
      "194: [D loss: 0.317322, acc: 0.875000]: [A loss: 2.111344, acc: 0.117188]\n",
      "195: [D loss: 0.451868, acc: 0.718750]: [A loss: 3.192304, acc: 0.003906]\n",
      "196: [D loss: 0.352372, acc: 0.869141]: [A loss: 1.334027, acc: 0.500000]\n",
      "197: [D loss: 0.546572, acc: 0.726562]: [A loss: 2.977853, acc: 0.023438]\n",
      "198: [D loss: 0.369714, acc: 0.837891]: [A loss: 1.688266, acc: 0.367188]\n",
      "199: [D loss: 0.372269, acc: 0.759766]: [A loss: 2.644557, acc: 0.023438]\n",
      "200: [D loss: 0.380625, acc: 0.791016]: [A loss: 2.308212, acc: 0.078125]\n",
      "201: [D loss: 0.310450, acc: 0.859375]: [A loss: 2.108307, acc: 0.132812]\n",
      "202: [D loss: 0.487665, acc: 0.734375]: [A loss: 2.960217, acc: 0.003906]\n",
      "203: [D loss: 0.345255, acc: 0.882812]: [A loss: 1.647643, acc: 0.367188]\n",
      "204: [D loss: 0.458884, acc: 0.724609]: [A loss: 3.119813, acc: 0.000000]\n",
      "205: [D loss: 0.373919, acc: 0.859375]: [A loss: 1.511528, acc: 0.433594]\n",
      "206: [D loss: 0.531312, acc: 0.707031]: [A loss: 3.301234, acc: 0.000000]\n",
      "207: [D loss: 0.380290, acc: 0.830078]: [A loss: 1.247989, acc: 0.503906]\n",
      "208: [D loss: 0.593471, acc: 0.703125]: [A loss: 2.752065, acc: 0.003906]\n",
      "209: [D loss: 0.346132, acc: 0.867188]: [A loss: 1.497575, acc: 0.378906]\n",
      "210: [D loss: 0.462341, acc: 0.712891]: [A loss: 2.500938, acc: 0.046875]\n",
      "211: [D loss: 0.374817, acc: 0.814453]: [A loss: 2.014338, acc: 0.140625]\n",
      "212: [D loss: 0.346622, acc: 0.812500]: [A loss: 2.341569, acc: 0.070312]\n",
      "213: [D loss: 0.384363, acc: 0.812500]: [A loss: 2.580155, acc: 0.050781]\n",
      "214: [D loss: 0.291363, acc: 0.927734]: [A loss: 2.103364, acc: 0.156250]\n",
      "215: [D loss: 0.464005, acc: 0.759766]: [A loss: 3.316682, acc: 0.011719]\n",
      "216: [D loss: 0.362551, acc: 0.865234]: [A loss: 1.214637, acc: 0.531250]\n",
      "217: [D loss: 0.621911, acc: 0.701172]: [A loss: 3.112527, acc: 0.003906]\n",
      "218: [D loss: 0.410448, acc: 0.832031]: [A loss: 1.450890, acc: 0.421875]\n",
      "219: [D loss: 0.485978, acc: 0.718750]: [A loss: 2.630582, acc: 0.019531]\n",
      "220: [D loss: 0.347802, acc: 0.853516]: [A loss: 1.797453, acc: 0.242188]\n",
      "221: [D loss: 0.401927, acc: 0.763672]: [A loss: 2.551145, acc: 0.042969]\n",
      "222: [D loss: 0.404222, acc: 0.783203]: [A loss: 2.223653, acc: 0.105469]\n",
      "223: [D loss: 0.349974, acc: 0.822266]: [A loss: 2.258608, acc: 0.058594]\n",
      "224: [D loss: 0.417812, acc: 0.771484]: [A loss: 2.855983, acc: 0.031250]\n",
      "225: [D loss: 0.318114, acc: 0.902344]: [A loss: 1.556156, acc: 0.378906]\n",
      "226: [D loss: 0.530097, acc: 0.728516]: [A loss: 3.432250, acc: 0.007812]\n",
      "227: [D loss: 0.380447, acc: 0.835938]: [A loss: 1.142370, acc: 0.554688]\n",
      "228: [D loss: 0.663426, acc: 0.707031]: [A loss: 2.745021, acc: 0.003906]\n",
      "229: [D loss: 0.386591, acc: 0.826172]: [A loss: 1.557501, acc: 0.316406]\n",
      "230: [D loss: 0.420962, acc: 0.750000]: [A loss: 2.556251, acc: 0.027344]\n",
      "231: [D loss: 0.380709, acc: 0.824219]: [A loss: 1.911007, acc: 0.195312]\n",
      "232: [D loss: 0.389896, acc: 0.775391]: [A loss: 2.454091, acc: 0.039062]\n",
      "233: [D loss: 0.417235, acc: 0.779297]: [A loss: 2.706703, acc: 0.035156]\n",
      "234: [D loss: 0.310260, acc: 0.900391]: [A loss: 1.707635, acc: 0.316406]\n",
      "235: [D loss: 0.511245, acc: 0.724609]: [A loss: 3.454923, acc: 0.007812]\n",
      "236: [D loss: 0.426382, acc: 0.826172]: [A loss: 1.064110, acc: 0.589844]\n",
      "237: [D loss: 0.654278, acc: 0.707031]: [A loss: 2.722285, acc: 0.027344]\n",
      "238: [D loss: 0.371919, acc: 0.841797]: [A loss: 1.567435, acc: 0.281250]\n",
      "239: [D loss: 0.492895, acc: 0.734375]: [A loss: 2.814032, acc: 0.007812]\n",
      "240: [D loss: 0.357351, acc: 0.849609]: [A loss: 1.543170, acc: 0.308594]\n",
      "241: [D loss: 0.480575, acc: 0.705078]: [A loss: 2.710375, acc: 0.011719]\n",
      "242: [D loss: 0.368430, acc: 0.857422]: [A loss: 1.476459, acc: 0.339844]\n",
      "243: [D loss: 0.470624, acc: 0.732422]: [A loss: 2.824666, acc: 0.023438]\n",
      "244: [D loss: 0.328750, acc: 0.890625]: [A loss: 1.713436, acc: 0.289062]\n",
      "245: [D loss: 0.486224, acc: 0.744141]: [A loss: 3.211914, acc: 0.011719]\n",
      "246: [D loss: 0.338489, acc: 0.880859]: [A loss: 1.275840, acc: 0.464844]\n",
      "247: [D loss: 0.594886, acc: 0.734375]: [A loss: 2.603385, acc: 0.007812]\n",
      "248: [D loss: 0.356254, acc: 0.857422]: [A loss: 1.773934, acc: 0.214844]\n",
      "249: [D loss: 0.401159, acc: 0.759766]: [A loss: 2.616570, acc: 0.015625]\n",
      "250: [D loss: 0.375573, acc: 0.843750]: [A loss: 1.729441, acc: 0.246094]\n",
      "251: [D loss: 0.455793, acc: 0.724609]: [A loss: 2.927764, acc: 0.031250]\n",
      "252: [D loss: 0.358781, acc: 0.833984]: [A loss: 1.456159, acc: 0.375000]\n",
      "253: [D loss: 0.470635, acc: 0.732422]: [A loss: 2.949198, acc: 0.003906]\n",
      "254: [D loss: 0.402621, acc: 0.806641]: [A loss: 1.685598, acc: 0.292969]\n",
      "255: [D loss: 0.408540, acc: 0.746094]: [A loss: 2.939323, acc: 0.011719]\n",
      "256: [D loss: 0.394698, acc: 0.806641]: [A loss: 1.662693, acc: 0.339844]\n",
      "257: [D loss: 0.427382, acc: 0.746094]: [A loss: 3.251380, acc: 0.000000]\n",
      "258: [D loss: 0.387597, acc: 0.839844]: [A loss: 1.394696, acc: 0.433594]\n",
      "259: [D loss: 0.509296, acc: 0.712891]: [A loss: 3.476954, acc: 0.000000]\n",
      "260: [D loss: 0.372047, acc: 0.855469]: [A loss: 1.143008, acc: 0.546875]\n",
      "261: [D loss: 0.614225, acc: 0.695312]: [A loss: 2.887627, acc: 0.031250]\n",
      "262: [D loss: 0.352755, acc: 0.857422]: [A loss: 1.453991, acc: 0.402344]\n",
      "263: [D loss: 0.550471, acc: 0.720703]: [A loss: 2.731081, acc: 0.011719]\n",
      "264: [D loss: 0.372965, acc: 0.861328]: [A loss: 1.425494, acc: 0.324219]\n",
      "265: [D loss: 0.546468, acc: 0.677734]: [A loss: 3.219789, acc: 0.011719]\n",
      "266: [D loss: 0.373095, acc: 0.863281]: [A loss: 1.222801, acc: 0.468750]\n",
      "267: [D loss: 0.664835, acc: 0.662109]: [A loss: 2.851940, acc: 0.019531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268: [D loss: 0.401730, acc: 0.833984]: [A loss: 1.223134, acc: 0.457031]\n",
      "269: [D loss: 0.565689, acc: 0.666016]: [A loss: 2.644583, acc: 0.007812]\n",
      "270: [D loss: 0.415053, acc: 0.798828]: [A loss: 1.411076, acc: 0.316406]\n",
      "271: [D loss: 0.514763, acc: 0.705078]: [A loss: 2.338082, acc: 0.035156]\n",
      "272: [D loss: 0.391764, acc: 0.828125]: [A loss: 1.573618, acc: 0.214844]\n",
      "273: [D loss: 0.450983, acc: 0.750000]: [A loss: 2.395576, acc: 0.035156]\n",
      "274: [D loss: 0.383724, acc: 0.830078]: [A loss: 2.130756, acc: 0.078125]\n",
      "275: [D loss: 0.382386, acc: 0.810547]: [A loss: 2.145676, acc: 0.085938]\n",
      "276: [D loss: 0.478005, acc: 0.728516]: [A loss: 2.871481, acc: 0.007812]\n",
      "277: [D loss: 0.318734, acc: 0.916016]: [A loss: 1.472458, acc: 0.324219]\n",
      "278: [D loss: 0.621734, acc: 0.705078]: [A loss: 3.584842, acc: 0.003906]\n",
      "279: [D loss: 0.427653, acc: 0.812500]: [A loss: 1.158841, acc: 0.539062]\n",
      "280: [D loss: 0.606128, acc: 0.671875]: [A loss: 2.849263, acc: 0.019531]\n",
      "281: [D loss: 0.368449, acc: 0.865234]: [A loss: 1.300714, acc: 0.398438]\n",
      "282: [D loss: 0.544814, acc: 0.703125]: [A loss: 2.819947, acc: 0.031250]\n",
      "283: [D loss: 0.363679, acc: 0.859375]: [A loss: 1.463340, acc: 0.335938]\n",
      "284: [D loss: 0.535646, acc: 0.710938]: [A loss: 2.692594, acc: 0.015625]\n",
      "285: [D loss: 0.364294, acc: 0.861328]: [A loss: 1.617622, acc: 0.253906]\n",
      "286: [D loss: 0.514727, acc: 0.714844]: [A loss: 2.904877, acc: 0.031250]\n",
      "287: [D loss: 0.389338, acc: 0.851562]: [A loss: 1.217001, acc: 0.507812]\n",
      "288: [D loss: 0.591420, acc: 0.671875]: [A loss: 3.172879, acc: 0.039062]\n",
      "289: [D loss: 0.402955, acc: 0.802734]: [A loss: 1.313210, acc: 0.445312]\n",
      "290: [D loss: 0.501019, acc: 0.722656]: [A loss: 2.549021, acc: 0.023438]\n",
      "291: [D loss: 0.426434, acc: 0.794922]: [A loss: 1.872136, acc: 0.152344]\n",
      "292: [D loss: 0.421632, acc: 0.783203]: [A loss: 2.568874, acc: 0.003906]\n",
      "293: [D loss: 0.429748, acc: 0.812500]: [A loss: 2.078035, acc: 0.164062]\n",
      "294: [D loss: 0.368493, acc: 0.833984]: [A loss: 2.450856, acc: 0.039062]\n",
      "295: [D loss: 0.445714, acc: 0.779297]: [A loss: 2.932532, acc: 0.007812]\n",
      "296: [D loss: 0.367479, acc: 0.857422]: [A loss: 1.584906, acc: 0.273438]\n",
      "297: [D loss: 0.538266, acc: 0.722656]: [A loss: 3.788688, acc: 0.007812]\n",
      "298: [D loss: 0.401097, acc: 0.822266]: [A loss: 0.959736, acc: 0.574219]\n",
      "299: [D loss: 0.791920, acc: 0.634766]: [A loss: 3.159779, acc: 0.011719]\n",
      "300: [D loss: 0.438237, acc: 0.796875]: [A loss: 1.117288, acc: 0.492188]\n",
      "301: [D loss: 0.626881, acc: 0.656250]: [A loss: 2.723761, acc: 0.015625]\n",
      "302: [D loss: 0.394036, acc: 0.833984]: [A loss: 1.529698, acc: 0.210938]\n",
      "303: [D loss: 0.471060, acc: 0.734375]: [A loss: 2.549740, acc: 0.042969]\n",
      "304: [D loss: 0.369893, acc: 0.847656]: [A loss: 1.724489, acc: 0.187500]\n",
      "305: [D loss: 0.485799, acc: 0.750000]: [A loss: 2.508208, acc: 0.015625]\n",
      "306: [D loss: 0.399032, acc: 0.841797]: [A loss: 1.579824, acc: 0.183594]\n",
      "307: [D loss: 0.515886, acc: 0.722656]: [A loss: 3.249037, acc: 0.011719]\n",
      "308: [D loss: 0.376198, acc: 0.867188]: [A loss: 1.138228, acc: 0.371094]\n",
      "309: [D loss: 0.672010, acc: 0.667969]: [A loss: 3.595770, acc: 0.011719]\n",
      "310: [D loss: 0.353476, acc: 0.876953]: [A loss: 1.033896, acc: 0.375000]\n",
      "311: [D loss: 0.765357, acc: 0.664062]: [A loss: 3.314321, acc: 0.015625]\n",
      "312: [D loss: 0.384123, acc: 0.847656]: [A loss: 1.253390, acc: 0.304688]\n",
      "313: [D loss: 0.552425, acc: 0.685547]: [A loss: 2.658781, acc: 0.039062]\n",
      "314: [D loss: 0.364994, acc: 0.832031]: [A loss: 1.551496, acc: 0.148438]\n",
      "315: [D loss: 0.531803, acc: 0.720703]: [A loss: 2.810667, acc: 0.019531]\n",
      "316: [D loss: 0.375733, acc: 0.857422]: [A loss: 1.304231, acc: 0.277344]\n",
      "317: [D loss: 0.481043, acc: 0.753906]: [A loss: 2.867594, acc: 0.027344]\n",
      "318: [D loss: 0.379196, acc: 0.837891]: [A loss: 1.462193, acc: 0.218750]\n",
      "319: [D loss: 0.522644, acc: 0.710938]: [A loss: 3.069625, acc: 0.003906]\n",
      "320: [D loss: 0.364516, acc: 0.859375]: [A loss: 1.317304, acc: 0.300781]\n",
      "321: [D loss: 0.476357, acc: 0.732422]: [A loss: 3.083388, acc: 0.011719]\n",
      "322: [D loss: 0.381590, acc: 0.816406]: [A loss: 1.443497, acc: 0.218750]\n",
      "323: [D loss: 0.455114, acc: 0.761719]: [A loss: 2.723520, acc: 0.003906]\n",
      "324: [D loss: 0.432919, acc: 0.824219]: [A loss: 1.419681, acc: 0.207031]\n",
      "325: [D loss: 0.443115, acc: 0.759766]: [A loss: 3.245347, acc: 0.003906]\n",
      "326: [D loss: 0.413237, acc: 0.802734]: [A loss: 1.184766, acc: 0.347656]\n",
      "327: [D loss: 0.569905, acc: 0.673828]: [A loss: 3.308063, acc: 0.003906]\n",
      "328: [D loss: 0.417465, acc: 0.839844]: [A loss: 0.944108, acc: 0.402344]\n",
      "329: [D loss: 0.661692, acc: 0.662109]: [A loss: 3.426816, acc: 0.003906]\n",
      "330: [D loss: 0.419849, acc: 0.849609]: [A loss: 0.866215, acc: 0.414062]\n",
      "331: [D loss: 0.678713, acc: 0.644531]: [A loss: 3.077434, acc: 0.003906]\n",
      "332: [D loss: 0.431253, acc: 0.824219]: [A loss: 1.012617, acc: 0.378906]\n",
      "333: [D loss: 0.649270, acc: 0.634766]: [A loss: 2.641212, acc: 0.003906]\n",
      "334: [D loss: 0.394746, acc: 0.853516]: [A loss: 1.102797, acc: 0.324219]\n",
      "335: [D loss: 0.600496, acc: 0.662109]: [A loss: 2.941521, acc: 0.003906]\n",
      "336: [D loss: 0.429951, acc: 0.802734]: [A loss: 1.154685, acc: 0.347656]\n",
      "337: [D loss: 0.559379, acc: 0.683594]: [A loss: 2.722054, acc: 0.000000]\n",
      "338: [D loss: 0.409859, acc: 0.824219]: [A loss: 1.427149, acc: 0.183594]\n",
      "339: [D loss: 0.553224, acc: 0.683594]: [A loss: 2.891773, acc: 0.003906]\n",
      "340: [D loss: 0.449865, acc: 0.826172]: [A loss: 1.006434, acc: 0.382812]\n",
      "341: [D loss: 0.596687, acc: 0.650391]: [A loss: 2.803739, acc: 0.011719]\n",
      "342: [D loss: 0.426651, acc: 0.835938]: [A loss: 0.974002, acc: 0.335938]\n",
      "343: [D loss: 0.646642, acc: 0.623047]: [A loss: 2.738488, acc: 0.007812]\n",
      "344: [D loss: 0.420741, acc: 0.832031]: [A loss: 0.930432, acc: 0.394531]\n",
      "345: [D loss: 0.695436, acc: 0.621094]: [A loss: 3.049654, acc: 0.000000]\n",
      "346: [D loss: 0.503346, acc: 0.773438]: [A loss: 0.888083, acc: 0.441406]\n",
      "347: [D loss: 0.701179, acc: 0.591797]: [A loss: 2.703171, acc: 0.003906]\n",
      "348: [D loss: 0.476536, acc: 0.796875]: [A loss: 0.941111, acc: 0.375000]\n",
      "349: [D loss: 0.665340, acc: 0.625000]: [A loss: 2.573012, acc: 0.007812]\n",
      "350: [D loss: 0.440785, acc: 0.833984]: [A loss: 1.099188, acc: 0.246094]\n",
      "351: [D loss: 0.630499, acc: 0.626953]: [A loss: 2.702058, acc: 0.000000]\n",
      "352: [D loss: 0.460817, acc: 0.802734]: [A loss: 1.017245, acc: 0.292969]\n",
      "353: [D loss: 0.733315, acc: 0.593750]: [A loss: 2.839773, acc: 0.000000]\n",
      "354: [D loss: 0.486523, acc: 0.789062]: [A loss: 0.844207, acc: 0.480469]\n",
      "355: [D loss: 0.680085, acc: 0.574219]: [A loss: 2.909789, acc: 0.003906]\n",
      "356: [D loss: 0.438791, acc: 0.832031]: [A loss: 1.013131, acc: 0.332031]\n",
      "357: [D loss: 0.680630, acc: 0.564453]: [A loss: 2.705622, acc: 0.003906]\n",
      "358: [D loss: 0.502869, acc: 0.761719]: [A loss: 0.922569, acc: 0.441406]\n",
      "359: [D loss: 0.616584, acc: 0.576172]: [A loss: 2.391790, acc: 0.000000]\n",
      "360: [D loss: 0.471480, acc: 0.779297]: [A loss: 1.362214, acc: 0.191406]\n",
      "361: [D loss: 0.545574, acc: 0.681641]: [A loss: 2.327233, acc: 0.003906]\n",
      "362: [D loss: 0.459701, acc: 0.810547]: [A loss: 1.263618, acc: 0.203125]\n",
      "363: [D loss: 0.592377, acc: 0.640625]: [A loss: 2.751163, acc: 0.000000]\n",
      "364: [D loss: 0.485437, acc: 0.775391]: [A loss: 0.961950, acc: 0.386719]\n",
      "365: [D loss: 0.666219, acc: 0.562500]: [A loss: 3.063298, acc: 0.000000]\n",
      "366: [D loss: 0.519601, acc: 0.750000]: [A loss: 0.695833, acc: 0.585938]\n",
      "367: [D loss: 0.761116, acc: 0.539062]: [A loss: 2.697215, acc: 0.000000]\n",
      "368: [D loss: 0.506936, acc: 0.787109]: [A loss: 0.749979, acc: 0.531250]\n",
      "369: [D loss: 0.703486, acc: 0.548828]: [A loss: 2.431126, acc: 0.003906]\n",
      "370: [D loss: 0.500829, acc: 0.781250]: [A loss: 0.838964, acc: 0.464844]\n",
      "371: [D loss: 0.654027, acc: 0.566406]: [A loss: 2.431962, acc: 0.003906]\n",
      "372: [D loss: 0.497057, acc: 0.759766]: [A loss: 1.027433, acc: 0.289062]\n",
      "373: [D loss: 0.672592, acc: 0.580078]: [A loss: 2.573990, acc: 0.000000]\n",
      "374: [D loss: 0.497128, acc: 0.777344]: [A loss: 0.942962, acc: 0.355469]\n",
      "375: [D loss: 0.630825, acc: 0.580078]: [A loss: 2.588354, acc: 0.003906]\n",
      "376: [D loss: 0.506222, acc: 0.751953]: [A loss: 0.962753, acc: 0.382812]\n",
      "377: [D loss: 0.660110, acc: 0.580078]: [A loss: 2.427360, acc: 0.003906]\n",
      "378: [D loss: 0.529087, acc: 0.775391]: [A loss: 0.923167, acc: 0.324219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379: [D loss: 0.648601, acc: 0.591797]: [A loss: 2.361754, acc: 0.003906]\n",
      "380: [D loss: 0.478168, acc: 0.800781]: [A loss: 1.030878, acc: 0.296875]\n",
      "381: [D loss: 0.627175, acc: 0.609375]: [A loss: 2.416614, acc: 0.003906]\n",
      "382: [D loss: 0.486995, acc: 0.796875]: [A loss: 0.916796, acc: 0.414062]\n",
      "383: [D loss: 0.682953, acc: 0.576172]: [A loss: 2.752622, acc: 0.000000]\n",
      "384: [D loss: 0.512304, acc: 0.804688]: [A loss: 0.672862, acc: 0.621094]\n",
      "385: [D loss: 0.846507, acc: 0.517578]: [A loss: 2.572353, acc: 0.007812]\n",
      "386: [D loss: 0.513346, acc: 0.761719]: [A loss: 0.720475, acc: 0.515625]\n",
      "387: [D loss: 0.674021, acc: 0.570312]: [A loss: 2.240123, acc: 0.011719]\n",
      "388: [D loss: 0.532320, acc: 0.746094]: [A loss: 1.004486, acc: 0.324219]\n",
      "389: [D loss: 0.645579, acc: 0.576172]: [A loss: 2.370641, acc: 0.000000]\n",
      "390: [D loss: 0.505463, acc: 0.775391]: [A loss: 1.101382, acc: 0.222656]\n",
      "391: [D loss: 0.619750, acc: 0.574219]: [A loss: 2.193468, acc: 0.000000]\n",
      "392: [D loss: 0.497678, acc: 0.757812]: [A loss: 1.204312, acc: 0.199219]\n",
      "393: [D loss: 0.600809, acc: 0.638672]: [A loss: 2.133613, acc: 0.003906]\n",
      "394: [D loss: 0.527463, acc: 0.751953]: [A loss: 1.071471, acc: 0.292969]\n",
      "395: [D loss: 0.615167, acc: 0.611328]: [A loss: 2.454749, acc: 0.000000]\n",
      "396: [D loss: 0.516676, acc: 0.744141]: [A loss: 0.883240, acc: 0.410156]\n",
      "397: [D loss: 0.674918, acc: 0.562500]: [A loss: 2.530220, acc: 0.000000]\n",
      "398: [D loss: 0.504912, acc: 0.767578]: [A loss: 0.719975, acc: 0.542969]\n",
      "399: [D loss: 0.735248, acc: 0.556641]: [A loss: 2.857748, acc: 0.000000]\n",
      "400: [D loss: 0.563593, acc: 0.703125]: [A loss: 0.579348, acc: 0.734375]\n",
      "401: [D loss: 0.870851, acc: 0.517578]: [A loss: 2.461365, acc: 0.000000]\n",
      "402: [D loss: 0.538561, acc: 0.746094]: [A loss: 0.723325, acc: 0.578125]\n",
      "403: [D loss: 0.711624, acc: 0.525391]: [A loss: 2.037580, acc: 0.003906]\n",
      "404: [D loss: 0.533331, acc: 0.732422]: [A loss: 0.986089, acc: 0.296875]\n",
      "405: [D loss: 0.664574, acc: 0.570312]: [A loss: 2.042039, acc: 0.007812]\n",
      "406: [D loss: 0.549165, acc: 0.744141]: [A loss: 1.019177, acc: 0.218750]\n",
      "407: [D loss: 0.662204, acc: 0.578125]: [A loss: 2.211644, acc: 0.011719]\n",
      "408: [D loss: 0.500431, acc: 0.773438]: [A loss: 1.117904, acc: 0.199219]\n",
      "409: [D loss: 0.600110, acc: 0.619141]: [A loss: 2.166107, acc: 0.000000]\n",
      "410: [D loss: 0.520611, acc: 0.767578]: [A loss: 0.890588, acc: 0.355469]\n",
      "411: [D loss: 0.687685, acc: 0.587891]: [A loss: 2.614955, acc: 0.000000]\n",
      "412: [D loss: 0.541320, acc: 0.738281]: [A loss: 0.626282, acc: 0.687500]\n",
      "413: [D loss: 0.776362, acc: 0.529297]: [A loss: 2.349362, acc: 0.003906]\n",
      "414: [D loss: 0.520409, acc: 0.755859]: [A loss: 0.750602, acc: 0.496094]\n",
      "415: [D loss: 0.759584, acc: 0.535156]: [A loss: 2.178500, acc: 0.003906]\n",
      "416: [D loss: 0.529231, acc: 0.763672]: [A loss: 0.901193, acc: 0.363281]\n",
      "417: [D loss: 0.678227, acc: 0.568359]: [A loss: 2.235552, acc: 0.007812]\n",
      "418: [D loss: 0.552986, acc: 0.722656]: [A loss: 0.827303, acc: 0.429688]\n",
      "419: [D loss: 0.650924, acc: 0.580078]: [A loss: 1.986630, acc: 0.003906]\n",
      "420: [D loss: 0.547458, acc: 0.732422]: [A loss: 0.934134, acc: 0.335938]\n",
      "421: [D loss: 0.624102, acc: 0.591797]: [A loss: 2.108099, acc: 0.015625]\n",
      "422: [D loss: 0.519289, acc: 0.759766]: [A loss: 1.059372, acc: 0.257812]\n",
      "423: [D loss: 0.638055, acc: 0.609375]: [A loss: 2.236994, acc: 0.007812]\n",
      "424: [D loss: 0.555131, acc: 0.718750]: [A loss: 0.857747, acc: 0.429688]\n",
      "425: [D loss: 0.655693, acc: 0.570312]: [A loss: 2.352162, acc: 0.000000]\n",
      "426: [D loss: 0.539448, acc: 0.720703]: [A loss: 0.740277, acc: 0.511719]\n",
      "427: [D loss: 0.687726, acc: 0.564453]: [A loss: 2.292774, acc: 0.003906]\n",
      "428: [D loss: 0.548584, acc: 0.726562]: [A loss: 0.675394, acc: 0.597656]\n",
      "429: [D loss: 0.702523, acc: 0.576172]: [A loss: 2.146725, acc: 0.000000]\n",
      "430: [D loss: 0.506318, acc: 0.775391]: [A loss: 0.801055, acc: 0.496094]\n",
      "431: [D loss: 0.705239, acc: 0.570312]: [A loss: 2.290881, acc: 0.011719]\n",
      "432: [D loss: 0.509399, acc: 0.787109]: [A loss: 0.861602, acc: 0.425781]\n",
      "433: [D loss: 0.698654, acc: 0.566406]: [A loss: 2.130344, acc: 0.003906]\n",
      "434: [D loss: 0.533659, acc: 0.746094]: [A loss: 0.871969, acc: 0.367188]\n",
      "435: [D loss: 0.679289, acc: 0.580078]: [A loss: 2.005780, acc: 0.003906]\n",
      "436: [D loss: 0.537426, acc: 0.753906]: [A loss: 0.888584, acc: 0.343750]\n",
      "437: [D loss: 0.664291, acc: 0.580078]: [A loss: 2.199186, acc: 0.011719]\n",
      "438: [D loss: 0.541439, acc: 0.763672]: [A loss: 0.932231, acc: 0.332031]\n",
      "439: [D loss: 0.658334, acc: 0.595703]: [A loss: 2.233290, acc: 0.000000]\n",
      "440: [D loss: 0.556707, acc: 0.732422]: [A loss: 0.792460, acc: 0.433594]\n",
      "441: [D loss: 0.683269, acc: 0.537109]: [A loss: 2.345324, acc: 0.000000]\n",
      "442: [D loss: 0.529948, acc: 0.767578]: [A loss: 0.720524, acc: 0.554688]\n",
      "443: [D loss: 0.716195, acc: 0.525391]: [A loss: 2.027959, acc: 0.000000]\n",
      "444: [D loss: 0.563311, acc: 0.742188]: [A loss: 0.767518, acc: 0.492188]\n",
      "445: [D loss: 0.673934, acc: 0.548828]: [A loss: 2.113221, acc: 0.015625]\n",
      "446: [D loss: 0.577756, acc: 0.734375]: [A loss: 0.749839, acc: 0.464844]\n",
      "447: [D loss: 0.671162, acc: 0.539062]: [A loss: 2.148130, acc: 0.003906]\n",
      "448: [D loss: 0.562452, acc: 0.714844]: [A loss: 0.677663, acc: 0.566406]\n",
      "449: [D loss: 0.711305, acc: 0.550781]: [A loss: 2.053007, acc: 0.000000]\n",
      "450: [D loss: 0.593499, acc: 0.699219]: [A loss: 0.779290, acc: 0.441406]\n",
      "451: [D loss: 0.706326, acc: 0.574219]: [A loss: 2.140133, acc: 0.003906]\n",
      "452: [D loss: 0.529887, acc: 0.757812]: [A loss: 0.820266, acc: 0.406250]\n",
      "453: [D loss: 0.698219, acc: 0.560547]: [A loss: 2.104417, acc: 0.003906]\n",
      "454: [D loss: 0.554119, acc: 0.742188]: [A loss: 0.779441, acc: 0.468750]\n",
      "455: [D loss: 0.711010, acc: 0.541016]: [A loss: 1.966592, acc: 0.000000]\n",
      "456: [D loss: 0.574183, acc: 0.707031]: [A loss: 0.689372, acc: 0.578125]\n",
      "457: [D loss: 0.694675, acc: 0.541016]: [A loss: 1.907585, acc: 0.003906]\n",
      "458: [D loss: 0.569760, acc: 0.699219]: [A loss: 0.868366, acc: 0.332031]\n",
      "459: [D loss: 0.644652, acc: 0.593750]: [A loss: 1.835671, acc: 0.000000]\n",
      "460: [D loss: 0.545078, acc: 0.746094]: [A loss: 1.005868, acc: 0.246094]\n",
      "461: [D loss: 0.621332, acc: 0.626953]: [A loss: 1.887940, acc: 0.019531]\n",
      "462: [D loss: 0.531529, acc: 0.738281]: [A loss: 1.082406, acc: 0.195312]\n",
      "463: [D loss: 0.605362, acc: 0.611328]: [A loss: 1.997228, acc: 0.003906]\n",
      "464: [D loss: 0.557629, acc: 0.742188]: [A loss: 1.057757, acc: 0.191406]\n",
      "465: [D loss: 0.615493, acc: 0.626953]: [A loss: 2.227642, acc: 0.000000]\n",
      "466: [D loss: 0.572622, acc: 0.695312]: [A loss: 0.637130, acc: 0.625000]\n",
      "467: [D loss: 0.758637, acc: 0.527344]: [A loss: 2.490222, acc: 0.000000]\n",
      "468: [D loss: 0.598710, acc: 0.664062]: [A loss: 0.515340, acc: 0.832031]\n",
      "469: [D loss: 0.785278, acc: 0.513672]: [A loss: 1.977806, acc: 0.000000]\n",
      "470: [D loss: 0.576945, acc: 0.701172]: [A loss: 0.796464, acc: 0.382812]\n",
      "471: [D loss: 0.672283, acc: 0.556641]: [A loss: 1.713451, acc: 0.007812]\n",
      "472: [D loss: 0.576557, acc: 0.726562]: [A loss: 0.857520, acc: 0.371094]\n",
      "473: [D loss: 0.676643, acc: 0.568359]: [A loss: 1.778583, acc: 0.015625]\n",
      "474: [D loss: 0.565089, acc: 0.740234]: [A loss: 0.872410, acc: 0.304688]\n",
      "475: [D loss: 0.691601, acc: 0.578125]: [A loss: 1.877691, acc: 0.011719]\n",
      "476: [D loss: 0.569400, acc: 0.728516]: [A loss: 0.803960, acc: 0.382812]\n",
      "477: [D loss: 0.697412, acc: 0.552734]: [A loss: 2.076399, acc: 0.000000]\n",
      "478: [D loss: 0.560657, acc: 0.726562]: [A loss: 0.765728, acc: 0.464844]\n",
      "479: [D loss: 0.694955, acc: 0.564453]: [A loss: 2.099168, acc: 0.011719]\n",
      "480: [D loss: 0.571763, acc: 0.697266]: [A loss: 0.727895, acc: 0.453125]\n",
      "481: [D loss: 0.698347, acc: 0.554688]: [A loss: 1.951569, acc: 0.000000]\n",
      "482: [D loss: 0.576406, acc: 0.740234]: [A loss: 0.769689, acc: 0.464844]\n",
      "483: [D loss: 0.687803, acc: 0.544922]: [A loss: 1.870087, acc: 0.003906]\n",
      "484: [D loss: 0.587207, acc: 0.689453]: [A loss: 0.854361, acc: 0.371094]\n",
      "485: [D loss: 0.659981, acc: 0.572266]: [A loss: 1.899969, acc: 0.000000]\n",
      "486: [D loss: 0.558059, acc: 0.699219]: [A loss: 0.781088, acc: 0.449219]\n",
      "487: [D loss: 0.702720, acc: 0.544922]: [A loss: 2.020236, acc: 0.003906]\n",
      "488: [D loss: 0.556074, acc: 0.738281]: [A loss: 0.731892, acc: 0.542969]\n",
      "489: [D loss: 0.682410, acc: 0.552734]: [A loss: 1.968406, acc: 0.003906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490: [D loss: 0.578805, acc: 0.689453]: [A loss: 0.703613, acc: 0.550781]\n",
      "491: [D loss: 0.697538, acc: 0.525391]: [A loss: 2.006592, acc: 0.000000]\n",
      "492: [D loss: 0.598785, acc: 0.664062]: [A loss: 0.721230, acc: 0.511719]\n",
      "493: [D loss: 0.705789, acc: 0.541016]: [A loss: 1.775756, acc: 0.000000]\n",
      "494: [D loss: 0.572688, acc: 0.746094]: [A loss: 0.808126, acc: 0.402344]\n",
      "495: [D loss: 0.660815, acc: 0.601562]: [A loss: 1.752613, acc: 0.011719]\n",
      "496: [D loss: 0.573250, acc: 0.703125]: [A loss: 0.916962, acc: 0.265625]\n",
      "497: [D loss: 0.631542, acc: 0.617188]: [A loss: 1.854524, acc: 0.011719]\n",
      "498: [D loss: 0.590165, acc: 0.693359]: [A loss: 0.865110, acc: 0.363281]\n",
      "499: [D loss: 0.668486, acc: 0.562500]: [A loss: 1.987882, acc: 0.000000]\n",
      "500: [D loss: 0.581497, acc: 0.707031]: [A loss: 0.618127, acc: 0.683594]\n",
      "501: [D loss: 0.785571, acc: 0.527344]: [A loss: 2.032128, acc: 0.000000]\n",
      "502: [D loss: 0.606226, acc: 0.681641]: [A loss: 0.642042, acc: 0.652344]\n",
      "503: [D loss: 0.756232, acc: 0.523438]: [A loss: 1.651079, acc: 0.019531]\n",
      "504: [D loss: 0.591518, acc: 0.701172]: [A loss: 0.875215, acc: 0.292969]\n",
      "505: [D loss: 0.655251, acc: 0.568359]: [A loss: 1.428205, acc: 0.035156]\n",
      "506: [D loss: 0.588278, acc: 0.712891]: [A loss: 1.074836, acc: 0.179688]\n",
      "507: [D loss: 0.644580, acc: 0.609375]: [A loss: 1.557481, acc: 0.011719]\n",
      "508: [D loss: 0.589457, acc: 0.707031]: [A loss: 1.167712, acc: 0.121094]\n",
      "509: [D loss: 0.620327, acc: 0.642578]: [A loss: 1.801017, acc: 0.011719]\n",
      "510: [D loss: 0.566437, acc: 0.689453]: [A loss: 0.916309, acc: 0.269531]\n",
      "511: [D loss: 0.691705, acc: 0.568359]: [A loss: 2.238076, acc: 0.000000]\n",
      "512: [D loss: 0.595899, acc: 0.677734]: [A loss: 0.501064, acc: 0.835938]\n",
      "513: [D loss: 0.747888, acc: 0.515625]: [A loss: 1.946986, acc: 0.007812]\n",
      "514: [D loss: 0.599485, acc: 0.656250]: [A loss: 0.584121, acc: 0.722656]\n",
      "515: [D loss: 0.751415, acc: 0.531250]: [A loss: 1.692327, acc: 0.003906]\n",
      "516: [D loss: 0.592318, acc: 0.697266]: [A loss: 0.753181, acc: 0.445312]\n",
      "517: [D loss: 0.687865, acc: 0.546875]: [A loss: 1.646755, acc: 0.011719]\n",
      "518: [D loss: 0.574398, acc: 0.759766]: [A loss: 0.834554, acc: 0.375000]\n",
      "519: [D loss: 0.666489, acc: 0.601562]: [A loss: 1.553621, acc: 0.015625]\n",
      "520: [D loss: 0.578857, acc: 0.728516]: [A loss: 0.830446, acc: 0.343750]\n",
      "521: [D loss: 0.696480, acc: 0.548828]: [A loss: 1.689203, acc: 0.011719]\n",
      "522: [D loss: 0.585605, acc: 0.722656]: [A loss: 0.831550, acc: 0.382812]\n",
      "523: [D loss: 0.683507, acc: 0.550781]: [A loss: 1.820656, acc: 0.000000]\n",
      "524: [D loss: 0.569765, acc: 0.726562]: [A loss: 0.702992, acc: 0.527344]\n",
      "525: [D loss: 0.679276, acc: 0.554688]: [A loss: 1.961906, acc: 0.011719]\n",
      "526: [D loss: 0.566337, acc: 0.720703]: [A loss: 0.694240, acc: 0.562500]\n",
      "527: [D loss: 0.715139, acc: 0.550781]: [A loss: 1.824274, acc: 0.003906]\n",
      "528: [D loss: 0.609773, acc: 0.703125]: [A loss: 0.724494, acc: 0.484375]\n",
      "529: [D loss: 0.705998, acc: 0.527344]: [A loss: 1.759535, acc: 0.000000]\n",
      "530: [D loss: 0.566258, acc: 0.742188]: [A loss: 0.785565, acc: 0.464844]\n",
      "531: [D loss: 0.683309, acc: 0.560547]: [A loss: 1.552581, acc: 0.007812]\n",
      "532: [D loss: 0.590261, acc: 0.697266]: [A loss: 0.787942, acc: 0.425781]\n",
      "533: [D loss: 0.663541, acc: 0.560547]: [A loss: 1.569175, acc: 0.007812]\n",
      "534: [D loss: 0.572110, acc: 0.726562]: [A loss: 0.821063, acc: 0.398438]\n",
      "535: [D loss: 0.664380, acc: 0.566406]: [A loss: 1.868862, acc: 0.000000]\n",
      "536: [D loss: 0.563877, acc: 0.720703]: [A loss: 0.706188, acc: 0.527344]\n",
      "537: [D loss: 0.731158, acc: 0.525391]: [A loss: 2.191527, acc: 0.000000]\n",
      "538: [D loss: 0.619672, acc: 0.656250]: [A loss: 0.606796, acc: 0.746094]\n",
      "539: [D loss: 0.745785, acc: 0.519531]: [A loss: 1.548580, acc: 0.007812]\n",
      "540: [D loss: 0.602465, acc: 0.664062]: [A loss: 0.767447, acc: 0.441406]\n",
      "541: [D loss: 0.665131, acc: 0.580078]: [A loss: 1.579022, acc: 0.015625]\n",
      "542: [D loss: 0.598626, acc: 0.691406]: [A loss: 0.854522, acc: 0.328125]\n",
      "543: [D loss: 0.652626, acc: 0.578125]: [A loss: 1.513104, acc: 0.011719]\n",
      "544: [D loss: 0.612919, acc: 0.693359]: [A loss: 0.830808, acc: 0.378906]\n",
      "545: [D loss: 0.649841, acc: 0.576172]: [A loss: 1.615358, acc: 0.000000]\n",
      "546: [D loss: 0.596946, acc: 0.693359]: [A loss: 0.908302, acc: 0.289062]\n",
      "547: [D loss: 0.650180, acc: 0.572266]: [A loss: 1.889034, acc: 0.003906]\n",
      "548: [D loss: 0.598702, acc: 0.685547]: [A loss: 0.717955, acc: 0.503906]\n",
      "549: [D loss: 0.725418, acc: 0.519531]: [A loss: 1.923971, acc: 0.000000]\n",
      "550: [D loss: 0.612733, acc: 0.648438]: [A loss: 0.594084, acc: 0.699219]\n",
      "551: [D loss: 0.720527, acc: 0.535156]: [A loss: 1.754205, acc: 0.000000]\n",
      "552: [D loss: 0.596502, acc: 0.703125]: [A loss: 0.712947, acc: 0.527344]\n",
      "553: [D loss: 0.687905, acc: 0.548828]: [A loss: 1.592179, acc: 0.003906]\n",
      "554: [D loss: 0.598719, acc: 0.722656]: [A loss: 0.734566, acc: 0.468750]\n",
      "555: [D loss: 0.676490, acc: 0.566406]: [A loss: 1.614870, acc: 0.003906]\n",
      "556: [D loss: 0.582193, acc: 0.734375]: [A loss: 0.745628, acc: 0.441406]\n",
      "557: [D loss: 0.684724, acc: 0.576172]: [A loss: 1.668254, acc: 0.003906]\n",
      "558: [D loss: 0.593607, acc: 0.714844]: [A loss: 0.775027, acc: 0.476562]\n",
      "559: [D loss: 0.708104, acc: 0.533203]: [A loss: 1.827847, acc: 0.007812]\n",
      "560: [D loss: 0.609977, acc: 0.705078]: [A loss: 0.634502, acc: 0.675781]\n",
      "561: [D loss: 0.706912, acc: 0.527344]: [A loss: 1.636328, acc: 0.007812]\n",
      "562: [D loss: 0.629108, acc: 0.673828]: [A loss: 0.687148, acc: 0.562500]\n",
      "563: [D loss: 0.702033, acc: 0.535156]: [A loss: 1.584324, acc: 0.000000]\n",
      "564: [D loss: 0.614712, acc: 0.673828]: [A loss: 0.819797, acc: 0.347656]\n",
      "565: [D loss: 0.656924, acc: 0.578125]: [A loss: 1.344037, acc: 0.027344]\n",
      "566: [D loss: 0.627632, acc: 0.650391]: [A loss: 0.968637, acc: 0.175781]\n",
      "567: [D loss: 0.640380, acc: 0.580078]: [A loss: 1.384272, acc: 0.046875]\n",
      "568: [D loss: 0.615054, acc: 0.652344]: [A loss: 0.977484, acc: 0.179688]\n",
      "569: [D loss: 0.647860, acc: 0.583984]: [A loss: 1.482057, acc: 0.019531]\n",
      "570: [D loss: 0.611928, acc: 0.664062]: [A loss: 0.849800, acc: 0.312500]\n",
      "571: [D loss: 0.642140, acc: 0.587891]: [A loss: 1.739758, acc: 0.011719]\n",
      "572: [D loss: 0.588183, acc: 0.697266]: [A loss: 0.677311, acc: 0.535156]\n",
      "573: [D loss: 0.753573, acc: 0.529297]: [A loss: 1.979583, acc: 0.000000]\n",
      "574: [D loss: 0.652883, acc: 0.611328]: [A loss: 0.536761, acc: 0.820312]\n",
      "575: [D loss: 0.773947, acc: 0.507812]: [A loss: 1.415087, acc: 0.003906]\n",
      "576: [D loss: 0.606342, acc: 0.714844]: [A loss: 0.797475, acc: 0.394531]\n",
      "577: [D loss: 0.660018, acc: 0.574219]: [A loss: 1.290143, acc: 0.031250]\n",
      "578: [D loss: 0.619577, acc: 0.705078]: [A loss: 0.955769, acc: 0.167969]\n",
      "579: [D loss: 0.643232, acc: 0.613281]: [A loss: 1.330965, acc: 0.027344]\n",
      "580: [D loss: 0.618476, acc: 0.677734]: [A loss: 0.978575, acc: 0.191406]\n",
      "581: [D loss: 0.652043, acc: 0.605469]: [A loss: 1.378554, acc: 0.035156]\n",
      "582: [D loss: 0.623293, acc: 0.664062]: [A loss: 0.906277, acc: 0.253906]\n",
      "583: [D loss: 0.652849, acc: 0.580078]: [A loss: 1.613799, acc: 0.000000]\n",
      "584: [D loss: 0.617160, acc: 0.673828]: [A loss: 0.695727, acc: 0.558594]\n",
      "585: [D loss: 0.728517, acc: 0.515625]: [A loss: 1.950611, acc: 0.000000]\n",
      "586: [D loss: 0.645448, acc: 0.605469]: [A loss: 0.539209, acc: 0.808594]\n",
      "587: [D loss: 0.758292, acc: 0.501953]: [A loss: 1.406762, acc: 0.015625]\n",
      "588: [D loss: 0.621029, acc: 0.660156]: [A loss: 0.734492, acc: 0.445312]\n",
      "589: [D loss: 0.664414, acc: 0.552734]: [A loss: 1.281617, acc: 0.027344]\n",
      "590: [D loss: 0.600666, acc: 0.689453]: [A loss: 0.852552, acc: 0.296875]\n",
      "591: [D loss: 0.663119, acc: 0.580078]: [A loss: 1.339427, acc: 0.011719]\n",
      "592: [D loss: 0.596197, acc: 0.712891]: [A loss: 0.817942, acc: 0.343750]\n",
      "593: [D loss: 0.654210, acc: 0.578125]: [A loss: 1.548329, acc: 0.019531]\n",
      "594: [D loss: 0.607336, acc: 0.669922]: [A loss: 0.842480, acc: 0.308594]\n",
      "595: [D loss: 0.677092, acc: 0.566406]: [A loss: 1.631493, acc: 0.003906]\n",
      "596: [D loss: 0.609333, acc: 0.673828]: [A loss: 0.624114, acc: 0.652344]\n",
      "597: [D loss: 0.745496, acc: 0.527344]: [A loss: 1.668505, acc: 0.000000]\n",
      "598: [D loss: 0.629136, acc: 0.634766]: [A loss: 0.617801, acc: 0.679688]\n",
      "599: [D loss: 0.719791, acc: 0.521484]: [A loss: 1.578954, acc: 0.003906]\n",
      "600: [D loss: 0.591420, acc: 0.714844]: [A loss: 0.763632, acc: 0.429688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601: [D loss: 0.676097, acc: 0.562500]: [A loss: 1.353065, acc: 0.007812]\n",
      "602: [D loss: 0.618769, acc: 0.677734]: [A loss: 0.856755, acc: 0.234375]\n",
      "603: [D loss: 0.671314, acc: 0.568359]: [A loss: 1.382392, acc: 0.019531]\n",
      "604: [D loss: 0.625192, acc: 0.679688]: [A loss: 0.782147, acc: 0.375000]\n",
      "605: [D loss: 0.693293, acc: 0.556641]: [A loss: 1.424202, acc: 0.007812]\n",
      "606: [D loss: 0.624179, acc: 0.654297]: [A loss: 0.711257, acc: 0.492188]\n",
      "607: [D loss: 0.674018, acc: 0.554688]: [A loss: 1.516566, acc: 0.027344]\n",
      "608: [D loss: 0.635610, acc: 0.628906]: [A loss: 0.709211, acc: 0.515625]\n",
      "609: [D loss: 0.697548, acc: 0.537109]: [A loss: 1.589410, acc: 0.015625]\n",
      "610: [D loss: 0.612327, acc: 0.656250]: [A loss: 0.735077, acc: 0.476562]\n",
      "611: [D loss: 0.698890, acc: 0.556641]: [A loss: 1.362751, acc: 0.023438]\n",
      "612: [D loss: 0.638211, acc: 0.656250]: [A loss: 0.767563, acc: 0.414062]\n",
      "613: [D loss: 0.692925, acc: 0.554688]: [A loss: 1.444571, acc: 0.011719]\n",
      "614: [D loss: 0.621601, acc: 0.626953]: [A loss: 0.750549, acc: 0.453125]\n",
      "615: [D loss: 0.641928, acc: 0.621094]: [A loss: 1.521782, acc: 0.023438]\n",
      "616: [D loss: 0.550675, acc: 0.775391]: [A loss: 0.692973, acc: 0.554688]\n",
      "617: [D loss: 0.709951, acc: 0.566406]: [A loss: 1.866830, acc: 0.003906]\n",
      "618: [D loss: 0.637160, acc: 0.625000]: [A loss: 0.563879, acc: 0.746094]\n",
      "619: [D loss: 0.765926, acc: 0.513672]: [A loss: 1.501892, acc: 0.003906]\n",
      "620: [D loss: 0.637748, acc: 0.632812]: [A loss: 0.707883, acc: 0.503906]\n",
      "621: [D loss: 0.689507, acc: 0.544922]: [A loss: 1.294848, acc: 0.023438]\n",
      "622: [D loss: 0.630802, acc: 0.652344]: [A loss: 0.776628, acc: 0.406250]\n",
      "623: [D loss: 0.696439, acc: 0.550781]: [A loss: 1.217123, acc: 0.027344]\n",
      "624: [D loss: 0.623972, acc: 0.671875]: [A loss: 0.908459, acc: 0.207031]\n",
      "625: [D loss: 0.656008, acc: 0.587891]: [A loss: 1.279482, acc: 0.027344]\n",
      "626: [D loss: 0.621068, acc: 0.664062]: [A loss: 0.883977, acc: 0.289062]\n",
      "627: [D loss: 0.640905, acc: 0.628906]: [A loss: 1.337117, acc: 0.023438]\n",
      "628: [D loss: 0.639628, acc: 0.619141]: [A loss: 0.849074, acc: 0.285156]\n",
      "629: [D loss: 0.679085, acc: 0.572266]: [A loss: 1.486595, acc: 0.007812]\n",
      "630: [D loss: 0.619151, acc: 0.667969]: [A loss: 0.645196, acc: 0.605469]\n",
      "631: [D loss: 0.726041, acc: 0.531250]: [A loss: 1.692528, acc: 0.000000]\n",
      "632: [D loss: 0.642152, acc: 0.623047]: [A loss: 0.593614, acc: 0.738281]\n",
      "633: [D loss: 0.739026, acc: 0.513672]: [A loss: 1.408889, acc: 0.007812]\n",
      "634: [D loss: 0.635600, acc: 0.650391]: [A loss: 0.713041, acc: 0.542969]\n",
      "635: [D loss: 0.697063, acc: 0.525391]: [A loss: 1.332022, acc: 0.015625]\n",
      "636: [D loss: 0.626930, acc: 0.658203]: [A loss: 0.811389, acc: 0.296875]\n",
      "637: [D loss: 0.650683, acc: 0.580078]: [A loss: 1.259761, acc: 0.023438]\n",
      "638: [D loss: 0.621950, acc: 0.666016]: [A loss: 0.861845, acc: 0.265625]\n",
      "639: [D loss: 0.657333, acc: 0.607422]: [A loss: 1.256078, acc: 0.019531]\n",
      "640: [D loss: 0.630004, acc: 0.640625]: [A loss: 0.925211, acc: 0.203125]\n",
      "641: [D loss: 0.654386, acc: 0.597656]: [A loss: 1.420379, acc: 0.007812]\n",
      "642: [D loss: 0.602198, acc: 0.712891]: [A loss: 0.769840, acc: 0.417969]\n",
      "643: [D loss: 0.691863, acc: 0.558594]: [A loss: 1.698615, acc: 0.015625]\n",
      "644: [D loss: 0.663706, acc: 0.601562]: [A loss: 0.573396, acc: 0.796875]\n",
      "645: [D loss: 0.785059, acc: 0.500000]: [A loss: 1.538204, acc: 0.000000]\n",
      "646: [D loss: 0.643478, acc: 0.632812]: [A loss: 0.652219, acc: 0.644531]\n",
      "647: [D loss: 0.687503, acc: 0.539062]: [A loss: 1.242834, acc: 0.023438]\n",
      "648: [D loss: 0.630302, acc: 0.671875]: [A loss: 0.774560, acc: 0.363281]\n",
      "649: [D loss: 0.673590, acc: 0.568359]: [A loss: 1.174450, acc: 0.039062]\n",
      "650: [D loss: 0.630807, acc: 0.640625]: [A loss: 0.929603, acc: 0.207031]\n",
      "651: [D loss: 0.647755, acc: 0.615234]: [A loss: 1.159358, acc: 0.042969]\n",
      "652: [D loss: 0.641382, acc: 0.652344]: [A loss: 0.956851, acc: 0.191406]\n",
      "653: [D loss: 0.621443, acc: 0.623047]: [A loss: 1.430583, acc: 0.035156]\n",
      "654: [D loss: 0.572424, acc: 0.746094]: [A loss: 0.738462, acc: 0.476562]\n",
      "655: [D loss: 0.752523, acc: 0.560547]: [A loss: 1.749403, acc: 0.000000]\n",
      "656: [D loss: 0.644571, acc: 0.599609]: [A loss: 0.580468, acc: 0.757812]\n",
      "657: [D loss: 0.751396, acc: 0.521484]: [A loss: 1.489303, acc: 0.000000]\n",
      "658: [D loss: 0.647364, acc: 0.609375]: [A loss: 0.662325, acc: 0.601562]\n",
      "659: [D loss: 0.717224, acc: 0.533203]: [A loss: 1.267750, acc: 0.011719]\n",
      "660: [D loss: 0.632872, acc: 0.652344]: [A loss: 0.740955, acc: 0.476562]\n",
      "661: [D loss: 0.666190, acc: 0.562500]: [A loss: 1.270538, acc: 0.031250]\n",
      "662: [D loss: 0.652561, acc: 0.597656]: [A loss: 0.819412, acc: 0.304688]\n",
      "663: [D loss: 0.681653, acc: 0.556641]: [A loss: 1.208253, acc: 0.031250]\n",
      "664: [D loss: 0.641542, acc: 0.654297]: [A loss: 0.866681, acc: 0.292969]\n",
      "665: [D loss: 0.655516, acc: 0.583984]: [A loss: 1.260361, acc: 0.023438]\n",
      "666: [D loss: 0.631878, acc: 0.667969]: [A loss: 0.888401, acc: 0.316406]\n",
      "667: [D loss: 0.653577, acc: 0.603516]: [A loss: 1.240296, acc: 0.054688]\n",
      "668: [D loss: 0.616318, acc: 0.673828]: [A loss: 0.859413, acc: 0.320312]\n",
      "669: [D loss: 0.676606, acc: 0.552734]: [A loss: 1.547575, acc: 0.000000]\n",
      "670: [D loss: 0.639716, acc: 0.636719]: [A loss: 0.663003, acc: 0.597656]\n",
      "671: [D loss: 0.733459, acc: 0.527344]: [A loss: 1.733943, acc: 0.003906]\n",
      "672: [D loss: 0.663204, acc: 0.597656]: [A loss: 0.550185, acc: 0.781250]\n",
      "673: [D loss: 0.728426, acc: 0.515625]: [A loss: 1.309584, acc: 0.019531]\n",
      "674: [D loss: 0.656543, acc: 0.613281]: [A loss: 0.679204, acc: 0.542969]\n",
      "675: [D loss: 0.682227, acc: 0.558594]: [A loss: 1.164541, acc: 0.019531]\n",
      "676: [D loss: 0.654257, acc: 0.615234]: [A loss: 0.823502, acc: 0.253906]\n",
      "677: [D loss: 0.666268, acc: 0.578125]: [A loss: 1.083267, acc: 0.070312]\n",
      "678: [D loss: 0.641833, acc: 0.638672]: [A loss: 0.960342, acc: 0.144531]\n",
      "679: [D loss: 0.655830, acc: 0.615234]: [A loss: 1.167174, acc: 0.042969]\n",
      "680: [D loss: 0.628703, acc: 0.654297]: [A loss: 0.954735, acc: 0.191406]\n",
      "681: [D loss: 0.656494, acc: 0.605469]: [A loss: 1.270591, acc: 0.027344]\n",
      "682: [D loss: 0.610661, acc: 0.718750]: [A loss: 0.829950, acc: 0.343750]\n",
      "683: [D loss: 0.710322, acc: 0.548828]: [A loss: 1.689097, acc: 0.003906]\n",
      "684: [D loss: 0.648969, acc: 0.628906]: [A loss: 0.544251, acc: 0.824219]\n",
      "685: [D loss: 0.756644, acc: 0.503906]: [A loss: 1.517615, acc: 0.000000]\n",
      "686: [D loss: 0.663546, acc: 0.595703]: [A loss: 0.631632, acc: 0.679688]\n",
      "687: [D loss: 0.710285, acc: 0.519531]: [A loss: 1.133846, acc: 0.050781]\n",
      "688: [D loss: 0.641352, acc: 0.632812]: [A loss: 0.819946, acc: 0.332031]\n",
      "689: [D loss: 0.670115, acc: 0.583984]: [A loss: 1.091078, acc: 0.046875]\n",
      "690: [D loss: 0.633784, acc: 0.662109]: [A loss: 0.814198, acc: 0.312500]\n",
      "691: [D loss: 0.675525, acc: 0.560547]: [A loss: 1.225080, acc: 0.019531]\n",
      "692: [D loss: 0.629383, acc: 0.683594]: [A loss: 0.858379, acc: 0.250000]\n",
      "693: [D loss: 0.677710, acc: 0.591797]: [A loss: 1.278559, acc: 0.015625]\n",
      "694: [D loss: 0.650278, acc: 0.626953]: [A loss: 0.720945, acc: 0.488281]\n",
      "695: [D loss: 0.699830, acc: 0.552734]: [A loss: 1.454214, acc: 0.007812]\n",
      "696: [D loss: 0.648105, acc: 0.615234]: [A loss: 0.610460, acc: 0.730469]\n",
      "697: [D loss: 0.725063, acc: 0.515625]: [A loss: 1.509975, acc: 0.007812]\n",
      "698: [D loss: 0.653468, acc: 0.597656]: [A loss: 0.608190, acc: 0.734375]\n",
      "699: [D loss: 0.706205, acc: 0.525391]: [A loss: 1.283567, acc: 0.023438]\n",
      "700: [D loss: 0.647169, acc: 0.628906]: [A loss: 0.755866, acc: 0.433594]\n",
      "701: [D loss: 0.674568, acc: 0.578125]: [A loss: 1.190351, acc: 0.011719]\n",
      "702: [D loss: 0.634698, acc: 0.640625]: [A loss: 0.719820, acc: 0.492188]\n",
      "703: [D loss: 0.684776, acc: 0.542969]: [A loss: 1.358274, acc: 0.000000]\n",
      "704: [D loss: 0.659318, acc: 0.603516]: [A loss: 0.680219, acc: 0.566406]\n",
      "705: [D loss: 0.700289, acc: 0.544922]: [A loss: 1.310005, acc: 0.007812]\n",
      "706: [D loss: 0.642069, acc: 0.617188]: [A loss: 0.746941, acc: 0.421875]\n",
      "707: [D loss: 0.675055, acc: 0.566406]: [A loss: 1.214527, acc: 0.023438]\n",
      "708: [D loss: 0.626328, acc: 0.671875]: [A loss: 0.825934, acc: 0.332031]\n",
      "709: [D loss: 0.683969, acc: 0.550781]: [A loss: 1.269803, acc: 0.031250]\n",
      "710: [D loss: 0.624204, acc: 0.669922]: [A loss: 0.767616, acc: 0.421875]\n",
      "711: [D loss: 0.678874, acc: 0.548828]: [A loss: 1.451043, acc: 0.003906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712: [D loss: 0.622997, acc: 0.669922]: [A loss: 0.740181, acc: 0.445312]\n",
      "713: [D loss: 0.675987, acc: 0.544922]: [A loss: 1.375765, acc: 0.011719]\n",
      "714: [D loss: 0.642658, acc: 0.636719]: [A loss: 0.727906, acc: 0.460938]\n",
      "715: [D loss: 0.698301, acc: 0.550781]: [A loss: 1.435379, acc: 0.000000]\n",
      "716: [D loss: 0.646713, acc: 0.630859]: [A loss: 0.646186, acc: 0.648438]\n",
      "717: [D loss: 0.729282, acc: 0.515625]: [A loss: 1.349959, acc: 0.019531]\n",
      "718: [D loss: 0.661367, acc: 0.611328]: [A loss: 0.698318, acc: 0.531250]\n",
      "719: [D loss: 0.688679, acc: 0.552734]: [A loss: 1.211134, acc: 0.015625]\n",
      "720: [D loss: 0.657109, acc: 0.607422]: [A loss: 0.753877, acc: 0.417969]\n",
      "721: [D loss: 0.692876, acc: 0.556641]: [A loss: 1.194705, acc: 0.035156]\n",
      "722: [D loss: 0.633521, acc: 0.652344]: [A loss: 0.778461, acc: 0.347656]\n",
      "723: [D loss: 0.672340, acc: 0.542969]: [A loss: 1.209914, acc: 0.035156]\n",
      "724: [D loss: 0.640859, acc: 0.623047]: [A loss: 0.747777, acc: 0.476562]\n",
      "725: [D loss: 0.711554, acc: 0.537109]: [A loss: 1.285007, acc: 0.019531]\n",
      "726: [D loss: 0.640208, acc: 0.640625]: [A loss: 0.714531, acc: 0.496094]\n",
      "727: [D loss: 0.713196, acc: 0.529297]: [A loss: 1.396203, acc: 0.003906]\n",
      "728: [D loss: 0.635598, acc: 0.646484]: [A loss: 0.687782, acc: 0.542969]\n",
      "729: [D loss: 0.702684, acc: 0.531250]: [A loss: 1.309675, acc: 0.003906]\n",
      "730: [D loss: 0.636752, acc: 0.654297]: [A loss: 0.709309, acc: 0.480469]\n",
      "731: [D loss: 0.712265, acc: 0.517578]: [A loss: 1.195136, acc: 0.011719]\n",
      "732: [D loss: 0.653061, acc: 0.625000]: [A loss: 0.775035, acc: 0.363281]\n",
      "733: [D loss: 0.689044, acc: 0.537109]: [A loss: 1.223779, acc: 0.015625]\n",
      "734: [D loss: 0.633969, acc: 0.666016]: [A loss: 0.829093, acc: 0.308594]\n",
      "735: [D loss: 0.685686, acc: 0.552734]: [A loss: 1.188087, acc: 0.054688]\n",
      "736: [D loss: 0.660392, acc: 0.599609]: [A loss: 0.842266, acc: 0.285156]\n",
      "737: [D loss: 0.651475, acc: 0.599609]: [A loss: 1.226628, acc: 0.015625]\n",
      "738: [D loss: 0.643158, acc: 0.654297]: [A loss: 0.820100, acc: 0.339844]\n",
      "739: [D loss: 0.677319, acc: 0.560547]: [A loss: 1.338042, acc: 0.003906]\n",
      "740: [D loss: 0.651190, acc: 0.613281]: [A loss: 0.698666, acc: 0.507812]\n",
      "741: [D loss: 0.712785, acc: 0.527344]: [A loss: 1.406497, acc: 0.003906]\n",
      "742: [D loss: 0.650968, acc: 0.621094]: [A loss: 0.583408, acc: 0.750000]\n",
      "743: [D loss: 0.742104, acc: 0.515625]: [A loss: 1.372677, acc: 0.007812]\n",
      "744: [D loss: 0.667162, acc: 0.583984]: [A loss: 0.627968, acc: 0.667969]\n",
      "745: [D loss: 0.708714, acc: 0.521484]: [A loss: 1.099863, acc: 0.039062]\n",
      "746: [D loss: 0.649345, acc: 0.640625]: [A loss: 0.794474, acc: 0.316406]\n",
      "747: [D loss: 0.665061, acc: 0.582031]: [A loss: 0.991439, acc: 0.082031]\n",
      "748: [D loss: 0.657103, acc: 0.597656]: [A loss: 0.949737, acc: 0.128906]\n",
      "749: [D loss: 0.654621, acc: 0.605469]: [A loss: 1.010599, acc: 0.078125]\n",
      "750: [D loss: 0.661977, acc: 0.607422]: [A loss: 0.969731, acc: 0.121094]\n",
      "751: [D loss: 0.657853, acc: 0.578125]: [A loss: 1.096072, acc: 0.031250]\n",
      "752: [D loss: 0.660198, acc: 0.595703]: [A loss: 0.972186, acc: 0.140625]\n",
      "753: [D loss: 0.662925, acc: 0.601562]: [A loss: 1.164385, acc: 0.046875]\n",
      "754: [D loss: 0.652359, acc: 0.611328]: [A loss: 0.848277, acc: 0.296875]\n",
      "755: [D loss: 0.658251, acc: 0.578125]: [A loss: 1.302172, acc: 0.003906]\n",
      "756: [D loss: 0.654967, acc: 0.640625]: [A loss: 0.796465, acc: 0.335938]\n",
      "757: [D loss: 0.669101, acc: 0.552734]: [A loss: 1.413690, acc: 0.011719]\n",
      "758: [D loss: 0.639892, acc: 0.638672]: [A loss: 0.633810, acc: 0.652344]\n",
      "759: [D loss: 0.712358, acc: 0.546875]: [A loss: 1.530955, acc: 0.003906]\n",
      "760: [D loss: 0.667909, acc: 0.585938]: [A loss: 0.541391, acc: 0.847656]\n",
      "761: [D loss: 0.755627, acc: 0.507812]: [A loss: 1.249128, acc: 0.007812]\n",
      "762: [D loss: 0.658776, acc: 0.634766]: [A loss: 0.680456, acc: 0.546875]\n",
      "763: [D loss: 0.705818, acc: 0.517578]: [A loss: 1.038571, acc: 0.070312]\n",
      "764: [D loss: 0.645973, acc: 0.632812]: [A loss: 0.792137, acc: 0.347656]\n",
      "765: [D loss: 0.669856, acc: 0.564453]: [A loss: 1.082636, acc: 0.027344]\n",
      "766: [D loss: 0.635876, acc: 0.666016]: [A loss: 0.871320, acc: 0.234375]\n",
      "767: [D loss: 0.670025, acc: 0.572266]: [A loss: 1.109547, acc: 0.042969]\n",
      "768: [D loss: 0.645202, acc: 0.628906]: [A loss: 0.814221, acc: 0.250000]\n",
      "769: [D loss: 0.673405, acc: 0.582031]: [A loss: 1.161435, acc: 0.042969]\n",
      "770: [D loss: 0.652365, acc: 0.625000]: [A loss: 0.843652, acc: 0.242188]\n",
      "771: [D loss: 0.683021, acc: 0.558594]: [A loss: 1.287190, acc: 0.003906]\n",
      "772: [D loss: 0.636917, acc: 0.650391]: [A loss: 0.754020, acc: 0.402344]\n",
      "773: [D loss: 0.715314, acc: 0.517578]: [A loss: 1.478038, acc: 0.007812]\n",
      "774: [D loss: 0.657156, acc: 0.576172]: [A loss: 0.569247, acc: 0.769531]\n",
      "775: [D loss: 0.747573, acc: 0.515625]: [A loss: 1.295788, acc: 0.003906]\n",
      "776: [D loss: 0.659379, acc: 0.603516]: [A loss: 0.642353, acc: 0.652344]\n",
      "777: [D loss: 0.692377, acc: 0.539062]: [A loss: 1.077578, acc: 0.078125]\n",
      "778: [D loss: 0.643967, acc: 0.666016]: [A loss: 0.762255, acc: 0.394531]\n",
      "779: [D loss: 0.687096, acc: 0.535156]: [A loss: 1.071628, acc: 0.054688]\n",
      "780: [D loss: 0.654425, acc: 0.626953]: [A loss: 0.788982, acc: 0.351562]\n",
      "781: [D loss: 0.675089, acc: 0.570312]: [A loss: 1.152788, acc: 0.031250]\n",
      "782: [D loss: 0.652828, acc: 0.623047]: [A loss: 0.771411, acc: 0.386719]\n",
      "783: [D loss: 0.691053, acc: 0.531250]: [A loss: 1.177630, acc: 0.023438]\n",
      "784: [D loss: 0.668580, acc: 0.595703]: [A loss: 0.749771, acc: 0.394531]\n",
      "785: [D loss: 0.687164, acc: 0.572266]: [A loss: 1.279023, acc: 0.007812]\n",
      "786: [D loss: 0.644231, acc: 0.638672]: [A loss: 0.684083, acc: 0.601562]\n",
      "787: [D loss: 0.697945, acc: 0.535156]: [A loss: 1.287906, acc: 0.003906]\n",
      "788: [D loss: 0.658276, acc: 0.597656]: [A loss: 0.694956, acc: 0.500000]\n",
      "789: [D loss: 0.684151, acc: 0.548828]: [A loss: 1.218979, acc: 0.035156]\n",
      "790: [D loss: 0.659079, acc: 0.585938]: [A loss: 0.720043, acc: 0.472656]\n",
      "791: [D loss: 0.703430, acc: 0.515625]: [A loss: 1.219880, acc: 0.015625]\n",
      "792: [D loss: 0.652778, acc: 0.587891]: [A loss: 0.646277, acc: 0.656250]\n",
      "793: [D loss: 0.704497, acc: 0.541016]: [A loss: 1.208810, acc: 0.007812]\n",
      "794: [D loss: 0.649230, acc: 0.636719]: [A loss: 0.734256, acc: 0.453125]\n",
      "795: [D loss: 0.667055, acc: 0.568359]: [A loss: 1.106584, acc: 0.054688]\n",
      "796: [D loss: 0.658829, acc: 0.599609]: [A loss: 0.809159, acc: 0.289062]\n",
      "797: [D loss: 0.672238, acc: 0.564453]: [A loss: 1.076200, acc: 0.042969]\n",
      "798: [D loss: 0.650154, acc: 0.630859]: [A loss: 0.787632, acc: 0.367188]\n",
      "799: [D loss: 0.693727, acc: 0.517578]: [A loss: 1.232848, acc: 0.023438]\n",
      "800: [D loss: 0.661617, acc: 0.599609]: [A loss: 0.750289, acc: 0.402344]\n",
      "801: [D loss: 0.703202, acc: 0.535156]: [A loss: 1.306385, acc: 0.027344]\n",
      "802: [D loss: 0.665300, acc: 0.628906]: [A loss: 0.681944, acc: 0.578125]\n",
      "803: [D loss: 0.696874, acc: 0.535156]: [A loss: 1.234511, acc: 0.007812]\n",
      "804: [D loss: 0.654232, acc: 0.613281]: [A loss: 0.704342, acc: 0.511719]\n",
      "805: [D loss: 0.702223, acc: 0.527344]: [A loss: 1.211948, acc: 0.011719]\n",
      "806: [D loss: 0.663439, acc: 0.603516]: [A loss: 0.730490, acc: 0.398438]\n",
      "807: [D loss: 0.675284, acc: 0.572266]: [A loss: 1.120083, acc: 0.046875]\n",
      "808: [D loss: 0.646899, acc: 0.605469]: [A loss: 0.822376, acc: 0.304688]\n",
      "809: [D loss: 0.654521, acc: 0.597656]: [A loss: 1.128128, acc: 0.042969]\n",
      "810: [D loss: 0.646107, acc: 0.628906]: [A loss: 0.781469, acc: 0.355469]\n",
      "811: [D loss: 0.677506, acc: 0.556641]: [A loss: 1.270094, acc: 0.011719]\n",
      "812: [D loss: 0.656698, acc: 0.583984]: [A loss: 0.710355, acc: 0.484375]\n",
      "813: [D loss: 0.701165, acc: 0.550781]: [A loss: 1.282246, acc: 0.003906]\n",
      "814: [D loss: 0.655193, acc: 0.615234]: [A loss: 0.621018, acc: 0.683594]\n",
      "815: [D loss: 0.733000, acc: 0.519531]: [A loss: 1.316563, acc: 0.003906]\n",
      "816: [D loss: 0.674194, acc: 0.601562]: [A loss: 0.650613, acc: 0.628906]\n",
      "817: [D loss: 0.689489, acc: 0.556641]: [A loss: 1.117575, acc: 0.011719]\n",
      "818: [D loss: 0.652174, acc: 0.613281]: [A loss: 0.766504, acc: 0.355469]\n",
      "819: [D loss: 0.692648, acc: 0.542969]: [A loss: 1.084971, acc: 0.046875]\n",
      "820: [D loss: 0.661775, acc: 0.599609]: [A loss: 0.854295, acc: 0.234375]\n",
      "821: [D loss: 0.666598, acc: 0.574219]: [A loss: 1.069103, acc: 0.066406]\n",
      "822: [D loss: 0.652054, acc: 0.615234]: [A loss: 0.827203, acc: 0.265625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823: [D loss: 0.673689, acc: 0.552734]: [A loss: 1.065202, acc: 0.050781]\n",
      "824: [D loss: 0.649453, acc: 0.617188]: [A loss: 0.869004, acc: 0.265625]\n",
      "825: [D loss: 0.672446, acc: 0.560547]: [A loss: 1.162258, acc: 0.019531]\n",
      "826: [D loss: 0.651692, acc: 0.619141]: [A loss: 0.747043, acc: 0.429688]\n",
      "827: [D loss: 0.697418, acc: 0.548828]: [A loss: 1.384339, acc: 0.000000]\n",
      "828: [D loss: 0.652080, acc: 0.587891]: [A loss: 0.551316, acc: 0.812500]\n",
      "829: [D loss: 0.744694, acc: 0.503906]: [A loss: 1.256944, acc: 0.015625]\n",
      "830: [D loss: 0.650267, acc: 0.626953]: [A loss: 0.691346, acc: 0.523438]\n",
      "831: [D loss: 0.707302, acc: 0.535156]: [A loss: 1.085935, acc: 0.042969]\n",
      "832: [D loss: 0.666002, acc: 0.609375]: [A loss: 0.766158, acc: 0.371094]\n",
      "833: [D loss: 0.677091, acc: 0.566406]: [A loss: 1.096020, acc: 0.042969]\n",
      "834: [D loss: 0.646310, acc: 0.626953]: [A loss: 0.756608, acc: 0.398438]\n",
      "835: [D loss: 0.677390, acc: 0.574219]: [A loss: 1.146873, acc: 0.035156]\n",
      "836: [D loss: 0.641590, acc: 0.648438]: [A loss: 0.760151, acc: 0.386719]\n",
      "837: [D loss: 0.698049, acc: 0.554688]: [A loss: 1.220561, acc: 0.023438]\n",
      "838: [D loss: 0.655676, acc: 0.611328]: [A loss: 0.753764, acc: 0.457031]\n",
      "839: [D loss: 0.715093, acc: 0.511719]: [A loss: 1.253069, acc: 0.011719]\n",
      "840: [D loss: 0.658273, acc: 0.599609]: [A loss: 0.689678, acc: 0.511719]\n",
      "841: [D loss: 0.701708, acc: 0.533203]: [A loss: 1.200532, acc: 0.019531]\n",
      "842: [D loss: 0.657001, acc: 0.638672]: [A loss: 0.712500, acc: 0.500000]\n",
      "843: [D loss: 0.687817, acc: 0.552734]: [A loss: 1.138184, acc: 0.042969]\n",
      "844: [D loss: 0.652999, acc: 0.623047]: [A loss: 0.760325, acc: 0.394531]\n",
      "845: [D loss: 0.693232, acc: 0.539062]: [A loss: 1.173223, acc: 0.015625]\n",
      "846: [D loss: 0.654525, acc: 0.615234]: [A loss: 0.682295, acc: 0.562500]\n",
      "847: [D loss: 0.700952, acc: 0.539062]: [A loss: 1.219862, acc: 0.015625]\n",
      "848: [D loss: 0.651217, acc: 0.591797]: [A loss: 0.660114, acc: 0.609375]\n",
      "849: [D loss: 0.723076, acc: 0.523438]: [A loss: 1.188552, acc: 0.023438]\n",
      "850: [D loss: 0.669104, acc: 0.576172]: [A loss: 0.719679, acc: 0.453125]\n",
      "851: [D loss: 0.688607, acc: 0.552734]: [A loss: 1.005434, acc: 0.070312]\n",
      "852: [D loss: 0.657039, acc: 0.609375]: [A loss: 0.802252, acc: 0.300781]\n",
      "853: [D loss: 0.682841, acc: 0.582031]: [A loss: 1.133436, acc: 0.023438]\n",
      "854: [D loss: 0.655285, acc: 0.607422]: [A loss: 0.788717, acc: 0.300781]\n",
      "855: [D loss: 0.688752, acc: 0.558594]: [A loss: 1.094142, acc: 0.015625]\n",
      "856: [D loss: 0.657402, acc: 0.603516]: [A loss: 0.771643, acc: 0.355469]\n",
      "857: [D loss: 0.678187, acc: 0.558594]: [A loss: 1.161281, acc: 0.015625]\n",
      "858: [D loss: 0.667167, acc: 0.591797]: [A loss: 0.728072, acc: 0.460938]\n",
      "859: [D loss: 0.693418, acc: 0.544922]: [A loss: 1.206265, acc: 0.007812]\n",
      "860: [D loss: 0.662817, acc: 0.582031]: [A loss: 0.716671, acc: 0.457031]\n",
      "861: [D loss: 0.683278, acc: 0.529297]: [A loss: 1.142346, acc: 0.031250]\n",
      "862: [D loss: 0.645909, acc: 0.623047]: [A loss: 0.742426, acc: 0.449219]\n",
      "863: [D loss: 0.682752, acc: 0.554688]: [A loss: 1.228634, acc: 0.031250]\n",
      "864: [D loss: 0.655330, acc: 0.623047]: [A loss: 0.709464, acc: 0.449219]\n",
      "865: [D loss: 0.692264, acc: 0.537109]: [A loss: 1.283159, acc: 0.023438]\n",
      "866: [D loss: 0.639923, acc: 0.626953]: [A loss: 0.701392, acc: 0.496094]\n",
      "867: [D loss: 0.729133, acc: 0.519531]: [A loss: 1.304448, acc: 0.000000]\n",
      "868: [D loss: 0.674072, acc: 0.570312]: [A loss: 0.655225, acc: 0.625000]\n",
      "869: [D loss: 0.717588, acc: 0.509766]: [A loss: 1.117022, acc: 0.019531]\n",
      "870: [D loss: 0.664712, acc: 0.583984]: [A loss: 0.785607, acc: 0.324219]\n",
      "871: [D loss: 0.671131, acc: 0.560547]: [A loss: 1.003565, acc: 0.058594]\n",
      "872: [D loss: 0.663322, acc: 0.582031]: [A loss: 0.815849, acc: 0.281250]\n",
      "873: [D loss: 0.675995, acc: 0.591797]: [A loss: 1.076675, acc: 0.054688]\n",
      "874: [D loss: 0.663703, acc: 0.605469]: [A loss: 0.805649, acc: 0.292969]\n",
      "875: [D loss: 0.690204, acc: 0.558594]: [A loss: 1.077746, acc: 0.035156]\n",
      "876: [D loss: 0.659378, acc: 0.597656]: [A loss: 0.771459, acc: 0.359375]\n",
      "877: [D loss: 0.705292, acc: 0.548828]: [A loss: 1.144781, acc: 0.011719]\n",
      "878: [D loss: 0.667936, acc: 0.574219]: [A loss: 0.734444, acc: 0.410156]\n",
      "879: [D loss: 0.695024, acc: 0.529297]: [A loss: 1.182634, acc: 0.023438]\n",
      "880: [D loss: 0.662875, acc: 0.621094]: [A loss: 0.773361, acc: 0.363281]\n",
      "881: [D loss: 0.682549, acc: 0.546875]: [A loss: 1.139371, acc: 0.023438]\n",
      "882: [D loss: 0.648564, acc: 0.654297]: [A loss: 0.710472, acc: 0.480469]\n",
      "883: [D loss: 0.705058, acc: 0.529297]: [A loss: 1.208319, acc: 0.011719]\n",
      "884: [D loss: 0.648118, acc: 0.642578]: [A loss: 0.737496, acc: 0.449219]\n",
      "885: [D loss: 0.705265, acc: 0.529297]: [A loss: 1.194472, acc: 0.011719]\n",
      "886: [D loss: 0.666636, acc: 0.566406]: [A loss: 0.742419, acc: 0.421875]\n",
      "887: [D loss: 0.686946, acc: 0.533203]: [A loss: 1.111968, acc: 0.019531]\n",
      "888: [D loss: 0.659301, acc: 0.599609]: [A loss: 0.795726, acc: 0.320312]\n",
      "889: [D loss: 0.694841, acc: 0.550781]: [A loss: 1.147725, acc: 0.027344]\n",
      "890: [D loss: 0.656351, acc: 0.603516]: [A loss: 0.738458, acc: 0.390625]\n",
      "891: [D loss: 0.691599, acc: 0.550781]: [A loss: 1.219773, acc: 0.011719]\n",
      "892: [D loss: 0.661140, acc: 0.609375]: [A loss: 0.677048, acc: 0.585938]\n",
      "893: [D loss: 0.697916, acc: 0.541016]: [A loss: 1.148972, acc: 0.042969]\n",
      "894: [D loss: 0.671028, acc: 0.574219]: [A loss: 0.748637, acc: 0.371094]\n",
      "895: [D loss: 0.684366, acc: 0.533203]: [A loss: 1.012558, acc: 0.078125]\n",
      "896: [D loss: 0.670317, acc: 0.576172]: [A loss: 0.833222, acc: 0.261719]\n",
      "897: [D loss: 0.693206, acc: 0.542969]: [A loss: 1.057825, acc: 0.027344]\n",
      "898: [D loss: 0.665798, acc: 0.587891]: [A loss: 0.779234, acc: 0.343750]\n",
      "899: [D loss: 0.687029, acc: 0.556641]: [A loss: 1.158819, acc: 0.019531]\n",
      "900: [D loss: 0.664383, acc: 0.574219]: [A loss: 0.718154, acc: 0.437500]\n",
      "901: [D loss: 0.706196, acc: 0.542969]: [A loss: 1.127950, acc: 0.019531]\n",
      "902: [D loss: 0.659568, acc: 0.607422]: [A loss: 0.718710, acc: 0.453125]\n",
      "903: [D loss: 0.693434, acc: 0.554688]: [A loss: 1.129920, acc: 0.031250]\n",
      "904: [D loss: 0.655877, acc: 0.619141]: [A loss: 0.726441, acc: 0.433594]\n",
      "905: [D loss: 0.695490, acc: 0.550781]: [A loss: 1.117704, acc: 0.027344]\n",
      "906: [D loss: 0.661987, acc: 0.583984]: [A loss: 0.729414, acc: 0.464844]\n",
      "907: [D loss: 0.681994, acc: 0.560547]: [A loss: 1.117829, acc: 0.054688]\n",
      "908: [D loss: 0.664013, acc: 0.597656]: [A loss: 0.733446, acc: 0.457031]\n",
      "909: [D loss: 0.701346, acc: 0.562500]: [A loss: 1.211357, acc: 0.023438]\n",
      "910: [D loss: 0.661596, acc: 0.582031]: [A loss: 0.710576, acc: 0.503906]\n",
      "911: [D loss: 0.683293, acc: 0.531250]: [A loss: 1.093709, acc: 0.050781]\n",
      "912: [D loss: 0.667757, acc: 0.589844]: [A loss: 0.738160, acc: 0.398438]\n",
      "913: [D loss: 0.694681, acc: 0.539062]: [A loss: 1.089358, acc: 0.023438]\n",
      "914: [D loss: 0.650138, acc: 0.634766]: [A loss: 0.757018, acc: 0.371094]\n",
      "915: [D loss: 0.684015, acc: 0.552734]: [A loss: 1.141873, acc: 0.031250]\n",
      "916: [D loss: 0.656716, acc: 0.613281]: [A loss: 0.729830, acc: 0.437500]\n",
      "917: [D loss: 0.693689, acc: 0.544922]: [A loss: 1.091063, acc: 0.046875]\n",
      "918: [D loss: 0.660338, acc: 0.613281]: [A loss: 0.820279, acc: 0.281250]\n",
      "919: [D loss: 0.704438, acc: 0.513672]: [A loss: 1.136917, acc: 0.031250]\n",
      "920: [D loss: 0.663697, acc: 0.585938]: [A loss: 0.701088, acc: 0.500000]\n",
      "921: [D loss: 0.697967, acc: 0.542969]: [A loss: 1.188388, acc: 0.039062]\n",
      "922: [D loss: 0.654434, acc: 0.597656]: [A loss: 0.666130, acc: 0.597656]\n",
      "923: [D loss: 0.713895, acc: 0.521484]: [A loss: 1.210218, acc: 0.015625]\n",
      "924: [D loss: 0.663074, acc: 0.601562]: [A loss: 0.665265, acc: 0.601562]\n",
      "925: [D loss: 0.713109, acc: 0.529297]: [A loss: 1.075530, acc: 0.027344]\n",
      "926: [D loss: 0.647206, acc: 0.652344]: [A loss: 0.757086, acc: 0.390625]\n",
      "927: [D loss: 0.663435, acc: 0.568359]: [A loss: 1.051429, acc: 0.074219]\n",
      "928: [D loss: 0.660856, acc: 0.625000]: [A loss: 0.765576, acc: 0.359375]\n",
      "929: [D loss: 0.711043, acc: 0.535156]: [A loss: 1.135661, acc: 0.042969]\n",
      "930: [D loss: 0.665187, acc: 0.589844]: [A loss: 0.750083, acc: 0.414062]\n",
      "931: [D loss: 0.677311, acc: 0.546875]: [A loss: 1.092515, acc: 0.066406]\n",
      "932: [D loss: 0.656651, acc: 0.613281]: [A loss: 0.797958, acc: 0.347656]\n",
      "933: [D loss: 0.670378, acc: 0.572266]: [A loss: 1.044365, acc: 0.097656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934: [D loss: 0.650289, acc: 0.650391]: [A loss: 0.740186, acc: 0.410156]\n",
      "935: [D loss: 0.693163, acc: 0.568359]: [A loss: 1.099981, acc: 0.054688]\n",
      "936: [D loss: 0.659900, acc: 0.613281]: [A loss: 0.738055, acc: 0.476562]\n",
      "937: [D loss: 0.703162, acc: 0.550781]: [A loss: 1.247596, acc: 0.011719]\n",
      "938: [D loss: 0.671163, acc: 0.568359]: [A loss: 0.696542, acc: 0.546875]\n",
      "939: [D loss: 0.711603, acc: 0.529297]: [A loss: 1.168219, acc: 0.035156]\n",
      "940: [D loss: 0.667993, acc: 0.593750]: [A loss: 0.705677, acc: 0.480469]\n",
      "941: [D loss: 0.698237, acc: 0.523438]: [A loss: 1.057096, acc: 0.058594]\n",
      "942: [D loss: 0.664926, acc: 0.593750]: [A loss: 0.744716, acc: 0.402344]\n",
      "943: [D loss: 0.684943, acc: 0.560547]: [A loss: 1.057386, acc: 0.054688]\n",
      "944: [D loss: 0.656458, acc: 0.619141]: [A loss: 0.767639, acc: 0.378906]\n",
      "945: [D loss: 0.682270, acc: 0.544922]: [A loss: 1.095783, acc: 0.054688]\n",
      "946: [D loss: 0.649549, acc: 0.648438]: [A loss: 0.758112, acc: 0.378906]\n",
      "947: [D loss: 0.692718, acc: 0.552734]: [A loss: 1.095297, acc: 0.050781]\n",
      "948: [D loss: 0.655754, acc: 0.617188]: [A loss: 0.741951, acc: 0.460938]\n",
      "949: [D loss: 0.708309, acc: 0.535156]: [A loss: 1.203437, acc: 0.015625]\n",
      "950: [D loss: 0.661256, acc: 0.607422]: [A loss: 0.693402, acc: 0.554688]\n",
      "951: [D loss: 0.725065, acc: 0.503906]: [A loss: 1.173001, acc: 0.011719]\n",
      "952: [D loss: 0.668774, acc: 0.570312]: [A loss: 0.733106, acc: 0.437500]\n",
      "953: [D loss: 0.686000, acc: 0.546875]: [A loss: 1.109224, acc: 0.039062]\n",
      "954: [D loss: 0.664837, acc: 0.611328]: [A loss: 0.765055, acc: 0.355469]\n",
      "955: [D loss: 0.703363, acc: 0.548828]: [A loss: 1.144567, acc: 0.031250]\n",
      "956: [D loss: 0.674107, acc: 0.589844]: [A loss: 0.679999, acc: 0.558594]\n",
      "957: [D loss: 0.707241, acc: 0.535156]: [A loss: 1.120714, acc: 0.039062]\n",
      "958: [D loss: 0.674627, acc: 0.578125]: [A loss: 0.697710, acc: 0.542969]\n",
      "959: [D loss: 0.695983, acc: 0.554688]: [A loss: 1.041135, acc: 0.046875]\n",
      "960: [D loss: 0.662136, acc: 0.591797]: [A loss: 0.752690, acc: 0.414062]\n",
      "961: [D loss: 0.694696, acc: 0.546875]: [A loss: 1.101604, acc: 0.031250]\n",
      "962: [D loss: 0.651536, acc: 0.628906]: [A loss: 0.777270, acc: 0.351562]\n",
      "963: [D loss: 0.675479, acc: 0.556641]: [A loss: 1.052267, acc: 0.062500]\n",
      "964: [D loss: 0.662752, acc: 0.597656]: [A loss: 0.781187, acc: 0.355469]\n",
      "965: [D loss: 0.684945, acc: 0.539062]: [A loss: 1.110237, acc: 0.035156]\n",
      "966: [D loss: 0.668721, acc: 0.597656]: [A loss: 0.704463, acc: 0.480469]\n",
      "967: [D loss: 0.708845, acc: 0.523438]: [A loss: 1.124954, acc: 0.011719]\n",
      "968: [D loss: 0.673648, acc: 0.554688]: [A loss: 0.703639, acc: 0.507812]\n",
      "969: [D loss: 0.707349, acc: 0.537109]: [A loss: 1.104069, acc: 0.023438]\n",
      "970: [D loss: 0.662580, acc: 0.607422]: [A loss: 0.711554, acc: 0.472656]\n",
      "971: [D loss: 0.699980, acc: 0.546875]: [A loss: 1.074401, acc: 0.058594]\n",
      "972: [D loss: 0.666931, acc: 0.599609]: [A loss: 0.748795, acc: 0.410156]\n",
      "973: [D loss: 0.679050, acc: 0.560547]: [A loss: 1.054540, acc: 0.035156]\n",
      "974: [D loss: 0.670603, acc: 0.611328]: [A loss: 0.777925, acc: 0.355469]\n",
      "975: [D loss: 0.692680, acc: 0.542969]: [A loss: 1.029722, acc: 0.042969]\n",
      "976: [D loss: 0.659725, acc: 0.611328]: [A loss: 0.769839, acc: 0.414062]\n",
      "977: [D loss: 0.685423, acc: 0.548828]: [A loss: 1.036010, acc: 0.089844]\n",
      "978: [D loss: 0.662777, acc: 0.589844]: [A loss: 0.794444, acc: 0.292969]\n",
      "979: [D loss: 0.666573, acc: 0.589844]: [A loss: 1.076485, acc: 0.070312]\n",
      "980: [D loss: 0.667368, acc: 0.611328]: [A loss: 0.682980, acc: 0.550781]\n",
      "981: [D loss: 0.709480, acc: 0.527344]: [A loss: 1.208153, acc: 0.015625]\n",
      "982: [D loss: 0.676049, acc: 0.568359]: [A loss: 0.688875, acc: 0.546875]\n",
      "983: [D loss: 0.693412, acc: 0.541016]: [A loss: 1.034999, acc: 0.046875]\n",
      "984: [D loss: 0.655463, acc: 0.615234]: [A loss: 0.765287, acc: 0.363281]\n",
      "985: [D loss: 0.695391, acc: 0.544922]: [A loss: 1.153570, acc: 0.027344]\n",
      "986: [D loss: 0.673411, acc: 0.591797]: [A loss: 0.724870, acc: 0.500000]\n",
      "987: [D loss: 0.692734, acc: 0.546875]: [A loss: 1.067019, acc: 0.054688]\n",
      "988: [D loss: 0.666804, acc: 0.585938]: [A loss: 0.733110, acc: 0.437500]\n",
      "989: [D loss: 0.685499, acc: 0.548828]: [A loss: 1.001500, acc: 0.054688]\n",
      "990: [D loss: 0.668414, acc: 0.603516]: [A loss: 0.711661, acc: 0.484375]\n",
      "991: [D loss: 0.695504, acc: 0.535156]: [A loss: 1.099481, acc: 0.035156]\n",
      "992: [D loss: 0.663588, acc: 0.597656]: [A loss: 0.689649, acc: 0.527344]\n",
      "993: [D loss: 0.697008, acc: 0.539062]: [A loss: 1.088225, acc: 0.023438]\n",
      "994: [D loss: 0.668559, acc: 0.595703]: [A loss: 0.729176, acc: 0.441406]\n",
      "995: [D loss: 0.695413, acc: 0.529297]: [A loss: 1.070683, acc: 0.039062]\n",
      "996: [D loss: 0.666222, acc: 0.582031]: [A loss: 0.753954, acc: 0.410156]\n",
      "997: [D loss: 0.681003, acc: 0.556641]: [A loss: 1.019981, acc: 0.074219]\n",
      "998: [D loss: 0.665082, acc: 0.580078]: [A loss: 0.742196, acc: 0.402344]\n",
      "999: [D loss: 0.686147, acc: 0.546875]: [A loss: 1.025071, acc: 0.066406]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mnist_dcgan = MNIST_DCGAN()\n",
    "    mnist_dcgan.train(train_steps=1000, batch_size=256, save_interval=500)\n",
    "    mnist_dcgan.plot_images(fake=True)\n",
    "    mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [D loss: 0.664667, acc: 0.580078]: [A loss: 0.738886, acc: 0.429688]\n",
      "1: [D loss: 0.709825, acc: 0.531250]: [A loss: 1.130259, acc: 0.023438]\n",
      "2: [D loss: 0.668784, acc: 0.597656]: [A loss: 0.677219, acc: 0.558594]\n",
      "3: [D loss: 0.694586, acc: 0.525391]: [A loss: 1.096853, acc: 0.062500]\n",
      "4: [D loss: 0.653423, acc: 0.640625]: [A loss: 0.777022, acc: 0.320312]\n",
      "5: [D loss: 0.691917, acc: 0.556641]: [A loss: 1.023301, acc: 0.050781]\n",
      "6: [D loss: 0.654527, acc: 0.617188]: [A loss: 0.784455, acc: 0.332031]\n",
      "7: [D loss: 0.678461, acc: 0.554688]: [A loss: 1.029855, acc: 0.050781]\n",
      "8: [D loss: 0.664468, acc: 0.595703]: [A loss: 0.725829, acc: 0.468750]\n",
      "9: [D loss: 0.710644, acc: 0.525391]: [A loss: 1.082477, acc: 0.039062]\n",
      "10: [D loss: 0.672392, acc: 0.580078]: [A loss: 0.702425, acc: 0.535156]\n",
      "11: [D loss: 0.710547, acc: 0.529297]: [A loss: 1.089906, acc: 0.031250]\n",
      "12: [D loss: 0.673204, acc: 0.583984]: [A loss: 0.649436, acc: 0.667969]\n",
      "13: [D loss: 0.716384, acc: 0.527344]: [A loss: 1.075300, acc: 0.019531]\n",
      "14: [D loss: 0.677191, acc: 0.580078]: [A loss: 0.676214, acc: 0.562500]\n",
      "15: [D loss: 0.691872, acc: 0.542969]: [A loss: 1.026796, acc: 0.039062]\n",
      "16: [D loss: 0.670639, acc: 0.576172]: [A loss: 0.748270, acc: 0.410156]\n",
      "17: [D loss: 0.688109, acc: 0.572266]: [A loss: 0.983598, acc: 0.085938]\n",
      "18: [D loss: 0.666057, acc: 0.593750]: [A loss: 0.844316, acc: 0.218750]\n",
      "19: [D loss: 0.664248, acc: 0.595703]: [A loss: 0.943841, acc: 0.121094]\n",
      "20: [D loss: 0.674477, acc: 0.568359]: [A loss: 0.884940, acc: 0.214844]\n",
      "21: [D loss: 0.692356, acc: 0.554688]: [A loss: 0.968565, acc: 0.113281]\n",
      "22: [D loss: 0.656065, acc: 0.613281]: [A loss: 0.869687, acc: 0.195312]\n",
      "23: [D loss: 0.674302, acc: 0.576172]: [A loss: 0.998451, acc: 0.097656]\n",
      "24: [D loss: 0.667659, acc: 0.611328]: [A loss: 0.819694, acc: 0.246094]\n",
      "25: [D loss: 0.680702, acc: 0.544922]: [A loss: 0.983644, acc: 0.097656]\n",
      "26: [D loss: 0.691183, acc: 0.525391]: [A loss: 0.823799, acc: 0.261719]\n",
      "27: [D loss: 0.669144, acc: 0.564453]: [A loss: 1.004205, acc: 0.078125]\n",
      "28: [D loss: 0.664002, acc: 0.607422]: [A loss: 0.799218, acc: 0.320312]\n",
      "29: [D loss: 0.698038, acc: 0.556641]: [A loss: 1.107203, acc: 0.050781]\n",
      "30: [D loss: 0.674557, acc: 0.568359]: [A loss: 0.641881, acc: 0.609375]\n",
      "31: [D loss: 0.702137, acc: 0.537109]: [A loss: 1.181971, acc: 0.007812]\n",
      "32: [D loss: 0.672346, acc: 0.580078]: [A loss: 0.660006, acc: 0.582031]\n",
      "33: [D loss: 0.710707, acc: 0.535156]: [A loss: 1.027576, acc: 0.046875]\n",
      "34: [D loss: 0.667718, acc: 0.572266]: [A loss: 0.704580, acc: 0.507812]\n",
      "35: [D loss: 0.706406, acc: 0.517578]: [A loss: 1.023023, acc: 0.050781]\n",
      "36: [D loss: 0.665231, acc: 0.619141]: [A loss: 0.790707, acc: 0.269531]\n",
      "37: [D loss: 0.692154, acc: 0.544922]: [A loss: 1.026847, acc: 0.050781]\n",
      "38: [D loss: 0.662519, acc: 0.626953]: [A loss: 0.713210, acc: 0.445312]\n",
      "39: [D loss: 0.689414, acc: 0.556641]: [A loss: 1.101548, acc: 0.035156]\n",
      "40: [D loss: 0.649183, acc: 0.619141]: [A loss: 0.669766, acc: 0.578125]\n",
      "41: [D loss: 0.722324, acc: 0.539062]: [A loss: 1.117177, acc: 0.031250]\n",
      "42: [D loss: 0.676591, acc: 0.574219]: [A loss: 0.684002, acc: 0.507812]\n",
      "43: [D loss: 0.698198, acc: 0.533203]: [A loss: 1.053257, acc: 0.042969]\n",
      "44: [D loss: 0.659567, acc: 0.619141]: [A loss: 0.707782, acc: 0.496094]\n",
      "45: [D loss: 0.702567, acc: 0.542969]: [A loss: 0.984410, acc: 0.070312]\n",
      "46: [D loss: 0.669590, acc: 0.554688]: [A loss: 0.763829, acc: 0.363281]\n",
      "47: [D loss: 0.687302, acc: 0.556641]: [A loss: 0.996365, acc: 0.046875]\n",
      "48: [D loss: 0.667116, acc: 0.603516]: [A loss: 0.753931, acc: 0.382812]\n",
      "49: [D loss: 0.665521, acc: 0.583984]: [A loss: 1.087843, acc: 0.035156]\n",
      "50: [D loss: 0.657981, acc: 0.625000]: [A loss: 0.720447, acc: 0.468750]\n",
      "51: [D loss: 0.697961, acc: 0.548828]: [A loss: 1.109195, acc: 0.035156]\n",
      "52: [D loss: 0.668054, acc: 0.617188]: [A loss: 0.741919, acc: 0.406250]\n",
      "53: [D loss: 0.696725, acc: 0.525391]: [A loss: 1.037562, acc: 0.039062]\n",
      "54: [D loss: 0.655730, acc: 0.632812]: [A loss: 0.753992, acc: 0.351562]\n",
      "55: [D loss: 0.693897, acc: 0.572266]: [A loss: 1.101710, acc: 0.039062]\n",
      "56: [D loss: 0.671016, acc: 0.576172]: [A loss: 0.689432, acc: 0.531250]\n",
      "57: [D loss: 0.703293, acc: 0.529297]: [A loss: 1.039603, acc: 0.039062]\n",
      "58: [D loss: 0.643938, acc: 0.662109]: [A loss: 0.690964, acc: 0.546875]\n",
      "59: [D loss: 0.699341, acc: 0.533203]: [A loss: 1.106593, acc: 0.019531]\n",
      "60: [D loss: 0.667702, acc: 0.597656]: [A loss: 0.717665, acc: 0.472656]\n",
      "61: [D loss: 0.708061, acc: 0.537109]: [A loss: 1.036635, acc: 0.039062]\n",
      "62: [D loss: 0.666460, acc: 0.599609]: [A loss: 0.711919, acc: 0.511719]\n",
      "63: [D loss: 0.709332, acc: 0.523438]: [A loss: 1.010785, acc: 0.027344]\n",
      "64: [D loss: 0.678814, acc: 0.582031]: [A loss: 0.769501, acc: 0.316406]\n",
      "65: [D loss: 0.696391, acc: 0.529297]: [A loss: 0.927430, acc: 0.113281]\n",
      "66: [D loss: 0.656618, acc: 0.654297]: [A loss: 0.799222, acc: 0.308594]\n",
      "67: [D loss: 0.690681, acc: 0.533203]: [A loss: 1.017960, acc: 0.066406]\n",
      "68: [D loss: 0.673456, acc: 0.574219]: [A loss: 0.776813, acc: 0.328125]\n",
      "69: [D loss: 0.709593, acc: 0.523438]: [A loss: 0.980236, acc: 0.085938]\n",
      "70: [D loss: 0.662250, acc: 0.601562]: [A loss: 0.743271, acc: 0.398438]\n",
      "71: [D loss: 0.698395, acc: 0.539062]: [A loss: 1.019466, acc: 0.062500]\n",
      "72: [D loss: 0.655149, acc: 0.648438]: [A loss: 0.670520, acc: 0.562500]\n",
      "73: [D loss: 0.723216, acc: 0.539062]: [A loss: 1.082079, acc: 0.015625]\n",
      "74: [D loss: 0.674004, acc: 0.578125]: [A loss: 0.747568, acc: 0.386719]\n",
      "75: [D loss: 0.681350, acc: 0.552734]: [A loss: 0.949304, acc: 0.082031]\n",
      "76: [D loss: 0.666590, acc: 0.589844]: [A loss: 0.830117, acc: 0.253906]\n",
      "77: [D loss: 0.672973, acc: 0.570312]: [A loss: 1.014375, acc: 0.078125]\n",
      "78: [D loss: 0.668983, acc: 0.587891]: [A loss: 0.840649, acc: 0.222656]\n",
      "79: [D loss: 0.674348, acc: 0.539062]: [A loss: 0.959113, acc: 0.101562]\n",
      "80: [D loss: 0.691043, acc: 0.562500]: [A loss: 0.845470, acc: 0.199219]\n",
      "81: [D loss: 0.673205, acc: 0.599609]: [A loss: 0.950197, acc: 0.101562]\n",
      "82: [D loss: 0.664497, acc: 0.609375]: [A loss: 0.769975, acc: 0.367188]\n",
      "83: [D loss: 0.688045, acc: 0.539062]: [A loss: 1.252415, acc: 0.015625]\n",
      "84: [D loss: 0.669664, acc: 0.597656]: [A loss: 0.603843, acc: 0.742188]\n",
      "85: [D loss: 0.751871, acc: 0.505859]: [A loss: 1.181788, acc: 0.000000]\n",
      "86: [D loss: 0.687077, acc: 0.552734]: [A loss: 0.638284, acc: 0.656250]\n",
      "87: [D loss: 0.729297, acc: 0.492188]: [A loss: 0.917145, acc: 0.089844]\n",
      "88: [D loss: 0.682179, acc: 0.542969]: [A loss: 0.716413, acc: 0.464844]\n",
      "89: [D loss: 0.692183, acc: 0.550781]: [A loss: 0.928282, acc: 0.113281]\n",
      "90: [D loss: 0.672527, acc: 0.576172]: [A loss: 0.852019, acc: 0.195312]\n",
      "91: [D loss: 0.681911, acc: 0.562500]: [A loss: 0.900917, acc: 0.121094]\n",
      "92: [D loss: 0.673913, acc: 0.587891]: [A loss: 0.807582, acc: 0.277344]\n",
      "93: [D loss: 0.673346, acc: 0.601562]: [A loss: 0.909577, acc: 0.136719]\n",
      "94: [D loss: 0.668924, acc: 0.593750]: [A loss: 0.849256, acc: 0.238281]\n",
      "95: [D loss: 0.669764, acc: 0.607422]: [A loss: 0.932478, acc: 0.132812]\n",
      "96: [D loss: 0.684045, acc: 0.548828]: [A loss: 0.888341, acc: 0.167969]\n",
      "97: [D loss: 0.673638, acc: 0.574219]: [A loss: 0.939264, acc: 0.144531]\n",
      "98: [D loss: 0.681189, acc: 0.589844]: [A loss: 0.827579, acc: 0.246094]\n",
      "99: [D loss: 0.672228, acc: 0.585938]: [A loss: 0.976054, acc: 0.085938]\n",
      "100: [D loss: 0.670184, acc: 0.597656]: [A loss: 0.769015, acc: 0.312500]\n",
      "101: [D loss: 0.693089, acc: 0.539062]: [A loss: 1.132088, acc: 0.027344]\n",
      "102: [D loss: 0.673042, acc: 0.570312]: [A loss: 0.652621, acc: 0.644531]\n",
      "103: [D loss: 0.729495, acc: 0.503906]: [A loss: 1.183701, acc: 0.007812]\n",
      "104: [D loss: 0.684299, acc: 0.548828]: [A loss: 0.654211, acc: 0.648438]\n",
      "105: [D loss: 0.720869, acc: 0.533203]: [A loss: 1.042711, acc: 0.031250]\n",
      "106: [D loss: 0.679071, acc: 0.568359]: [A loss: 0.709642, acc: 0.507812]\n",
      "107: [D loss: 0.673655, acc: 0.556641]: [A loss: 0.928766, acc: 0.085938]\n",
      "108: [D loss: 0.666040, acc: 0.593750]: [A loss: 0.795341, acc: 0.316406]\n",
      "109: [D loss: 0.681152, acc: 0.585938]: [A loss: 0.963804, acc: 0.074219]\n",
      "110: [D loss: 0.676090, acc: 0.599609]: [A loss: 0.781177, acc: 0.324219]\n",
      "111: [D loss: 0.678641, acc: 0.564453]: [A loss: 1.005306, acc: 0.039062]\n",
      "112: [D loss: 0.656473, acc: 0.609375]: [A loss: 0.716835, acc: 0.484375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113: [D loss: 0.698848, acc: 0.533203]: [A loss: 1.126435, acc: 0.007812]\n",
      "114: [D loss: 0.673439, acc: 0.589844]: [A loss: 0.712643, acc: 0.441406]\n",
      "115: [D loss: 0.686743, acc: 0.546875]: [A loss: 1.008965, acc: 0.066406]\n",
      "116: [D loss: 0.679703, acc: 0.548828]: [A loss: 0.721410, acc: 0.464844]\n",
      "117: [D loss: 0.700700, acc: 0.539062]: [A loss: 1.097959, acc: 0.042969]\n",
      "118: [D loss: 0.665375, acc: 0.593750]: [A loss: 0.698667, acc: 0.531250]\n",
      "119: [D loss: 0.710357, acc: 0.537109]: [A loss: 1.099703, acc: 0.003906]\n",
      "120: [D loss: 0.679035, acc: 0.564453]: [A loss: 0.660332, acc: 0.562500]\n",
      "121: [D loss: 0.706958, acc: 0.541016]: [A loss: 1.017741, acc: 0.046875]\n",
      "122: [D loss: 0.688661, acc: 0.556641]: [A loss: 0.708966, acc: 0.484375]\n",
      "123: [D loss: 0.688581, acc: 0.560547]: [A loss: 0.904056, acc: 0.109375]\n",
      "124: [D loss: 0.682179, acc: 0.566406]: [A loss: 0.770041, acc: 0.320312]\n",
      "125: [D loss: 0.683242, acc: 0.566406]: [A loss: 0.892572, acc: 0.128906]\n",
      "126: [D loss: 0.671607, acc: 0.609375]: [A loss: 0.828496, acc: 0.234375]\n",
      "127: [D loss: 0.690539, acc: 0.550781]: [A loss: 0.909791, acc: 0.101562]\n",
      "128: [D loss: 0.674789, acc: 0.562500]: [A loss: 0.850522, acc: 0.199219]\n",
      "129: [D loss: 0.682178, acc: 0.564453]: [A loss: 0.846813, acc: 0.226562]\n",
      "130: [D loss: 0.680071, acc: 0.578125]: [A loss: 0.848334, acc: 0.183594]\n",
      "131: [D loss: 0.682146, acc: 0.566406]: [A loss: 0.782332, acc: 0.292969]\n",
      "132: [D loss: 0.683054, acc: 0.574219]: [A loss: 0.924380, acc: 0.082031]\n",
      "133: [D loss: 0.659912, acc: 0.626953]: [A loss: 0.775004, acc: 0.312500]\n",
      "134: [D loss: 0.685883, acc: 0.558594]: [A loss: 1.066451, acc: 0.042969]\n",
      "135: [D loss: 0.658577, acc: 0.615234]: [A loss: 0.654654, acc: 0.613281]\n",
      "136: [D loss: 0.723872, acc: 0.515625]: [A loss: 1.172232, acc: 0.015625]\n",
      "137: [D loss: 0.675814, acc: 0.591797]: [A loss: 0.645896, acc: 0.667969]\n",
      "138: [D loss: 0.711432, acc: 0.531250]: [A loss: 0.995826, acc: 0.046875]\n",
      "139: [D loss: 0.676223, acc: 0.582031]: [A loss: 0.768469, acc: 0.308594]\n",
      "140: [D loss: 0.683344, acc: 0.533203]: [A loss: 0.909126, acc: 0.121094]\n",
      "141: [D loss: 0.671241, acc: 0.585938]: [A loss: 0.781754, acc: 0.300781]\n",
      "142: [D loss: 0.688024, acc: 0.568359]: [A loss: 0.945208, acc: 0.101562]\n",
      "143: [D loss: 0.671998, acc: 0.585938]: [A loss: 0.782751, acc: 0.277344]\n",
      "144: [D loss: 0.685936, acc: 0.560547]: [A loss: 0.991013, acc: 0.058594]\n",
      "145: [D loss: 0.669948, acc: 0.593750]: [A loss: 0.712276, acc: 0.445312]\n",
      "146: [D loss: 0.681085, acc: 0.554688]: [A loss: 1.010232, acc: 0.042969]\n",
      "147: [D loss: 0.666994, acc: 0.626953]: [A loss: 0.697340, acc: 0.527344]\n",
      "148: [D loss: 0.715043, acc: 0.535156]: [A loss: 1.081498, acc: 0.031250]\n",
      "149: [D loss: 0.663959, acc: 0.609375]: [A loss: 0.673931, acc: 0.601562]\n",
      "150: [D loss: 0.708463, acc: 0.537109]: [A loss: 0.946129, acc: 0.078125]\n",
      "151: [D loss: 0.669420, acc: 0.580078]: [A loss: 0.785617, acc: 0.320312]\n",
      "152: [D loss: 0.691131, acc: 0.556641]: [A loss: 0.900673, acc: 0.156250]\n",
      "153: [D loss: 0.690317, acc: 0.546875]: [A loss: 0.821747, acc: 0.226562]\n",
      "154: [D loss: 0.679760, acc: 0.550781]: [A loss: 0.920248, acc: 0.117188]\n",
      "155: [D loss: 0.683532, acc: 0.562500]: [A loss: 0.831004, acc: 0.226562]\n",
      "156: [D loss: 0.689598, acc: 0.552734]: [A loss: 0.915441, acc: 0.125000]\n",
      "157: [D loss: 0.675677, acc: 0.576172]: [A loss: 0.737032, acc: 0.417969]\n",
      "158: [D loss: 0.698217, acc: 0.535156]: [A loss: 0.995813, acc: 0.054688]\n",
      "159: [D loss: 0.685367, acc: 0.556641]: [A loss: 0.779430, acc: 0.312500]\n",
      "160: [D loss: 0.685298, acc: 0.535156]: [A loss: 0.985804, acc: 0.046875]\n",
      "161: [D loss: 0.674686, acc: 0.589844]: [A loss: 0.738738, acc: 0.414062]\n",
      "162: [D loss: 0.711741, acc: 0.525391]: [A loss: 1.094924, acc: 0.023438]\n",
      "163: [D loss: 0.682632, acc: 0.564453]: [A loss: 0.662141, acc: 0.605469]\n",
      "164: [D loss: 0.708659, acc: 0.517578]: [A loss: 1.111012, acc: 0.023438]\n",
      "165: [D loss: 0.665271, acc: 0.591797]: [A loss: 0.653373, acc: 0.656250]\n",
      "166: [D loss: 0.708008, acc: 0.513672]: [A loss: 1.019068, acc: 0.046875]\n",
      "167: [D loss: 0.677540, acc: 0.580078]: [A loss: 0.677805, acc: 0.605469]\n",
      "168: [D loss: 0.697675, acc: 0.554688]: [A loss: 0.917324, acc: 0.097656]\n",
      "169: [D loss: 0.670008, acc: 0.576172]: [A loss: 0.763475, acc: 0.351562]\n",
      "170: [D loss: 0.697324, acc: 0.535156]: [A loss: 0.914202, acc: 0.101562]\n",
      "171: [D loss: 0.671730, acc: 0.595703]: [A loss: 0.785344, acc: 0.367188]\n",
      "172: [D loss: 0.682892, acc: 0.564453]: [A loss: 0.966092, acc: 0.093750]\n",
      "173: [D loss: 0.670677, acc: 0.574219]: [A loss: 0.732909, acc: 0.417969]\n",
      "174: [D loss: 0.685939, acc: 0.548828]: [A loss: 0.956164, acc: 0.074219]\n",
      "175: [D loss: 0.661968, acc: 0.625000]: [A loss: 0.786014, acc: 0.332031]\n",
      "176: [D loss: 0.689526, acc: 0.537109]: [A loss: 0.938859, acc: 0.105469]\n",
      "177: [D loss: 0.678393, acc: 0.558594]: [A loss: 0.736393, acc: 0.449219]\n",
      "178: [D loss: 0.701429, acc: 0.550781]: [A loss: 1.095766, acc: 0.031250]\n",
      "179: [D loss: 0.674859, acc: 0.583984]: [A loss: 0.658404, acc: 0.609375]\n",
      "180: [D loss: 0.707080, acc: 0.521484]: [A loss: 1.061069, acc: 0.031250]\n",
      "181: [D loss: 0.674473, acc: 0.574219]: [A loss: 0.691781, acc: 0.539062]\n",
      "182: [D loss: 0.685298, acc: 0.556641]: [A loss: 0.985613, acc: 0.058594]\n",
      "183: [D loss: 0.677572, acc: 0.564453]: [A loss: 0.750575, acc: 0.378906]\n",
      "184: [D loss: 0.706308, acc: 0.527344]: [A loss: 1.008370, acc: 0.039062]\n",
      "185: [D loss: 0.670471, acc: 0.574219]: [A loss: 0.722501, acc: 0.410156]\n",
      "186: [D loss: 0.693411, acc: 0.529297]: [A loss: 0.978353, acc: 0.070312]\n",
      "187: [D loss: 0.659614, acc: 0.634766]: [A loss: 0.706391, acc: 0.488281]\n",
      "188: [D loss: 0.699610, acc: 0.533203]: [A loss: 1.005540, acc: 0.050781]\n",
      "189: [D loss: 0.686832, acc: 0.558594]: [A loss: 0.744965, acc: 0.402344]\n",
      "190: [D loss: 0.690423, acc: 0.517578]: [A loss: 0.974398, acc: 0.035156]\n",
      "191: [D loss: 0.670864, acc: 0.560547]: [A loss: 0.722263, acc: 0.480469]\n",
      "192: [D loss: 0.684838, acc: 0.564453]: [A loss: 0.936431, acc: 0.113281]\n",
      "193: [D loss: 0.691173, acc: 0.544922]: [A loss: 0.785719, acc: 0.339844]\n",
      "194: [D loss: 0.687830, acc: 0.542969]: [A loss: 0.944828, acc: 0.093750]\n",
      "195: [D loss: 0.680497, acc: 0.558594]: [A loss: 0.790153, acc: 0.296875]\n",
      "196: [D loss: 0.676867, acc: 0.568359]: [A loss: 0.960191, acc: 0.089844]\n",
      "197: [D loss: 0.679326, acc: 0.568359]: [A loss: 0.743848, acc: 0.406250]\n",
      "198: [D loss: 0.687076, acc: 0.539062]: [A loss: 1.019845, acc: 0.058594]\n",
      "199: [D loss: 0.675887, acc: 0.572266]: [A loss: 0.653576, acc: 0.613281]\n",
      "200: [D loss: 0.704628, acc: 0.533203]: [A loss: 1.060843, acc: 0.019531]\n",
      "201: [D loss: 0.674322, acc: 0.568359]: [A loss: 0.637763, acc: 0.667969]\n",
      "202: [D loss: 0.699361, acc: 0.523438]: [A loss: 0.943776, acc: 0.074219]\n",
      "203: [D loss: 0.669876, acc: 0.583984]: [A loss: 0.716065, acc: 0.445312]\n",
      "204: [D loss: 0.700603, acc: 0.541016]: [A loss: 0.925119, acc: 0.089844]\n",
      "205: [D loss: 0.695704, acc: 0.525391]: [A loss: 0.752042, acc: 0.394531]\n",
      "206: [D loss: 0.687425, acc: 0.542969]: [A loss: 0.910329, acc: 0.093750]\n",
      "207: [D loss: 0.670230, acc: 0.587891]: [A loss: 0.782861, acc: 0.328125]\n",
      "208: [D loss: 0.679368, acc: 0.554688]: [A loss: 0.942472, acc: 0.093750]\n",
      "209: [D loss: 0.671019, acc: 0.576172]: [A loss: 0.753428, acc: 0.371094]\n",
      "210: [D loss: 0.680077, acc: 0.578125]: [A loss: 0.960862, acc: 0.082031]\n",
      "211: [D loss: 0.665087, acc: 0.591797]: [A loss: 0.775692, acc: 0.316406]\n",
      "212: [D loss: 0.710254, acc: 0.498047]: [A loss: 0.987949, acc: 0.070312]\n",
      "213: [D loss: 0.669401, acc: 0.601562]: [A loss: 0.751699, acc: 0.390625]\n",
      "214: [D loss: 0.695316, acc: 0.535156]: [A loss: 1.077825, acc: 0.027344]\n",
      "215: [D loss: 0.669410, acc: 0.580078]: [A loss: 0.666601, acc: 0.554688]\n",
      "216: [D loss: 0.710091, acc: 0.541016]: [A loss: 1.054975, acc: 0.035156]\n",
      "217: [D loss: 0.668818, acc: 0.568359]: [A loss: 0.670896, acc: 0.578125]\n",
      "218: [D loss: 0.695347, acc: 0.527344]: [A loss: 0.935786, acc: 0.089844]\n",
      "219: [D loss: 0.664241, acc: 0.617188]: [A loss: 0.706417, acc: 0.484375]\n",
      "220: [D loss: 0.701011, acc: 0.537109]: [A loss: 0.967222, acc: 0.085938]\n",
      "221: [D loss: 0.674470, acc: 0.568359]: [A loss: 0.748674, acc: 0.406250]\n",
      "222: [D loss: 0.677927, acc: 0.552734]: [A loss: 0.864685, acc: 0.156250]\n",
      "223: [D loss: 0.677836, acc: 0.582031]: [A loss: 0.791229, acc: 0.296875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224: [D loss: 0.676216, acc: 0.574219]: [A loss: 0.961161, acc: 0.093750]\n",
      "225: [D loss: 0.663110, acc: 0.621094]: [A loss: 0.770642, acc: 0.343750]\n",
      "226: [D loss: 0.676504, acc: 0.572266]: [A loss: 0.964865, acc: 0.066406]\n",
      "227: [D loss: 0.658549, acc: 0.613281]: [A loss: 0.712174, acc: 0.480469]\n",
      "228: [D loss: 0.699395, acc: 0.541016]: [A loss: 1.041339, acc: 0.019531]\n",
      "229: [D loss: 0.680081, acc: 0.537109]: [A loss: 0.728917, acc: 0.457031]\n",
      "230: [D loss: 0.712079, acc: 0.527344]: [A loss: 1.062457, acc: 0.031250]\n",
      "231: [D loss: 0.681764, acc: 0.546875]: [A loss: 0.669390, acc: 0.566406]\n",
      "232: [D loss: 0.718618, acc: 0.515625]: [A loss: 0.958899, acc: 0.093750]\n",
      "233: [D loss: 0.670645, acc: 0.589844]: [A loss: 0.719568, acc: 0.468750]\n",
      "234: [D loss: 0.704035, acc: 0.494141]: [A loss: 0.938947, acc: 0.093750]\n",
      "235: [D loss: 0.679908, acc: 0.568359]: [A loss: 0.777031, acc: 0.339844]\n",
      "236: [D loss: 0.680636, acc: 0.572266]: [A loss: 0.919896, acc: 0.105469]\n",
      "237: [D loss: 0.660661, acc: 0.619141]: [A loss: 0.764457, acc: 0.316406]\n",
      "238: [D loss: 0.692302, acc: 0.572266]: [A loss: 0.920556, acc: 0.117188]\n",
      "239: [D loss: 0.680584, acc: 0.558594]: [A loss: 0.792258, acc: 0.335938]\n",
      "240: [D loss: 0.669144, acc: 0.568359]: [A loss: 0.921612, acc: 0.093750]\n",
      "241: [D loss: 0.682273, acc: 0.562500]: [A loss: 0.766753, acc: 0.371094]\n",
      "242: [D loss: 0.705574, acc: 0.537109]: [A loss: 1.007274, acc: 0.039062]\n",
      "243: [D loss: 0.666302, acc: 0.611328]: [A loss: 0.664687, acc: 0.601562]\n",
      "244: [D loss: 0.715133, acc: 0.513672]: [A loss: 1.055358, acc: 0.019531]\n",
      "245: [D loss: 0.681355, acc: 0.554688]: [A loss: 0.705903, acc: 0.484375]\n",
      "246: [D loss: 0.697923, acc: 0.537109]: [A loss: 0.953810, acc: 0.066406]\n",
      "247: [D loss: 0.684375, acc: 0.539062]: [A loss: 0.663467, acc: 0.609375]\n",
      "248: [D loss: 0.689309, acc: 0.533203]: [A loss: 0.945147, acc: 0.109375]\n",
      "249: [D loss: 0.670161, acc: 0.593750]: [A loss: 0.698111, acc: 0.531250]\n",
      "250: [D loss: 0.703915, acc: 0.533203]: [A loss: 0.941064, acc: 0.078125]\n",
      "251: [D loss: 0.678927, acc: 0.552734]: [A loss: 0.743882, acc: 0.390625]\n",
      "252: [D loss: 0.682277, acc: 0.564453]: [A loss: 0.922664, acc: 0.113281]\n",
      "253: [D loss: 0.678620, acc: 0.574219]: [A loss: 0.748426, acc: 0.375000]\n",
      "254: [D loss: 0.701793, acc: 0.505859]: [A loss: 0.900445, acc: 0.128906]\n",
      "255: [D loss: 0.672960, acc: 0.583984]: [A loss: 0.794713, acc: 0.320312]\n",
      "256: [D loss: 0.693070, acc: 0.568359]: [A loss: 0.929978, acc: 0.101562]\n",
      "257: [D loss: 0.670997, acc: 0.585938]: [A loss: 0.818966, acc: 0.246094]\n",
      "258: [D loss: 0.690424, acc: 0.541016]: [A loss: 0.915270, acc: 0.113281]\n",
      "259: [D loss: 0.683457, acc: 0.564453]: [A loss: 0.795597, acc: 0.265625]\n",
      "260: [D loss: 0.683836, acc: 0.546875]: [A loss: 0.893393, acc: 0.144531]\n",
      "261: [D loss: 0.688565, acc: 0.535156]: [A loss: 0.822066, acc: 0.230469]\n",
      "262: [D loss: 0.684355, acc: 0.558594]: [A loss: 0.858971, acc: 0.222656]\n",
      "263: [D loss: 0.687377, acc: 0.554688]: [A loss: 0.779230, acc: 0.316406]\n",
      "264: [D loss: 0.695781, acc: 0.531250]: [A loss: 0.952020, acc: 0.097656]\n",
      "265: [D loss: 0.662264, acc: 0.613281]: [A loss: 0.712271, acc: 0.484375]\n",
      "266: [D loss: 0.695893, acc: 0.537109]: [A loss: 1.046678, acc: 0.042969]\n",
      "267: [D loss: 0.684661, acc: 0.542969]: [A loss: 0.645606, acc: 0.660156]\n",
      "268: [D loss: 0.719292, acc: 0.529297]: [A loss: 1.013867, acc: 0.062500]\n",
      "269: [D loss: 0.680526, acc: 0.542969]: [A loss: 0.696303, acc: 0.515625]\n",
      "270: [D loss: 0.690523, acc: 0.548828]: [A loss: 0.924679, acc: 0.105469]\n",
      "271: [D loss: 0.682724, acc: 0.568359]: [A loss: 0.791402, acc: 0.289062]\n",
      "272: [D loss: 0.691906, acc: 0.548828]: [A loss: 0.836925, acc: 0.207031]\n",
      "273: [D loss: 0.675724, acc: 0.591797]: [A loss: 0.829102, acc: 0.226562]\n",
      "274: [D loss: 0.671677, acc: 0.603516]: [A loss: 0.819737, acc: 0.269531]\n",
      "275: [D loss: 0.678568, acc: 0.558594]: [A loss: 0.889848, acc: 0.167969]\n",
      "276: [D loss: 0.674347, acc: 0.589844]: [A loss: 0.770561, acc: 0.277344]\n",
      "277: [D loss: 0.693015, acc: 0.527344]: [A loss: 0.912568, acc: 0.144531]\n",
      "278: [D loss: 0.684181, acc: 0.578125]: [A loss: 0.730035, acc: 0.433594]\n",
      "279: [D loss: 0.704800, acc: 0.537109]: [A loss: 1.010430, acc: 0.039062]\n",
      "280: [D loss: 0.670324, acc: 0.583984]: [A loss: 0.717165, acc: 0.488281]\n",
      "281: [D loss: 0.707531, acc: 0.541016]: [A loss: 1.002073, acc: 0.058594]\n",
      "282: [D loss: 0.670646, acc: 0.593750]: [A loss: 0.698975, acc: 0.523438]\n",
      "283: [D loss: 0.719733, acc: 0.519531]: [A loss: 0.963865, acc: 0.054688]\n",
      "284: [D loss: 0.689366, acc: 0.535156]: [A loss: 0.729711, acc: 0.445312]\n",
      "285: [D loss: 0.687171, acc: 0.539062]: [A loss: 0.843871, acc: 0.179688]\n",
      "286: [D loss: 0.685573, acc: 0.517578]: [A loss: 0.865299, acc: 0.156250]\n",
      "287: [D loss: 0.679003, acc: 0.576172]: [A loss: 0.776711, acc: 0.335938]\n",
      "288: [D loss: 0.686867, acc: 0.552734]: [A loss: 0.859402, acc: 0.156250]\n",
      "289: [D loss: 0.685964, acc: 0.552734]: [A loss: 0.817761, acc: 0.277344]\n",
      "290: [D loss: 0.671196, acc: 0.582031]: [A loss: 0.892037, acc: 0.160156]\n",
      "291: [D loss: 0.679086, acc: 0.556641]: [A loss: 0.718082, acc: 0.464844]\n",
      "292: [D loss: 0.691129, acc: 0.548828]: [A loss: 0.936990, acc: 0.089844]\n",
      "293: [D loss: 0.671831, acc: 0.568359]: [A loss: 0.817436, acc: 0.261719]\n",
      "294: [D loss: 0.684789, acc: 0.560547]: [A loss: 0.859565, acc: 0.195312]\n",
      "295: [D loss: 0.684186, acc: 0.562500]: [A loss: 0.825668, acc: 0.250000]\n",
      "296: [D loss: 0.679531, acc: 0.558594]: [A loss: 0.943128, acc: 0.117188]\n",
      "297: [D loss: 0.671645, acc: 0.576172]: [A loss: 0.698811, acc: 0.507812]\n",
      "298: [D loss: 0.690447, acc: 0.527344]: [A loss: 1.074693, acc: 0.023438]\n",
      "299: [D loss: 0.673562, acc: 0.578125]: [A loss: 0.630488, acc: 0.683594]\n",
      "300: [D loss: 0.720370, acc: 0.521484]: [A loss: 1.026859, acc: 0.023438]\n",
      "301: [D loss: 0.681745, acc: 0.548828]: [A loss: 0.692090, acc: 0.500000]\n",
      "302: [D loss: 0.700728, acc: 0.527344]: [A loss: 0.901405, acc: 0.160156]\n",
      "303: [D loss: 0.674435, acc: 0.578125]: [A loss: 0.790917, acc: 0.308594]\n",
      "304: [D loss: 0.683692, acc: 0.574219]: [A loss: 0.881000, acc: 0.187500]\n",
      "305: [D loss: 0.673265, acc: 0.589844]: [A loss: 0.857706, acc: 0.160156]\n",
      "306: [D loss: 0.670645, acc: 0.576172]: [A loss: 0.836969, acc: 0.210938]\n",
      "307: [D loss: 0.681865, acc: 0.564453]: [A loss: 0.845097, acc: 0.195312]\n",
      "308: [D loss: 0.687613, acc: 0.546875]: [A loss: 0.817652, acc: 0.226562]\n",
      "309: [D loss: 0.681809, acc: 0.566406]: [A loss: 0.889423, acc: 0.148438]\n",
      "310: [D loss: 0.673564, acc: 0.587891]: [A loss: 0.831145, acc: 0.246094]\n",
      "311: [D loss: 0.696587, acc: 0.541016]: [A loss: 0.836051, acc: 0.226562]\n",
      "312: [D loss: 0.684600, acc: 0.566406]: [A loss: 0.820763, acc: 0.281250]\n",
      "313: [D loss: 0.679087, acc: 0.580078]: [A loss: 0.958845, acc: 0.062500]\n",
      "314: [D loss: 0.675733, acc: 0.548828]: [A loss: 0.744629, acc: 0.402344]\n",
      "315: [D loss: 0.697607, acc: 0.541016]: [A loss: 1.005498, acc: 0.050781]\n",
      "316: [D loss: 0.704134, acc: 0.501953]: [A loss: 0.672025, acc: 0.570312]\n",
      "317: [D loss: 0.693457, acc: 0.539062]: [A loss: 0.967962, acc: 0.070312]\n",
      "318: [D loss: 0.676784, acc: 0.580078]: [A loss: 0.675115, acc: 0.578125]\n",
      "319: [D loss: 0.700736, acc: 0.535156]: [A loss: 0.917653, acc: 0.109375]\n",
      "320: [D loss: 0.684475, acc: 0.566406]: [A loss: 0.768459, acc: 0.320312]\n",
      "321: [D loss: 0.706873, acc: 0.523438]: [A loss: 0.955392, acc: 0.070312]\n",
      "322: [D loss: 0.677583, acc: 0.546875]: [A loss: 0.698553, acc: 0.511719]\n",
      "323: [D loss: 0.693181, acc: 0.539062]: [A loss: 0.902177, acc: 0.136719]\n",
      "324: [D loss: 0.677704, acc: 0.568359]: [A loss: 0.750963, acc: 0.375000]\n",
      "325: [D loss: 0.678699, acc: 0.582031]: [A loss: 0.936709, acc: 0.097656]\n",
      "326: [D loss: 0.676656, acc: 0.562500]: [A loss: 0.718180, acc: 0.484375]\n",
      "327: [D loss: 0.683865, acc: 0.552734]: [A loss: 0.882766, acc: 0.171875]\n",
      "328: [D loss: 0.665234, acc: 0.582031]: [A loss: 0.754915, acc: 0.386719]\n",
      "329: [D loss: 0.690486, acc: 0.533203]: [A loss: 0.911692, acc: 0.097656]\n",
      "330: [D loss: 0.679985, acc: 0.597656]: [A loss: 0.692655, acc: 0.550781]\n",
      "331: [D loss: 0.706184, acc: 0.564453]: [A loss: 0.942810, acc: 0.074219]\n",
      "332: [D loss: 0.685306, acc: 0.535156]: [A loss: 0.692318, acc: 0.523438]\n",
      "333: [D loss: 0.711613, acc: 0.535156]: [A loss: 1.044296, acc: 0.050781]\n",
      "334: [D loss: 0.671434, acc: 0.582031]: [A loss: 0.689568, acc: 0.500000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335: [D loss: 0.694730, acc: 0.509766]: [A loss: 0.918195, acc: 0.121094]\n",
      "336: [D loss: 0.684309, acc: 0.560547]: [A loss: 0.718226, acc: 0.464844]\n",
      "337: [D loss: 0.693532, acc: 0.542969]: [A loss: 0.903086, acc: 0.121094]\n",
      "338: [D loss: 0.685469, acc: 0.560547]: [A loss: 0.782159, acc: 0.347656]\n",
      "339: [D loss: 0.682215, acc: 0.537109]: [A loss: 0.839023, acc: 0.183594]\n",
      "340: [D loss: 0.687467, acc: 0.552734]: [A loss: 0.770488, acc: 0.312500]\n",
      "341: [D loss: 0.697475, acc: 0.550781]: [A loss: 0.873671, acc: 0.140625]\n",
      "342: [D loss: 0.686292, acc: 0.558594]: [A loss: 0.807855, acc: 0.242188]\n",
      "343: [D loss: 0.690493, acc: 0.523438]: [A loss: 0.882266, acc: 0.136719]\n",
      "344: [D loss: 0.684989, acc: 0.572266]: [A loss: 0.795613, acc: 0.265625]\n",
      "345: [D loss: 0.672818, acc: 0.556641]: [A loss: 0.854230, acc: 0.156250]\n",
      "346: [D loss: 0.675879, acc: 0.574219]: [A loss: 0.764557, acc: 0.339844]\n",
      "347: [D loss: 0.683092, acc: 0.558594]: [A loss: 0.890639, acc: 0.144531]\n",
      "348: [D loss: 0.672344, acc: 0.587891]: [A loss: 0.730337, acc: 0.449219]\n",
      "349: [D loss: 0.700597, acc: 0.517578]: [A loss: 0.956894, acc: 0.062500]\n",
      "350: [D loss: 0.676427, acc: 0.609375]: [A loss: 0.735630, acc: 0.398438]\n",
      "351: [D loss: 0.697946, acc: 0.537109]: [A loss: 0.931730, acc: 0.085938]\n",
      "352: [D loss: 0.686468, acc: 0.541016]: [A loss: 0.723214, acc: 0.429688]\n",
      "353: [D loss: 0.701705, acc: 0.537109]: [A loss: 0.944829, acc: 0.046875]\n",
      "354: [D loss: 0.677162, acc: 0.599609]: [A loss: 0.727697, acc: 0.429688]\n",
      "355: [D loss: 0.707668, acc: 0.521484]: [A loss: 0.995982, acc: 0.046875]\n",
      "356: [D loss: 0.679278, acc: 0.572266]: [A loss: 0.662125, acc: 0.613281]\n",
      "357: [D loss: 0.718320, acc: 0.503906]: [A loss: 0.939892, acc: 0.058594]\n",
      "358: [D loss: 0.683806, acc: 0.554688]: [A loss: 0.693100, acc: 0.546875]\n",
      "359: [D loss: 0.692668, acc: 0.539062]: [A loss: 0.965907, acc: 0.070312]\n",
      "360: [D loss: 0.681683, acc: 0.527344]: [A loss: 0.700288, acc: 0.468750]\n",
      "361: [D loss: 0.698135, acc: 0.537109]: [A loss: 0.936023, acc: 0.074219]\n",
      "362: [D loss: 0.683079, acc: 0.552734]: [A loss: 0.736751, acc: 0.406250]\n",
      "363: [D loss: 0.695186, acc: 0.544922]: [A loss: 0.898594, acc: 0.105469]\n",
      "364: [D loss: 0.669415, acc: 0.595703]: [A loss: 0.749543, acc: 0.363281]\n",
      "365: [D loss: 0.700851, acc: 0.496094]: [A loss: 0.932282, acc: 0.066406]\n",
      "366: [D loss: 0.684388, acc: 0.539062]: [A loss: 0.726457, acc: 0.417969]\n",
      "367: [D loss: 0.682698, acc: 0.541016]: [A loss: 0.901881, acc: 0.101562]\n",
      "368: [D loss: 0.675847, acc: 0.582031]: [A loss: 0.731740, acc: 0.417969]\n",
      "369: [D loss: 0.687029, acc: 0.548828]: [A loss: 0.880738, acc: 0.132812]\n",
      "370: [D loss: 0.684574, acc: 0.554688]: [A loss: 0.754813, acc: 0.367188]\n",
      "371: [D loss: 0.683146, acc: 0.582031]: [A loss: 0.871106, acc: 0.148438]\n",
      "372: [D loss: 0.677886, acc: 0.550781]: [A loss: 0.723559, acc: 0.460938]\n",
      "373: [D loss: 0.694368, acc: 0.525391]: [A loss: 0.909763, acc: 0.144531]\n",
      "374: [D loss: 0.692263, acc: 0.533203]: [A loss: 0.746660, acc: 0.390625]\n",
      "375: [D loss: 0.695950, acc: 0.533203]: [A loss: 0.898231, acc: 0.066406]\n",
      "376: [D loss: 0.689000, acc: 0.544922]: [A loss: 0.714776, acc: 0.460938]\n",
      "377: [D loss: 0.708561, acc: 0.515625]: [A loss: 0.970372, acc: 0.085938]\n",
      "378: [D loss: 0.691624, acc: 0.523438]: [A loss: 0.744485, acc: 0.398438]\n",
      "379: [D loss: 0.696646, acc: 0.535156]: [A loss: 0.897276, acc: 0.121094]\n",
      "380: [D loss: 0.683178, acc: 0.568359]: [A loss: 0.709597, acc: 0.496094]\n",
      "381: [D loss: 0.689522, acc: 0.521484]: [A loss: 0.879574, acc: 0.125000]\n",
      "382: [D loss: 0.696257, acc: 0.517578]: [A loss: 0.765295, acc: 0.335938]\n",
      "383: [D loss: 0.697431, acc: 0.546875]: [A loss: 0.899783, acc: 0.097656]\n",
      "384: [D loss: 0.684530, acc: 0.546875]: [A loss: 0.716772, acc: 0.464844]\n",
      "385: [D loss: 0.678932, acc: 0.574219]: [A loss: 0.828953, acc: 0.199219]\n",
      "386: [D loss: 0.679432, acc: 0.576172]: [A loss: 0.782270, acc: 0.304688]\n",
      "387: [D loss: 0.688079, acc: 0.560547]: [A loss: 0.779460, acc: 0.289062]\n",
      "388: [D loss: 0.687469, acc: 0.570312]: [A loss: 0.826090, acc: 0.207031]\n",
      "389: [D loss: 0.683363, acc: 0.546875]: [A loss: 0.852539, acc: 0.144531]\n",
      "390: [D loss: 0.684678, acc: 0.546875]: [A loss: 0.813194, acc: 0.242188]\n",
      "391: [D loss: 0.697625, acc: 0.533203]: [A loss: 0.920701, acc: 0.082031]\n",
      "392: [D loss: 0.684349, acc: 0.548828]: [A loss: 0.752358, acc: 0.363281]\n",
      "393: [D loss: 0.687561, acc: 0.572266]: [A loss: 0.868620, acc: 0.140625]\n",
      "394: [D loss: 0.682702, acc: 0.556641]: [A loss: 0.747319, acc: 0.390625]\n",
      "395: [D loss: 0.684666, acc: 0.546875]: [A loss: 0.897100, acc: 0.117188]\n",
      "396: [D loss: 0.672234, acc: 0.582031]: [A loss: 0.722445, acc: 0.429688]\n",
      "397: [D loss: 0.704448, acc: 0.544922]: [A loss: 0.992296, acc: 0.039062]\n",
      "398: [D loss: 0.691314, acc: 0.552734]: [A loss: 0.685045, acc: 0.535156]\n",
      "399: [D loss: 0.701222, acc: 0.527344]: [A loss: 0.966351, acc: 0.042969]\n",
      "400: [D loss: 0.680918, acc: 0.550781]: [A loss: 0.713735, acc: 0.425781]\n",
      "401: [D loss: 0.699390, acc: 0.531250]: [A loss: 0.937127, acc: 0.050781]\n",
      "402: [D loss: 0.686863, acc: 0.535156]: [A loss: 0.708437, acc: 0.476562]\n",
      "403: [D loss: 0.698014, acc: 0.535156]: [A loss: 0.906233, acc: 0.074219]\n",
      "404: [D loss: 0.674512, acc: 0.566406]: [A loss: 0.756943, acc: 0.308594]\n",
      "405: [D loss: 0.706356, acc: 0.511719]: [A loss: 0.914270, acc: 0.101562]\n",
      "406: [D loss: 0.696524, acc: 0.503906]: [A loss: 0.757207, acc: 0.324219]\n",
      "407: [D loss: 0.702772, acc: 0.523438]: [A loss: 0.919442, acc: 0.074219]\n",
      "408: [D loss: 0.671097, acc: 0.583984]: [A loss: 0.705074, acc: 0.500000]\n",
      "409: [D loss: 0.700515, acc: 0.525391]: [A loss: 0.920547, acc: 0.066406]\n",
      "410: [D loss: 0.681895, acc: 0.562500]: [A loss: 0.726070, acc: 0.441406]\n",
      "411: [D loss: 0.689273, acc: 0.558594]: [A loss: 0.842422, acc: 0.156250]\n",
      "412: [D loss: 0.678110, acc: 0.566406]: [A loss: 0.760594, acc: 0.339844]\n",
      "413: [D loss: 0.696049, acc: 0.539062]: [A loss: 0.927841, acc: 0.066406]\n",
      "414: [D loss: 0.682584, acc: 0.556641]: [A loss: 0.738731, acc: 0.394531]\n",
      "415: [D loss: 0.690570, acc: 0.539062]: [A loss: 0.879566, acc: 0.156250]\n",
      "416: [D loss: 0.682833, acc: 0.593750]: [A loss: 0.718956, acc: 0.445312]\n",
      "417: [D loss: 0.695929, acc: 0.525391]: [A loss: 0.881373, acc: 0.136719]\n",
      "418: [D loss: 0.677876, acc: 0.535156]: [A loss: 0.735579, acc: 0.421875]\n",
      "419: [D loss: 0.697301, acc: 0.509766]: [A loss: 0.960646, acc: 0.070312]\n",
      "420: [D loss: 0.682791, acc: 0.554688]: [A loss: 0.717747, acc: 0.445312]\n",
      "421: [D loss: 0.704087, acc: 0.527344]: [A loss: 0.905223, acc: 0.074219]\n",
      "422: [D loss: 0.685704, acc: 0.544922]: [A loss: 0.724227, acc: 0.433594]\n",
      "423: [D loss: 0.692350, acc: 0.542969]: [A loss: 0.885426, acc: 0.070312]\n",
      "424: [D loss: 0.679931, acc: 0.578125]: [A loss: 0.787422, acc: 0.285156]\n",
      "425: [D loss: 0.696399, acc: 0.531250]: [A loss: 0.870043, acc: 0.132812]\n",
      "426: [D loss: 0.673904, acc: 0.601562]: [A loss: 0.779382, acc: 0.316406]\n",
      "427: [D loss: 0.676303, acc: 0.562500]: [A loss: 0.844334, acc: 0.156250]\n",
      "428: [D loss: 0.682410, acc: 0.539062]: [A loss: 0.742813, acc: 0.417969]\n",
      "429: [D loss: 0.699453, acc: 0.541016]: [A loss: 0.938225, acc: 0.066406]\n",
      "430: [D loss: 0.677828, acc: 0.572266]: [A loss: 0.711730, acc: 0.468750]\n",
      "431: [D loss: 0.699859, acc: 0.550781]: [A loss: 0.935307, acc: 0.046875]\n",
      "432: [D loss: 0.683538, acc: 0.568359]: [A loss: 0.703238, acc: 0.511719]\n",
      "433: [D loss: 0.698871, acc: 0.537109]: [A loss: 0.931050, acc: 0.085938]\n",
      "434: [D loss: 0.684724, acc: 0.546875]: [A loss: 0.704288, acc: 0.503906]\n",
      "435: [D loss: 0.707378, acc: 0.527344]: [A loss: 0.957369, acc: 0.050781]\n",
      "436: [D loss: 0.690917, acc: 0.529297]: [A loss: 0.712337, acc: 0.480469]\n",
      "437: [D loss: 0.694725, acc: 0.548828]: [A loss: 0.942760, acc: 0.093750]\n",
      "438: [D loss: 0.693516, acc: 0.535156]: [A loss: 0.686544, acc: 0.492188]\n",
      "439: [D loss: 0.703783, acc: 0.519531]: [A loss: 0.891315, acc: 0.125000]\n",
      "440: [D loss: 0.686049, acc: 0.550781]: [A loss: 0.693973, acc: 0.480469]\n",
      "441: [D loss: 0.693246, acc: 0.533203]: [A loss: 0.864555, acc: 0.160156]\n",
      "442: [D loss: 0.677573, acc: 0.554688]: [A loss: 0.729217, acc: 0.433594]\n",
      "443: [D loss: 0.684308, acc: 0.550781]: [A loss: 0.854563, acc: 0.171875]\n",
      "444: [D loss: 0.681340, acc: 0.578125]: [A loss: 0.796065, acc: 0.269531]\n",
      "445: [D loss: 0.684749, acc: 0.562500]: [A loss: 0.837152, acc: 0.191406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446: [D loss: 0.685254, acc: 0.568359]: [A loss: 0.805585, acc: 0.253906]\n",
      "447: [D loss: 0.680180, acc: 0.570312]: [A loss: 0.857998, acc: 0.167969]\n",
      "448: [D loss: 0.676981, acc: 0.574219]: [A loss: 0.800767, acc: 0.281250]\n",
      "449: [D loss: 0.690243, acc: 0.552734]: [A loss: 0.874400, acc: 0.156250]\n",
      "450: [D loss: 0.697071, acc: 0.517578]: [A loss: 0.830940, acc: 0.238281]\n",
      "451: [D loss: 0.692224, acc: 0.541016]: [A loss: 0.854503, acc: 0.132812]\n",
      "452: [D loss: 0.676824, acc: 0.578125]: [A loss: 0.815865, acc: 0.218750]\n",
      "453: [D loss: 0.685402, acc: 0.562500]: [A loss: 0.847163, acc: 0.195312]\n",
      "454: [D loss: 0.691569, acc: 0.548828]: [A loss: 0.798360, acc: 0.277344]\n",
      "455: [D loss: 0.677389, acc: 0.556641]: [A loss: 0.910719, acc: 0.117188]\n",
      "456: [D loss: 0.703947, acc: 0.505859]: [A loss: 0.747044, acc: 0.363281]\n",
      "457: [D loss: 0.709537, acc: 0.488281]: [A loss: 0.983266, acc: 0.050781]\n",
      "458: [D loss: 0.684399, acc: 0.544922]: [A loss: 0.629595, acc: 0.703125]\n",
      "459: [D loss: 0.720365, acc: 0.521484]: [A loss: 0.991446, acc: 0.046875]\n",
      "460: [D loss: 0.680278, acc: 0.550781]: [A loss: 0.680628, acc: 0.539062]\n",
      "461: [D loss: 0.695014, acc: 0.519531]: [A loss: 0.832512, acc: 0.171875]\n",
      "462: [D loss: 0.679933, acc: 0.556641]: [A loss: 0.728996, acc: 0.421875]\n",
      "463: [D loss: 0.684195, acc: 0.558594]: [A loss: 0.826042, acc: 0.207031]\n",
      "464: [D loss: 0.697603, acc: 0.505859]: [A loss: 0.809895, acc: 0.218750]\n",
      "465: [D loss: 0.682898, acc: 0.574219]: [A loss: 0.810558, acc: 0.238281]\n",
      "466: [D loss: 0.675832, acc: 0.585938]: [A loss: 0.761457, acc: 0.359375]\n",
      "467: [D loss: 0.677794, acc: 0.544922]: [A loss: 0.764166, acc: 0.335938]\n",
      "468: [D loss: 0.691987, acc: 0.560547]: [A loss: 0.855735, acc: 0.164062]\n",
      "469: [D loss: 0.679649, acc: 0.582031]: [A loss: 0.767264, acc: 0.335938]\n",
      "470: [D loss: 0.704020, acc: 0.525391]: [A loss: 0.895246, acc: 0.109375]\n",
      "471: [D loss: 0.695836, acc: 0.541016]: [A loss: 0.764937, acc: 0.363281]\n",
      "472: [D loss: 0.682398, acc: 0.560547]: [A loss: 0.848282, acc: 0.171875]\n",
      "473: [D loss: 0.687350, acc: 0.554688]: [A loss: 0.765613, acc: 0.335938]\n",
      "474: [D loss: 0.695370, acc: 0.525391]: [A loss: 0.914478, acc: 0.121094]\n",
      "475: [D loss: 0.686864, acc: 0.546875]: [A loss: 0.715489, acc: 0.453125]\n",
      "476: [D loss: 0.699754, acc: 0.523438]: [A loss: 0.930821, acc: 0.070312]\n",
      "477: [D loss: 0.677365, acc: 0.566406]: [A loss: 0.679801, acc: 0.546875]\n",
      "478: [D loss: 0.703841, acc: 0.519531]: [A loss: 0.934958, acc: 0.078125]\n",
      "479: [D loss: 0.683114, acc: 0.558594]: [A loss: 0.659942, acc: 0.617188]\n",
      "480: [D loss: 0.693367, acc: 0.525391]: [A loss: 0.835995, acc: 0.164062]\n",
      "481: [D loss: 0.684382, acc: 0.550781]: [A loss: 0.740430, acc: 0.406250]\n",
      "482: [D loss: 0.684596, acc: 0.535156]: [A loss: 0.833368, acc: 0.183594]\n",
      "483: [D loss: 0.671312, acc: 0.574219]: [A loss: 0.760057, acc: 0.347656]\n",
      "484: [D loss: 0.685023, acc: 0.560547]: [A loss: 0.870211, acc: 0.171875]\n",
      "485: [D loss: 0.690107, acc: 0.558594]: [A loss: 0.764057, acc: 0.296875]\n",
      "486: [D loss: 0.685643, acc: 0.556641]: [A loss: 0.821325, acc: 0.234375]\n",
      "487: [D loss: 0.681175, acc: 0.578125]: [A loss: 0.812260, acc: 0.222656]\n",
      "488: [D loss: 0.698816, acc: 0.541016]: [A loss: 0.855173, acc: 0.164062]\n",
      "489: [D loss: 0.684150, acc: 0.578125]: [A loss: 0.733686, acc: 0.421875]\n",
      "490: [D loss: 0.701099, acc: 0.523438]: [A loss: 0.931954, acc: 0.050781]\n",
      "491: [D loss: 0.689284, acc: 0.529297]: [A loss: 0.691275, acc: 0.519531]\n",
      "492: [D loss: 0.699194, acc: 0.527344]: [A loss: 0.906291, acc: 0.113281]\n",
      "493: [D loss: 0.695459, acc: 0.525391]: [A loss: 0.700090, acc: 0.519531]\n",
      "494: [D loss: 0.699066, acc: 0.523438]: [A loss: 0.849168, acc: 0.164062]\n",
      "495: [D loss: 0.684106, acc: 0.554688]: [A loss: 0.744780, acc: 0.382812]\n",
      "496: [D loss: 0.700277, acc: 0.535156]: [A loss: 0.872347, acc: 0.144531]\n",
      "497: [D loss: 0.683136, acc: 0.562500]: [A loss: 0.761857, acc: 0.339844]\n",
      "498: [D loss: 0.680914, acc: 0.537109]: [A loss: 0.860530, acc: 0.128906]\n",
      "499: [D loss: 0.680380, acc: 0.576172]: [A loss: 0.779711, acc: 0.281250]\n",
      "500: [D loss: 0.686080, acc: 0.541016]: [A loss: 0.844754, acc: 0.148438]\n",
      "501: [D loss: 0.694572, acc: 0.548828]: [A loss: 0.785469, acc: 0.253906]\n",
      "502: [D loss: 0.679152, acc: 0.554688]: [A loss: 0.791461, acc: 0.269531]\n",
      "503: [D loss: 0.672361, acc: 0.587891]: [A loss: 0.760823, acc: 0.324219]\n",
      "504: [D loss: 0.688085, acc: 0.550781]: [A loss: 0.868387, acc: 0.160156]\n",
      "505: [D loss: 0.694808, acc: 0.531250]: [A loss: 0.816466, acc: 0.246094]\n",
      "506: [D loss: 0.691478, acc: 0.544922]: [A loss: 0.855625, acc: 0.160156]\n",
      "507: [D loss: 0.684034, acc: 0.539062]: [A loss: 0.759674, acc: 0.355469]\n",
      "508: [D loss: 0.697178, acc: 0.552734]: [A loss: 0.908805, acc: 0.109375]\n",
      "509: [D loss: 0.682175, acc: 0.544922]: [A loss: 0.697988, acc: 0.546875]\n",
      "510: [D loss: 0.697610, acc: 0.552734]: [A loss: 0.920306, acc: 0.097656]\n",
      "511: [D loss: 0.683815, acc: 0.548828]: [A loss: 0.668024, acc: 0.574219]\n",
      "512: [D loss: 0.700609, acc: 0.548828]: [A loss: 0.913476, acc: 0.085938]\n",
      "513: [D loss: 0.683967, acc: 0.519531]: [A loss: 0.714909, acc: 0.464844]\n",
      "514: [D loss: 0.704928, acc: 0.537109]: [A loss: 0.979940, acc: 0.050781]\n",
      "515: [D loss: 0.682034, acc: 0.552734]: [A loss: 0.722806, acc: 0.410156]\n",
      "516: [D loss: 0.696221, acc: 0.556641]: [A loss: 0.897462, acc: 0.062500]\n",
      "517: [D loss: 0.680465, acc: 0.574219]: [A loss: 0.705586, acc: 0.472656]\n",
      "518: [D loss: 0.692834, acc: 0.537109]: [A loss: 0.863169, acc: 0.125000]\n",
      "519: [D loss: 0.689655, acc: 0.548828]: [A loss: 0.735994, acc: 0.386719]\n",
      "520: [D loss: 0.682371, acc: 0.556641]: [A loss: 0.840374, acc: 0.164062]\n",
      "521: [D loss: 0.681390, acc: 0.578125]: [A loss: 0.763588, acc: 0.355469]\n",
      "522: [D loss: 0.691339, acc: 0.550781]: [A loss: 0.811351, acc: 0.250000]\n",
      "523: [D loss: 0.702256, acc: 0.548828]: [A loss: 0.849124, acc: 0.171875]\n",
      "524: [D loss: 0.680542, acc: 0.570312]: [A loss: 0.747466, acc: 0.390625]\n",
      "525: [D loss: 0.700120, acc: 0.523438]: [A loss: 0.921809, acc: 0.089844]\n",
      "526: [D loss: 0.681046, acc: 0.585938]: [A loss: 0.720873, acc: 0.437500]\n",
      "527: [D loss: 0.706741, acc: 0.523438]: [A loss: 0.937570, acc: 0.066406]\n",
      "528: [D loss: 0.683129, acc: 0.544922]: [A loss: 0.711596, acc: 0.464844]\n",
      "529: [D loss: 0.703428, acc: 0.519531]: [A loss: 0.869565, acc: 0.136719]\n",
      "530: [D loss: 0.696018, acc: 0.513672]: [A loss: 0.763599, acc: 0.355469]\n",
      "531: [D loss: 0.693578, acc: 0.537109]: [A loss: 0.867299, acc: 0.164062]\n",
      "532: [D loss: 0.676265, acc: 0.589844]: [A loss: 0.731855, acc: 0.406250]\n",
      "533: [D loss: 0.690199, acc: 0.531250]: [A loss: 0.869906, acc: 0.140625]\n",
      "534: [D loss: 0.687957, acc: 0.541016]: [A loss: 0.749535, acc: 0.347656]\n",
      "535: [D loss: 0.681433, acc: 0.550781]: [A loss: 0.864468, acc: 0.125000]\n",
      "536: [D loss: 0.689031, acc: 0.527344]: [A loss: 0.734544, acc: 0.394531]\n",
      "537: [D loss: 0.704180, acc: 0.541016]: [A loss: 0.856689, acc: 0.128906]\n",
      "538: [D loss: 0.686829, acc: 0.550781]: [A loss: 0.746170, acc: 0.378906]\n",
      "539: [D loss: 0.702822, acc: 0.519531]: [A loss: 0.875275, acc: 0.128906]\n",
      "540: [D loss: 0.688487, acc: 0.548828]: [A loss: 0.726378, acc: 0.441406]\n",
      "541: [D loss: 0.704306, acc: 0.525391]: [A loss: 0.871791, acc: 0.128906]\n",
      "542: [D loss: 0.672292, acc: 0.572266]: [A loss: 0.704813, acc: 0.484375]\n",
      "543: [D loss: 0.701482, acc: 0.535156]: [A loss: 0.931130, acc: 0.074219]\n",
      "544: [D loss: 0.689647, acc: 0.556641]: [A loss: 0.694735, acc: 0.519531]\n",
      "545: [D loss: 0.696278, acc: 0.509766]: [A loss: 0.838454, acc: 0.156250]\n",
      "546: [D loss: 0.676257, acc: 0.574219]: [A loss: 0.721528, acc: 0.460938]\n",
      "547: [D loss: 0.704096, acc: 0.529297]: [A loss: 0.878356, acc: 0.125000]\n",
      "548: [D loss: 0.696064, acc: 0.529297]: [A loss: 0.717746, acc: 0.421875]\n",
      "549: [D loss: 0.692998, acc: 0.548828]: [A loss: 0.835722, acc: 0.171875]\n",
      "550: [D loss: 0.688979, acc: 0.537109]: [A loss: 0.745394, acc: 0.363281]\n",
      "551: [D loss: 0.688221, acc: 0.541016]: [A loss: 0.863889, acc: 0.132812]\n",
      "552: [D loss: 0.690443, acc: 0.542969]: [A loss: 0.741082, acc: 0.410156]\n",
      "553: [D loss: 0.697626, acc: 0.527344]: [A loss: 0.831918, acc: 0.148438]\n",
      "554: [D loss: 0.670796, acc: 0.587891]: [A loss: 0.713435, acc: 0.457031]\n",
      "555: [D loss: 0.690271, acc: 0.550781]: [A loss: 0.889139, acc: 0.101562]\n",
      "556: [D loss: 0.685478, acc: 0.562500]: [A loss: 0.704037, acc: 0.484375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557: [D loss: 0.702536, acc: 0.517578]: [A loss: 0.913345, acc: 0.085938]\n",
      "558: [D loss: 0.693369, acc: 0.544922]: [A loss: 0.692206, acc: 0.507812]\n",
      "559: [D loss: 0.691843, acc: 0.531250]: [A loss: 0.865289, acc: 0.125000]\n",
      "560: [D loss: 0.680789, acc: 0.570312]: [A loss: 0.774914, acc: 0.308594]\n",
      "561: [D loss: 0.694040, acc: 0.558594]: [A loss: 0.843089, acc: 0.167969]\n",
      "562: [D loss: 0.690867, acc: 0.529297]: [A loss: 0.751413, acc: 0.359375]\n",
      "563: [D loss: 0.696586, acc: 0.531250]: [A loss: 0.804449, acc: 0.207031]\n",
      "564: [D loss: 0.691144, acc: 0.517578]: [A loss: 0.756817, acc: 0.355469]\n",
      "565: [D loss: 0.690360, acc: 0.554688]: [A loss: 0.833992, acc: 0.203125]\n",
      "566: [D loss: 0.691373, acc: 0.535156]: [A loss: 0.785807, acc: 0.292969]\n",
      "567: [D loss: 0.686565, acc: 0.527344]: [A loss: 0.865078, acc: 0.140625]\n",
      "568: [D loss: 0.681091, acc: 0.535156]: [A loss: 0.768031, acc: 0.320312]\n",
      "569: [D loss: 0.689005, acc: 0.548828]: [A loss: 0.905785, acc: 0.101562]\n",
      "570: [D loss: 0.686120, acc: 0.570312]: [A loss: 0.710169, acc: 0.488281]\n",
      "571: [D loss: 0.694311, acc: 0.546875]: [A loss: 0.904831, acc: 0.074219]\n",
      "572: [D loss: 0.676549, acc: 0.597656]: [A loss: 0.708076, acc: 0.480469]\n",
      "573: [D loss: 0.699066, acc: 0.511719]: [A loss: 0.885336, acc: 0.109375]\n",
      "574: [D loss: 0.684052, acc: 0.558594]: [A loss: 0.753214, acc: 0.312500]\n",
      "575: [D loss: 0.706187, acc: 0.523438]: [A loss: 0.868830, acc: 0.140625]\n",
      "576: [D loss: 0.701017, acc: 0.484375]: [A loss: 0.748406, acc: 0.417969]\n",
      "577: [D loss: 0.704827, acc: 0.507812]: [A loss: 0.883801, acc: 0.125000]\n",
      "578: [D loss: 0.675619, acc: 0.564453]: [A loss: 0.765289, acc: 0.308594]\n",
      "579: [D loss: 0.678166, acc: 0.582031]: [A loss: 0.851998, acc: 0.171875]\n",
      "580: [D loss: 0.691839, acc: 0.548828]: [A loss: 0.704820, acc: 0.472656]\n",
      "581: [D loss: 0.699923, acc: 0.541016]: [A loss: 0.919277, acc: 0.097656]\n",
      "582: [D loss: 0.685119, acc: 0.535156]: [A loss: 0.686994, acc: 0.523438]\n",
      "583: [D loss: 0.695875, acc: 0.527344]: [A loss: 0.901055, acc: 0.097656]\n",
      "584: [D loss: 0.687666, acc: 0.535156]: [A loss: 0.709713, acc: 0.457031]\n",
      "585: [D loss: 0.699832, acc: 0.535156]: [A loss: 0.806140, acc: 0.226562]\n",
      "586: [D loss: 0.697059, acc: 0.525391]: [A loss: 0.779734, acc: 0.261719]\n",
      "587: [D loss: 0.681877, acc: 0.578125]: [A loss: 0.800509, acc: 0.222656]\n",
      "588: [D loss: 0.697617, acc: 0.525391]: [A loss: 0.760490, acc: 0.335938]\n",
      "589: [D loss: 0.682144, acc: 0.544922]: [A loss: 0.819770, acc: 0.167969]\n",
      "590: [D loss: 0.681317, acc: 0.558594]: [A loss: 0.754583, acc: 0.371094]\n",
      "591: [D loss: 0.699522, acc: 0.542969]: [A loss: 0.913173, acc: 0.097656]\n",
      "592: [D loss: 0.678098, acc: 0.562500]: [A loss: 0.705530, acc: 0.484375]\n",
      "593: [D loss: 0.705562, acc: 0.519531]: [A loss: 0.936028, acc: 0.085938]\n",
      "594: [D loss: 0.677822, acc: 0.552734]: [A loss: 0.713745, acc: 0.449219]\n",
      "595: [D loss: 0.707593, acc: 0.521484]: [A loss: 0.920568, acc: 0.082031]\n",
      "596: [D loss: 0.680170, acc: 0.576172]: [A loss: 0.723474, acc: 0.437500]\n",
      "597: [D loss: 0.697317, acc: 0.535156]: [A loss: 0.864560, acc: 0.128906]\n",
      "598: [D loss: 0.683803, acc: 0.564453]: [A loss: 0.707819, acc: 0.457031]\n",
      "599: [D loss: 0.686427, acc: 0.531250]: [A loss: 0.866062, acc: 0.167969]\n",
      "600: [D loss: 0.685544, acc: 0.554688]: [A loss: 0.709001, acc: 0.445312]\n",
      "601: [D loss: 0.688788, acc: 0.560547]: [A loss: 0.859443, acc: 0.152344]\n",
      "602: [D loss: 0.692813, acc: 0.523438]: [A loss: 0.702994, acc: 0.460938]\n",
      "603: [D loss: 0.691842, acc: 0.552734]: [A loss: 0.848961, acc: 0.164062]\n",
      "604: [D loss: 0.680106, acc: 0.550781]: [A loss: 0.729175, acc: 0.402344]\n",
      "605: [D loss: 0.703693, acc: 0.515625]: [A loss: 0.809133, acc: 0.234375]\n",
      "606: [D loss: 0.695483, acc: 0.517578]: [A loss: 0.731577, acc: 0.402344]\n",
      "607: [D loss: 0.689303, acc: 0.552734]: [A loss: 0.812408, acc: 0.234375]\n",
      "608: [D loss: 0.694199, acc: 0.529297]: [A loss: 0.803945, acc: 0.289062]\n",
      "609: [D loss: 0.681365, acc: 0.566406]: [A loss: 0.807988, acc: 0.214844]\n",
      "610: [D loss: 0.685383, acc: 0.574219]: [A loss: 0.753849, acc: 0.351562]\n",
      "611: [D loss: 0.695632, acc: 0.525391]: [A loss: 0.843925, acc: 0.152344]\n",
      "612: [D loss: 0.689381, acc: 0.542969]: [A loss: 0.766865, acc: 0.289062]\n",
      "613: [D loss: 0.685599, acc: 0.552734]: [A loss: 0.772510, acc: 0.328125]\n",
      "614: [D loss: 0.686700, acc: 0.529297]: [A loss: 0.761715, acc: 0.304688]\n",
      "615: [D loss: 0.686481, acc: 0.552734]: [A loss: 0.859848, acc: 0.164062]\n",
      "616: [D loss: 0.695971, acc: 0.531250]: [A loss: 0.772842, acc: 0.281250]\n",
      "617: [D loss: 0.685184, acc: 0.562500]: [A loss: 0.813755, acc: 0.195312]\n",
      "618: [D loss: 0.670152, acc: 0.582031]: [A loss: 0.726289, acc: 0.371094]\n",
      "619: [D loss: 0.696328, acc: 0.531250]: [A loss: 0.834994, acc: 0.179688]\n",
      "620: [D loss: 0.673909, acc: 0.603516]: [A loss: 0.693866, acc: 0.500000]\n",
      "621: [D loss: 0.704818, acc: 0.519531]: [A loss: 0.950262, acc: 0.078125]\n",
      "622: [D loss: 0.681437, acc: 0.572266]: [A loss: 0.724439, acc: 0.429688]\n",
      "623: [D loss: 0.711645, acc: 0.529297]: [A loss: 0.908329, acc: 0.074219]\n",
      "624: [D loss: 0.699456, acc: 0.498047]: [A loss: 0.722842, acc: 0.410156]\n",
      "625: [D loss: 0.702734, acc: 0.515625]: [A loss: 0.852403, acc: 0.167969]\n",
      "626: [D loss: 0.683973, acc: 0.546875]: [A loss: 0.718354, acc: 0.433594]\n",
      "627: [D loss: 0.693878, acc: 0.535156]: [A loss: 0.843353, acc: 0.152344]\n",
      "628: [D loss: 0.688466, acc: 0.525391]: [A loss: 0.770665, acc: 0.296875]\n",
      "629: [D loss: 0.694395, acc: 0.513672]: [A loss: 0.803218, acc: 0.226562]\n",
      "630: [D loss: 0.698084, acc: 0.550781]: [A loss: 0.782343, acc: 0.226562]\n",
      "631: [D loss: 0.686660, acc: 0.550781]: [A loss: 0.777398, acc: 0.285156]\n",
      "632: [D loss: 0.690871, acc: 0.542969]: [A loss: 0.767594, acc: 0.312500]\n",
      "633: [D loss: 0.692769, acc: 0.542969]: [A loss: 0.798924, acc: 0.218750]\n",
      "634: [D loss: 0.681825, acc: 0.552734]: [A loss: 0.771482, acc: 0.296875]\n",
      "635: [D loss: 0.685013, acc: 0.550781]: [A loss: 0.813902, acc: 0.203125]\n",
      "636: [D loss: 0.687953, acc: 0.531250]: [A loss: 0.735338, acc: 0.398438]\n",
      "637: [D loss: 0.685809, acc: 0.546875]: [A loss: 0.878746, acc: 0.140625]\n",
      "638: [D loss: 0.677116, acc: 0.574219]: [A loss: 0.699865, acc: 0.480469]\n",
      "639: [D loss: 0.690191, acc: 0.578125]: [A loss: 0.949050, acc: 0.078125]\n",
      "640: [D loss: 0.696817, acc: 0.523438]: [A loss: 0.687360, acc: 0.566406]\n",
      "641: [D loss: 0.699911, acc: 0.552734]: [A loss: 0.834152, acc: 0.164062]\n",
      "642: [D loss: 0.693214, acc: 0.513672]: [A loss: 0.743225, acc: 0.398438]\n",
      "643: [D loss: 0.694236, acc: 0.544922]: [A loss: 0.837229, acc: 0.183594]\n",
      "644: [D loss: 0.687462, acc: 0.531250]: [A loss: 0.740857, acc: 0.335938]\n",
      "645: [D loss: 0.693387, acc: 0.552734]: [A loss: 0.824748, acc: 0.183594]\n",
      "646: [D loss: 0.677366, acc: 0.578125]: [A loss: 0.749999, acc: 0.363281]\n",
      "647: [D loss: 0.689687, acc: 0.554688]: [A loss: 0.865304, acc: 0.156250]\n",
      "648: [D loss: 0.679280, acc: 0.566406]: [A loss: 0.725171, acc: 0.433594]\n",
      "649: [D loss: 0.703328, acc: 0.498047]: [A loss: 0.923359, acc: 0.074219]\n",
      "650: [D loss: 0.674990, acc: 0.589844]: [A loss: 0.681266, acc: 0.566406]\n",
      "651: [D loss: 0.698896, acc: 0.527344]: [A loss: 0.879601, acc: 0.136719]\n",
      "652: [D loss: 0.682346, acc: 0.560547]: [A loss: 0.723640, acc: 0.425781]\n",
      "653: [D loss: 0.702345, acc: 0.535156]: [A loss: 0.837412, acc: 0.164062]\n",
      "654: [D loss: 0.680937, acc: 0.548828]: [A loss: 0.751795, acc: 0.335938]\n",
      "655: [D loss: 0.693101, acc: 0.552734]: [A loss: 0.817470, acc: 0.160156]\n",
      "656: [D loss: 0.692899, acc: 0.546875]: [A loss: 0.752668, acc: 0.328125]\n",
      "657: [D loss: 0.683845, acc: 0.558594]: [A loss: 0.811806, acc: 0.199219]\n",
      "658: [D loss: 0.690266, acc: 0.542969]: [A loss: 0.768303, acc: 0.316406]\n",
      "659: [D loss: 0.694527, acc: 0.521484]: [A loss: 0.794095, acc: 0.246094]\n",
      "660: [D loss: 0.700072, acc: 0.519531]: [A loss: 0.819092, acc: 0.199219]\n",
      "661: [D loss: 0.687695, acc: 0.542969]: [A loss: 0.755567, acc: 0.351562]\n",
      "662: [D loss: 0.691333, acc: 0.513672]: [A loss: 0.796429, acc: 0.218750]\n",
      "663: [D loss: 0.686842, acc: 0.560547]: [A loss: 0.760788, acc: 0.343750]\n",
      "664: [D loss: 0.694627, acc: 0.507812]: [A loss: 0.800246, acc: 0.218750]\n",
      "665: [D loss: 0.684533, acc: 0.548828]: [A loss: 0.735149, acc: 0.390625]\n",
      "666: [D loss: 0.694261, acc: 0.535156]: [A loss: 0.906493, acc: 0.093750]\n",
      "667: [D loss: 0.684525, acc: 0.550781]: [A loss: 0.712991, acc: 0.496094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668: [D loss: 0.704296, acc: 0.531250]: [A loss: 0.898147, acc: 0.128906]\n",
      "669: [D loss: 0.690032, acc: 0.546875]: [A loss: 0.664127, acc: 0.566406]\n",
      "670: [D loss: 0.713066, acc: 0.544922]: [A loss: 0.857165, acc: 0.160156]\n",
      "671: [D loss: 0.690171, acc: 0.515625]: [A loss: 0.726684, acc: 0.425781]\n",
      "672: [D loss: 0.682141, acc: 0.554688]: [A loss: 0.790359, acc: 0.273438]\n",
      "673: [D loss: 0.693841, acc: 0.523438]: [A loss: 0.790219, acc: 0.242188]\n",
      "674: [D loss: 0.696029, acc: 0.541016]: [A loss: 0.794266, acc: 0.234375]\n",
      "675: [D loss: 0.677050, acc: 0.587891]: [A loss: 0.744656, acc: 0.355469]\n",
      "676: [D loss: 0.692657, acc: 0.525391]: [A loss: 0.846101, acc: 0.167969]\n",
      "677: [D loss: 0.686222, acc: 0.541016]: [A loss: 0.691270, acc: 0.515625]\n",
      "678: [D loss: 0.697203, acc: 0.519531]: [A loss: 0.879521, acc: 0.101562]\n",
      "679: [D loss: 0.699728, acc: 0.501953]: [A loss: 0.683279, acc: 0.546875]\n",
      "680: [D loss: 0.696797, acc: 0.552734]: [A loss: 0.845385, acc: 0.144531]\n",
      "681: [D loss: 0.684671, acc: 0.574219]: [A loss: 0.751213, acc: 0.328125]\n",
      "682: [D loss: 0.691719, acc: 0.558594]: [A loss: 0.817240, acc: 0.242188]\n",
      "683: [D loss: 0.694356, acc: 0.552734]: [A loss: 0.766015, acc: 0.320312]\n",
      "684: [D loss: 0.684749, acc: 0.558594]: [A loss: 0.795098, acc: 0.250000]\n",
      "685: [D loss: 0.686890, acc: 0.564453]: [A loss: 0.753580, acc: 0.375000]\n",
      "686: [D loss: 0.693503, acc: 0.515625]: [A loss: 0.787959, acc: 0.257812]\n",
      "687: [D loss: 0.695504, acc: 0.523438]: [A loss: 0.798662, acc: 0.234375]\n",
      "688: [D loss: 0.688939, acc: 0.564453]: [A loss: 0.788871, acc: 0.285156]\n",
      "689: [D loss: 0.685115, acc: 0.539062]: [A loss: 0.813745, acc: 0.203125]\n",
      "690: [D loss: 0.692799, acc: 0.531250]: [A loss: 0.748425, acc: 0.355469]\n",
      "691: [D loss: 0.696574, acc: 0.541016]: [A loss: 0.807008, acc: 0.234375]\n",
      "692: [D loss: 0.690256, acc: 0.539062]: [A loss: 0.739049, acc: 0.390625]\n",
      "693: [D loss: 0.688459, acc: 0.572266]: [A loss: 0.865694, acc: 0.148438]\n",
      "694: [D loss: 0.680596, acc: 0.542969]: [A loss: 0.737317, acc: 0.398438]\n",
      "695: [D loss: 0.690204, acc: 0.550781]: [A loss: 0.902164, acc: 0.101562]\n",
      "696: [D loss: 0.687218, acc: 0.542969]: [A loss: 0.703692, acc: 0.496094]\n",
      "697: [D loss: 0.695565, acc: 0.537109]: [A loss: 0.849614, acc: 0.160156]\n",
      "698: [D loss: 0.689891, acc: 0.542969]: [A loss: 0.702374, acc: 0.472656]\n",
      "699: [D loss: 0.685722, acc: 0.554688]: [A loss: 0.885563, acc: 0.117188]\n",
      "700: [D loss: 0.690305, acc: 0.527344]: [A loss: 0.649017, acc: 0.667969]\n",
      "701: [D loss: 0.696486, acc: 0.525391]: [A loss: 0.889759, acc: 0.097656]\n",
      "702: [D loss: 0.682923, acc: 0.564453]: [A loss: 0.727903, acc: 0.433594]\n",
      "703: [D loss: 0.705688, acc: 0.521484]: [A loss: 0.826628, acc: 0.191406]\n",
      "704: [D loss: 0.685107, acc: 0.552734]: [A loss: 0.750711, acc: 0.324219]\n",
      "705: [D loss: 0.700040, acc: 0.531250]: [A loss: 0.819385, acc: 0.218750]\n",
      "706: [D loss: 0.680801, acc: 0.558594]: [A loss: 0.758103, acc: 0.324219]\n",
      "707: [D loss: 0.706490, acc: 0.521484]: [A loss: 0.805171, acc: 0.203125]\n",
      "708: [D loss: 0.695763, acc: 0.548828]: [A loss: 0.750228, acc: 0.382812]\n",
      "709: [D loss: 0.690063, acc: 0.539062]: [A loss: 0.809762, acc: 0.210938]\n",
      "710: [D loss: 0.687375, acc: 0.568359]: [A loss: 0.732767, acc: 0.406250]\n",
      "711: [D loss: 0.703096, acc: 0.515625]: [A loss: 0.838420, acc: 0.164062]\n",
      "712: [D loss: 0.676367, acc: 0.574219]: [A loss: 0.780365, acc: 0.296875]\n",
      "713: [D loss: 0.701184, acc: 0.496094]: [A loss: 0.781938, acc: 0.253906]\n",
      "714: [D loss: 0.689646, acc: 0.535156]: [A loss: 0.742909, acc: 0.378906]\n",
      "715: [D loss: 0.688234, acc: 0.552734]: [A loss: 0.826029, acc: 0.226562]\n",
      "716: [D loss: 0.694255, acc: 0.507812]: [A loss: 0.742090, acc: 0.382812]\n",
      "717: [D loss: 0.692438, acc: 0.546875]: [A loss: 0.835648, acc: 0.171875]\n",
      "718: [D loss: 0.686478, acc: 0.558594]: [A loss: 0.770018, acc: 0.312500]\n",
      "719: [D loss: 0.697081, acc: 0.519531]: [A loss: 0.801787, acc: 0.210938]\n",
      "720: [D loss: 0.691695, acc: 0.537109]: [A loss: 0.704628, acc: 0.496094]\n",
      "721: [D loss: 0.684799, acc: 0.542969]: [A loss: 0.786880, acc: 0.238281]\n",
      "722: [D loss: 0.689637, acc: 0.542969]: [A loss: 0.787920, acc: 0.316406]\n",
      "723: [D loss: 0.707422, acc: 0.498047]: [A loss: 0.812888, acc: 0.222656]\n",
      "724: [D loss: 0.686852, acc: 0.554688]: [A loss: 0.710586, acc: 0.464844]\n",
      "725: [D loss: 0.694920, acc: 0.539062]: [A loss: 0.823666, acc: 0.199219]\n",
      "726: [D loss: 0.687884, acc: 0.535156]: [A loss: 0.700839, acc: 0.492188]\n",
      "727: [D loss: 0.697738, acc: 0.542969]: [A loss: 0.920491, acc: 0.101562]\n",
      "728: [D loss: 0.686339, acc: 0.546875]: [A loss: 0.699651, acc: 0.523438]\n",
      "729: [D loss: 0.709158, acc: 0.492188]: [A loss: 0.878015, acc: 0.097656]\n",
      "730: [D loss: 0.695242, acc: 0.511719]: [A loss: 0.736791, acc: 0.382812]\n",
      "731: [D loss: 0.684882, acc: 0.580078]: [A loss: 0.809921, acc: 0.195312]\n",
      "732: [D loss: 0.700772, acc: 0.503906]: [A loss: 0.732887, acc: 0.398438]\n",
      "733: [D loss: 0.706018, acc: 0.531250]: [A loss: 0.862474, acc: 0.117188]\n",
      "734: [D loss: 0.683448, acc: 0.558594]: [A loss: 0.754710, acc: 0.316406]\n",
      "735: [D loss: 0.697329, acc: 0.511719]: [A loss: 0.824273, acc: 0.195312]\n",
      "736: [D loss: 0.694729, acc: 0.523438]: [A loss: 0.748635, acc: 0.359375]\n",
      "737: [D loss: 0.695131, acc: 0.537109]: [A loss: 0.789677, acc: 0.222656]\n",
      "738: [D loss: 0.688043, acc: 0.537109]: [A loss: 0.769448, acc: 0.304688]\n",
      "739: [D loss: 0.693728, acc: 0.531250]: [A loss: 0.798021, acc: 0.234375]\n",
      "740: [D loss: 0.694992, acc: 0.529297]: [A loss: 0.816834, acc: 0.175781]\n",
      "741: [D loss: 0.688983, acc: 0.525391]: [A loss: 0.761714, acc: 0.339844]\n",
      "742: [D loss: 0.707988, acc: 0.523438]: [A loss: 0.804752, acc: 0.207031]\n",
      "743: [D loss: 0.683907, acc: 0.541016]: [A loss: 0.769265, acc: 0.269531]\n",
      "744: [D loss: 0.693143, acc: 0.552734]: [A loss: 0.793502, acc: 0.226562]\n",
      "745: [D loss: 0.695841, acc: 0.517578]: [A loss: 0.737196, acc: 0.429688]\n",
      "746: [D loss: 0.691172, acc: 0.544922]: [A loss: 0.847042, acc: 0.156250]\n",
      "747: [D loss: 0.678528, acc: 0.558594]: [A loss: 0.697387, acc: 0.519531]\n",
      "748: [D loss: 0.687384, acc: 0.523438]: [A loss: 0.840433, acc: 0.175781]\n",
      "749: [D loss: 0.693267, acc: 0.542969]: [A loss: 0.673661, acc: 0.609375]\n",
      "750: [D loss: 0.714868, acc: 0.492188]: [A loss: 0.905800, acc: 0.089844]\n",
      "751: [D loss: 0.694405, acc: 0.511719]: [A loss: 0.709974, acc: 0.460938]\n",
      "752: [D loss: 0.699936, acc: 0.525391]: [A loss: 0.829449, acc: 0.136719]\n",
      "753: [D loss: 0.688020, acc: 0.548828]: [A loss: 0.690625, acc: 0.507812]\n",
      "754: [D loss: 0.704278, acc: 0.509766]: [A loss: 0.820706, acc: 0.203125]\n",
      "755: [D loss: 0.684925, acc: 0.541016]: [A loss: 0.753481, acc: 0.339844]\n",
      "756: [D loss: 0.703963, acc: 0.517578]: [A loss: 0.827551, acc: 0.164062]\n",
      "757: [D loss: 0.699553, acc: 0.509766]: [A loss: 0.719654, acc: 0.410156]\n",
      "758: [D loss: 0.692793, acc: 0.527344]: [A loss: 0.785503, acc: 0.246094]\n",
      "759: [D loss: 0.691671, acc: 0.521484]: [A loss: 0.764973, acc: 0.281250]\n",
      "760: [D loss: 0.704497, acc: 0.507812]: [A loss: 0.801042, acc: 0.218750]\n",
      "761: [D loss: 0.689598, acc: 0.542969]: [A loss: 0.695625, acc: 0.519531]\n",
      "762: [D loss: 0.689541, acc: 0.542969]: [A loss: 0.769994, acc: 0.257812]\n",
      "763: [D loss: 0.680380, acc: 0.564453]: [A loss: 0.743102, acc: 0.371094]\n",
      "764: [D loss: 0.694016, acc: 0.525391]: [A loss: 0.815188, acc: 0.171875]\n",
      "765: [D loss: 0.690249, acc: 0.556641]: [A loss: 0.725138, acc: 0.410156]\n",
      "766: [D loss: 0.702948, acc: 0.490234]: [A loss: 0.827205, acc: 0.187500]\n",
      "767: [D loss: 0.689954, acc: 0.537109]: [A loss: 0.765905, acc: 0.312500]\n",
      "768: [D loss: 0.688107, acc: 0.546875]: [A loss: 0.803152, acc: 0.199219]\n",
      "769: [D loss: 0.685950, acc: 0.558594]: [A loss: 0.780841, acc: 0.246094]\n",
      "770: [D loss: 0.689399, acc: 0.539062]: [A loss: 0.727405, acc: 0.441406]\n",
      "771: [D loss: 0.695772, acc: 0.529297]: [A loss: 0.807558, acc: 0.203125]\n",
      "772: [D loss: 0.689140, acc: 0.521484]: [A loss: 0.719492, acc: 0.453125]\n",
      "773: [D loss: 0.704495, acc: 0.529297]: [A loss: 0.855308, acc: 0.136719]\n",
      "774: [D loss: 0.689935, acc: 0.548828]: [A loss: 0.718988, acc: 0.441406]\n",
      "775: [D loss: 0.703242, acc: 0.527344]: [A loss: 0.805920, acc: 0.203125]\n",
      "776: [D loss: 0.688726, acc: 0.541016]: [A loss: 0.757974, acc: 0.312500]\n",
      "777: [D loss: 0.691867, acc: 0.542969]: [A loss: 0.805412, acc: 0.207031]\n",
      "778: [D loss: 0.680703, acc: 0.576172]: [A loss: 0.755980, acc: 0.324219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779: [D loss: 0.700688, acc: 0.529297]: [A loss: 0.820997, acc: 0.187500]\n",
      "780: [D loss: 0.682713, acc: 0.556641]: [A loss: 0.693749, acc: 0.515625]\n",
      "781: [D loss: 0.700095, acc: 0.531250]: [A loss: 0.863835, acc: 0.113281]\n",
      "782: [D loss: 0.687738, acc: 0.564453]: [A loss: 0.689586, acc: 0.531250]\n",
      "783: [D loss: 0.699907, acc: 0.523438]: [A loss: 0.842430, acc: 0.113281]\n",
      "784: [D loss: 0.684995, acc: 0.556641]: [A loss: 0.711771, acc: 0.464844]\n",
      "785: [D loss: 0.690613, acc: 0.548828]: [A loss: 0.812411, acc: 0.167969]\n",
      "786: [D loss: 0.692791, acc: 0.537109]: [A loss: 0.747828, acc: 0.335938]\n",
      "787: [D loss: 0.683474, acc: 0.558594]: [A loss: 0.785616, acc: 0.234375]\n",
      "788: [D loss: 0.686077, acc: 0.537109]: [A loss: 0.776223, acc: 0.281250]\n",
      "789: [D loss: 0.688418, acc: 0.541016]: [A loss: 0.770236, acc: 0.289062]\n",
      "790: [D loss: 0.693647, acc: 0.556641]: [A loss: 0.804581, acc: 0.195312]\n",
      "791: [D loss: 0.709207, acc: 0.486328]: [A loss: 0.800745, acc: 0.214844]\n",
      "792: [D loss: 0.692608, acc: 0.521484]: [A loss: 0.719905, acc: 0.406250]\n",
      "793: [D loss: 0.693636, acc: 0.527344]: [A loss: 0.817447, acc: 0.160156]\n",
      "794: [D loss: 0.689245, acc: 0.544922]: [A loss: 0.710451, acc: 0.468750]\n",
      "795: [D loss: 0.708514, acc: 0.492188]: [A loss: 0.858686, acc: 0.105469]\n",
      "796: [D loss: 0.694136, acc: 0.513672]: [A loss: 0.728684, acc: 0.382812]\n",
      "797: [D loss: 0.694835, acc: 0.496094]: [A loss: 0.841340, acc: 0.109375]\n",
      "798: [D loss: 0.692122, acc: 0.517578]: [A loss: 0.715936, acc: 0.417969]\n",
      "799: [D loss: 0.694976, acc: 0.519531]: [A loss: 0.790753, acc: 0.222656]\n",
      "800: [D loss: 0.703323, acc: 0.488281]: [A loss: 0.673511, acc: 0.597656]\n",
      "801: [D loss: 0.707299, acc: 0.513672]: [A loss: 0.777291, acc: 0.242188]\n",
      "802: [D loss: 0.687020, acc: 0.558594]: [A loss: 0.753099, acc: 0.316406]\n",
      "803: [D loss: 0.690606, acc: 0.521484]: [A loss: 0.770045, acc: 0.277344]\n",
      "804: [D loss: 0.688922, acc: 0.535156]: [A loss: 0.736549, acc: 0.382812]\n",
      "805: [D loss: 0.692893, acc: 0.544922]: [A loss: 0.760847, acc: 0.289062]\n",
      "806: [D loss: 0.682958, acc: 0.564453]: [A loss: 0.759057, acc: 0.300781]\n",
      "807: [D loss: 0.684331, acc: 0.587891]: [A loss: 0.711215, acc: 0.496094]\n",
      "808: [D loss: 0.706112, acc: 0.503906]: [A loss: 0.797957, acc: 0.199219]\n",
      "809: [D loss: 0.677932, acc: 0.585938]: [A loss: 0.745018, acc: 0.285156]\n",
      "810: [D loss: 0.687721, acc: 0.548828]: [A loss: 0.770873, acc: 0.300781]\n",
      "811: [D loss: 0.695659, acc: 0.517578]: [A loss: 0.756203, acc: 0.355469]\n",
      "812: [D loss: 0.687086, acc: 0.542969]: [A loss: 0.757532, acc: 0.335938]\n",
      "813: [D loss: 0.696677, acc: 0.517578]: [A loss: 0.766441, acc: 0.296875]\n",
      "814: [D loss: 0.690541, acc: 0.542969]: [A loss: 0.781213, acc: 0.281250]\n",
      "815: [D loss: 0.697339, acc: 0.498047]: [A loss: 0.751237, acc: 0.320312]\n",
      "816: [D loss: 0.695969, acc: 0.531250]: [A loss: 0.781200, acc: 0.238281]\n",
      "817: [D loss: 0.692517, acc: 0.525391]: [A loss: 0.757604, acc: 0.285156]\n",
      "818: [D loss: 0.698757, acc: 0.494141]: [A loss: 0.746738, acc: 0.308594]\n",
      "819: [D loss: 0.683953, acc: 0.574219]: [A loss: 0.794996, acc: 0.246094]\n",
      "820: [D loss: 0.696465, acc: 0.507812]: [A loss: 0.726340, acc: 0.417969]\n",
      "821: [D loss: 0.690771, acc: 0.537109]: [A loss: 0.858124, acc: 0.117188]\n",
      "822: [D loss: 0.703910, acc: 0.490234]: [A loss: 0.737200, acc: 0.343750]\n",
      "823: [D loss: 0.687106, acc: 0.589844]: [A loss: 0.763360, acc: 0.269531]\n",
      "824: [D loss: 0.692141, acc: 0.521484]: [A loss: 0.731333, acc: 0.378906]\n",
      "825: [D loss: 0.702842, acc: 0.486328]: [A loss: 0.822818, acc: 0.152344]\n",
      "826: [D loss: 0.692636, acc: 0.523438]: [A loss: 0.723338, acc: 0.371094]\n",
      "827: [D loss: 0.690454, acc: 0.525391]: [A loss: 0.865239, acc: 0.078125]\n",
      "828: [D loss: 0.692260, acc: 0.521484]: [A loss: 0.684198, acc: 0.554688]\n",
      "829: [D loss: 0.686980, acc: 0.527344]: [A loss: 0.772979, acc: 0.304688]\n",
      "830: [D loss: 0.702096, acc: 0.509766]: [A loss: 0.746930, acc: 0.339844]\n",
      "831: [D loss: 0.691338, acc: 0.523438]: [A loss: 0.768730, acc: 0.261719]\n",
      "832: [D loss: 0.693321, acc: 0.511719]: [A loss: 0.733456, acc: 0.351562]\n",
      "833: [D loss: 0.701822, acc: 0.523438]: [A loss: 0.788274, acc: 0.234375]\n",
      "834: [D loss: 0.688649, acc: 0.544922]: [A loss: 0.712861, acc: 0.433594]\n",
      "835: [D loss: 0.703555, acc: 0.498047]: [A loss: 0.842788, acc: 0.093750]\n",
      "836: [D loss: 0.693468, acc: 0.519531]: [A loss: 0.698330, acc: 0.492188]\n",
      "837: [D loss: 0.690691, acc: 0.535156]: [A loss: 0.816686, acc: 0.132812]\n",
      "838: [D loss: 0.697791, acc: 0.521484]: [A loss: 0.710648, acc: 0.472656]\n",
      "839: [D loss: 0.689489, acc: 0.544922]: [A loss: 0.767536, acc: 0.253906]\n",
      "840: [D loss: 0.689682, acc: 0.509766]: [A loss: 0.747720, acc: 0.308594]\n",
      "841: [D loss: 0.697079, acc: 0.523438]: [A loss: 0.742160, acc: 0.335938]\n",
      "842: [D loss: 0.706138, acc: 0.460938]: [A loss: 0.760715, acc: 0.277344]\n",
      "843: [D loss: 0.696822, acc: 0.539062]: [A loss: 0.759190, acc: 0.289062]\n",
      "844: [D loss: 0.689594, acc: 0.529297]: [A loss: 0.753473, acc: 0.320312]\n",
      "845: [D loss: 0.685274, acc: 0.554688]: [A loss: 0.738794, acc: 0.347656]\n",
      "846: [D loss: 0.689161, acc: 0.517578]: [A loss: 0.780000, acc: 0.207031]\n",
      "847: [D loss: 0.690626, acc: 0.535156]: [A loss: 0.733118, acc: 0.378906]\n",
      "848: [D loss: 0.695410, acc: 0.515625]: [A loss: 0.784590, acc: 0.222656]\n",
      "849: [D loss: 0.700161, acc: 0.494141]: [A loss: 0.761687, acc: 0.281250]\n",
      "850: [D loss: 0.702036, acc: 0.494141]: [A loss: 0.758003, acc: 0.296875]\n",
      "851: [D loss: 0.704021, acc: 0.498047]: [A loss: 0.810385, acc: 0.148438]\n",
      "852: [D loss: 0.693463, acc: 0.550781]: [A loss: 0.694816, acc: 0.507812]\n",
      "853: [D loss: 0.686874, acc: 0.554688]: [A loss: 0.840115, acc: 0.132812]\n",
      "854: [D loss: 0.689065, acc: 0.541016]: [A loss: 0.718234, acc: 0.421875]\n",
      "855: [D loss: 0.694877, acc: 0.525391]: [A loss: 0.815475, acc: 0.175781]\n",
      "856: [D loss: 0.682455, acc: 0.570312]: [A loss: 0.716032, acc: 0.488281]\n",
      "857: [D loss: 0.689597, acc: 0.542969]: [A loss: 0.812925, acc: 0.156250]\n",
      "858: [D loss: 0.696670, acc: 0.507812]: [A loss: 0.741592, acc: 0.375000]\n",
      "859: [D loss: 0.696968, acc: 0.523438]: [A loss: 0.764442, acc: 0.265625]\n",
      "860: [D loss: 0.703078, acc: 0.498047]: [A loss: 0.758785, acc: 0.281250]\n",
      "861: [D loss: 0.693151, acc: 0.515625]: [A loss: 0.764615, acc: 0.273438]\n",
      "862: [D loss: 0.692861, acc: 0.521484]: [A loss: 0.786057, acc: 0.218750]\n",
      "863: [D loss: 0.694646, acc: 0.513672]: [A loss: 0.773068, acc: 0.253906]\n",
      "864: [D loss: 0.688066, acc: 0.541016]: [A loss: 0.766034, acc: 0.312500]\n",
      "865: [D loss: 0.684332, acc: 0.552734]: [A loss: 0.745497, acc: 0.324219]\n",
      "866: [D loss: 0.704516, acc: 0.511719]: [A loss: 0.794588, acc: 0.187500]\n",
      "867: [D loss: 0.682153, acc: 0.560547]: [A loss: 0.716408, acc: 0.453125]\n",
      "868: [D loss: 0.699078, acc: 0.525391]: [A loss: 0.834573, acc: 0.148438]\n",
      "869: [D loss: 0.694025, acc: 0.496094]: [A loss: 0.672696, acc: 0.582031]\n",
      "870: [D loss: 0.699037, acc: 0.519531]: [A loss: 0.859654, acc: 0.101562]\n",
      "871: [D loss: 0.692109, acc: 0.515625]: [A loss: 0.679722, acc: 0.546875]\n",
      "872: [D loss: 0.699883, acc: 0.519531]: [A loss: 0.827505, acc: 0.144531]\n",
      "873: [D loss: 0.687978, acc: 0.542969]: [A loss: 0.677187, acc: 0.574219]\n",
      "874: [D loss: 0.704117, acc: 0.496094]: [A loss: 0.793520, acc: 0.203125]\n",
      "875: [D loss: 0.688674, acc: 0.527344]: [A loss: 0.732611, acc: 0.371094]\n",
      "876: [D loss: 0.699795, acc: 0.513672]: [A loss: 0.801098, acc: 0.203125]\n",
      "877: [D loss: 0.691540, acc: 0.513672]: [A loss: 0.718753, acc: 0.410156]\n",
      "878: [D loss: 0.692842, acc: 0.515625]: [A loss: 0.771208, acc: 0.253906]\n",
      "879: [D loss: 0.690081, acc: 0.535156]: [A loss: 0.757991, acc: 0.281250]\n",
      "880: [D loss: 0.688774, acc: 0.541016]: [A loss: 0.771237, acc: 0.277344]\n",
      "881: [D loss: 0.691176, acc: 0.535156]: [A loss: 0.710251, acc: 0.445312]\n",
      "882: [D loss: 0.698862, acc: 0.492188]: [A loss: 0.847674, acc: 0.117188]\n",
      "883: [D loss: 0.685533, acc: 0.535156]: [A loss: 0.713889, acc: 0.441406]\n",
      "884: [D loss: 0.696752, acc: 0.527344]: [A loss: 0.798469, acc: 0.203125]\n",
      "885: [D loss: 0.689606, acc: 0.542969]: [A loss: 0.755584, acc: 0.324219]\n",
      "886: [D loss: 0.694141, acc: 0.521484]: [A loss: 0.788616, acc: 0.218750]\n",
      "887: [D loss: 0.697796, acc: 0.517578]: [A loss: 0.701574, acc: 0.468750]\n",
      "888: [D loss: 0.712819, acc: 0.492188]: [A loss: 0.823085, acc: 0.144531]\n",
      "889: [D loss: 0.696292, acc: 0.500000]: [A loss: 0.694848, acc: 0.492188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890: [D loss: 0.707232, acc: 0.486328]: [A loss: 0.814067, acc: 0.140625]\n",
      "891: [D loss: 0.689920, acc: 0.539062]: [A loss: 0.718246, acc: 0.398438]\n",
      "892: [D loss: 0.708262, acc: 0.470703]: [A loss: 0.789319, acc: 0.218750]\n",
      "893: [D loss: 0.690053, acc: 0.527344]: [A loss: 0.747698, acc: 0.312500]\n",
      "894: [D loss: 0.694911, acc: 0.527344]: [A loss: 0.771453, acc: 0.257812]\n",
      "895: [D loss: 0.691887, acc: 0.531250]: [A loss: 0.748735, acc: 0.351562]\n",
      "896: [D loss: 0.692659, acc: 0.529297]: [A loss: 0.717496, acc: 0.402344]\n",
      "897: [D loss: 0.702802, acc: 0.484375]: [A loss: 0.763232, acc: 0.234375]\n",
      "898: [D loss: 0.695902, acc: 0.509766]: [A loss: 0.750269, acc: 0.339844]\n",
      "899: [D loss: 0.689310, acc: 0.544922]: [A loss: 0.763895, acc: 0.277344]\n",
      "900: [D loss: 0.707598, acc: 0.488281]: [A loss: 0.783657, acc: 0.199219]\n",
      "901: [D loss: 0.684603, acc: 0.535156]: [A loss: 0.708325, acc: 0.464844]\n",
      "902: [D loss: 0.693881, acc: 0.539062]: [A loss: 0.794608, acc: 0.214844]\n",
      "903: [D loss: 0.696344, acc: 0.496094]: [A loss: 0.735187, acc: 0.359375]\n",
      "904: [D loss: 0.695600, acc: 0.523438]: [A loss: 0.759164, acc: 0.261719]\n",
      "905: [D loss: 0.697498, acc: 0.509766]: [A loss: 0.735876, acc: 0.375000]\n",
      "906: [D loss: 0.686576, acc: 0.537109]: [A loss: 0.788939, acc: 0.195312]\n",
      "907: [D loss: 0.697286, acc: 0.517578]: [A loss: 0.725735, acc: 0.421875]\n",
      "908: [D loss: 0.693435, acc: 0.515625]: [A loss: 0.793065, acc: 0.183594]\n",
      "909: [D loss: 0.685141, acc: 0.533203]: [A loss: 0.728416, acc: 0.378906]\n",
      "910: [D loss: 0.700872, acc: 0.501953]: [A loss: 0.783695, acc: 0.222656]\n",
      "911: [D loss: 0.690712, acc: 0.533203]: [A loss: 0.729717, acc: 0.394531]\n",
      "912: [D loss: 0.696445, acc: 0.537109]: [A loss: 0.807333, acc: 0.191406]\n",
      "913: [D loss: 0.692480, acc: 0.527344]: [A loss: 0.739818, acc: 0.378906]\n",
      "914: [D loss: 0.696107, acc: 0.541016]: [A loss: 0.800894, acc: 0.160156]\n",
      "915: [D loss: 0.689419, acc: 0.539062]: [A loss: 0.774170, acc: 0.222656]\n",
      "916: [D loss: 0.695807, acc: 0.505859]: [A loss: 0.785315, acc: 0.195312]\n",
      "917: [D loss: 0.692782, acc: 0.503906]: [A loss: 0.733070, acc: 0.378906]\n",
      "918: [D loss: 0.686574, acc: 0.554688]: [A loss: 0.792628, acc: 0.191406]\n",
      "919: [D loss: 0.689165, acc: 0.544922]: [A loss: 0.772482, acc: 0.238281]\n",
      "920: [D loss: 0.683076, acc: 0.541016]: [A loss: 0.771475, acc: 0.257812]\n",
      "921: [D loss: 0.701867, acc: 0.480469]: [A loss: 0.841386, acc: 0.136719]\n",
      "922: [D loss: 0.699711, acc: 0.523438]: [A loss: 0.672895, acc: 0.589844]\n",
      "923: [D loss: 0.715730, acc: 0.501953]: [A loss: 0.853884, acc: 0.097656]\n",
      "924: [D loss: 0.696803, acc: 0.503906]: [A loss: 0.684929, acc: 0.527344]\n",
      "925: [D loss: 0.696973, acc: 0.525391]: [A loss: 0.813319, acc: 0.152344]\n",
      "926: [D loss: 0.686874, acc: 0.556641]: [A loss: 0.706734, acc: 0.457031]\n",
      "927: [D loss: 0.693010, acc: 0.546875]: [A loss: 0.788603, acc: 0.210938]\n",
      "928: [D loss: 0.699500, acc: 0.511719]: [A loss: 0.731459, acc: 0.359375]\n",
      "929: [D loss: 0.688798, acc: 0.556641]: [A loss: 0.745941, acc: 0.347656]\n",
      "930: [D loss: 0.691783, acc: 0.542969]: [A loss: 0.731335, acc: 0.375000]\n",
      "931: [D loss: 0.692124, acc: 0.537109]: [A loss: 0.795383, acc: 0.210938]\n",
      "932: [D loss: 0.692400, acc: 0.533203]: [A loss: 0.723046, acc: 0.410156]\n",
      "933: [D loss: 0.686361, acc: 0.562500]: [A loss: 0.812225, acc: 0.183594]\n",
      "934: [D loss: 0.688573, acc: 0.533203]: [A loss: 0.689692, acc: 0.519531]\n",
      "935: [D loss: 0.696666, acc: 0.521484]: [A loss: 0.860680, acc: 0.101562]\n",
      "936: [D loss: 0.694805, acc: 0.517578]: [A loss: 0.697222, acc: 0.523438]\n",
      "937: [D loss: 0.707651, acc: 0.531250]: [A loss: 0.810918, acc: 0.156250]\n",
      "938: [D loss: 0.691714, acc: 0.509766]: [A loss: 0.677761, acc: 0.562500]\n",
      "939: [D loss: 0.697733, acc: 0.529297]: [A loss: 0.793166, acc: 0.179688]\n",
      "940: [D loss: 0.688662, acc: 0.537109]: [A loss: 0.699848, acc: 0.492188]\n",
      "941: [D loss: 0.704985, acc: 0.507812]: [A loss: 0.819803, acc: 0.160156]\n",
      "942: [D loss: 0.703092, acc: 0.478516]: [A loss: 0.749626, acc: 0.328125]\n",
      "943: [D loss: 0.689046, acc: 0.535156]: [A loss: 0.720197, acc: 0.406250]\n",
      "944: [D loss: 0.691740, acc: 0.515625]: [A loss: 0.772247, acc: 0.226562]\n",
      "945: [D loss: 0.693392, acc: 0.511719]: [A loss: 0.767841, acc: 0.261719]\n",
      "946: [D loss: 0.696015, acc: 0.529297]: [A loss: 0.719562, acc: 0.406250]\n",
      "947: [D loss: 0.692033, acc: 0.535156]: [A loss: 0.777167, acc: 0.222656]\n",
      "948: [D loss: 0.694681, acc: 0.511719]: [A loss: 0.764511, acc: 0.285156]\n",
      "949: [D loss: 0.696306, acc: 0.525391]: [A loss: 0.741809, acc: 0.351562]\n",
      "950: [D loss: 0.693283, acc: 0.550781]: [A loss: 0.791519, acc: 0.191406]\n",
      "951: [D loss: 0.694761, acc: 0.509766]: [A loss: 0.694254, acc: 0.507812]\n",
      "952: [D loss: 0.693371, acc: 0.515625]: [A loss: 0.844028, acc: 0.105469]\n",
      "953: [D loss: 0.683663, acc: 0.542969]: [A loss: 0.697785, acc: 0.472656]\n",
      "954: [D loss: 0.704224, acc: 0.511719]: [A loss: 0.812909, acc: 0.160156]\n",
      "955: [D loss: 0.685176, acc: 0.548828]: [A loss: 0.697840, acc: 0.476562]\n",
      "956: [D loss: 0.693965, acc: 0.542969]: [A loss: 0.822389, acc: 0.121094]\n",
      "957: [D loss: 0.684385, acc: 0.544922]: [A loss: 0.706432, acc: 0.468750]\n",
      "958: [D loss: 0.703320, acc: 0.494141]: [A loss: 0.792728, acc: 0.187500]\n",
      "959: [D loss: 0.691806, acc: 0.523438]: [A loss: 0.705477, acc: 0.445312]\n",
      "960: [D loss: 0.703176, acc: 0.521484]: [A loss: 0.821340, acc: 0.132812]\n",
      "961: [D loss: 0.694485, acc: 0.498047]: [A loss: 0.744061, acc: 0.320312]\n",
      "962: [D loss: 0.697017, acc: 0.500000]: [A loss: 0.821829, acc: 0.144531]\n",
      "963: [D loss: 0.692422, acc: 0.505859]: [A loss: 0.743413, acc: 0.375000]\n",
      "964: [D loss: 0.689486, acc: 0.535156]: [A loss: 0.782153, acc: 0.246094]\n",
      "965: [D loss: 0.687502, acc: 0.513672]: [A loss: 0.712439, acc: 0.453125]\n",
      "966: [D loss: 0.693405, acc: 0.544922]: [A loss: 0.808607, acc: 0.152344]\n",
      "967: [D loss: 0.689338, acc: 0.519531]: [A loss: 0.703832, acc: 0.484375]\n",
      "968: [D loss: 0.695207, acc: 0.539062]: [A loss: 0.800519, acc: 0.222656]\n",
      "969: [D loss: 0.692726, acc: 0.521484]: [A loss: 0.704352, acc: 0.453125]\n",
      "970: [D loss: 0.706034, acc: 0.494141]: [A loss: 0.857018, acc: 0.046875]\n",
      "971: [D loss: 0.689436, acc: 0.529297]: [A loss: 0.680810, acc: 0.566406]\n",
      "972: [D loss: 0.703842, acc: 0.513672]: [A loss: 0.874011, acc: 0.082031]\n",
      "973: [D loss: 0.688954, acc: 0.546875]: [A loss: 0.668836, acc: 0.582031]\n",
      "974: [D loss: 0.703402, acc: 0.501953]: [A loss: 0.811844, acc: 0.156250]\n",
      "975: [D loss: 0.687717, acc: 0.566406]: [A loss: 0.714969, acc: 0.453125]\n",
      "976: [D loss: 0.693130, acc: 0.539062]: [A loss: 0.736355, acc: 0.363281]\n",
      "977: [D loss: 0.699387, acc: 0.521484]: [A loss: 0.745018, acc: 0.335938]\n",
      "978: [D loss: 0.689255, acc: 0.503906]: [A loss: 0.782322, acc: 0.222656]\n",
      "979: [D loss: 0.697871, acc: 0.537109]: [A loss: 0.742659, acc: 0.355469]\n",
      "980: [D loss: 0.692406, acc: 0.531250]: [A loss: 0.785508, acc: 0.222656]\n",
      "981: [D loss: 0.693733, acc: 0.519531]: [A loss: 0.785347, acc: 0.246094]\n",
      "982: [D loss: 0.695306, acc: 0.523438]: [A loss: 0.774628, acc: 0.285156]\n",
      "983: [D loss: 0.689143, acc: 0.541016]: [A loss: 0.730953, acc: 0.363281]\n",
      "984: [D loss: 0.696479, acc: 0.521484]: [A loss: 0.804471, acc: 0.183594]\n",
      "985: [D loss: 0.696727, acc: 0.513672]: [A loss: 0.720502, acc: 0.398438]\n",
      "986: [D loss: 0.695074, acc: 0.517578]: [A loss: 0.796026, acc: 0.199219]\n",
      "987: [D loss: 0.691848, acc: 0.529297]: [A loss: 0.742456, acc: 0.363281]\n",
      "988: [D loss: 0.696354, acc: 0.511719]: [A loss: 0.768002, acc: 0.273438]\n",
      "989: [D loss: 0.699066, acc: 0.533203]: [A loss: 0.769443, acc: 0.273438]\n",
      "990: [D loss: 0.687136, acc: 0.576172]: [A loss: 0.703288, acc: 0.472656]\n",
      "991: [D loss: 0.698797, acc: 0.525391]: [A loss: 0.778545, acc: 0.226562]\n",
      "992: [D loss: 0.700073, acc: 0.498047]: [A loss: 0.792946, acc: 0.207031]\n",
      "993: [D loss: 0.688091, acc: 0.542969]: [A loss: 0.753012, acc: 0.308594]\n",
      "994: [D loss: 0.696707, acc: 0.529297]: [A loss: 0.798502, acc: 0.187500]\n",
      "995: [D loss: 0.703762, acc: 0.507812]: [A loss: 0.786662, acc: 0.226562]\n",
      "996: [D loss: 0.692705, acc: 0.527344]: [A loss: 0.752421, acc: 0.296875]\n",
      "997: [D loss: 0.688893, acc: 0.556641]: [A loss: 0.752531, acc: 0.359375]\n",
      "998: [D loss: 0.697842, acc: 0.511719]: [A loss: 0.824705, acc: 0.160156]\n",
      "999: [D loss: 0.683806, acc: 0.552734]: [A loss: 0.663740, acc: 0.636719]\n",
      "1000: [D loss: 0.707295, acc: 0.519531]: [A loss: 0.914367, acc: 0.058594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001: [D loss: 0.694972, acc: 0.523438]: [A loss: 0.650265, acc: 0.675781]\n",
      "1002: [D loss: 0.714175, acc: 0.505859]: [A loss: 0.819396, acc: 0.117188]\n",
      "1003: [D loss: 0.700347, acc: 0.480469]: [A loss: 0.699711, acc: 0.511719]\n",
      "1004: [D loss: 0.697007, acc: 0.546875]: [A loss: 0.808418, acc: 0.144531]\n",
      "1005: [D loss: 0.691046, acc: 0.533203]: [A loss: 0.692452, acc: 0.531250]\n",
      "1006: [D loss: 0.696399, acc: 0.521484]: [A loss: 0.784829, acc: 0.242188]\n",
      "1007: [D loss: 0.695070, acc: 0.496094]: [A loss: 0.750922, acc: 0.316406]\n",
      "1008: [D loss: 0.696820, acc: 0.521484]: [A loss: 0.779539, acc: 0.246094]\n",
      "1009: [D loss: 0.695185, acc: 0.511719]: [A loss: 0.767037, acc: 0.269531]\n",
      "1010: [D loss: 0.690566, acc: 0.515625]: [A loss: 0.713626, acc: 0.441406]\n",
      "1011: [D loss: 0.700100, acc: 0.509766]: [A loss: 0.759721, acc: 0.250000]\n",
      "1012: [D loss: 0.694052, acc: 0.507812]: [A loss: 0.717932, acc: 0.445312]\n",
      "1013: [D loss: 0.689292, acc: 0.544922]: [A loss: 0.786767, acc: 0.257812]\n",
      "1014: [D loss: 0.683190, acc: 0.544922]: [A loss: 0.708128, acc: 0.453125]\n",
      "1015: [D loss: 0.691136, acc: 0.529297]: [A loss: 0.803772, acc: 0.210938]\n",
      "1016: [D loss: 0.691744, acc: 0.556641]: [A loss: 0.733631, acc: 0.355469]\n",
      "1017: [D loss: 0.688985, acc: 0.519531]: [A loss: 0.805648, acc: 0.187500]\n",
      "1018: [D loss: 0.697632, acc: 0.529297]: [A loss: 0.769193, acc: 0.292969]\n",
      "1019: [D loss: 0.698006, acc: 0.533203]: [A loss: 0.824022, acc: 0.167969]\n",
      "1020: [D loss: 0.704704, acc: 0.503906]: [A loss: 0.721470, acc: 0.410156]\n",
      "1021: [D loss: 0.687585, acc: 0.566406]: [A loss: 0.758497, acc: 0.273438]\n",
      "1022: [D loss: 0.695058, acc: 0.521484]: [A loss: 0.766946, acc: 0.273438]\n",
      "1023: [D loss: 0.692176, acc: 0.525391]: [A loss: 0.757094, acc: 0.308594]\n",
      "1024: [D loss: 0.705061, acc: 0.492188]: [A loss: 0.776477, acc: 0.230469]\n",
      "1025: [D loss: 0.698558, acc: 0.519531]: [A loss: 0.804024, acc: 0.160156]\n",
      "1026: [D loss: 0.679343, acc: 0.548828]: [A loss: 0.745132, acc: 0.308594]\n",
      "1027: [D loss: 0.700007, acc: 0.496094]: [A loss: 0.815709, acc: 0.148438]\n",
      "1028: [D loss: 0.693723, acc: 0.509766]: [A loss: 0.694413, acc: 0.480469]\n",
      "1029: [D loss: 0.700280, acc: 0.498047]: [A loss: 0.812893, acc: 0.175781]\n",
      "1030: [D loss: 0.686878, acc: 0.544922]: [A loss: 0.702042, acc: 0.523438]\n",
      "1031: [D loss: 0.703072, acc: 0.519531]: [A loss: 0.792219, acc: 0.214844]\n",
      "1032: [D loss: 0.698580, acc: 0.501953]: [A loss: 0.718025, acc: 0.417969]\n",
      "1033: [D loss: 0.696542, acc: 0.533203]: [A loss: 0.790707, acc: 0.195312]\n",
      "1034: [D loss: 0.685334, acc: 0.541016]: [A loss: 0.699691, acc: 0.488281]\n",
      "1035: [D loss: 0.684306, acc: 0.521484]: [A loss: 0.781741, acc: 0.222656]\n",
      "1036: [D loss: 0.690525, acc: 0.529297]: [A loss: 0.724996, acc: 0.382812]\n",
      "1037: [D loss: 0.693040, acc: 0.531250]: [A loss: 0.773169, acc: 0.238281]\n",
      "1038: [D loss: 0.700446, acc: 0.496094]: [A loss: 0.749634, acc: 0.304688]\n",
      "1039: [D loss: 0.686215, acc: 0.523438]: [A loss: 0.802816, acc: 0.164062]\n",
      "1040: [D loss: 0.686718, acc: 0.535156]: [A loss: 0.762251, acc: 0.273438]\n",
      "1041: [D loss: 0.689770, acc: 0.554688]: [A loss: 0.728283, acc: 0.390625]\n",
      "1042: [D loss: 0.696842, acc: 0.500000]: [A loss: 0.798259, acc: 0.191406]\n",
      "1043: [D loss: 0.694736, acc: 0.527344]: [A loss: 0.751158, acc: 0.351562]\n",
      "1044: [D loss: 0.696118, acc: 0.521484]: [A loss: 0.805628, acc: 0.164062]\n",
      "1045: [D loss: 0.693971, acc: 0.501953]: [A loss: 0.722606, acc: 0.433594]\n",
      "1046: [D loss: 0.690546, acc: 0.535156]: [A loss: 0.840192, acc: 0.125000]\n",
      "1047: [D loss: 0.684192, acc: 0.542969]: [A loss: 0.667689, acc: 0.570312]\n",
      "1048: [D loss: 0.710610, acc: 0.486328]: [A loss: 0.850913, acc: 0.078125]\n",
      "1049: [D loss: 0.699850, acc: 0.500000]: [A loss: 0.694061, acc: 0.507812]\n",
      "1050: [D loss: 0.704894, acc: 0.507812]: [A loss: 0.846974, acc: 0.117188]\n",
      "1051: [D loss: 0.692787, acc: 0.535156]: [A loss: 0.722385, acc: 0.417969]\n",
      "1052: [D loss: 0.705930, acc: 0.515625]: [A loss: 0.816634, acc: 0.156250]\n",
      "1053: [D loss: 0.689290, acc: 0.542969]: [A loss: 0.681009, acc: 0.535156]\n",
      "1054: [D loss: 0.706015, acc: 0.503906]: [A loss: 0.777997, acc: 0.210938]\n",
      "1055: [D loss: 0.687903, acc: 0.527344]: [A loss: 0.689080, acc: 0.531250]\n",
      "1056: [D loss: 0.696699, acc: 0.511719]: [A loss: 0.772269, acc: 0.238281]\n",
      "1057: [D loss: 0.678306, acc: 0.589844]: [A loss: 0.716772, acc: 0.433594]\n",
      "1058: [D loss: 0.698815, acc: 0.503906]: [A loss: 0.767059, acc: 0.257812]\n",
      "1059: [D loss: 0.700036, acc: 0.501953]: [A loss: 0.765031, acc: 0.289062]\n",
      "1060: [D loss: 0.686054, acc: 0.535156]: [A loss: 0.742583, acc: 0.332031]\n",
      "1061: [D loss: 0.696835, acc: 0.513672]: [A loss: 0.760299, acc: 0.285156]\n",
      "1062: [D loss: 0.692656, acc: 0.533203]: [A loss: 0.743039, acc: 0.320312]\n",
      "1063: [D loss: 0.690277, acc: 0.513672]: [A loss: 0.748526, acc: 0.343750]\n",
      "1064: [D loss: 0.691932, acc: 0.511719]: [A loss: 0.794044, acc: 0.183594]\n",
      "1065: [D loss: 0.693700, acc: 0.517578]: [A loss: 0.764190, acc: 0.289062]\n",
      "1066: [D loss: 0.688460, acc: 0.513672]: [A loss: 0.750053, acc: 0.378906]\n",
      "1067: [D loss: 0.693199, acc: 0.523438]: [A loss: 0.746700, acc: 0.332031]\n",
      "1068: [D loss: 0.683469, acc: 0.570312]: [A loss: 0.715801, acc: 0.437500]\n",
      "1069: [D loss: 0.687728, acc: 0.546875]: [A loss: 0.828677, acc: 0.156250]\n",
      "1070: [D loss: 0.688430, acc: 0.556641]: [A loss: 0.708523, acc: 0.449219]\n",
      "1071: [D loss: 0.697664, acc: 0.521484]: [A loss: 0.924438, acc: 0.042969]\n",
      "1072: [D loss: 0.698979, acc: 0.500000]: [A loss: 0.660295, acc: 0.617188]\n",
      "1073: [D loss: 0.708953, acc: 0.515625]: [A loss: 0.884802, acc: 0.046875]\n",
      "1074: [D loss: 0.689818, acc: 0.537109]: [A loss: 0.683922, acc: 0.554688]\n",
      "1075: [D loss: 0.697371, acc: 0.509766]: [A loss: 0.837105, acc: 0.121094]\n",
      "1076: [D loss: 0.691002, acc: 0.554688]: [A loss: 0.684844, acc: 0.574219]\n",
      "1077: [D loss: 0.700851, acc: 0.513672]: [A loss: 0.802570, acc: 0.152344]\n",
      "1078: [D loss: 0.696253, acc: 0.490234]: [A loss: 0.733578, acc: 0.332031]\n",
      "1079: [D loss: 0.695723, acc: 0.515625]: [A loss: 0.773615, acc: 0.226562]\n",
      "1080: [D loss: 0.692523, acc: 0.523438]: [A loss: 0.750452, acc: 0.312500]\n",
      "1081: [D loss: 0.701799, acc: 0.511719]: [A loss: 0.772568, acc: 0.226562]\n",
      "1082: [D loss: 0.698069, acc: 0.511719]: [A loss: 0.744357, acc: 0.332031]\n",
      "1083: [D loss: 0.698840, acc: 0.511719]: [A loss: 0.775688, acc: 0.277344]\n",
      "1084: [D loss: 0.698853, acc: 0.513672]: [A loss: 0.759835, acc: 0.285156]\n",
      "1085: [D loss: 0.688141, acc: 0.537109]: [A loss: 0.744540, acc: 0.375000]\n",
      "1086: [D loss: 0.695801, acc: 0.513672]: [A loss: 0.790763, acc: 0.234375]\n",
      "1087: [D loss: 0.693548, acc: 0.556641]: [A loss: 0.756055, acc: 0.281250]\n",
      "1088: [D loss: 0.696703, acc: 0.509766]: [A loss: 0.732797, acc: 0.378906]\n",
      "1089: [D loss: 0.697334, acc: 0.511719]: [A loss: 0.749782, acc: 0.285156]\n",
      "1090: [D loss: 0.697217, acc: 0.503906]: [A loss: 0.723289, acc: 0.429688]\n",
      "1091: [D loss: 0.697544, acc: 0.562500]: [A loss: 0.774902, acc: 0.253906]\n",
      "1092: [D loss: 0.694545, acc: 0.521484]: [A loss: 0.782207, acc: 0.238281]\n",
      "1093: [D loss: 0.692579, acc: 0.513672]: [A loss: 0.721059, acc: 0.421875]\n",
      "1094: [D loss: 0.691127, acc: 0.531250]: [A loss: 0.849084, acc: 0.109375]\n",
      "1095: [D loss: 0.685920, acc: 0.578125]: [A loss: 0.702443, acc: 0.480469]\n",
      "1096: [D loss: 0.695001, acc: 0.525391]: [A loss: 0.808219, acc: 0.144531]\n",
      "1097: [D loss: 0.686905, acc: 0.558594]: [A loss: 0.714556, acc: 0.437500]\n",
      "1098: [D loss: 0.697680, acc: 0.501953]: [A loss: 0.807712, acc: 0.152344]\n",
      "1099: [D loss: 0.704759, acc: 0.500000]: [A loss: 0.753875, acc: 0.320312]\n",
      "1100: [D loss: 0.689587, acc: 0.537109]: [A loss: 0.762488, acc: 0.261719]\n",
      "1101: [D loss: 0.688837, acc: 0.531250]: [A loss: 0.757759, acc: 0.320312]\n",
      "1102: [D loss: 0.688628, acc: 0.576172]: [A loss: 0.783985, acc: 0.246094]\n",
      "1103: [D loss: 0.693684, acc: 0.535156]: [A loss: 0.732176, acc: 0.378906]\n",
      "1104: [D loss: 0.702280, acc: 0.505859]: [A loss: 0.810310, acc: 0.148438]\n",
      "1105: [D loss: 0.693955, acc: 0.527344]: [A loss: 0.724988, acc: 0.433594]\n",
      "1106: [D loss: 0.694926, acc: 0.533203]: [A loss: 0.824250, acc: 0.121094]\n",
      "1107: [D loss: 0.697853, acc: 0.519531]: [A loss: 0.741408, acc: 0.332031]\n",
      "1108: [D loss: 0.691583, acc: 0.554688]: [A loss: 0.732047, acc: 0.402344]\n",
      "1109: [D loss: 0.699105, acc: 0.509766]: [A loss: 0.823922, acc: 0.144531]\n",
      "1110: [D loss: 0.698698, acc: 0.515625]: [A loss: 0.688801, acc: 0.535156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111: [D loss: 0.694883, acc: 0.548828]: [A loss: 0.828190, acc: 0.101562]\n",
      "1112: [D loss: 0.674796, acc: 0.593750]: [A loss: 0.727610, acc: 0.429688]\n",
      "1113: [D loss: 0.701250, acc: 0.509766]: [A loss: 0.796558, acc: 0.171875]\n",
      "1114: [D loss: 0.690663, acc: 0.527344]: [A loss: 0.710191, acc: 0.425781]\n",
      "1115: [D loss: 0.692811, acc: 0.519531]: [A loss: 0.817866, acc: 0.156250]\n",
      "1116: [D loss: 0.701893, acc: 0.500000]: [A loss: 0.698227, acc: 0.468750]\n",
      "1117: [D loss: 0.691862, acc: 0.511719]: [A loss: 0.849192, acc: 0.093750]\n",
      "1118: [D loss: 0.695565, acc: 0.527344]: [A loss: 0.682986, acc: 0.566406]\n",
      "1119: [D loss: 0.690041, acc: 0.533203]: [A loss: 0.781926, acc: 0.210938]\n",
      "1120: [D loss: 0.701452, acc: 0.505859]: [A loss: 0.725170, acc: 0.355469]\n",
      "1121: [D loss: 0.699457, acc: 0.539062]: [A loss: 0.791433, acc: 0.175781]\n",
      "1122: [D loss: 0.687452, acc: 0.521484]: [A loss: 0.719903, acc: 0.445312]\n",
      "1123: [D loss: 0.696925, acc: 0.513672]: [A loss: 0.766328, acc: 0.218750]\n",
      "1124: [D loss: 0.688907, acc: 0.523438]: [A loss: 0.729340, acc: 0.386719]\n",
      "1125: [D loss: 0.702085, acc: 0.503906]: [A loss: 0.746086, acc: 0.285156]\n",
      "1126: [D loss: 0.692741, acc: 0.548828]: [A loss: 0.766259, acc: 0.281250]\n",
      "1127: [D loss: 0.685625, acc: 0.546875]: [A loss: 0.723380, acc: 0.417969]\n",
      "1128: [D loss: 0.695470, acc: 0.521484]: [A loss: 0.819678, acc: 0.175781]\n",
      "1129: [D loss: 0.687468, acc: 0.562500]: [A loss: 0.722093, acc: 0.398438]\n",
      "1130: [D loss: 0.696146, acc: 0.533203]: [A loss: 0.819157, acc: 0.140625]\n",
      "1131: [D loss: 0.685333, acc: 0.537109]: [A loss: 0.729964, acc: 0.367188]\n",
      "1132: [D loss: 0.695215, acc: 0.505859]: [A loss: 0.818668, acc: 0.160156]\n",
      "1133: [D loss: 0.700357, acc: 0.517578]: [A loss: 0.691642, acc: 0.542969]\n",
      "1134: [D loss: 0.692237, acc: 0.535156]: [A loss: 0.815231, acc: 0.167969]\n",
      "1135: [D loss: 0.687603, acc: 0.541016]: [A loss: 0.762194, acc: 0.281250]\n",
      "1136: [D loss: 0.702626, acc: 0.484375]: [A loss: 0.822916, acc: 0.125000]\n",
      "1137: [D loss: 0.690407, acc: 0.529297]: [A loss: 0.749399, acc: 0.347656]\n",
      "1138: [D loss: 0.691329, acc: 0.500000]: [A loss: 0.745663, acc: 0.351562]\n",
      "1139: [D loss: 0.695168, acc: 0.542969]: [A loss: 0.765101, acc: 0.265625]\n",
      "1140: [D loss: 0.684769, acc: 0.541016]: [A loss: 0.707885, acc: 0.496094]\n",
      "1141: [D loss: 0.699344, acc: 0.507812]: [A loss: 0.811744, acc: 0.156250]\n",
      "1142: [D loss: 0.692625, acc: 0.527344]: [A loss: 0.715727, acc: 0.417969]\n",
      "1143: [D loss: 0.693439, acc: 0.556641]: [A loss: 0.822811, acc: 0.125000]\n",
      "1144: [D loss: 0.692244, acc: 0.521484]: [A loss: 0.701261, acc: 0.488281]\n",
      "1145: [D loss: 0.705355, acc: 0.509766]: [A loss: 0.839545, acc: 0.128906]\n",
      "1146: [D loss: 0.685844, acc: 0.548828]: [A loss: 0.657682, acc: 0.628906]\n",
      "1147: [D loss: 0.693823, acc: 0.535156]: [A loss: 0.832572, acc: 0.078125]\n",
      "1148: [D loss: 0.683488, acc: 0.544922]: [A loss: 0.655185, acc: 0.644531]\n",
      "1149: [D loss: 0.709423, acc: 0.501953]: [A loss: 0.801797, acc: 0.175781]\n",
      "1150: [D loss: 0.691376, acc: 0.535156]: [A loss: 0.645510, acc: 0.695312]\n",
      "1151: [D loss: 0.718827, acc: 0.478516]: [A loss: 0.796417, acc: 0.152344]\n",
      "1152: [D loss: 0.686772, acc: 0.554688]: [A loss: 0.715737, acc: 0.421875]\n",
      "1153: [D loss: 0.692691, acc: 0.519531]: [A loss: 0.755908, acc: 0.308594]\n",
      "1154: [D loss: 0.687661, acc: 0.554688]: [A loss: 0.765093, acc: 0.253906]\n",
      "1155: [D loss: 0.684778, acc: 0.564453]: [A loss: 0.770434, acc: 0.289062]\n",
      "1156: [D loss: 0.690893, acc: 0.505859]: [A loss: 0.725947, acc: 0.398438]\n",
      "1157: [D loss: 0.714537, acc: 0.476562]: [A loss: 0.813285, acc: 0.121094]\n",
      "1158: [D loss: 0.692062, acc: 0.541016]: [A loss: 0.706511, acc: 0.480469]\n",
      "1159: [D loss: 0.697011, acc: 0.519531]: [A loss: 0.806435, acc: 0.164062]\n",
      "1160: [D loss: 0.697227, acc: 0.525391]: [A loss: 0.714403, acc: 0.417969]\n",
      "1161: [D loss: 0.698547, acc: 0.535156]: [A loss: 0.789527, acc: 0.207031]\n",
      "1162: [D loss: 0.697596, acc: 0.509766]: [A loss: 0.748075, acc: 0.300781]\n",
      "1163: [D loss: 0.695471, acc: 0.531250]: [A loss: 0.842874, acc: 0.132812]\n",
      "1164: [D loss: 0.691420, acc: 0.523438]: [A loss: 0.708199, acc: 0.468750]\n",
      "1165: [D loss: 0.707338, acc: 0.484375]: [A loss: 0.802231, acc: 0.167969]\n",
      "1166: [D loss: 0.692197, acc: 0.500000]: [A loss: 0.716956, acc: 0.382812]\n",
      "1167: [D loss: 0.690501, acc: 0.541016]: [A loss: 0.757202, acc: 0.304688]\n",
      "1168: [D loss: 0.700067, acc: 0.515625]: [A loss: 0.741861, acc: 0.316406]\n",
      "1169: [D loss: 0.686990, acc: 0.556641]: [A loss: 0.761228, acc: 0.261719]\n",
      "1170: [D loss: 0.691727, acc: 0.552734]: [A loss: 0.798268, acc: 0.203125]\n",
      "1171: [D loss: 0.693782, acc: 0.539062]: [A loss: 0.739433, acc: 0.343750]\n",
      "1172: [D loss: 0.698138, acc: 0.513672]: [A loss: 0.772138, acc: 0.226562]\n",
      "1173: [D loss: 0.689972, acc: 0.535156]: [A loss: 0.726156, acc: 0.417969]\n",
      "1174: [D loss: 0.690041, acc: 0.535156]: [A loss: 0.761016, acc: 0.292969]\n",
      "1175: [D loss: 0.685548, acc: 0.556641]: [A loss: 0.721719, acc: 0.410156]\n",
      "1176: [D loss: 0.702099, acc: 0.513672]: [A loss: 0.783692, acc: 0.234375]\n",
      "1177: [D loss: 0.698797, acc: 0.494141]: [A loss: 0.766804, acc: 0.273438]\n",
      "1178: [D loss: 0.688572, acc: 0.531250]: [A loss: 0.745074, acc: 0.359375]\n",
      "1179: [D loss: 0.693635, acc: 0.519531]: [A loss: 0.793990, acc: 0.214844]\n",
      "1180: [D loss: 0.699388, acc: 0.503906]: [A loss: 0.740252, acc: 0.351562]\n",
      "1181: [D loss: 0.699151, acc: 0.503906]: [A loss: 0.783912, acc: 0.230469]\n",
      "1182: [D loss: 0.684747, acc: 0.539062]: [A loss: 0.710416, acc: 0.476562]\n",
      "1183: [D loss: 0.691369, acc: 0.527344]: [A loss: 0.844542, acc: 0.089844]\n",
      "1184: [D loss: 0.688312, acc: 0.539062]: [A loss: 0.704858, acc: 0.457031]\n",
      "1185: [D loss: 0.689868, acc: 0.542969]: [A loss: 0.843223, acc: 0.144531]\n",
      "1186: [D loss: 0.690339, acc: 0.521484]: [A loss: 0.697829, acc: 0.503906]\n",
      "1187: [D loss: 0.704821, acc: 0.507812]: [A loss: 0.885760, acc: 0.082031]\n",
      "1188: [D loss: 0.690459, acc: 0.529297]: [A loss: 0.651111, acc: 0.667969]\n",
      "1189: [D loss: 0.705191, acc: 0.515625]: [A loss: 0.815134, acc: 0.164062]\n",
      "1190: [D loss: 0.697266, acc: 0.505859]: [A loss: 0.706224, acc: 0.472656]\n",
      "1191: [D loss: 0.698216, acc: 0.525391]: [A loss: 0.805559, acc: 0.148438]\n",
      "1192: [D loss: 0.694908, acc: 0.552734]: [A loss: 0.732409, acc: 0.367188]\n",
      "1193: [D loss: 0.696178, acc: 0.509766]: [A loss: 0.736982, acc: 0.351562]\n",
      "1194: [D loss: 0.692604, acc: 0.546875]: [A loss: 0.724830, acc: 0.429688]\n",
      "1195: [D loss: 0.704673, acc: 0.488281]: [A loss: 0.792759, acc: 0.179688]\n",
      "1196: [D loss: 0.687481, acc: 0.546875]: [A loss: 0.723915, acc: 0.414062]\n",
      "1197: [D loss: 0.692510, acc: 0.519531]: [A loss: 0.797898, acc: 0.199219]\n",
      "1198: [D loss: 0.697394, acc: 0.515625]: [A loss: 0.719314, acc: 0.429688]\n",
      "1199: [D loss: 0.694583, acc: 0.513672]: [A loss: 0.786627, acc: 0.175781]\n",
      "1200: [D loss: 0.698636, acc: 0.505859]: [A loss: 0.752217, acc: 0.300781]\n",
      "1201: [D loss: 0.695000, acc: 0.496094]: [A loss: 0.779044, acc: 0.218750]\n",
      "1202: [D loss: 0.690269, acc: 0.546875]: [A loss: 0.747514, acc: 0.281250]\n",
      "1203: [D loss: 0.694859, acc: 0.523438]: [A loss: 0.746796, acc: 0.308594]\n",
      "1204: [D loss: 0.693546, acc: 0.525391]: [A loss: 0.805775, acc: 0.191406]\n",
      "1205: [D loss: 0.689298, acc: 0.548828]: [A loss: 0.721290, acc: 0.394531]\n",
      "1206: [D loss: 0.693704, acc: 0.507812]: [A loss: 0.797737, acc: 0.210938]\n",
      "1207: [D loss: 0.685495, acc: 0.541016]: [A loss: 0.705729, acc: 0.488281]\n",
      "1208: [D loss: 0.700093, acc: 0.519531]: [A loss: 0.850959, acc: 0.097656]\n",
      "1209: [D loss: 0.689165, acc: 0.560547]: [A loss: 0.692045, acc: 0.531250]\n",
      "1210: [D loss: 0.686358, acc: 0.531250]: [A loss: 0.817144, acc: 0.132812]\n",
      "1211: [D loss: 0.696145, acc: 0.490234]: [A loss: 0.736259, acc: 0.386719]\n",
      "1212: [D loss: 0.696003, acc: 0.509766]: [A loss: 0.760640, acc: 0.320312]\n",
      "1213: [D loss: 0.693378, acc: 0.519531]: [A loss: 0.740728, acc: 0.347656]\n",
      "1214: [D loss: 0.700506, acc: 0.480469]: [A loss: 0.798256, acc: 0.195312]\n",
      "1215: [D loss: 0.690552, acc: 0.531250]: [A loss: 0.707798, acc: 0.445312]\n",
      "1216: [D loss: 0.690166, acc: 0.535156]: [A loss: 0.815914, acc: 0.156250]\n",
      "1217: [D loss: 0.695483, acc: 0.515625]: [A loss: 0.706609, acc: 0.464844]\n",
      "1218: [D loss: 0.702656, acc: 0.523438]: [A loss: 0.828033, acc: 0.105469]\n",
      "1219: [D loss: 0.690262, acc: 0.554688]: [A loss: 0.681363, acc: 0.566406]\n",
      "1220: [D loss: 0.694770, acc: 0.535156]: [A loss: 0.787774, acc: 0.207031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221: [D loss: 0.684799, acc: 0.570312]: [A loss: 0.752035, acc: 0.296875]\n",
      "1222: [D loss: 0.690700, acc: 0.535156]: [A loss: 0.737227, acc: 0.363281]\n",
      "1223: [D loss: 0.697694, acc: 0.537109]: [A loss: 0.751559, acc: 0.273438]\n",
      "1224: [D loss: 0.692332, acc: 0.527344]: [A loss: 0.767219, acc: 0.273438]\n",
      "1225: [D loss: 0.694672, acc: 0.503906]: [A loss: 0.793500, acc: 0.214844]\n",
      "1226: [D loss: 0.689795, acc: 0.535156]: [A loss: 0.698149, acc: 0.531250]\n",
      "1227: [D loss: 0.694661, acc: 0.525391]: [A loss: 0.844182, acc: 0.078125]\n",
      "1228: [D loss: 0.687521, acc: 0.521484]: [A loss: 0.669355, acc: 0.617188]\n",
      "1229: [D loss: 0.702338, acc: 0.503906]: [A loss: 0.823720, acc: 0.132812]\n",
      "1230: [D loss: 0.691497, acc: 0.542969]: [A loss: 0.696624, acc: 0.480469]\n",
      "1231: [D loss: 0.700285, acc: 0.513672]: [A loss: 0.825649, acc: 0.140625]\n",
      "1232: [D loss: 0.696309, acc: 0.519531]: [A loss: 0.708967, acc: 0.476562]\n",
      "1233: [D loss: 0.698591, acc: 0.500000]: [A loss: 0.797785, acc: 0.191406]\n",
      "1234: [D loss: 0.692166, acc: 0.548828]: [A loss: 0.735133, acc: 0.351562]\n",
      "1235: [D loss: 0.696348, acc: 0.533203]: [A loss: 0.760055, acc: 0.277344]\n",
      "1236: [D loss: 0.693566, acc: 0.521484]: [A loss: 0.728808, acc: 0.386719]\n",
      "1237: [D loss: 0.692488, acc: 0.511719]: [A loss: 0.787739, acc: 0.226562]\n",
      "1238: [D loss: 0.692482, acc: 0.511719]: [A loss: 0.747418, acc: 0.320312]\n",
      "1239: [D loss: 0.684960, acc: 0.533203]: [A loss: 0.784742, acc: 0.242188]\n",
      "1240: [D loss: 0.693959, acc: 0.515625]: [A loss: 0.693258, acc: 0.511719]\n",
      "1241: [D loss: 0.698668, acc: 0.515625]: [A loss: 0.783036, acc: 0.214844]\n",
      "1242: [D loss: 0.689297, acc: 0.542969]: [A loss: 0.665620, acc: 0.632812]\n",
      "1243: [D loss: 0.701836, acc: 0.523438]: [A loss: 0.808024, acc: 0.167969]\n",
      "1244: [D loss: 0.695264, acc: 0.537109]: [A loss: 0.712203, acc: 0.457031]\n",
      "1245: [D loss: 0.709190, acc: 0.488281]: [A loss: 0.806688, acc: 0.218750]\n",
      "1246: [D loss: 0.685323, acc: 0.544922]: [A loss: 0.716763, acc: 0.421875]\n",
      "1247: [D loss: 0.698278, acc: 0.529297]: [A loss: 0.788377, acc: 0.222656]\n",
      "1248: [D loss: 0.690369, acc: 0.521484]: [A loss: 0.707229, acc: 0.488281]\n",
      "1249: [D loss: 0.689783, acc: 0.539062]: [A loss: 0.763666, acc: 0.273438]\n",
      "1250: [D loss: 0.695851, acc: 0.494141]: [A loss: 0.778123, acc: 0.210938]\n",
      "1251: [D loss: 0.693606, acc: 0.507812]: [A loss: 0.715663, acc: 0.402344]\n",
      "1252: [D loss: 0.700496, acc: 0.501953]: [A loss: 0.812162, acc: 0.113281]\n",
      "1253: [D loss: 0.689527, acc: 0.529297]: [A loss: 0.727580, acc: 0.375000]\n",
      "1254: [D loss: 0.698557, acc: 0.527344]: [A loss: 0.728449, acc: 0.398438]\n",
      "1255: [D loss: 0.694798, acc: 0.537109]: [A loss: 0.803813, acc: 0.175781]\n",
      "1256: [D loss: 0.690177, acc: 0.509766]: [A loss: 0.724864, acc: 0.414062]\n",
      "1257: [D loss: 0.698136, acc: 0.509766]: [A loss: 0.796451, acc: 0.164062]\n",
      "1258: [D loss: 0.684181, acc: 0.550781]: [A loss: 0.700531, acc: 0.496094]\n",
      "1259: [D loss: 0.694244, acc: 0.535156]: [A loss: 0.786276, acc: 0.222656]\n",
      "1260: [D loss: 0.688586, acc: 0.548828]: [A loss: 0.701214, acc: 0.464844]\n",
      "1261: [D loss: 0.698817, acc: 0.511719]: [A loss: 0.808137, acc: 0.160156]\n",
      "1262: [D loss: 0.696924, acc: 0.539062]: [A loss: 0.731386, acc: 0.371094]\n",
      "1263: [D loss: 0.693347, acc: 0.539062]: [A loss: 0.749398, acc: 0.304688]\n",
      "1264: [D loss: 0.694758, acc: 0.535156]: [A loss: 0.777548, acc: 0.207031]\n",
      "1265: [D loss: 0.693494, acc: 0.533203]: [A loss: 0.722245, acc: 0.390625]\n",
      "1266: [D loss: 0.695768, acc: 0.531250]: [A loss: 0.840300, acc: 0.097656]\n",
      "1267: [D loss: 0.699312, acc: 0.488281]: [A loss: 0.737641, acc: 0.363281]\n",
      "1268: [D loss: 0.692592, acc: 0.535156]: [A loss: 0.780366, acc: 0.238281]\n",
      "1269: [D loss: 0.689778, acc: 0.533203]: [A loss: 0.737810, acc: 0.343750]\n",
      "1270: [D loss: 0.699442, acc: 0.515625]: [A loss: 0.822426, acc: 0.105469]\n",
      "1271: [D loss: 0.691573, acc: 0.531250]: [A loss: 0.755309, acc: 0.289062]\n",
      "1272: [D loss: 0.688272, acc: 0.533203]: [A loss: 0.728385, acc: 0.355469]\n",
      "1273: [D loss: 0.696321, acc: 0.537109]: [A loss: 0.761543, acc: 0.261719]\n",
      "1274: [D loss: 0.697533, acc: 0.488281]: [A loss: 0.724097, acc: 0.378906]\n",
      "1275: [D loss: 0.692354, acc: 0.496094]: [A loss: 0.757486, acc: 0.289062]\n",
      "1276: [D loss: 0.693937, acc: 0.513672]: [A loss: 0.752594, acc: 0.304688]\n",
      "1277: [D loss: 0.698427, acc: 0.501953]: [A loss: 0.797157, acc: 0.175781]\n",
      "1278: [D loss: 0.693548, acc: 0.509766]: [A loss: 0.728746, acc: 0.382812]\n",
      "1279: [D loss: 0.683646, acc: 0.574219]: [A loss: 0.823251, acc: 0.148438]\n",
      "1280: [D loss: 0.702080, acc: 0.496094]: [A loss: 0.733601, acc: 0.355469]\n",
      "1281: [D loss: 0.696273, acc: 0.529297]: [A loss: 0.812737, acc: 0.160156]\n",
      "1282: [D loss: 0.697445, acc: 0.517578]: [A loss: 0.775508, acc: 0.195312]\n",
      "1283: [D loss: 0.695585, acc: 0.517578]: [A loss: 0.737061, acc: 0.328125]\n",
      "1284: [D loss: 0.692175, acc: 0.525391]: [A loss: 0.730955, acc: 0.363281]\n",
      "1285: [D loss: 0.698923, acc: 0.500000]: [A loss: 0.734533, acc: 0.421875]\n",
      "1286: [D loss: 0.687350, acc: 0.525391]: [A loss: 0.801272, acc: 0.160156]\n",
      "1287: [D loss: 0.689829, acc: 0.554688]: [A loss: 0.731275, acc: 0.363281]\n",
      "1288: [D loss: 0.684063, acc: 0.552734]: [A loss: 0.786173, acc: 0.214844]\n",
      "1289: [D loss: 0.687892, acc: 0.519531]: [A loss: 0.676682, acc: 0.562500]\n",
      "1290: [D loss: 0.709198, acc: 0.503906]: [A loss: 0.884384, acc: 0.058594]\n",
      "1291: [D loss: 0.692386, acc: 0.533203]: [A loss: 0.669010, acc: 0.617188]\n",
      "1292: [D loss: 0.705606, acc: 0.498047]: [A loss: 0.837561, acc: 0.097656]\n",
      "1293: [D loss: 0.692207, acc: 0.523438]: [A loss: 0.756448, acc: 0.289062]\n",
      "1294: [D loss: 0.691542, acc: 0.527344]: [A loss: 0.763276, acc: 0.281250]\n",
      "1295: [D loss: 0.691549, acc: 0.539062]: [A loss: 0.738962, acc: 0.355469]\n",
      "1296: [D loss: 0.692621, acc: 0.542969]: [A loss: 0.756440, acc: 0.304688]\n",
      "1297: [D loss: 0.704947, acc: 0.490234]: [A loss: 0.743646, acc: 0.328125]\n",
      "1298: [D loss: 0.695833, acc: 0.519531]: [A loss: 0.773942, acc: 0.238281]\n",
      "1299: [D loss: 0.694494, acc: 0.509766]: [A loss: 0.702974, acc: 0.476562]\n",
      "1300: [D loss: 0.697136, acc: 0.509766]: [A loss: 0.777717, acc: 0.222656]\n",
      "1301: [D loss: 0.690371, acc: 0.548828]: [A loss: 0.718984, acc: 0.394531]\n",
      "1302: [D loss: 0.692608, acc: 0.513672]: [A loss: 0.807471, acc: 0.125000]\n",
      "1303: [D loss: 0.696353, acc: 0.515625]: [A loss: 0.683225, acc: 0.597656]\n",
      "1304: [D loss: 0.707166, acc: 0.498047]: [A loss: 0.854443, acc: 0.117188]\n",
      "1305: [D loss: 0.693213, acc: 0.507812]: [A loss: 0.712236, acc: 0.417969]\n",
      "1306: [D loss: 0.700146, acc: 0.488281]: [A loss: 0.764902, acc: 0.253906]\n",
      "1307: [D loss: 0.696312, acc: 0.503906]: [A loss: 0.754278, acc: 0.285156]\n",
      "1308: [D loss: 0.696083, acc: 0.515625]: [A loss: 0.732838, acc: 0.335938]\n",
      "1309: [D loss: 0.694686, acc: 0.505859]: [A loss: 0.757403, acc: 0.261719]\n",
      "1310: [D loss: 0.694186, acc: 0.529297]: [A loss: 0.786327, acc: 0.242188]\n",
      "1311: [D loss: 0.690825, acc: 0.523438]: [A loss: 0.723416, acc: 0.375000]\n",
      "1312: [D loss: 0.699581, acc: 0.531250]: [A loss: 0.806009, acc: 0.167969]\n",
      "1313: [D loss: 0.695772, acc: 0.505859]: [A loss: 0.708679, acc: 0.449219]\n",
      "1314: [D loss: 0.692798, acc: 0.513672]: [A loss: 0.772221, acc: 0.265625]\n",
      "1315: [D loss: 0.682741, acc: 0.560547]: [A loss: 0.759261, acc: 0.296875]\n",
      "1316: [D loss: 0.692191, acc: 0.537109]: [A loss: 0.765215, acc: 0.269531]\n",
      "1317: [D loss: 0.695249, acc: 0.505859]: [A loss: 0.718964, acc: 0.433594]\n",
      "1318: [D loss: 0.690493, acc: 0.525391]: [A loss: 0.776938, acc: 0.234375]\n",
      "1319: [D loss: 0.698777, acc: 0.488281]: [A loss: 0.758868, acc: 0.281250]\n",
      "1320: [D loss: 0.693301, acc: 0.527344]: [A loss: 0.769941, acc: 0.265625]\n",
      "1321: [D loss: 0.696814, acc: 0.494141]: [A loss: 0.727593, acc: 0.402344]\n",
      "1322: [D loss: 0.699131, acc: 0.496094]: [A loss: 0.804713, acc: 0.195312]\n",
      "1323: [D loss: 0.691562, acc: 0.533203]: [A loss: 0.733771, acc: 0.343750]\n",
      "1324: [D loss: 0.694369, acc: 0.531250]: [A loss: 0.788932, acc: 0.214844]\n",
      "1325: [D loss: 0.691174, acc: 0.535156]: [A loss: 0.770883, acc: 0.292969]\n",
      "1326: [D loss: 0.695430, acc: 0.503906]: [A loss: 0.736189, acc: 0.375000]\n",
      "1327: [D loss: 0.695197, acc: 0.521484]: [A loss: 0.787276, acc: 0.175781]\n",
      "1328: [D loss: 0.696562, acc: 0.492188]: [A loss: 0.754671, acc: 0.281250]\n",
      "1329: [D loss: 0.694661, acc: 0.523438]: [A loss: 0.757911, acc: 0.257812]\n",
      "1330: [D loss: 0.699923, acc: 0.501953]: [A loss: 0.702858, acc: 0.480469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1331: [D loss: 0.706400, acc: 0.539062]: [A loss: 0.876977, acc: 0.066406]\n",
      "1332: [D loss: 0.693817, acc: 0.509766]: [A loss: 0.665548, acc: 0.605469]\n",
      "1333: [D loss: 0.705629, acc: 0.501953]: [A loss: 0.850183, acc: 0.062500]\n",
      "1334: [D loss: 0.688286, acc: 0.558594]: [A loss: 0.669896, acc: 0.582031]\n",
      "1335: [D loss: 0.706276, acc: 0.492188]: [A loss: 0.801024, acc: 0.156250]\n",
      "1336: [D loss: 0.689228, acc: 0.537109]: [A loss: 0.770722, acc: 0.207031]\n",
      "1337: [D loss: 0.692907, acc: 0.509766]: [A loss: 0.774599, acc: 0.222656]\n",
      "1338: [D loss: 0.682110, acc: 0.574219]: [A loss: 0.756558, acc: 0.328125]\n",
      "1339: [D loss: 0.694110, acc: 0.529297]: [A loss: 0.736992, acc: 0.324219]\n",
      "1340: [D loss: 0.692266, acc: 0.519531]: [A loss: 0.764399, acc: 0.257812]\n",
      "1341: [D loss: 0.689798, acc: 0.529297]: [A loss: 0.693963, acc: 0.519531]\n",
      "1342: [D loss: 0.703977, acc: 0.525391]: [A loss: 0.835337, acc: 0.113281]\n",
      "1343: [D loss: 0.688412, acc: 0.552734]: [A loss: 0.695527, acc: 0.507812]\n",
      "1344: [D loss: 0.705057, acc: 0.513672]: [A loss: 0.793716, acc: 0.199219]\n",
      "1345: [D loss: 0.690010, acc: 0.519531]: [A loss: 0.704717, acc: 0.464844]\n",
      "1346: [D loss: 0.707439, acc: 0.503906]: [A loss: 0.822456, acc: 0.156250]\n",
      "1347: [D loss: 0.692752, acc: 0.548828]: [A loss: 0.674903, acc: 0.593750]\n",
      "1348: [D loss: 0.698909, acc: 0.517578]: [A loss: 0.770773, acc: 0.238281]\n",
      "1349: [D loss: 0.691335, acc: 0.533203]: [A loss: 0.727136, acc: 0.398438]\n",
      "1350: [D loss: 0.698261, acc: 0.490234]: [A loss: 0.724256, acc: 0.378906]\n",
      "1351: [D loss: 0.692429, acc: 0.527344]: [A loss: 0.745024, acc: 0.300781]\n",
      "1352: [D loss: 0.692088, acc: 0.535156]: [A loss: 0.745623, acc: 0.339844]\n",
      "1353: [D loss: 0.688853, acc: 0.519531]: [A loss: 0.741793, acc: 0.316406]\n",
      "1354: [D loss: 0.693620, acc: 0.527344]: [A loss: 0.780271, acc: 0.250000]\n",
      "1355: [D loss: 0.697647, acc: 0.511719]: [A loss: 0.732765, acc: 0.367188]\n",
      "1356: [D loss: 0.691010, acc: 0.533203]: [A loss: 0.718246, acc: 0.406250]\n",
      "1357: [D loss: 0.701051, acc: 0.501953]: [A loss: 0.751540, acc: 0.324219]\n",
      "1358: [D loss: 0.697179, acc: 0.496094]: [A loss: 0.741352, acc: 0.335938]\n",
      "1359: [D loss: 0.698227, acc: 0.494141]: [A loss: 0.809900, acc: 0.195312]\n",
      "1360: [D loss: 0.690513, acc: 0.546875]: [A loss: 0.698766, acc: 0.457031]\n",
      "1361: [D loss: 0.702584, acc: 0.500000]: [A loss: 0.818331, acc: 0.152344]\n",
      "1362: [D loss: 0.689550, acc: 0.525391]: [A loss: 0.695061, acc: 0.515625]\n",
      "1363: [D loss: 0.703454, acc: 0.517578]: [A loss: 0.828361, acc: 0.136719]\n",
      "1364: [D loss: 0.694408, acc: 0.503906]: [A loss: 0.674806, acc: 0.574219]\n",
      "1365: [D loss: 0.694049, acc: 0.533203]: [A loss: 0.767551, acc: 0.261719]\n",
      "1366: [D loss: 0.687626, acc: 0.541016]: [A loss: 0.754375, acc: 0.308594]\n",
      "1367: [D loss: 0.701307, acc: 0.513672]: [A loss: 0.743226, acc: 0.328125]\n",
      "1368: [D loss: 0.696329, acc: 0.503906]: [A loss: 0.761203, acc: 0.277344]\n",
      "1369: [D loss: 0.694228, acc: 0.511719]: [A loss: 0.701412, acc: 0.500000]\n",
      "1370: [D loss: 0.695494, acc: 0.511719]: [A loss: 0.805587, acc: 0.167969]\n",
      "1371: [D loss: 0.690806, acc: 0.533203]: [A loss: 0.705612, acc: 0.484375]\n",
      "1372: [D loss: 0.702115, acc: 0.513672]: [A loss: 0.795373, acc: 0.171875]\n",
      "1373: [D loss: 0.689495, acc: 0.541016]: [A loss: 0.724639, acc: 0.421875]\n",
      "1374: [D loss: 0.706711, acc: 0.458984]: [A loss: 0.797603, acc: 0.203125]\n",
      "1375: [D loss: 0.694003, acc: 0.527344]: [A loss: 0.680496, acc: 0.574219]\n",
      "1376: [D loss: 0.710497, acc: 0.509766]: [A loss: 0.830466, acc: 0.085938]\n",
      "1377: [D loss: 0.690108, acc: 0.521484]: [A loss: 0.707690, acc: 0.488281]\n",
      "1378: [D loss: 0.699374, acc: 0.507812]: [A loss: 0.775714, acc: 0.195312]\n",
      "1379: [D loss: 0.692377, acc: 0.519531]: [A loss: 0.695091, acc: 0.503906]\n",
      "1380: [D loss: 0.693146, acc: 0.505859]: [A loss: 0.738666, acc: 0.351562]\n",
      "1381: [D loss: 0.689800, acc: 0.546875]: [A loss: 0.775369, acc: 0.218750]\n",
      "1382: [D loss: 0.693243, acc: 0.527344]: [A loss: 0.676687, acc: 0.593750]\n",
      "1383: [D loss: 0.698180, acc: 0.521484]: [A loss: 0.797254, acc: 0.203125]\n",
      "1384: [D loss: 0.691965, acc: 0.517578]: [A loss: 0.708762, acc: 0.441406]\n",
      "1385: [D loss: 0.696661, acc: 0.505859]: [A loss: 0.791386, acc: 0.199219]\n",
      "1386: [D loss: 0.704597, acc: 0.490234]: [A loss: 0.698282, acc: 0.519531]\n",
      "1387: [D loss: 0.698667, acc: 0.531250]: [A loss: 0.768133, acc: 0.238281]\n",
      "1388: [D loss: 0.681247, acc: 0.578125]: [A loss: 0.732058, acc: 0.367188]\n",
      "1389: [D loss: 0.700913, acc: 0.492188]: [A loss: 0.761504, acc: 0.257812]\n",
      "1390: [D loss: 0.692066, acc: 0.509766]: [A loss: 0.719421, acc: 0.382812]\n",
      "1391: [D loss: 0.695196, acc: 0.525391]: [A loss: 0.773264, acc: 0.234375]\n",
      "1392: [D loss: 0.690054, acc: 0.535156]: [A loss: 0.698603, acc: 0.511719]\n",
      "1393: [D loss: 0.694376, acc: 0.515625]: [A loss: 0.750427, acc: 0.328125]\n",
      "1394: [D loss: 0.697787, acc: 0.488281]: [A loss: 0.737603, acc: 0.324219]\n",
      "1395: [D loss: 0.692487, acc: 0.541016]: [A loss: 0.788403, acc: 0.175781]\n",
      "1396: [D loss: 0.696015, acc: 0.519531]: [A loss: 0.765777, acc: 0.246094]\n",
      "1397: [D loss: 0.695265, acc: 0.515625]: [A loss: 0.736671, acc: 0.347656]\n",
      "1398: [D loss: 0.697614, acc: 0.523438]: [A loss: 0.757293, acc: 0.265625]\n",
      "1399: [D loss: 0.697174, acc: 0.501953]: [A loss: 0.708958, acc: 0.476562]\n",
      "1400: [D loss: 0.693482, acc: 0.533203]: [A loss: 0.776543, acc: 0.222656]\n",
      "1401: [D loss: 0.694829, acc: 0.519531]: [A loss: 0.700887, acc: 0.503906]\n",
      "1402: [D loss: 0.694647, acc: 0.533203]: [A loss: 0.786851, acc: 0.226562]\n",
      "1403: [D loss: 0.693066, acc: 0.546875]: [A loss: 0.745211, acc: 0.304688]\n",
      "1404: [D loss: 0.697233, acc: 0.525391]: [A loss: 0.809535, acc: 0.117188]\n",
      "1405: [D loss: 0.685746, acc: 0.539062]: [A loss: 0.698454, acc: 0.476562]\n",
      "1406: [D loss: 0.686157, acc: 0.535156]: [A loss: 0.757524, acc: 0.234375]\n",
      "1407: [D loss: 0.694872, acc: 0.535156]: [A loss: 0.708517, acc: 0.472656]\n",
      "1408: [D loss: 0.699828, acc: 0.519531]: [A loss: 0.805679, acc: 0.128906]\n",
      "1409: [D loss: 0.695763, acc: 0.523438]: [A loss: 0.690598, acc: 0.496094]\n",
      "1410: [D loss: 0.698485, acc: 0.535156]: [A loss: 0.800469, acc: 0.160156]\n",
      "1411: [D loss: 0.690741, acc: 0.541016]: [A loss: 0.698900, acc: 0.484375]\n",
      "1412: [D loss: 0.703874, acc: 0.503906]: [A loss: 0.804700, acc: 0.148438]\n",
      "1413: [D loss: 0.692344, acc: 0.539062]: [A loss: 0.727037, acc: 0.367188]\n",
      "1414: [D loss: 0.690220, acc: 0.537109]: [A loss: 0.842327, acc: 0.089844]\n",
      "1415: [D loss: 0.692488, acc: 0.531250]: [A loss: 0.702284, acc: 0.468750]\n",
      "1416: [D loss: 0.705636, acc: 0.505859]: [A loss: 0.792008, acc: 0.214844]\n",
      "1417: [D loss: 0.687184, acc: 0.535156]: [A loss: 0.726369, acc: 0.386719]\n",
      "1418: [D loss: 0.697182, acc: 0.501953]: [A loss: 0.756317, acc: 0.261719]\n",
      "1419: [D loss: 0.689753, acc: 0.548828]: [A loss: 0.731311, acc: 0.367188]\n",
      "1420: [D loss: 0.690065, acc: 0.541016]: [A loss: 0.705250, acc: 0.480469]\n",
      "1421: [D loss: 0.693075, acc: 0.511719]: [A loss: 0.782736, acc: 0.167969]\n",
      "1422: [D loss: 0.693193, acc: 0.529297]: [A loss: 0.721371, acc: 0.425781]\n",
      "1423: [D loss: 0.693996, acc: 0.525391]: [A loss: 0.770035, acc: 0.230469]\n",
      "1424: [D loss: 0.689544, acc: 0.521484]: [A loss: 0.744253, acc: 0.308594]\n",
      "1425: [D loss: 0.697179, acc: 0.515625]: [A loss: 0.801412, acc: 0.171875]\n",
      "1426: [D loss: 0.704064, acc: 0.488281]: [A loss: 0.744680, acc: 0.312500]\n",
      "1427: [D loss: 0.691391, acc: 0.535156]: [A loss: 0.777838, acc: 0.230469]\n",
      "1428: [D loss: 0.694695, acc: 0.523438]: [A loss: 0.752406, acc: 0.292969]\n",
      "1429: [D loss: 0.700049, acc: 0.486328]: [A loss: 0.735071, acc: 0.324219]\n",
      "1430: [D loss: 0.699024, acc: 0.513672]: [A loss: 0.733730, acc: 0.355469]\n",
      "1431: [D loss: 0.696159, acc: 0.511719]: [A loss: 0.790296, acc: 0.160156]\n",
      "1432: [D loss: 0.691328, acc: 0.525391]: [A loss: 0.716244, acc: 0.414062]\n",
      "1433: [D loss: 0.695332, acc: 0.501953]: [A loss: 0.786673, acc: 0.234375]\n",
      "1434: [D loss: 0.695990, acc: 0.527344]: [A loss: 0.680420, acc: 0.582031]\n",
      "1435: [D loss: 0.705260, acc: 0.501953]: [A loss: 0.751732, acc: 0.257812]\n",
      "1436: [D loss: 0.693589, acc: 0.535156]: [A loss: 0.719780, acc: 0.406250]\n",
      "1437: [D loss: 0.699477, acc: 0.494141]: [A loss: 0.767908, acc: 0.203125]\n",
      "1438: [D loss: 0.699394, acc: 0.509766]: [A loss: 0.728298, acc: 0.328125]\n",
      "1439: [D loss: 0.691968, acc: 0.556641]: [A loss: 0.756261, acc: 0.253906]\n",
      "1440: [D loss: 0.696990, acc: 0.519531]: [A loss: 0.778381, acc: 0.187500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441: [D loss: 0.689977, acc: 0.525391]: [A loss: 0.686244, acc: 0.546875]\n",
      "1442: [D loss: 0.695856, acc: 0.492188]: [A loss: 0.814441, acc: 0.132812]\n",
      "1443: [D loss: 0.692568, acc: 0.541016]: [A loss: 0.692807, acc: 0.531250]\n",
      "1444: [D loss: 0.704024, acc: 0.500000]: [A loss: 0.811887, acc: 0.113281]\n",
      "1445: [D loss: 0.692911, acc: 0.539062]: [A loss: 0.700400, acc: 0.484375]\n",
      "1446: [D loss: 0.698852, acc: 0.527344]: [A loss: 0.803443, acc: 0.183594]\n",
      "1447: [D loss: 0.691491, acc: 0.537109]: [A loss: 0.744986, acc: 0.277344]\n",
      "1448: [D loss: 0.693663, acc: 0.537109]: [A loss: 0.739338, acc: 0.378906]\n",
      "1449: [D loss: 0.694835, acc: 0.505859]: [A loss: 0.730040, acc: 0.390625]\n",
      "1450: [D loss: 0.698275, acc: 0.533203]: [A loss: 0.749053, acc: 0.308594]\n",
      "1451: [D loss: 0.694406, acc: 0.529297]: [A loss: 0.726797, acc: 0.371094]\n",
      "1452: [D loss: 0.696766, acc: 0.511719]: [A loss: 0.743061, acc: 0.335938]\n",
      "1453: [D loss: 0.690901, acc: 0.529297]: [A loss: 0.765246, acc: 0.246094]\n",
      "1454: [D loss: 0.694529, acc: 0.511719]: [A loss: 0.723569, acc: 0.382812]\n",
      "1455: [D loss: 0.699756, acc: 0.498047]: [A loss: 0.778874, acc: 0.203125]\n",
      "1456: [D loss: 0.700632, acc: 0.478516]: [A loss: 0.740398, acc: 0.312500]\n",
      "1457: [D loss: 0.692290, acc: 0.527344]: [A loss: 0.772974, acc: 0.226562]\n",
      "1458: [D loss: 0.693592, acc: 0.525391]: [A loss: 0.693980, acc: 0.468750]\n",
      "1459: [D loss: 0.707252, acc: 0.490234]: [A loss: 0.857318, acc: 0.097656]\n",
      "1460: [D loss: 0.699398, acc: 0.468750]: [A loss: 0.660498, acc: 0.625000]\n",
      "1461: [D loss: 0.703470, acc: 0.507812]: [A loss: 0.809482, acc: 0.164062]\n",
      "1462: [D loss: 0.696271, acc: 0.490234]: [A loss: 0.688545, acc: 0.523438]\n",
      "1463: [D loss: 0.699631, acc: 0.519531]: [A loss: 0.751661, acc: 0.269531]\n",
      "1464: [D loss: 0.696733, acc: 0.501953]: [A loss: 0.745057, acc: 0.292969]\n",
      "1465: [D loss: 0.695564, acc: 0.505859]: [A loss: 0.735621, acc: 0.335938]\n",
      "1466: [D loss: 0.695814, acc: 0.500000]: [A loss: 0.725092, acc: 0.371094]\n",
      "1467: [D loss: 0.705003, acc: 0.486328]: [A loss: 0.718865, acc: 0.378906]\n",
      "1468: [D loss: 0.703425, acc: 0.484375]: [A loss: 0.761352, acc: 0.238281]\n",
      "1469: [D loss: 0.692080, acc: 0.546875]: [A loss: 0.735759, acc: 0.351562]\n",
      "1470: [D loss: 0.695639, acc: 0.523438]: [A loss: 0.780305, acc: 0.195312]\n",
      "1471: [D loss: 0.698072, acc: 0.484375]: [A loss: 0.716958, acc: 0.406250]\n",
      "1472: [D loss: 0.695275, acc: 0.515625]: [A loss: 0.760701, acc: 0.273438]\n",
      "1473: [D loss: 0.695323, acc: 0.521484]: [A loss: 0.689483, acc: 0.558594]\n",
      "1474: [D loss: 0.701039, acc: 0.500000]: [A loss: 0.747945, acc: 0.312500]\n",
      "1475: [D loss: 0.698913, acc: 0.501953]: [A loss: 0.766225, acc: 0.234375]\n",
      "1476: [D loss: 0.689279, acc: 0.560547]: [A loss: 0.703759, acc: 0.527344]\n",
      "1477: [D loss: 0.696527, acc: 0.513672]: [A loss: 0.792247, acc: 0.156250]\n",
      "1478: [D loss: 0.688470, acc: 0.560547]: [A loss: 0.724241, acc: 0.394531]\n",
      "1479: [D loss: 0.695122, acc: 0.488281]: [A loss: 0.819246, acc: 0.109375]\n",
      "1480: [D loss: 0.691748, acc: 0.541016]: [A loss: 0.724670, acc: 0.402344]\n",
      "1481: [D loss: 0.697891, acc: 0.486328]: [A loss: 0.737747, acc: 0.347656]\n",
      "1482: [D loss: 0.693143, acc: 0.535156]: [A loss: 0.766403, acc: 0.230469]\n",
      "1483: [D loss: 0.691335, acc: 0.541016]: [A loss: 0.709819, acc: 0.496094]\n",
      "1484: [D loss: 0.707940, acc: 0.468750]: [A loss: 0.773718, acc: 0.242188]\n",
      "1485: [D loss: 0.694636, acc: 0.517578]: [A loss: 0.687764, acc: 0.566406]\n",
      "1486: [D loss: 0.690556, acc: 0.513672]: [A loss: 0.789311, acc: 0.144531]\n",
      "1487: [D loss: 0.693571, acc: 0.517578]: [A loss: 0.686908, acc: 0.546875]\n",
      "1488: [D loss: 0.685310, acc: 0.521484]: [A loss: 0.756870, acc: 0.265625]\n",
      "1489: [D loss: 0.691154, acc: 0.525391]: [A loss: 0.802179, acc: 0.148438]\n",
      "1490: [D loss: 0.692752, acc: 0.539062]: [A loss: 0.711312, acc: 0.445312]\n",
      "1491: [D loss: 0.700166, acc: 0.511719]: [A loss: 0.777559, acc: 0.195312]\n",
      "1492: [D loss: 0.699236, acc: 0.513672]: [A loss: 0.695115, acc: 0.507812]\n",
      "1493: [D loss: 0.695073, acc: 0.521484]: [A loss: 0.769407, acc: 0.207031]\n",
      "1494: [D loss: 0.685919, acc: 0.544922]: [A loss: 0.739713, acc: 0.332031]\n",
      "1495: [D loss: 0.696519, acc: 0.505859]: [A loss: 0.768725, acc: 0.210938]\n",
      "1496: [D loss: 0.693248, acc: 0.515625]: [A loss: 0.705408, acc: 0.488281]\n",
      "1497: [D loss: 0.695811, acc: 0.492188]: [A loss: 0.780659, acc: 0.187500]\n",
      "1498: [D loss: 0.692357, acc: 0.535156]: [A loss: 0.722968, acc: 0.406250]\n",
      "1499: [D loss: 0.696026, acc: 0.517578]: [A loss: 0.775870, acc: 0.207031]\n",
      "1500: [D loss: 0.688910, acc: 0.539062]: [A loss: 0.704307, acc: 0.449219]\n",
      "1501: [D loss: 0.694917, acc: 0.523438]: [A loss: 0.761913, acc: 0.230469]\n",
      "1502: [D loss: 0.687693, acc: 0.568359]: [A loss: 0.732849, acc: 0.343750]\n",
      "1503: [D loss: 0.690804, acc: 0.535156]: [A loss: 0.760624, acc: 0.277344]\n",
      "1504: [D loss: 0.690265, acc: 0.533203]: [A loss: 0.707017, acc: 0.453125]\n",
      "1505: [D loss: 0.696369, acc: 0.509766]: [A loss: 0.759275, acc: 0.273438]\n",
      "1506: [D loss: 0.690888, acc: 0.533203]: [A loss: 0.778937, acc: 0.195312]\n",
      "1507: [D loss: 0.687121, acc: 0.542969]: [A loss: 0.733037, acc: 0.343750]\n",
      "1508: [D loss: 0.694624, acc: 0.529297]: [A loss: 0.738380, acc: 0.359375]\n",
      "1509: [D loss: 0.698328, acc: 0.484375]: [A loss: 0.739212, acc: 0.324219]\n",
      "1510: [D loss: 0.706509, acc: 0.480469]: [A loss: 0.772887, acc: 0.226562]\n",
      "1511: [D loss: 0.686936, acc: 0.550781]: [A loss: 0.771065, acc: 0.234375]\n",
      "1512: [D loss: 0.689809, acc: 0.550781]: [A loss: 0.774483, acc: 0.210938]\n",
      "1513: [D loss: 0.683238, acc: 0.560547]: [A loss: 0.733338, acc: 0.339844]\n",
      "1514: [D loss: 0.700762, acc: 0.488281]: [A loss: 0.752490, acc: 0.296875]\n",
      "1515: [D loss: 0.693959, acc: 0.523438]: [A loss: 0.816399, acc: 0.136719]\n",
      "1516: [D loss: 0.701182, acc: 0.494141]: [A loss: 0.668966, acc: 0.617188]\n",
      "1517: [D loss: 0.705229, acc: 0.515625]: [A loss: 0.828764, acc: 0.097656]\n",
      "1518: [D loss: 0.700440, acc: 0.490234]: [A loss: 0.702605, acc: 0.507812]\n",
      "1519: [D loss: 0.703765, acc: 0.500000]: [A loss: 0.771223, acc: 0.253906]\n",
      "1520: [D loss: 0.693581, acc: 0.523438]: [A loss: 0.708395, acc: 0.429688]\n",
      "1521: [D loss: 0.700857, acc: 0.501953]: [A loss: 0.742987, acc: 0.316406]\n",
      "1522: [D loss: 0.704753, acc: 0.486328]: [A loss: 0.750084, acc: 0.250000]\n",
      "1523: [D loss: 0.693325, acc: 0.523438]: [A loss: 0.743927, acc: 0.312500]\n",
      "1524: [D loss: 0.698546, acc: 0.498047]: [A loss: 0.757833, acc: 0.253906]\n",
      "1525: [D loss: 0.694752, acc: 0.498047]: [A loss: 0.768245, acc: 0.187500]\n",
      "1526: [D loss: 0.695491, acc: 0.500000]: [A loss: 0.680975, acc: 0.589844]\n",
      "1527: [D loss: 0.698734, acc: 0.515625]: [A loss: 0.781896, acc: 0.160156]\n",
      "1528: [D loss: 0.694630, acc: 0.521484]: [A loss: 0.704680, acc: 0.457031]\n",
      "1529: [D loss: 0.693988, acc: 0.542969]: [A loss: 0.722755, acc: 0.367188]\n",
      "1530: [D loss: 0.686724, acc: 0.542969]: [A loss: 0.759949, acc: 0.238281]\n",
      "1531: [D loss: 0.694642, acc: 0.509766]: [A loss: 0.709399, acc: 0.457031]\n",
      "1532: [D loss: 0.694756, acc: 0.529297]: [A loss: 0.751416, acc: 0.308594]\n",
      "1533: [D loss: 0.688290, acc: 0.537109]: [A loss: 0.715257, acc: 0.453125]\n",
      "1534: [D loss: 0.696677, acc: 0.486328]: [A loss: 0.818931, acc: 0.085938]\n",
      "1535: [D loss: 0.688198, acc: 0.527344]: [A loss: 0.691721, acc: 0.511719]\n",
      "1536: [D loss: 0.703280, acc: 0.503906]: [A loss: 0.771418, acc: 0.187500]\n",
      "1537: [D loss: 0.694912, acc: 0.517578]: [A loss: 0.697944, acc: 0.492188]\n",
      "1538: [D loss: 0.695346, acc: 0.529297]: [A loss: 0.766860, acc: 0.230469]\n",
      "1539: [D loss: 0.690734, acc: 0.533203]: [A loss: 0.730941, acc: 0.320312]\n",
      "1540: [D loss: 0.702608, acc: 0.500000]: [A loss: 0.792422, acc: 0.156250]\n",
      "1541: [D loss: 0.694294, acc: 0.486328]: [A loss: 0.692355, acc: 0.511719]\n",
      "1542: [D loss: 0.693811, acc: 0.521484]: [A loss: 0.774904, acc: 0.226562]\n",
      "1543: [D loss: 0.695024, acc: 0.501953]: [A loss: 0.706405, acc: 0.464844]\n",
      "1544: [D loss: 0.695325, acc: 0.519531]: [A loss: 0.773523, acc: 0.207031]\n",
      "1545: [D loss: 0.688215, acc: 0.531250]: [A loss: 0.716024, acc: 0.433594]\n",
      "1546: [D loss: 0.688728, acc: 0.527344]: [A loss: 0.795824, acc: 0.179688]\n",
      "1547: [D loss: 0.694171, acc: 0.523438]: [A loss: 0.676641, acc: 0.570312]\n",
      "1548: [D loss: 0.704531, acc: 0.500000]: [A loss: 0.779701, acc: 0.183594]\n",
      "1549: [D loss: 0.689993, acc: 0.527344]: [A loss: 0.687134, acc: 0.515625]\n",
      "1550: [D loss: 0.700533, acc: 0.501953]: [A loss: 0.788338, acc: 0.175781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1551: [D loss: 0.687012, acc: 0.539062]: [A loss: 0.726975, acc: 0.351562]\n",
      "1552: [D loss: 0.688638, acc: 0.535156]: [A loss: 0.737866, acc: 0.316406]\n",
      "1553: [D loss: 0.701367, acc: 0.503906]: [A loss: 0.737738, acc: 0.320312]\n",
      "1554: [D loss: 0.699250, acc: 0.515625]: [A loss: 0.717965, acc: 0.425781]\n",
      "1555: [D loss: 0.692327, acc: 0.525391]: [A loss: 0.761457, acc: 0.246094]\n",
      "1556: [D loss: 0.698728, acc: 0.488281]: [A loss: 0.707812, acc: 0.425781]\n",
      "1557: [D loss: 0.692362, acc: 0.525391]: [A loss: 0.725010, acc: 0.375000]\n",
      "1558: [D loss: 0.691103, acc: 0.513672]: [A loss: 0.733332, acc: 0.355469]\n",
      "1559: [D loss: 0.699272, acc: 0.505859]: [A loss: 0.763280, acc: 0.222656]\n",
      "1560: [D loss: 0.706624, acc: 0.458984]: [A loss: 0.776570, acc: 0.207031]\n",
      "1561: [D loss: 0.697022, acc: 0.515625]: [A loss: 0.738702, acc: 0.335938]\n",
      "1562: [D loss: 0.694733, acc: 0.523438]: [A loss: 0.734955, acc: 0.335938]\n",
      "1563: [D loss: 0.688820, acc: 0.544922]: [A loss: 0.750104, acc: 0.300781]\n",
      "1564: [D loss: 0.695669, acc: 0.513672]: [A loss: 0.768570, acc: 0.226562]\n",
      "1565: [D loss: 0.698582, acc: 0.480469]: [A loss: 0.761645, acc: 0.226562]\n",
      "1566: [D loss: 0.695009, acc: 0.515625]: [A loss: 0.705702, acc: 0.457031]\n",
      "1567: [D loss: 0.694959, acc: 0.517578]: [A loss: 0.760275, acc: 0.238281]\n",
      "1568: [D loss: 0.697173, acc: 0.507812]: [A loss: 0.703263, acc: 0.453125]\n",
      "1569: [D loss: 0.693684, acc: 0.523438]: [A loss: 0.753535, acc: 0.230469]\n",
      "1570: [D loss: 0.693890, acc: 0.503906]: [A loss: 0.687900, acc: 0.515625]\n",
      "1571: [D loss: 0.691357, acc: 0.505859]: [A loss: 0.720274, acc: 0.394531]\n",
      "1572: [D loss: 0.693057, acc: 0.533203]: [A loss: 0.726304, acc: 0.375000]\n",
      "1573: [D loss: 0.691353, acc: 0.507812]: [A loss: 0.764864, acc: 0.226562]\n",
      "1574: [D loss: 0.688624, acc: 0.537109]: [A loss: 0.711085, acc: 0.468750]\n",
      "1575: [D loss: 0.698113, acc: 0.503906]: [A loss: 0.761542, acc: 0.257812]\n",
      "1576: [D loss: 0.688892, acc: 0.515625]: [A loss: 0.738078, acc: 0.347656]\n",
      "1577: [D loss: 0.700889, acc: 0.486328]: [A loss: 0.800540, acc: 0.171875]\n",
      "1578: [D loss: 0.687963, acc: 0.564453]: [A loss: 0.696404, acc: 0.488281]\n",
      "1579: [D loss: 0.699902, acc: 0.505859]: [A loss: 0.782885, acc: 0.160156]\n",
      "1580: [D loss: 0.696875, acc: 0.507812]: [A loss: 0.724792, acc: 0.382812]\n",
      "1581: [D loss: 0.696471, acc: 0.492188]: [A loss: 0.710593, acc: 0.406250]\n",
      "1582: [D loss: 0.694161, acc: 0.505859]: [A loss: 0.746589, acc: 0.332031]\n",
      "1583: [D loss: 0.693347, acc: 0.546875]: [A loss: 0.752707, acc: 0.308594]\n",
      "1584: [D loss: 0.689415, acc: 0.527344]: [A loss: 0.742989, acc: 0.339844]\n",
      "1585: [D loss: 0.702336, acc: 0.511719]: [A loss: 0.764445, acc: 0.226562]\n",
      "1586: [D loss: 0.688998, acc: 0.527344]: [A loss: 0.699048, acc: 0.519531]\n",
      "1587: [D loss: 0.699498, acc: 0.480469]: [A loss: 0.737151, acc: 0.335938]\n",
      "1588: [D loss: 0.693094, acc: 0.525391]: [A loss: 0.759976, acc: 0.238281]\n",
      "1589: [D loss: 0.689309, acc: 0.525391]: [A loss: 0.730424, acc: 0.363281]\n",
      "1590: [D loss: 0.694667, acc: 0.503906]: [A loss: 0.736690, acc: 0.339844]\n",
      "1591: [D loss: 0.702848, acc: 0.476562]: [A loss: 0.763290, acc: 0.230469]\n",
      "1592: [D loss: 0.696304, acc: 0.533203]: [A loss: 0.750507, acc: 0.269531]\n",
      "1593: [D loss: 0.691231, acc: 0.523438]: [A loss: 0.710135, acc: 0.402344]\n",
      "1594: [D loss: 0.689435, acc: 0.523438]: [A loss: 0.736071, acc: 0.343750]\n",
      "1595: [D loss: 0.691446, acc: 0.511719]: [A loss: 0.752811, acc: 0.292969]\n",
      "1596: [D loss: 0.692031, acc: 0.515625]: [A loss: 0.743375, acc: 0.304688]\n",
      "1597: [D loss: 0.692142, acc: 0.537109]: [A loss: 0.696667, acc: 0.488281]\n",
      "1598: [D loss: 0.701539, acc: 0.480469]: [A loss: 0.803700, acc: 0.132812]\n",
      "1599: [D loss: 0.693221, acc: 0.517578]: [A loss: 0.684296, acc: 0.562500]\n",
      "1600: [D loss: 0.703665, acc: 0.519531]: [A loss: 0.786062, acc: 0.160156]\n",
      "1601: [D loss: 0.691970, acc: 0.523438]: [A loss: 0.718851, acc: 0.398438]\n",
      "1602: [D loss: 0.698654, acc: 0.480469]: [A loss: 0.774831, acc: 0.175781]\n",
      "1603: [D loss: 0.689696, acc: 0.523438]: [A loss: 0.688376, acc: 0.542969]\n",
      "1604: [D loss: 0.697670, acc: 0.517578]: [A loss: 0.780583, acc: 0.187500]\n",
      "1605: [D loss: 0.692048, acc: 0.537109]: [A loss: 0.683594, acc: 0.558594]\n",
      "1606: [D loss: 0.693585, acc: 0.511719]: [A loss: 0.707488, acc: 0.457031]\n",
      "1607: [D loss: 0.693544, acc: 0.527344]: [A loss: 0.740350, acc: 0.300781]\n",
      "1608: [D loss: 0.699077, acc: 0.509766]: [A loss: 0.699119, acc: 0.527344]\n",
      "1609: [D loss: 0.693430, acc: 0.517578]: [A loss: 0.754277, acc: 0.277344]\n",
      "1610: [D loss: 0.692166, acc: 0.527344]: [A loss: 0.713947, acc: 0.421875]\n",
      "1611: [D loss: 0.695106, acc: 0.525391]: [A loss: 0.751124, acc: 0.269531]\n",
      "1612: [D loss: 0.693101, acc: 0.531250]: [A loss: 0.719084, acc: 0.382812]\n",
      "1613: [D loss: 0.695149, acc: 0.539062]: [A loss: 0.765372, acc: 0.253906]\n",
      "1614: [D loss: 0.703432, acc: 0.490234]: [A loss: 0.716311, acc: 0.417969]\n",
      "1615: [D loss: 0.697168, acc: 0.519531]: [A loss: 0.788010, acc: 0.160156]\n",
      "1616: [D loss: 0.690823, acc: 0.552734]: [A loss: 0.678389, acc: 0.582031]\n",
      "1617: [D loss: 0.695039, acc: 0.513672]: [A loss: 0.780765, acc: 0.210938]\n",
      "1618: [D loss: 0.703273, acc: 0.482422]: [A loss: 0.722496, acc: 0.375000]\n",
      "1619: [D loss: 0.699757, acc: 0.488281]: [A loss: 0.715371, acc: 0.417969]\n",
      "1620: [D loss: 0.698206, acc: 0.490234]: [A loss: 0.763132, acc: 0.242188]\n",
      "1621: [D loss: 0.702875, acc: 0.443359]: [A loss: 0.705796, acc: 0.476562]\n",
      "1622: [D loss: 0.694426, acc: 0.503906]: [A loss: 0.756604, acc: 0.246094]\n",
      "1623: [D loss: 0.692642, acc: 0.498047]: [A loss: 0.736379, acc: 0.300781]\n",
      "1624: [D loss: 0.692849, acc: 0.533203]: [A loss: 0.708822, acc: 0.441406]\n",
      "1625: [D loss: 0.689212, acc: 0.552734]: [A loss: 0.742153, acc: 0.292969]\n",
      "1626: [D loss: 0.694444, acc: 0.515625]: [A loss: 0.764389, acc: 0.207031]\n",
      "1627: [D loss: 0.690177, acc: 0.505859]: [A loss: 0.721410, acc: 0.390625]\n",
      "1628: [D loss: 0.693103, acc: 0.498047]: [A loss: 0.772106, acc: 0.191406]\n",
      "1629: [D loss: 0.690080, acc: 0.537109]: [A loss: 0.732284, acc: 0.324219]\n",
      "1630: [D loss: 0.695790, acc: 0.523438]: [A loss: 0.750742, acc: 0.265625]\n",
      "1631: [D loss: 0.691046, acc: 0.533203]: [A loss: 0.717410, acc: 0.398438]\n",
      "1632: [D loss: 0.691757, acc: 0.523438]: [A loss: 0.749986, acc: 0.308594]\n",
      "1633: [D loss: 0.693831, acc: 0.533203]: [A loss: 0.717764, acc: 0.417969]\n",
      "1634: [D loss: 0.701578, acc: 0.478516]: [A loss: 0.777898, acc: 0.230469]\n",
      "1635: [D loss: 0.696038, acc: 0.519531]: [A loss: 0.712577, acc: 0.406250]\n",
      "1636: [D loss: 0.692477, acc: 0.519531]: [A loss: 0.738116, acc: 0.285156]\n",
      "1637: [D loss: 0.699447, acc: 0.496094]: [A loss: 0.710508, acc: 0.445312]\n",
      "1638: [D loss: 0.688809, acc: 0.517578]: [A loss: 0.715085, acc: 0.394531]\n",
      "1639: [D loss: 0.697863, acc: 0.503906]: [A loss: 0.761000, acc: 0.226562]\n",
      "1640: [D loss: 0.690360, acc: 0.521484]: [A loss: 0.724809, acc: 0.363281]\n",
      "1641: [D loss: 0.696860, acc: 0.503906]: [A loss: 0.743204, acc: 0.292969]\n",
      "1642: [D loss: 0.696239, acc: 0.488281]: [A loss: 0.757953, acc: 0.253906]\n",
      "1643: [D loss: 0.696045, acc: 0.492188]: [A loss: 0.718937, acc: 0.398438]\n",
      "1644: [D loss: 0.702111, acc: 0.478516]: [A loss: 0.747045, acc: 0.261719]\n",
      "1645: [D loss: 0.692374, acc: 0.533203]: [A loss: 0.768083, acc: 0.246094]\n",
      "1646: [D loss: 0.698452, acc: 0.503906]: [A loss: 0.720089, acc: 0.386719]\n",
      "1647: [D loss: 0.695951, acc: 0.500000]: [A loss: 0.780933, acc: 0.191406]\n",
      "1648: [D loss: 0.699273, acc: 0.478516]: [A loss: 0.745645, acc: 0.285156]\n",
      "1649: [D loss: 0.690373, acc: 0.531250]: [A loss: 0.737783, acc: 0.335938]\n",
      "1650: [D loss: 0.694672, acc: 0.503906]: [A loss: 0.709006, acc: 0.441406]\n",
      "1651: [D loss: 0.690435, acc: 0.531250]: [A loss: 0.733919, acc: 0.320312]\n",
      "1652: [D loss: 0.702979, acc: 0.501953]: [A loss: 0.761540, acc: 0.242188]\n",
      "1653: [D loss: 0.701348, acc: 0.509766]: [A loss: 0.734083, acc: 0.308594]\n",
      "1654: [D loss: 0.694134, acc: 0.523438]: [A loss: 0.779036, acc: 0.191406]\n",
      "1655: [D loss: 0.697704, acc: 0.488281]: [A loss: 0.689073, acc: 0.550781]\n",
      "1656: [D loss: 0.704560, acc: 0.498047]: [A loss: 0.756517, acc: 0.234375]\n",
      "1657: [D loss: 0.683776, acc: 0.566406]: [A loss: 0.724076, acc: 0.355469]\n",
      "1658: [D loss: 0.698896, acc: 0.515625]: [A loss: 0.760487, acc: 0.238281]\n",
      "1659: [D loss: 0.689916, acc: 0.505859]: [A loss: 0.700623, acc: 0.515625]\n",
      "1660: [D loss: 0.696488, acc: 0.523438]: [A loss: 0.804153, acc: 0.156250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1661: [D loss: 0.690272, acc: 0.533203]: [A loss: 0.701028, acc: 0.472656]\n",
      "1662: [D loss: 0.694063, acc: 0.507812]: [A loss: 0.758952, acc: 0.210938]\n",
      "1663: [D loss: 0.697013, acc: 0.492188]: [A loss: 0.721754, acc: 0.382812]\n",
      "1664: [D loss: 0.692360, acc: 0.550781]: [A loss: 0.746119, acc: 0.269531]\n",
      "1665: [D loss: 0.683066, acc: 0.554688]: [A loss: 0.763192, acc: 0.269531]\n",
      "1666: [D loss: 0.697011, acc: 0.513672]: [A loss: 0.682735, acc: 0.570312]\n",
      "1667: [D loss: 0.698024, acc: 0.527344]: [A loss: 0.791175, acc: 0.160156]\n",
      "1668: [D loss: 0.690858, acc: 0.517578]: [A loss: 0.677043, acc: 0.574219]\n",
      "1669: [D loss: 0.697101, acc: 0.521484]: [A loss: 0.807525, acc: 0.140625]\n",
      "1670: [D loss: 0.694423, acc: 0.519531]: [A loss: 0.713089, acc: 0.398438]\n",
      "1671: [D loss: 0.688956, acc: 0.537109]: [A loss: 0.779094, acc: 0.171875]\n",
      "1672: [D loss: 0.696356, acc: 0.511719]: [A loss: 0.730140, acc: 0.339844]\n",
      "1673: [D loss: 0.698526, acc: 0.480469]: [A loss: 0.758357, acc: 0.261719]\n",
      "1674: [D loss: 0.696871, acc: 0.511719]: [A loss: 0.757207, acc: 0.265625]\n",
      "1675: [D loss: 0.687562, acc: 0.535156]: [A loss: 0.736908, acc: 0.324219]\n",
      "1676: [D loss: 0.691177, acc: 0.560547]: [A loss: 0.764066, acc: 0.210938]\n",
      "1677: [D loss: 0.696112, acc: 0.529297]: [A loss: 0.721434, acc: 0.382812]\n",
      "1678: [D loss: 0.697358, acc: 0.501953]: [A loss: 0.730698, acc: 0.316406]\n",
      "1679: [D loss: 0.696433, acc: 0.523438]: [A loss: 0.746717, acc: 0.308594]\n",
      "1680: [D loss: 0.694440, acc: 0.507812]: [A loss: 0.730011, acc: 0.363281]\n",
      "1681: [D loss: 0.698357, acc: 0.525391]: [A loss: 0.799889, acc: 0.140625]\n",
      "1682: [D loss: 0.693366, acc: 0.488281]: [A loss: 0.701062, acc: 0.445312]\n",
      "1683: [D loss: 0.696533, acc: 0.501953]: [A loss: 0.737980, acc: 0.324219]\n",
      "1684: [D loss: 0.698765, acc: 0.486328]: [A loss: 0.724705, acc: 0.347656]\n",
      "1685: [D loss: 0.691837, acc: 0.527344]: [A loss: 0.728869, acc: 0.332031]\n",
      "1686: [D loss: 0.691474, acc: 0.539062]: [A loss: 0.733229, acc: 0.359375]\n",
      "1687: [D loss: 0.692309, acc: 0.537109]: [A loss: 0.697068, acc: 0.519531]\n",
      "1688: [D loss: 0.696993, acc: 0.513672]: [A loss: 0.803227, acc: 0.144531]\n",
      "1689: [D loss: 0.693906, acc: 0.517578]: [A loss: 0.699630, acc: 0.472656]\n",
      "1690: [D loss: 0.700997, acc: 0.490234]: [A loss: 0.792979, acc: 0.152344]\n",
      "1691: [D loss: 0.696817, acc: 0.498047]: [A loss: 0.684080, acc: 0.542969]\n",
      "1692: [D loss: 0.696556, acc: 0.533203]: [A loss: 0.774220, acc: 0.187500]\n",
      "1693: [D loss: 0.693318, acc: 0.505859]: [A loss: 0.727491, acc: 0.378906]\n",
      "1694: [D loss: 0.695545, acc: 0.519531]: [A loss: 0.743900, acc: 0.312500]\n",
      "1695: [D loss: 0.688725, acc: 0.517578]: [A loss: 0.705073, acc: 0.492188]\n",
      "1696: [D loss: 0.691881, acc: 0.537109]: [A loss: 0.787669, acc: 0.156250]\n",
      "1697: [D loss: 0.696658, acc: 0.494141]: [A loss: 0.674981, acc: 0.585938]\n",
      "1698: [D loss: 0.694350, acc: 0.513672]: [A loss: 0.761351, acc: 0.230469]\n",
      "1699: [D loss: 0.690930, acc: 0.517578]: [A loss: 0.713255, acc: 0.421875]\n",
      "1700: [D loss: 0.698209, acc: 0.505859]: [A loss: 0.755178, acc: 0.238281]\n",
      "1701: [D loss: 0.697683, acc: 0.525391]: [A loss: 0.724929, acc: 0.363281]\n",
      "1702: [D loss: 0.695019, acc: 0.494141]: [A loss: 0.697847, acc: 0.480469]\n",
      "1703: [D loss: 0.703885, acc: 0.492188]: [A loss: 0.783479, acc: 0.187500]\n",
      "1704: [D loss: 0.701737, acc: 0.507812]: [A loss: 0.727658, acc: 0.375000]\n",
      "1705: [D loss: 0.694090, acc: 0.533203]: [A loss: 0.728407, acc: 0.355469]\n",
      "1706: [D loss: 0.700812, acc: 0.498047]: [A loss: 0.736841, acc: 0.332031]\n",
      "1707: [D loss: 0.702741, acc: 0.486328]: [A loss: 0.725999, acc: 0.371094]\n",
      "1708: [D loss: 0.696988, acc: 0.503906]: [A loss: 0.770016, acc: 0.230469]\n",
      "1709: [D loss: 0.693265, acc: 0.501953]: [A loss: 0.750062, acc: 0.253906]\n",
      "1710: [D loss: 0.692215, acc: 0.535156]: [A loss: 0.691834, acc: 0.511719]\n",
      "1711: [D loss: 0.706792, acc: 0.476562]: [A loss: 0.782020, acc: 0.191406]\n",
      "1712: [D loss: 0.693492, acc: 0.525391]: [A loss: 0.699391, acc: 0.496094]\n",
      "1713: [D loss: 0.695530, acc: 0.509766]: [A loss: 0.747683, acc: 0.281250]\n",
      "1714: [D loss: 0.700981, acc: 0.460938]: [A loss: 0.732185, acc: 0.308594]\n",
      "1715: [D loss: 0.701785, acc: 0.464844]: [A loss: 0.727377, acc: 0.308594]\n",
      "1716: [D loss: 0.693402, acc: 0.521484]: [A loss: 0.732047, acc: 0.343750]\n",
      "1717: [D loss: 0.699967, acc: 0.511719]: [A loss: 0.760234, acc: 0.234375]\n",
      "1718: [D loss: 0.691891, acc: 0.541016]: [A loss: 0.708910, acc: 0.441406]\n",
      "1719: [D loss: 0.692601, acc: 0.542969]: [A loss: 0.765401, acc: 0.187500]\n",
      "1720: [D loss: 0.693412, acc: 0.501953]: [A loss: 0.734112, acc: 0.332031]\n",
      "1721: [D loss: 0.690473, acc: 0.531250]: [A loss: 0.751540, acc: 0.269531]\n",
      "1722: [D loss: 0.703661, acc: 0.476562]: [A loss: 0.755248, acc: 0.222656]\n",
      "1723: [D loss: 0.696083, acc: 0.509766]: [A loss: 0.699364, acc: 0.507812]\n",
      "1724: [D loss: 0.694959, acc: 0.503906]: [A loss: 0.837888, acc: 0.078125]\n",
      "1725: [D loss: 0.690965, acc: 0.513672]: [A loss: 0.656012, acc: 0.699219]\n",
      "1726: [D loss: 0.703035, acc: 0.500000]: [A loss: 0.799094, acc: 0.128906]\n",
      "1727: [D loss: 0.682361, acc: 0.546875]: [A loss: 0.683161, acc: 0.570312]\n",
      "1728: [D loss: 0.694212, acc: 0.521484]: [A loss: 0.719716, acc: 0.394531]\n",
      "1729: [D loss: 0.699950, acc: 0.515625]: [A loss: 0.692369, acc: 0.542969]\n",
      "1730: [D loss: 0.696636, acc: 0.519531]: [A loss: 0.733421, acc: 0.324219]\n",
      "1731: [D loss: 0.697772, acc: 0.482422]: [A loss: 0.695302, acc: 0.503906]\n",
      "1732: [D loss: 0.699137, acc: 0.472656]: [A loss: 0.749102, acc: 0.242188]\n",
      "1733: [D loss: 0.698679, acc: 0.472656]: [A loss: 0.705529, acc: 0.429688]\n",
      "1734: [D loss: 0.689349, acc: 0.517578]: [A loss: 0.715543, acc: 0.449219]\n",
      "1735: [D loss: 0.693832, acc: 0.490234]: [A loss: 0.724694, acc: 0.363281]\n",
      "1736: [D loss: 0.695400, acc: 0.513672]: [A loss: 0.718296, acc: 0.398438]\n",
      "1737: [D loss: 0.694789, acc: 0.507812]: [A loss: 0.762466, acc: 0.230469]\n",
      "1738: [D loss: 0.700004, acc: 0.498047]: [A loss: 0.700039, acc: 0.437500]\n",
      "1739: [D loss: 0.694538, acc: 0.513672]: [A loss: 0.716499, acc: 0.390625]\n",
      "1740: [D loss: 0.690657, acc: 0.558594]: [A loss: 0.692488, acc: 0.519531]\n",
      "1741: [D loss: 0.695821, acc: 0.519531]: [A loss: 0.777654, acc: 0.148438]\n",
      "1742: [D loss: 0.694132, acc: 0.527344]: [A loss: 0.743458, acc: 0.292969]\n",
      "1743: [D loss: 0.704929, acc: 0.486328]: [A loss: 0.758790, acc: 0.234375]\n",
      "1744: [D loss: 0.690951, acc: 0.533203]: [A loss: 0.720941, acc: 0.398438]\n",
      "1745: [D loss: 0.695339, acc: 0.501953]: [A loss: 0.727504, acc: 0.285156]\n",
      "1746: [D loss: 0.690747, acc: 0.537109]: [A loss: 0.713012, acc: 0.421875]\n",
      "1747: [D loss: 0.696163, acc: 0.519531]: [A loss: 0.784049, acc: 0.171875]\n",
      "1748: [D loss: 0.696630, acc: 0.503906]: [A loss: 0.721345, acc: 0.367188]\n",
      "1749: [D loss: 0.690239, acc: 0.535156]: [A loss: 0.714584, acc: 0.390625]\n",
      "1750: [D loss: 0.688415, acc: 0.533203]: [A loss: 0.749722, acc: 0.250000]\n",
      "1751: [D loss: 0.698800, acc: 0.517578]: [A loss: 0.728837, acc: 0.359375]\n",
      "1752: [D loss: 0.697150, acc: 0.509766]: [A loss: 0.719469, acc: 0.363281]\n",
      "1753: [D loss: 0.706007, acc: 0.482422]: [A loss: 0.769847, acc: 0.179688]\n",
      "1754: [D loss: 0.685247, acc: 0.544922]: [A loss: 0.671401, acc: 0.605469]\n",
      "1755: [D loss: 0.701452, acc: 0.500000]: [A loss: 0.759964, acc: 0.242188]\n",
      "1756: [D loss: 0.696755, acc: 0.505859]: [A loss: 0.692647, acc: 0.523438]\n",
      "1757: [D loss: 0.693450, acc: 0.517578]: [A loss: 0.701273, acc: 0.460938]\n",
      "1758: [D loss: 0.691819, acc: 0.539062]: [A loss: 0.762455, acc: 0.187500]\n",
      "1759: [D loss: 0.686508, acc: 0.550781]: [A loss: 0.705540, acc: 0.453125]\n",
      "1760: [D loss: 0.692771, acc: 0.533203]: [A loss: 0.774258, acc: 0.175781]\n",
      "1761: [D loss: 0.700535, acc: 0.490234]: [A loss: 0.717232, acc: 0.355469]\n",
      "1762: [D loss: 0.692529, acc: 0.525391]: [A loss: 0.713094, acc: 0.433594]\n",
      "1763: [D loss: 0.700594, acc: 0.486328]: [A loss: 0.717845, acc: 0.375000]\n",
      "1764: [D loss: 0.697632, acc: 0.501953]: [A loss: 0.742264, acc: 0.320312]\n",
      "1765: [D loss: 0.697774, acc: 0.507812]: [A loss: 0.719696, acc: 0.386719]\n",
      "1766: [D loss: 0.689130, acc: 0.552734]: [A loss: 0.728812, acc: 0.332031]\n",
      "1767: [D loss: 0.695527, acc: 0.500000]: [A loss: 0.734442, acc: 0.324219]\n",
      "1768: [D loss: 0.692887, acc: 0.521484]: [A loss: 0.728484, acc: 0.316406]\n",
      "1769: [D loss: 0.687730, acc: 0.572266]: [A loss: 0.748536, acc: 0.238281]\n",
      "1770: [D loss: 0.689972, acc: 0.548828]: [A loss: 0.678326, acc: 0.558594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1771: [D loss: 0.699495, acc: 0.509766]: [A loss: 0.771046, acc: 0.210938]\n",
      "1772: [D loss: 0.696699, acc: 0.482422]: [A loss: 0.746737, acc: 0.273438]\n",
      "1773: [D loss: 0.700189, acc: 0.509766]: [A loss: 0.757620, acc: 0.257812]\n",
      "1774: [D loss: 0.701209, acc: 0.498047]: [A loss: 0.717552, acc: 0.421875]\n",
      "1775: [D loss: 0.689711, acc: 0.531250]: [A loss: 0.726629, acc: 0.335938]\n",
      "1776: [D loss: 0.696417, acc: 0.490234]: [A loss: 0.699442, acc: 0.449219]\n",
      "1777: [D loss: 0.691542, acc: 0.542969]: [A loss: 0.745286, acc: 0.281250]\n",
      "1778: [D loss: 0.695028, acc: 0.527344]: [A loss: 0.717428, acc: 0.378906]\n",
      "1779: [D loss: 0.704813, acc: 0.488281]: [A loss: 0.777775, acc: 0.167969]\n",
      "1780: [D loss: 0.695987, acc: 0.529297]: [A loss: 0.689866, acc: 0.507812]\n",
      "1781: [D loss: 0.701455, acc: 0.496094]: [A loss: 0.774373, acc: 0.191406]\n",
      "1782: [D loss: 0.691995, acc: 0.541016]: [A loss: 0.686827, acc: 0.507812]\n",
      "1783: [D loss: 0.705330, acc: 0.501953]: [A loss: 0.772630, acc: 0.183594]\n",
      "1784: [D loss: 0.695531, acc: 0.521484]: [A loss: 0.714186, acc: 0.414062]\n",
      "1785: [D loss: 0.696593, acc: 0.509766]: [A loss: 0.751135, acc: 0.207031]\n",
      "1786: [D loss: 0.689245, acc: 0.531250]: [A loss: 0.677724, acc: 0.546875]\n",
      "1787: [D loss: 0.691170, acc: 0.531250]: [A loss: 0.748657, acc: 0.257812]\n",
      "1788: [D loss: 0.697224, acc: 0.474609]: [A loss: 0.721802, acc: 0.332031]\n",
      "1789: [D loss: 0.692308, acc: 0.513672]: [A loss: 0.759999, acc: 0.242188]\n",
      "1790: [D loss: 0.693093, acc: 0.505859]: [A loss: 0.699468, acc: 0.484375]\n",
      "1791: [D loss: 0.691666, acc: 0.550781]: [A loss: 0.733093, acc: 0.339844]\n",
      "1792: [D loss: 0.700480, acc: 0.464844]: [A loss: 0.710726, acc: 0.406250]\n",
      "1793: [D loss: 0.696971, acc: 0.490234]: [A loss: 0.718498, acc: 0.382812]\n",
      "1794: [D loss: 0.694457, acc: 0.488281]: [A loss: 0.751867, acc: 0.246094]\n",
      "1795: [D loss: 0.691909, acc: 0.529297]: [A loss: 0.723530, acc: 0.394531]\n",
      "1796: [D loss: 0.693532, acc: 0.513672]: [A loss: 0.751153, acc: 0.257812]\n",
      "1797: [D loss: 0.690920, acc: 0.503906]: [A loss: 0.702346, acc: 0.441406]\n",
      "1798: [D loss: 0.699012, acc: 0.496094]: [A loss: 0.750820, acc: 0.238281]\n",
      "1799: [D loss: 0.696679, acc: 0.484375]: [A loss: 0.686031, acc: 0.562500]\n",
      "1800: [D loss: 0.694505, acc: 0.529297]: [A loss: 0.751754, acc: 0.222656]\n",
      "1801: [D loss: 0.692605, acc: 0.501953]: [A loss: 0.734223, acc: 0.304688]\n",
      "1802: [D loss: 0.688890, acc: 0.544922]: [A loss: 0.729319, acc: 0.320312]\n",
      "1803: [D loss: 0.694424, acc: 0.509766]: [A loss: 0.725780, acc: 0.347656]\n",
      "1804: [D loss: 0.691231, acc: 0.511719]: [A loss: 0.746221, acc: 0.269531]\n",
      "1805: [D loss: 0.689190, acc: 0.541016]: [A loss: 0.705112, acc: 0.429688]\n",
      "1806: [D loss: 0.690086, acc: 0.519531]: [A loss: 0.721634, acc: 0.382812]\n",
      "1807: [D loss: 0.690488, acc: 0.525391]: [A loss: 0.734589, acc: 0.316406]\n",
      "1808: [D loss: 0.692235, acc: 0.521484]: [A loss: 0.683792, acc: 0.535156]\n",
      "1809: [D loss: 0.691148, acc: 0.539062]: [A loss: 0.783396, acc: 0.144531]\n",
      "1810: [D loss: 0.696365, acc: 0.478516]: [A loss: 0.687994, acc: 0.531250]\n",
      "1811: [D loss: 0.705099, acc: 0.503906]: [A loss: 0.766787, acc: 0.207031]\n",
      "1812: [D loss: 0.689880, acc: 0.525391]: [A loss: 0.698118, acc: 0.500000]\n",
      "1813: [D loss: 0.689066, acc: 0.527344]: [A loss: 0.786276, acc: 0.156250]\n",
      "1814: [D loss: 0.695289, acc: 0.501953]: [A loss: 0.703718, acc: 0.464844]\n",
      "1815: [D loss: 0.692924, acc: 0.515625]: [A loss: 0.734066, acc: 0.304688]\n",
      "1816: [D loss: 0.689615, acc: 0.544922]: [A loss: 0.717363, acc: 0.382812]\n",
      "1817: [D loss: 0.696232, acc: 0.517578]: [A loss: 0.764689, acc: 0.226562]\n",
      "1818: [D loss: 0.696070, acc: 0.498047]: [A loss: 0.751490, acc: 0.273438]\n",
      "1819: [D loss: 0.693821, acc: 0.525391]: [A loss: 0.712186, acc: 0.445312]\n",
      "1820: [D loss: 0.697969, acc: 0.513672]: [A loss: 0.786686, acc: 0.175781]\n",
      "1821: [D loss: 0.701794, acc: 0.453125]: [A loss: 0.665189, acc: 0.617188]\n",
      "1822: [D loss: 0.702684, acc: 0.490234]: [A loss: 0.784722, acc: 0.132812]\n",
      "1823: [D loss: 0.694602, acc: 0.494141]: [A loss: 0.678732, acc: 0.574219]\n",
      "1824: [D loss: 0.700075, acc: 0.507812]: [A loss: 0.737042, acc: 0.332031]\n",
      "1825: [D loss: 0.696417, acc: 0.511719]: [A loss: 0.725325, acc: 0.355469]\n",
      "1826: [D loss: 0.700519, acc: 0.494141]: [A loss: 0.762362, acc: 0.226562]\n",
      "1827: [D loss: 0.694961, acc: 0.496094]: [A loss: 0.713527, acc: 0.441406]\n",
      "1828: [D loss: 0.695493, acc: 0.505859]: [A loss: 0.725893, acc: 0.343750]\n",
      "1829: [D loss: 0.701403, acc: 0.523438]: [A loss: 0.777292, acc: 0.152344]\n",
      "1830: [D loss: 0.697036, acc: 0.498047]: [A loss: 0.687209, acc: 0.562500]\n",
      "1831: [D loss: 0.700989, acc: 0.488281]: [A loss: 0.720692, acc: 0.417969]\n",
      "1832: [D loss: 0.694232, acc: 0.498047]: [A loss: 0.714838, acc: 0.402344]\n",
      "1833: [D loss: 0.694039, acc: 0.515625]: [A loss: 0.710910, acc: 0.390625]\n",
      "1834: [D loss: 0.689959, acc: 0.539062]: [A loss: 0.760073, acc: 0.210938]\n",
      "1835: [D loss: 0.693092, acc: 0.492188]: [A loss: 0.668216, acc: 0.644531]\n",
      "1836: [D loss: 0.694989, acc: 0.533203]: [A loss: 0.759678, acc: 0.226562]\n",
      "1837: [D loss: 0.693838, acc: 0.529297]: [A loss: 0.691740, acc: 0.535156]\n",
      "1838: [D loss: 0.705164, acc: 0.496094]: [A loss: 0.754585, acc: 0.226562]\n",
      "1839: [D loss: 0.692760, acc: 0.539062]: [A loss: 0.696848, acc: 0.464844]\n",
      "1840: [D loss: 0.692882, acc: 0.505859]: [A loss: 0.737613, acc: 0.332031]\n",
      "1841: [D loss: 0.693097, acc: 0.521484]: [A loss: 0.712726, acc: 0.375000]\n",
      "1842: [D loss: 0.695808, acc: 0.507812]: [A loss: 0.708182, acc: 0.421875]\n",
      "1843: [D loss: 0.697464, acc: 0.511719]: [A loss: 0.712521, acc: 0.390625]\n",
      "1844: [D loss: 0.689837, acc: 0.533203]: [A loss: 0.720593, acc: 0.371094]\n",
      "1845: [D loss: 0.689411, acc: 0.527344]: [A loss: 0.698831, acc: 0.503906]\n",
      "1846: [D loss: 0.691703, acc: 0.515625]: [A loss: 0.747577, acc: 0.234375]\n",
      "1847: [D loss: 0.691159, acc: 0.507812]: [A loss: 0.712017, acc: 0.410156]\n",
      "1848: [D loss: 0.698492, acc: 0.511719]: [A loss: 0.750621, acc: 0.234375]\n",
      "1849: [D loss: 0.691302, acc: 0.517578]: [A loss: 0.722784, acc: 0.355469]\n",
      "1850: [D loss: 0.696591, acc: 0.501953]: [A loss: 0.731422, acc: 0.308594]\n",
      "1851: [D loss: 0.697055, acc: 0.511719]: [A loss: 0.712771, acc: 0.414062]\n",
      "1852: [D loss: 0.694603, acc: 0.511719]: [A loss: 0.730374, acc: 0.289062]\n",
      "1853: [D loss: 0.689906, acc: 0.517578]: [A loss: 0.702633, acc: 0.468750]\n",
      "1854: [D loss: 0.694802, acc: 0.517578]: [A loss: 0.778242, acc: 0.179688]\n",
      "1855: [D loss: 0.697595, acc: 0.484375]: [A loss: 0.700721, acc: 0.445312]\n",
      "1856: [D loss: 0.701552, acc: 0.488281]: [A loss: 0.772296, acc: 0.152344]\n",
      "1857: [D loss: 0.695818, acc: 0.498047]: [A loss: 0.702535, acc: 0.472656]\n",
      "1858: [D loss: 0.692074, acc: 0.531250]: [A loss: 0.733381, acc: 0.316406]\n",
      "1859: [D loss: 0.702842, acc: 0.488281]: [A loss: 0.742645, acc: 0.246094]\n",
      "1860: [D loss: 0.697008, acc: 0.476562]: [A loss: 0.682909, acc: 0.570312]\n",
      "1861: [D loss: 0.702217, acc: 0.494141]: [A loss: 0.749217, acc: 0.218750]\n",
      "1862: [D loss: 0.690657, acc: 0.515625]: [A loss: 0.705772, acc: 0.410156]\n",
      "1863: [D loss: 0.694390, acc: 0.537109]: [A loss: 0.721913, acc: 0.375000]\n",
      "1864: [D loss: 0.697915, acc: 0.517578]: [A loss: 0.721424, acc: 0.355469]\n",
      "1865: [D loss: 0.699550, acc: 0.509766]: [A loss: 0.745801, acc: 0.234375]\n",
      "1866: [D loss: 0.696657, acc: 0.478516]: [A loss: 0.723279, acc: 0.386719]\n",
      "1867: [D loss: 0.694966, acc: 0.517578]: [A loss: 0.722367, acc: 0.359375]\n",
      "1868: [D loss: 0.704067, acc: 0.482422]: [A loss: 0.775590, acc: 0.144531]\n",
      "1869: [D loss: 0.693529, acc: 0.511719]: [A loss: 0.715486, acc: 0.382812]\n",
      "1870: [D loss: 0.695324, acc: 0.529297]: [A loss: 0.757142, acc: 0.246094]\n",
      "1871: [D loss: 0.691813, acc: 0.505859]: [A loss: 0.710279, acc: 0.449219]\n",
      "1872: [D loss: 0.700609, acc: 0.494141]: [A loss: 0.718302, acc: 0.367188]\n",
      "1873: [D loss: 0.695720, acc: 0.521484]: [A loss: 0.745018, acc: 0.273438]\n",
      "1874: [D loss: 0.691272, acc: 0.500000]: [A loss: 0.707485, acc: 0.433594]\n",
      "1875: [D loss: 0.692279, acc: 0.517578]: [A loss: 0.735149, acc: 0.308594]\n",
      "1876: [D loss: 0.694107, acc: 0.517578]: [A loss: 0.713053, acc: 0.453125]\n",
      "1877: [D loss: 0.693714, acc: 0.523438]: [A loss: 0.763964, acc: 0.207031]\n",
      "1878: [D loss: 0.689022, acc: 0.521484]: [A loss: 0.685627, acc: 0.582031]\n",
      "1879: [D loss: 0.694239, acc: 0.486328]: [A loss: 0.762403, acc: 0.210938]\n",
      "1880: [D loss: 0.693843, acc: 0.519531]: [A loss: 0.708569, acc: 0.437500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1881: [D loss: 0.702373, acc: 0.496094]: [A loss: 0.741421, acc: 0.265625]\n",
      "1882: [D loss: 0.694813, acc: 0.529297]: [A loss: 0.736309, acc: 0.335938]\n",
      "1883: [D loss: 0.690633, acc: 0.507812]: [A loss: 0.730029, acc: 0.347656]\n",
      "1884: [D loss: 0.697038, acc: 0.507812]: [A loss: 0.699100, acc: 0.488281]\n",
      "1885: [D loss: 0.697305, acc: 0.515625]: [A loss: 0.777835, acc: 0.156250]\n",
      "1886: [D loss: 0.701568, acc: 0.484375]: [A loss: 0.686304, acc: 0.539062]\n",
      "1887: [D loss: 0.700670, acc: 0.501953]: [A loss: 0.735200, acc: 0.269531]\n",
      "1888: [D loss: 0.694946, acc: 0.519531]: [A loss: 0.667532, acc: 0.628906]\n",
      "1889: [D loss: 0.697315, acc: 0.507812]: [A loss: 0.756494, acc: 0.203125]\n",
      "1890: [D loss: 0.690306, acc: 0.531250]: [A loss: 0.725752, acc: 0.332031]\n",
      "1891: [D loss: 0.689596, acc: 0.513672]: [A loss: 0.716033, acc: 0.398438]\n",
      "1892: [D loss: 0.704726, acc: 0.472656]: [A loss: 0.786792, acc: 0.136719]\n",
      "1893: [D loss: 0.693971, acc: 0.527344]: [A loss: 0.693314, acc: 0.519531]\n",
      "1894: [D loss: 0.699804, acc: 0.490234]: [A loss: 0.716206, acc: 0.382812]\n",
      "1895: [D loss: 0.695329, acc: 0.515625]: [A loss: 0.707364, acc: 0.417969]\n",
      "1896: [D loss: 0.693412, acc: 0.484375]: [A loss: 0.739738, acc: 0.296875]\n",
      "1897: [D loss: 0.692513, acc: 0.501953]: [A loss: 0.721329, acc: 0.390625]\n",
      "1898: [D loss: 0.696191, acc: 0.498047]: [A loss: 0.744383, acc: 0.265625]\n",
      "1899: [D loss: 0.700036, acc: 0.501953]: [A loss: 0.704986, acc: 0.468750]\n",
      "1900: [D loss: 0.697076, acc: 0.496094]: [A loss: 0.763628, acc: 0.203125]\n",
      "1901: [D loss: 0.692374, acc: 0.515625]: [A loss: 0.693036, acc: 0.519531]\n",
      "1902: [D loss: 0.704100, acc: 0.496094]: [A loss: 0.748410, acc: 0.246094]\n",
      "1903: [D loss: 0.687458, acc: 0.531250]: [A loss: 0.704595, acc: 0.437500]\n",
      "1904: [D loss: 0.696253, acc: 0.484375]: [A loss: 0.731976, acc: 0.281250]\n",
      "1905: [D loss: 0.696305, acc: 0.507812]: [A loss: 0.722965, acc: 0.367188]\n",
      "1906: [D loss: 0.696556, acc: 0.523438]: [A loss: 0.755875, acc: 0.230469]\n",
      "1907: [D loss: 0.697669, acc: 0.470703]: [A loss: 0.730954, acc: 0.300781]\n",
      "1908: [D loss: 0.698664, acc: 0.482422]: [A loss: 0.705321, acc: 0.425781]\n",
      "1909: [D loss: 0.691078, acc: 0.515625]: [A loss: 0.715031, acc: 0.351562]\n",
      "1910: [D loss: 0.690878, acc: 0.558594]: [A loss: 0.733707, acc: 0.335938]\n",
      "1911: [D loss: 0.695162, acc: 0.505859]: [A loss: 0.739321, acc: 0.312500]\n",
      "1912: [D loss: 0.693093, acc: 0.515625]: [A loss: 0.728443, acc: 0.343750]\n",
      "1913: [D loss: 0.691449, acc: 0.527344]: [A loss: 0.714704, acc: 0.398438]\n",
      "1914: [D loss: 0.698354, acc: 0.488281]: [A loss: 0.705259, acc: 0.453125]\n",
      "1915: [D loss: 0.702139, acc: 0.503906]: [A loss: 0.767436, acc: 0.171875]\n",
      "1916: [D loss: 0.688640, acc: 0.521484]: [A loss: 0.720409, acc: 0.375000]\n",
      "1917: [D loss: 0.697200, acc: 0.531250]: [A loss: 0.749560, acc: 0.246094]\n",
      "1918: [D loss: 0.695369, acc: 0.525391]: [A loss: 0.722332, acc: 0.375000]\n",
      "1919: [D loss: 0.696194, acc: 0.519531]: [A loss: 0.763466, acc: 0.222656]\n",
      "1920: [D loss: 0.698005, acc: 0.462891]: [A loss: 0.737786, acc: 0.281250]\n",
      "1921: [D loss: 0.688616, acc: 0.550781]: [A loss: 0.735294, acc: 0.277344]\n",
      "1922: [D loss: 0.698968, acc: 0.492188]: [A loss: 0.719922, acc: 0.375000]\n",
      "1923: [D loss: 0.697279, acc: 0.494141]: [A loss: 0.717571, acc: 0.371094]\n",
      "1924: [D loss: 0.696047, acc: 0.500000]: [A loss: 0.795515, acc: 0.113281]\n",
      "1925: [D loss: 0.687367, acc: 0.552734]: [A loss: 0.677167, acc: 0.617188]\n",
      "1926: [D loss: 0.696610, acc: 0.525391]: [A loss: 0.797819, acc: 0.101562]\n",
      "1927: [D loss: 0.685713, acc: 0.570312]: [A loss: 0.651707, acc: 0.695312]\n",
      "1928: [D loss: 0.704905, acc: 0.505859]: [A loss: 0.779284, acc: 0.164062]\n",
      "1929: [D loss: 0.697955, acc: 0.470703]: [A loss: 0.666951, acc: 0.660156]\n",
      "1930: [D loss: 0.696536, acc: 0.505859]: [A loss: 0.749774, acc: 0.246094]\n",
      "1931: [D loss: 0.700536, acc: 0.480469]: [A loss: 0.723619, acc: 0.375000]\n",
      "1932: [D loss: 0.700219, acc: 0.490234]: [A loss: 0.747545, acc: 0.230469]\n",
      "1933: [D loss: 0.690373, acc: 0.548828]: [A loss: 0.743079, acc: 0.257812]\n",
      "1934: [D loss: 0.697068, acc: 0.472656]: [A loss: 0.726969, acc: 0.359375]\n",
      "1935: [D loss: 0.701704, acc: 0.482422]: [A loss: 0.702024, acc: 0.464844]\n",
      "1936: [D loss: 0.690829, acc: 0.531250]: [A loss: 0.746698, acc: 0.246094]\n",
      "1937: [D loss: 0.696756, acc: 0.486328]: [A loss: 0.715056, acc: 0.425781]\n",
      "1938: [D loss: 0.686810, acc: 0.541016]: [A loss: 0.715786, acc: 0.402344]\n",
      "1939: [D loss: 0.694289, acc: 0.515625]: [A loss: 0.712506, acc: 0.386719]\n",
      "1940: [D loss: 0.694610, acc: 0.503906]: [A loss: 0.735591, acc: 0.296875]\n",
      "1941: [D loss: 0.696369, acc: 0.503906]: [A loss: 0.728914, acc: 0.300781]\n",
      "1942: [D loss: 0.686382, acc: 0.560547]: [A loss: 0.732217, acc: 0.300781]\n",
      "1943: [D loss: 0.696967, acc: 0.507812]: [A loss: 0.728175, acc: 0.343750]\n",
      "1944: [D loss: 0.694206, acc: 0.494141]: [A loss: 0.695815, acc: 0.468750]\n",
      "1945: [D loss: 0.691137, acc: 0.525391]: [A loss: 0.754783, acc: 0.199219]\n",
      "1946: [D loss: 0.696709, acc: 0.523438]: [A loss: 0.691447, acc: 0.535156]\n",
      "1947: [D loss: 0.702185, acc: 0.501953]: [A loss: 0.779700, acc: 0.160156]\n",
      "1948: [D loss: 0.691065, acc: 0.521484]: [A loss: 0.723499, acc: 0.382812]\n",
      "1949: [D loss: 0.696729, acc: 0.490234]: [A loss: 0.723520, acc: 0.363281]\n",
      "1950: [D loss: 0.690925, acc: 0.500000]: [A loss: 0.705476, acc: 0.453125]\n",
      "1951: [D loss: 0.701139, acc: 0.501953]: [A loss: 0.773473, acc: 0.152344]\n",
      "1952: [D loss: 0.695890, acc: 0.503906]: [A loss: 0.675748, acc: 0.593750]\n",
      "1953: [D loss: 0.699315, acc: 0.523438]: [A loss: 0.783331, acc: 0.167969]\n",
      "1954: [D loss: 0.692058, acc: 0.521484]: [A loss: 0.691524, acc: 0.519531]\n",
      "1955: [D loss: 0.703758, acc: 0.482422]: [A loss: 0.771760, acc: 0.175781]\n",
      "1956: [D loss: 0.695857, acc: 0.494141]: [A loss: 0.711080, acc: 0.394531]\n",
      "1957: [D loss: 0.693820, acc: 0.509766]: [A loss: 0.741443, acc: 0.292969]\n",
      "1958: [D loss: 0.696436, acc: 0.531250]: [A loss: 0.733209, acc: 0.320312]\n",
      "1959: [D loss: 0.697621, acc: 0.505859]: [A loss: 0.703833, acc: 0.441406]\n",
      "1960: [D loss: 0.695868, acc: 0.513672]: [A loss: 0.721462, acc: 0.347656]\n",
      "1961: [D loss: 0.697133, acc: 0.513672]: [A loss: 0.725223, acc: 0.359375]\n",
      "1962: [D loss: 0.689449, acc: 0.546875]: [A loss: 0.738003, acc: 0.296875]\n",
      "1963: [D loss: 0.695951, acc: 0.507812]: [A loss: 0.725575, acc: 0.343750]\n",
      "1964: [D loss: 0.698277, acc: 0.500000]: [A loss: 0.759221, acc: 0.203125]\n",
      "1965: [D loss: 0.688399, acc: 0.529297]: [A loss: 0.703316, acc: 0.457031]\n",
      "1966: [D loss: 0.699539, acc: 0.486328]: [A loss: 0.757320, acc: 0.242188]\n",
      "1967: [D loss: 0.690659, acc: 0.548828]: [A loss: 0.722185, acc: 0.363281]\n",
      "1968: [D loss: 0.695777, acc: 0.492188]: [A loss: 0.743859, acc: 0.277344]\n",
      "1969: [D loss: 0.691846, acc: 0.505859]: [A loss: 0.727329, acc: 0.328125]\n",
      "1970: [D loss: 0.700835, acc: 0.486328]: [A loss: 0.706059, acc: 0.441406]\n",
      "1971: [D loss: 0.691007, acc: 0.507812]: [A loss: 0.744743, acc: 0.300781]\n",
      "1972: [D loss: 0.699633, acc: 0.488281]: [A loss: 0.691227, acc: 0.511719]\n",
      "1973: [D loss: 0.697367, acc: 0.525391]: [A loss: 0.722752, acc: 0.335938]\n",
      "1974: [D loss: 0.697655, acc: 0.507812]: [A loss: 0.735278, acc: 0.289062]\n",
      "1975: [D loss: 0.693791, acc: 0.515625]: [A loss: 0.722613, acc: 0.390625]\n",
      "1976: [D loss: 0.693430, acc: 0.527344]: [A loss: 0.731869, acc: 0.324219]\n",
      "1977: [D loss: 0.687871, acc: 0.533203]: [A loss: 0.711846, acc: 0.371094]\n",
      "1978: [D loss: 0.692125, acc: 0.533203]: [A loss: 0.758890, acc: 0.195312]\n",
      "1979: [D loss: 0.693929, acc: 0.505859]: [A loss: 0.727500, acc: 0.390625]\n",
      "1980: [D loss: 0.693783, acc: 0.507812]: [A loss: 0.730215, acc: 0.328125]\n",
      "1981: [D loss: 0.699219, acc: 0.509766]: [A loss: 0.740173, acc: 0.304688]\n",
      "1982: [D loss: 0.693296, acc: 0.503906]: [A loss: 0.722736, acc: 0.367188]\n",
      "1983: [D loss: 0.694306, acc: 0.535156]: [A loss: 0.767416, acc: 0.203125]\n",
      "1984: [D loss: 0.691914, acc: 0.537109]: [A loss: 0.774646, acc: 0.175781]\n",
      "1985: [D loss: 0.689875, acc: 0.535156]: [A loss: 0.738247, acc: 0.273438]\n",
      "1986: [D loss: 0.699292, acc: 0.498047]: [A loss: 0.710563, acc: 0.425781]\n",
      "1987: [D loss: 0.707839, acc: 0.476562]: [A loss: 0.727738, acc: 0.335938]\n",
      "1988: [D loss: 0.697754, acc: 0.513672]: [A loss: 0.746068, acc: 0.261719]\n",
      "1989: [D loss: 0.691728, acc: 0.544922]: [A loss: 0.685659, acc: 0.570312]\n",
      "1990: [D loss: 0.701527, acc: 0.503906]: [A loss: 0.763293, acc: 0.183594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991: [D loss: 0.692833, acc: 0.544922]: [A loss: 0.708704, acc: 0.437500]\n",
      "1992: [D loss: 0.694613, acc: 0.490234]: [A loss: 0.722820, acc: 0.320312]\n",
      "1993: [D loss: 0.694833, acc: 0.521484]: [A loss: 0.744415, acc: 0.308594]\n",
      "1994: [D loss: 0.696483, acc: 0.500000]: [A loss: 0.703119, acc: 0.484375]\n",
      "1995: [D loss: 0.696205, acc: 0.521484]: [A loss: 0.757683, acc: 0.187500]\n",
      "1996: [D loss: 0.688147, acc: 0.544922]: [A loss: 0.677066, acc: 0.628906]\n",
      "1997: [D loss: 0.701402, acc: 0.503906]: [A loss: 0.757949, acc: 0.226562]\n",
      "1998: [D loss: 0.698853, acc: 0.476562]: [A loss: 0.697879, acc: 0.488281]\n",
      "1999: [D loss: 0.697966, acc: 0.496094]: [A loss: 0.739035, acc: 0.261719]\n",
      "2000: [D loss: 0.697415, acc: 0.455078]: [A loss: 0.718354, acc: 0.386719]\n",
      "2001: [D loss: 0.699092, acc: 0.513672]: [A loss: 0.709016, acc: 0.406250]\n",
      "2002: [D loss: 0.689251, acc: 0.515625]: [A loss: 0.719320, acc: 0.351562]\n",
      "2003: [D loss: 0.692808, acc: 0.519531]: [A loss: 0.720183, acc: 0.335938]\n",
      "2004: [D loss: 0.685790, acc: 0.548828]: [A loss: 0.713808, acc: 0.378906]\n",
      "2005: [D loss: 0.698804, acc: 0.501953]: [A loss: 0.758065, acc: 0.210938]\n",
      "2006: [D loss: 0.686324, acc: 0.566406]: [A loss: 0.681779, acc: 0.523438]\n",
      "2007: [D loss: 0.704516, acc: 0.490234]: [A loss: 0.778294, acc: 0.132812]\n",
      "2008: [D loss: 0.691318, acc: 0.535156]: [A loss: 0.697954, acc: 0.468750]\n",
      "2009: [D loss: 0.703384, acc: 0.496094]: [A loss: 0.730483, acc: 0.332031]\n",
      "2010: [D loss: 0.691573, acc: 0.541016]: [A loss: 0.690883, acc: 0.476562]\n",
      "2011: [D loss: 0.697198, acc: 0.501953]: [A loss: 0.763457, acc: 0.199219]\n",
      "2012: [D loss: 0.699180, acc: 0.503906]: [A loss: 0.714529, acc: 0.375000]\n",
      "2013: [D loss: 0.697886, acc: 0.503906]: [A loss: 0.718336, acc: 0.371094]\n",
      "2014: [D loss: 0.688886, acc: 0.511719]: [A loss: 0.716251, acc: 0.367188]\n",
      "2015: [D loss: 0.701262, acc: 0.484375]: [A loss: 0.745764, acc: 0.300781]\n",
      "2016: [D loss: 0.702368, acc: 0.496094]: [A loss: 0.791213, acc: 0.128906]\n",
      "2017: [D loss: 0.692001, acc: 0.519531]: [A loss: 0.698403, acc: 0.476562]\n",
      "2018: [D loss: 0.695214, acc: 0.513672]: [A loss: 0.771118, acc: 0.167969]\n",
      "2019: [D loss: 0.702108, acc: 0.492188]: [A loss: 0.714022, acc: 0.378906]\n",
      "2020: [D loss: 0.694225, acc: 0.511719]: [A loss: 0.733540, acc: 0.332031]\n",
      "2021: [D loss: 0.696674, acc: 0.505859]: [A loss: 0.738554, acc: 0.289062]\n",
      "2022: [D loss: 0.692440, acc: 0.517578]: [A loss: 0.727718, acc: 0.398438]\n",
      "2023: [D loss: 0.696027, acc: 0.498047]: [A loss: 0.750809, acc: 0.277344]\n",
      "2024: [D loss: 0.689871, acc: 0.511719]: [A loss: 0.681833, acc: 0.539062]\n",
      "2025: [D loss: 0.697297, acc: 0.509766]: [A loss: 0.733092, acc: 0.316406]\n",
      "2026: [D loss: 0.692106, acc: 0.533203]: [A loss: 0.733380, acc: 0.324219]\n",
      "2027: [D loss: 0.699358, acc: 0.474609]: [A loss: 0.747861, acc: 0.246094]\n",
      "2028: [D loss: 0.694215, acc: 0.501953]: [A loss: 0.717850, acc: 0.394531]\n",
      "2029: [D loss: 0.691700, acc: 0.505859]: [A loss: 0.734371, acc: 0.328125]\n",
      "2030: [D loss: 0.690301, acc: 0.548828]: [A loss: 0.786953, acc: 0.207031]\n",
      "2031: [D loss: 0.697636, acc: 0.494141]: [A loss: 0.688733, acc: 0.503906]\n",
      "2032: [D loss: 0.697113, acc: 0.513672]: [A loss: 0.756761, acc: 0.285156]\n",
      "2033: [D loss: 0.681147, acc: 0.570312]: [A loss: 0.726375, acc: 0.347656]\n",
      "2034: [D loss: 0.693905, acc: 0.496094]: [A loss: 0.700811, acc: 0.468750]\n",
      "2035: [D loss: 0.696619, acc: 0.509766]: [A loss: 0.815107, acc: 0.097656]\n",
      "2036: [D loss: 0.698358, acc: 0.503906]: [A loss: 0.671989, acc: 0.636719]\n",
      "2037: [D loss: 0.697258, acc: 0.509766]: [A loss: 0.798036, acc: 0.125000]\n",
      "2038: [D loss: 0.698976, acc: 0.490234]: [A loss: 0.693670, acc: 0.503906]\n",
      "2039: [D loss: 0.696297, acc: 0.527344]: [A loss: 0.707751, acc: 0.441406]\n",
      "2040: [D loss: 0.701667, acc: 0.519531]: [A loss: 0.742736, acc: 0.281250]\n",
      "2041: [D loss: 0.698187, acc: 0.490234]: [A loss: 0.690449, acc: 0.546875]\n",
      "2042: [D loss: 0.691622, acc: 0.511719]: [A loss: 0.714707, acc: 0.394531]\n",
      "2043: [D loss: 0.700010, acc: 0.507812]: [A loss: 0.751359, acc: 0.261719]\n",
      "2044: [D loss: 0.694793, acc: 0.517578]: [A loss: 0.720340, acc: 0.371094]\n",
      "2045: [D loss: 0.694943, acc: 0.531250]: [A loss: 0.770735, acc: 0.199219]\n",
      "2046: [D loss: 0.695234, acc: 0.527344]: [A loss: 0.671208, acc: 0.613281]\n",
      "2047: [D loss: 0.701673, acc: 0.517578]: [A loss: 0.746028, acc: 0.246094]\n",
      "2048: [D loss: 0.695574, acc: 0.490234]: [A loss: 0.670897, acc: 0.660156]\n",
      "2049: [D loss: 0.701993, acc: 0.523438]: [A loss: 0.738692, acc: 0.253906]\n",
      "2050: [D loss: 0.696269, acc: 0.509766]: [A loss: 0.723944, acc: 0.359375]\n",
      "2051: [D loss: 0.701021, acc: 0.490234]: [A loss: 0.753932, acc: 0.226562]\n",
      "2052: [D loss: 0.694084, acc: 0.533203]: [A loss: 0.733040, acc: 0.320312]\n",
      "2053: [D loss: 0.696796, acc: 0.492188]: [A loss: 0.731259, acc: 0.289062]\n",
      "2054: [D loss: 0.694666, acc: 0.529297]: [A loss: 0.710126, acc: 0.406250]\n",
      "2055: [D loss: 0.697794, acc: 0.484375]: [A loss: 0.761161, acc: 0.210938]\n",
      "2056: [D loss: 0.695678, acc: 0.501953]: [A loss: 0.699543, acc: 0.433594]\n",
      "2057: [D loss: 0.698711, acc: 0.513672]: [A loss: 0.793784, acc: 0.097656]\n",
      "2058: [D loss: 0.697785, acc: 0.470703]: [A loss: 0.682387, acc: 0.542969]\n",
      "2059: [D loss: 0.703996, acc: 0.501953]: [A loss: 0.765665, acc: 0.160156]\n",
      "2060: [D loss: 0.693382, acc: 0.501953]: [A loss: 0.706094, acc: 0.464844]\n",
      "2061: [D loss: 0.696174, acc: 0.509766]: [A loss: 0.744375, acc: 0.246094]\n",
      "2062: [D loss: 0.697100, acc: 0.486328]: [A loss: 0.706466, acc: 0.406250]\n",
      "2063: [D loss: 0.696830, acc: 0.519531]: [A loss: 0.727304, acc: 0.359375]\n",
      "2064: [D loss: 0.692945, acc: 0.517578]: [A loss: 0.728038, acc: 0.332031]\n",
      "2065: [D loss: 0.692857, acc: 0.531250]: [A loss: 0.685338, acc: 0.519531]\n",
      "2066: [D loss: 0.697653, acc: 0.519531]: [A loss: 0.777427, acc: 0.136719]\n",
      "2067: [D loss: 0.693759, acc: 0.537109]: [A loss: 0.705864, acc: 0.464844]\n",
      "2068: [D loss: 0.698818, acc: 0.500000]: [A loss: 0.752705, acc: 0.246094]\n",
      "2069: [D loss: 0.690802, acc: 0.546875]: [A loss: 0.696867, acc: 0.492188]\n",
      "2070: [D loss: 0.692440, acc: 0.511719]: [A loss: 0.749635, acc: 0.230469]\n",
      "2071: [D loss: 0.697466, acc: 0.521484]: [A loss: 0.752330, acc: 0.226562]\n",
      "2072: [D loss: 0.693219, acc: 0.521484]: [A loss: 0.702644, acc: 0.460938]\n",
      "2073: [D loss: 0.695831, acc: 0.521484]: [A loss: 0.751695, acc: 0.253906]\n",
      "2074: [D loss: 0.694616, acc: 0.523438]: [A loss: 0.705113, acc: 0.453125]\n",
      "2075: [D loss: 0.695976, acc: 0.521484]: [A loss: 0.745197, acc: 0.269531]\n",
      "2076: [D loss: 0.693516, acc: 0.500000]: [A loss: 0.704455, acc: 0.453125]\n",
      "2077: [D loss: 0.696872, acc: 0.501953]: [A loss: 0.745107, acc: 0.269531]\n",
      "2078: [D loss: 0.694557, acc: 0.498047]: [A loss: 0.696393, acc: 0.484375]\n",
      "2079: [D loss: 0.709733, acc: 0.470703]: [A loss: 0.768215, acc: 0.171875]\n",
      "2080: [D loss: 0.691841, acc: 0.531250]: [A loss: 0.677953, acc: 0.558594]\n",
      "2081: [D loss: 0.702963, acc: 0.503906]: [A loss: 0.810572, acc: 0.074219]\n",
      "2082: [D loss: 0.695171, acc: 0.492188]: [A loss: 0.685320, acc: 0.550781]\n",
      "2083: [D loss: 0.698229, acc: 0.509766]: [A loss: 0.758440, acc: 0.226562]\n",
      "2084: [D loss: 0.706134, acc: 0.451172]: [A loss: 0.725721, acc: 0.292969]\n",
      "2085: [D loss: 0.696585, acc: 0.503906]: [A loss: 0.712860, acc: 0.417969]\n",
      "2086: [D loss: 0.692488, acc: 0.535156]: [A loss: 0.711448, acc: 0.421875]\n",
      "2087: [D loss: 0.694804, acc: 0.519531]: [A loss: 0.730137, acc: 0.316406]\n",
      "2088: [D loss: 0.691614, acc: 0.521484]: [A loss: 0.702963, acc: 0.460938]\n",
      "2089: [D loss: 0.701637, acc: 0.501953]: [A loss: 0.772524, acc: 0.199219]\n",
      "2090: [D loss: 0.693621, acc: 0.496094]: [A loss: 0.680528, acc: 0.570312]\n",
      "2091: [D loss: 0.696146, acc: 0.496094]: [A loss: 0.744411, acc: 0.281250]\n",
      "2092: [D loss: 0.690005, acc: 0.541016]: [A loss: 0.686914, acc: 0.554688]\n",
      "2093: [D loss: 0.703403, acc: 0.505859]: [A loss: 0.773340, acc: 0.207031]\n",
      "2094: [D loss: 0.692299, acc: 0.509766]: [A loss: 0.659381, acc: 0.664062]\n",
      "2095: [D loss: 0.697166, acc: 0.503906]: [A loss: 0.772436, acc: 0.214844]\n",
      "2096: [D loss: 0.694681, acc: 0.519531]: [A loss: 0.703893, acc: 0.453125]\n",
      "2097: [D loss: 0.700347, acc: 0.492188]: [A loss: 0.745086, acc: 0.273438]\n",
      "2098: [D loss: 0.689856, acc: 0.535156]: [A loss: 0.697973, acc: 0.507812]\n",
      "2099: [D loss: 0.697765, acc: 0.505859]: [A loss: 0.748274, acc: 0.257812]\n",
      "2100: [D loss: 0.699890, acc: 0.468750]: [A loss: 0.745758, acc: 0.250000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2101: [D loss: 0.697247, acc: 0.494141]: [A loss: 0.731889, acc: 0.296875]\n",
      "2102: [D loss: 0.695676, acc: 0.521484]: [A loss: 0.758293, acc: 0.226562]\n",
      "2103: [D loss: 0.692810, acc: 0.511719]: [A loss: 0.729503, acc: 0.332031]\n",
      "2104: [D loss: 0.695285, acc: 0.500000]: [A loss: 0.689157, acc: 0.535156]\n",
      "2105: [D loss: 0.696830, acc: 0.505859]: [A loss: 0.740568, acc: 0.269531]\n",
      "2106: [D loss: 0.693381, acc: 0.529297]: [A loss: 0.719833, acc: 0.394531]\n",
      "2107: [D loss: 0.691469, acc: 0.531250]: [A loss: 0.744507, acc: 0.285156]\n",
      "2108: [D loss: 0.691309, acc: 0.527344]: [A loss: 0.696151, acc: 0.488281]\n",
      "2109: [D loss: 0.698845, acc: 0.503906]: [A loss: 0.749326, acc: 0.230469]\n",
      "2110: [D loss: 0.694174, acc: 0.458984]: [A loss: 0.709384, acc: 0.410156]\n",
      "2111: [D loss: 0.694402, acc: 0.503906]: [A loss: 0.731279, acc: 0.320312]\n",
      "2112: [D loss: 0.694403, acc: 0.533203]: [A loss: 0.721059, acc: 0.371094]\n",
      "2113: [D loss: 0.693692, acc: 0.511719]: [A loss: 0.752116, acc: 0.253906]\n",
      "2114: [D loss: 0.697117, acc: 0.472656]: [A loss: 0.710131, acc: 0.414062]\n",
      "2115: [D loss: 0.695389, acc: 0.513672]: [A loss: 0.710371, acc: 0.441406]\n",
      "2116: [D loss: 0.700268, acc: 0.529297]: [A loss: 0.795507, acc: 0.132812]\n",
      "2117: [D loss: 0.692063, acc: 0.519531]: [A loss: 0.663033, acc: 0.683594]\n",
      "2118: [D loss: 0.700601, acc: 0.505859]: [A loss: 0.752723, acc: 0.250000]\n",
      "2119: [D loss: 0.696904, acc: 0.476562]: [A loss: 0.703692, acc: 0.429688]\n",
      "2120: [D loss: 0.696156, acc: 0.519531]: [A loss: 0.741014, acc: 0.343750]\n",
      "2121: [D loss: 0.696453, acc: 0.525391]: [A loss: 0.716508, acc: 0.367188]\n",
      "2122: [D loss: 0.703955, acc: 0.496094]: [A loss: 0.748811, acc: 0.226562]\n",
      "2123: [D loss: 0.693049, acc: 0.509766]: [A loss: 0.704536, acc: 0.414062]\n",
      "2124: [D loss: 0.697056, acc: 0.505859]: [A loss: 0.759842, acc: 0.214844]\n",
      "2125: [D loss: 0.692874, acc: 0.519531]: [A loss: 0.717676, acc: 0.386719]\n",
      "2126: [D loss: 0.701578, acc: 0.496094]: [A loss: 0.716363, acc: 0.386719]\n",
      "2127: [D loss: 0.696753, acc: 0.505859]: [A loss: 0.761430, acc: 0.210938]\n",
      "2128: [D loss: 0.696884, acc: 0.476562]: [A loss: 0.716959, acc: 0.386719]\n",
      "2129: [D loss: 0.690252, acc: 0.515625]: [A loss: 0.738366, acc: 0.320312]\n",
      "2130: [D loss: 0.695229, acc: 0.511719]: [A loss: 0.732523, acc: 0.320312]\n",
      "2131: [D loss: 0.695378, acc: 0.503906]: [A loss: 0.746036, acc: 0.273438]\n",
      "2132: [D loss: 0.693352, acc: 0.513672]: [A loss: 0.746493, acc: 0.234375]\n",
      "2133: [D loss: 0.698200, acc: 0.513672]: [A loss: 0.709472, acc: 0.425781]\n",
      "2134: [D loss: 0.697313, acc: 0.513672]: [A loss: 0.764875, acc: 0.199219]\n",
      "2135: [D loss: 0.693953, acc: 0.519531]: [A loss: 0.729046, acc: 0.328125]\n",
      "2136: [D loss: 0.697811, acc: 0.517578]: [A loss: 0.739504, acc: 0.296875]\n",
      "2137: [D loss: 0.688232, acc: 0.521484]: [A loss: 0.732260, acc: 0.335938]\n",
      "2138: [D loss: 0.695229, acc: 0.523438]: [A loss: 0.692597, acc: 0.480469]\n",
      "2139: [D loss: 0.697672, acc: 0.521484]: [A loss: 0.779063, acc: 0.167969]\n",
      "2140: [D loss: 0.698867, acc: 0.505859]: [A loss: 0.711866, acc: 0.410156]\n",
      "2141: [D loss: 0.701162, acc: 0.507812]: [A loss: 0.754890, acc: 0.210938]\n",
      "2142: [D loss: 0.705664, acc: 0.449219]: [A loss: 0.734515, acc: 0.304688]\n",
      "2143: [D loss: 0.694371, acc: 0.517578]: [A loss: 0.736584, acc: 0.261719]\n",
      "2144: [D loss: 0.693126, acc: 0.527344]: [A loss: 0.697091, acc: 0.519531]\n",
      "2145: [D loss: 0.690605, acc: 0.498047]: [A loss: 0.699043, acc: 0.468750]\n",
      "2146: [D loss: 0.698722, acc: 0.511719]: [A loss: 0.761261, acc: 0.199219]\n",
      "2147: [D loss: 0.697946, acc: 0.505859]: [A loss: 0.726925, acc: 0.347656]\n",
      "2148: [D loss: 0.691971, acc: 0.519531]: [A loss: 0.695471, acc: 0.488281]\n",
      "2149: [D loss: 0.693910, acc: 0.533203]: [A loss: 0.780766, acc: 0.144531]\n",
      "2150: [D loss: 0.692554, acc: 0.537109]: [A loss: 0.686161, acc: 0.507812]\n",
      "2151: [D loss: 0.701366, acc: 0.507812]: [A loss: 0.755715, acc: 0.242188]\n",
      "2152: [D loss: 0.690181, acc: 0.521484]: [A loss: 0.688023, acc: 0.535156]\n",
      "2153: [D loss: 0.693418, acc: 0.529297]: [A loss: 0.736020, acc: 0.257812]\n",
      "2154: [D loss: 0.701322, acc: 0.455078]: [A loss: 0.712508, acc: 0.414062]\n",
      "2155: [D loss: 0.706131, acc: 0.474609]: [A loss: 0.756616, acc: 0.191406]\n",
      "2156: [D loss: 0.698706, acc: 0.490234]: [A loss: 0.670351, acc: 0.644531]\n",
      "2157: [D loss: 0.695263, acc: 0.515625]: [A loss: 0.752769, acc: 0.199219]\n",
      "2158: [D loss: 0.697364, acc: 0.500000]: [A loss: 0.723745, acc: 0.347656]\n",
      "2159: [D loss: 0.696080, acc: 0.515625]: [A loss: 0.731216, acc: 0.320312]\n",
      "2160: [D loss: 0.695084, acc: 0.503906]: [A loss: 0.702410, acc: 0.472656]\n",
      "2161: [D loss: 0.694142, acc: 0.521484]: [A loss: 0.728622, acc: 0.339844]\n",
      "2162: [D loss: 0.693432, acc: 0.503906]: [A loss: 0.718691, acc: 0.347656]\n",
      "2163: [D loss: 0.687381, acc: 0.542969]: [A loss: 0.730590, acc: 0.320312]\n",
      "2164: [D loss: 0.700830, acc: 0.488281]: [A loss: 0.753921, acc: 0.226562]\n",
      "2165: [D loss: 0.695857, acc: 0.486328]: [A loss: 0.801394, acc: 0.113281]\n",
      "2166: [D loss: 0.693118, acc: 0.511719]: [A loss: 0.666274, acc: 0.640625]\n",
      "2167: [D loss: 0.702577, acc: 0.501953]: [A loss: 0.794679, acc: 0.089844]\n",
      "2168: [D loss: 0.693430, acc: 0.513672]: [A loss: 0.660731, acc: 0.675781]\n",
      "2169: [D loss: 0.702342, acc: 0.501953]: [A loss: 0.745916, acc: 0.238281]\n",
      "2170: [D loss: 0.693538, acc: 0.501953]: [A loss: 0.690899, acc: 0.515625]\n",
      "2171: [D loss: 0.694895, acc: 0.519531]: [A loss: 0.719093, acc: 0.351562]\n",
      "2172: [D loss: 0.692968, acc: 0.531250]: [A loss: 0.694878, acc: 0.492188]\n",
      "2173: [D loss: 0.698836, acc: 0.494141]: [A loss: 0.716089, acc: 0.417969]\n",
      "2174: [D loss: 0.700671, acc: 0.509766]: [A loss: 0.726849, acc: 0.289062]\n",
      "2175: [D loss: 0.690311, acc: 0.544922]: [A loss: 0.711377, acc: 0.425781]\n",
      "2176: [D loss: 0.689742, acc: 0.542969]: [A loss: 0.719775, acc: 0.363281]\n",
      "2177: [D loss: 0.693797, acc: 0.515625]: [A loss: 0.739323, acc: 0.269531]\n",
      "2178: [D loss: 0.688192, acc: 0.531250]: [A loss: 0.735761, acc: 0.289062]\n",
      "2179: [D loss: 0.695151, acc: 0.507812]: [A loss: 0.743945, acc: 0.308594]\n",
      "2180: [D loss: 0.691790, acc: 0.523438]: [A loss: 0.759538, acc: 0.226562]\n",
      "2181: [D loss: 0.699594, acc: 0.476562]: [A loss: 0.690944, acc: 0.496094]\n",
      "2182: [D loss: 0.702805, acc: 0.490234]: [A loss: 0.757537, acc: 0.250000]\n",
      "2183: [D loss: 0.695693, acc: 0.490234]: [A loss: 0.671292, acc: 0.656250]\n",
      "2184: [D loss: 0.698406, acc: 0.511719]: [A loss: 0.733932, acc: 0.324219]\n",
      "2185: [D loss: 0.694299, acc: 0.531250]: [A loss: 0.697385, acc: 0.468750]\n",
      "2186: [D loss: 0.700373, acc: 0.509766]: [A loss: 0.757713, acc: 0.183594]\n",
      "2187: [D loss: 0.691042, acc: 0.494141]: [A loss: 0.722275, acc: 0.367188]\n",
      "2188: [D loss: 0.705707, acc: 0.476562]: [A loss: 0.742340, acc: 0.226562]\n",
      "2189: [D loss: 0.693482, acc: 0.539062]: [A loss: 0.715663, acc: 0.421875]\n",
      "2190: [D loss: 0.698921, acc: 0.503906]: [A loss: 0.733948, acc: 0.332031]\n",
      "2191: [D loss: 0.698382, acc: 0.480469]: [A loss: 0.752418, acc: 0.203125]\n",
      "2192: [D loss: 0.701232, acc: 0.484375]: [A loss: 0.705089, acc: 0.472656]\n",
      "2193: [D loss: 0.698518, acc: 0.484375]: [A loss: 0.742803, acc: 0.257812]\n",
      "2194: [D loss: 0.695843, acc: 0.521484]: [A loss: 0.686491, acc: 0.531250]\n",
      "2195: [D loss: 0.699656, acc: 0.500000]: [A loss: 0.736549, acc: 0.265625]\n",
      "2196: [D loss: 0.693606, acc: 0.507812]: [A loss: 0.711052, acc: 0.398438]\n",
      "2197: [D loss: 0.699043, acc: 0.525391]: [A loss: 0.774285, acc: 0.140625]\n",
      "2198: [D loss: 0.694760, acc: 0.498047]: [A loss: 0.691614, acc: 0.507812]\n",
      "2199: [D loss: 0.695631, acc: 0.509766]: [A loss: 0.750875, acc: 0.242188]\n",
      "2200: [D loss: 0.694393, acc: 0.511719]: [A loss: 0.689968, acc: 0.523438]\n",
      "2201: [D loss: 0.692956, acc: 0.531250]: [A loss: 0.752983, acc: 0.210938]\n",
      "2202: [D loss: 0.694678, acc: 0.501953]: [A loss: 0.732266, acc: 0.292969]\n",
      "2203: [D loss: 0.687742, acc: 0.546875]: [A loss: 0.687826, acc: 0.511719]\n",
      "2204: [D loss: 0.698668, acc: 0.501953]: [A loss: 0.749976, acc: 0.242188]\n",
      "2205: [D loss: 0.689525, acc: 0.562500]: [A loss: 0.704566, acc: 0.484375]\n",
      "2206: [D loss: 0.700105, acc: 0.501953]: [A loss: 0.736917, acc: 0.316406]\n",
      "2207: [D loss: 0.690354, acc: 0.513672]: [A loss: 0.724787, acc: 0.332031]\n",
      "2208: [D loss: 0.687157, acc: 0.552734]: [A loss: 0.714285, acc: 0.382812]\n",
      "2209: [D loss: 0.699846, acc: 0.492188]: [A loss: 0.706663, acc: 0.425781]\n",
      "2210: [D loss: 0.698734, acc: 0.480469]: [A loss: 0.689614, acc: 0.500000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211: [D loss: 0.693226, acc: 0.535156]: [A loss: 0.742700, acc: 0.269531]\n",
      "2212: [D loss: 0.698460, acc: 0.478516]: [A loss: 0.736148, acc: 0.292969]\n",
      "2213: [D loss: 0.690212, acc: 0.531250]: [A loss: 0.686496, acc: 0.562500]\n",
      "2214: [D loss: 0.700426, acc: 0.498047]: [A loss: 0.764403, acc: 0.179688]\n",
      "2215: [D loss: 0.688566, acc: 0.525391]: [A loss: 0.699225, acc: 0.480469]\n",
      "2216: [D loss: 0.695285, acc: 0.488281]: [A loss: 0.715504, acc: 0.390625]\n",
      "2217: [D loss: 0.692553, acc: 0.523438]: [A loss: 0.741602, acc: 0.281250]\n",
      "2218: [D loss: 0.697384, acc: 0.500000]: [A loss: 0.671109, acc: 0.632812]\n",
      "2219: [D loss: 0.699485, acc: 0.519531]: [A loss: 0.750089, acc: 0.218750]\n",
      "2220: [D loss: 0.697573, acc: 0.494141]: [A loss: 0.680473, acc: 0.566406]\n",
      "2221: [D loss: 0.701601, acc: 0.500000]: [A loss: 0.742759, acc: 0.246094]\n",
      "2222: [D loss: 0.692439, acc: 0.523438]: [A loss: 0.693491, acc: 0.496094]\n",
      "2223: [D loss: 0.690692, acc: 0.517578]: [A loss: 0.722755, acc: 0.378906]\n",
      "2224: [D loss: 0.692475, acc: 0.527344]: [A loss: 0.696658, acc: 0.496094]\n",
      "2225: [D loss: 0.705005, acc: 0.478516]: [A loss: 0.722771, acc: 0.367188]\n",
      "2226: [D loss: 0.698186, acc: 0.480469]: [A loss: 0.754174, acc: 0.199219]\n",
      "2227: [D loss: 0.697955, acc: 0.492188]: [A loss: 0.774205, acc: 0.144531]\n",
      "2228: [D loss: 0.689776, acc: 0.535156]: [A loss: 0.705002, acc: 0.457031]\n",
      "2229: [D loss: 0.695330, acc: 0.515625]: [A loss: 0.724164, acc: 0.332031]\n",
      "2230: [D loss: 0.697459, acc: 0.507812]: [A loss: 0.713359, acc: 0.394531]\n",
      "2231: [D loss: 0.700589, acc: 0.490234]: [A loss: 0.712423, acc: 0.421875]\n",
      "2232: [D loss: 0.694400, acc: 0.498047]: [A loss: 0.733373, acc: 0.281250]\n",
      "2233: [D loss: 0.696038, acc: 0.494141]: [A loss: 0.721247, acc: 0.320312]\n",
      "2234: [D loss: 0.692044, acc: 0.527344]: [A loss: 0.705460, acc: 0.437500]\n",
      "2235: [D loss: 0.702676, acc: 0.453125]: [A loss: 0.712642, acc: 0.437500]\n",
      "2236: [D loss: 0.690412, acc: 0.552734]: [A loss: 0.742896, acc: 0.296875]\n",
      "2237: [D loss: 0.696927, acc: 0.507812]: [A loss: 0.707588, acc: 0.429688]\n",
      "2238: [D loss: 0.693778, acc: 0.513672]: [A loss: 0.705276, acc: 0.441406]\n",
      "2239: [D loss: 0.706532, acc: 0.498047]: [A loss: 0.744614, acc: 0.250000]\n",
      "2240: [D loss: 0.694667, acc: 0.501953]: [A loss: 0.728350, acc: 0.347656]\n",
      "2241: [D loss: 0.696661, acc: 0.507812]: [A loss: 0.713590, acc: 0.398438]\n",
      "2242: [D loss: 0.697601, acc: 0.500000]: [A loss: 0.740781, acc: 0.273438]\n",
      "2243: [D loss: 0.692786, acc: 0.503906]: [A loss: 0.680934, acc: 0.562500]\n",
      "2244: [D loss: 0.694329, acc: 0.525391]: [A loss: 0.784339, acc: 0.093750]\n",
      "2245: [D loss: 0.695274, acc: 0.515625]: [A loss: 0.686878, acc: 0.566406]\n",
      "2246: [D loss: 0.696013, acc: 0.515625]: [A loss: 0.749942, acc: 0.222656]\n",
      "2247: [D loss: 0.691369, acc: 0.507812]: [A loss: 0.685371, acc: 0.578125]\n",
      "2248: [D loss: 0.696083, acc: 0.523438]: [A loss: 0.730857, acc: 0.312500]\n",
      "2249: [D loss: 0.700646, acc: 0.474609]: [A loss: 0.734481, acc: 0.316406]\n",
      "2250: [D loss: 0.698495, acc: 0.496094]: [A loss: 0.707797, acc: 0.441406]\n",
      "2251: [D loss: 0.697534, acc: 0.523438]: [A loss: 0.706107, acc: 0.425781]\n",
      "2252: [D loss: 0.689075, acc: 0.533203]: [A loss: 0.724476, acc: 0.363281]\n",
      "2253: [D loss: 0.698092, acc: 0.509766]: [A loss: 0.695825, acc: 0.523438]\n",
      "2254: [D loss: 0.691822, acc: 0.539062]: [A loss: 0.729383, acc: 0.355469]\n",
      "2255: [D loss: 0.696517, acc: 0.517578]: [A loss: 0.718879, acc: 0.332031]\n",
      "2256: [D loss: 0.691636, acc: 0.505859]: [A loss: 0.766035, acc: 0.191406]\n",
      "2257: [D loss: 0.690029, acc: 0.548828]: [A loss: 0.722651, acc: 0.371094]\n",
      "2258: [D loss: 0.693532, acc: 0.527344]: [A loss: 0.770015, acc: 0.156250]\n",
      "2259: [D loss: 0.696097, acc: 0.503906]: [A loss: 0.713849, acc: 0.425781]\n",
      "2260: [D loss: 0.696108, acc: 0.513672]: [A loss: 0.698608, acc: 0.472656]\n",
      "2261: [D loss: 0.696242, acc: 0.513672]: [A loss: 0.734670, acc: 0.269531]\n",
      "2262: [D loss: 0.689434, acc: 0.529297]: [A loss: 0.681358, acc: 0.589844]\n",
      "2263: [D loss: 0.696298, acc: 0.517578]: [A loss: 0.736293, acc: 0.296875]\n",
      "2264: [D loss: 0.696936, acc: 0.501953]: [A loss: 0.718600, acc: 0.382812]\n",
      "2265: [D loss: 0.701027, acc: 0.507812]: [A loss: 0.761787, acc: 0.218750]\n",
      "2266: [D loss: 0.699608, acc: 0.484375]: [A loss: 0.677356, acc: 0.566406]\n",
      "2267: [D loss: 0.690496, acc: 0.511719]: [A loss: 0.754021, acc: 0.218750]\n",
      "2268: [D loss: 0.691020, acc: 0.515625]: [A loss: 0.713688, acc: 0.425781]\n",
      "2269: [D loss: 0.695657, acc: 0.521484]: [A loss: 0.740924, acc: 0.273438]\n",
      "2270: [D loss: 0.691088, acc: 0.511719]: [A loss: 0.696635, acc: 0.480469]\n",
      "2271: [D loss: 0.694092, acc: 0.525391]: [A loss: 0.741152, acc: 0.285156]\n",
      "2272: [D loss: 0.697902, acc: 0.519531]: [A loss: 0.767109, acc: 0.175781]\n",
      "2273: [D loss: 0.693848, acc: 0.525391]: [A loss: 0.726409, acc: 0.328125]\n",
      "2274: [D loss: 0.696482, acc: 0.503906]: [A loss: 0.719238, acc: 0.339844]\n",
      "2275: [D loss: 0.688687, acc: 0.523438]: [A loss: 0.690425, acc: 0.523438]\n",
      "2276: [D loss: 0.696468, acc: 0.505859]: [A loss: 0.744285, acc: 0.281250]\n",
      "2277: [D loss: 0.695540, acc: 0.496094]: [A loss: 0.704475, acc: 0.476562]\n",
      "2278: [D loss: 0.691305, acc: 0.515625]: [A loss: 0.736756, acc: 0.300781]\n",
      "2279: [D loss: 0.691567, acc: 0.539062]: [A loss: 0.704086, acc: 0.441406]\n",
      "2280: [D loss: 0.692800, acc: 0.511719]: [A loss: 0.735717, acc: 0.308594]\n",
      "2281: [D loss: 0.695471, acc: 0.535156]: [A loss: 0.723484, acc: 0.359375]\n",
      "2282: [D loss: 0.694277, acc: 0.535156]: [A loss: 0.770394, acc: 0.171875]\n",
      "2283: [D loss: 0.685529, acc: 0.572266]: [A loss: 0.696193, acc: 0.496094]\n",
      "2284: [D loss: 0.689605, acc: 0.531250]: [A loss: 0.753960, acc: 0.207031]\n",
      "2285: [D loss: 0.696950, acc: 0.503906]: [A loss: 0.757694, acc: 0.226562]\n",
      "2286: [D loss: 0.692797, acc: 0.531250]: [A loss: 0.733643, acc: 0.308594]\n",
      "2287: [D loss: 0.698947, acc: 0.501953]: [A loss: 0.747312, acc: 0.222656]\n",
      "2288: [D loss: 0.691005, acc: 0.513672]: [A loss: 0.691445, acc: 0.515625]\n",
      "2289: [D loss: 0.694616, acc: 0.498047]: [A loss: 0.743210, acc: 0.285156]\n",
      "2290: [D loss: 0.697038, acc: 0.503906]: [A loss: 0.699164, acc: 0.496094]\n",
      "2291: [D loss: 0.698917, acc: 0.505859]: [A loss: 0.705908, acc: 0.425781]\n",
      "2292: [D loss: 0.701232, acc: 0.484375]: [A loss: 0.752650, acc: 0.187500]\n",
      "2293: [D loss: 0.691494, acc: 0.503906]: [A loss: 0.689007, acc: 0.554688]\n",
      "2294: [D loss: 0.691747, acc: 0.517578]: [A loss: 0.726532, acc: 0.343750]\n",
      "2295: [D loss: 0.695132, acc: 0.509766]: [A loss: 0.741706, acc: 0.265625]\n",
      "2296: [D loss: 0.693363, acc: 0.519531]: [A loss: 0.712234, acc: 0.371094]\n",
      "2297: [D loss: 0.693208, acc: 0.525391]: [A loss: 0.731634, acc: 0.312500]\n",
      "2298: [D loss: 0.698005, acc: 0.488281]: [A loss: 0.736983, acc: 0.261719]\n",
      "2299: [D loss: 0.691468, acc: 0.546875]: [A loss: 0.712731, acc: 0.402344]\n",
      "2300: [D loss: 0.694731, acc: 0.509766]: [A loss: 0.710548, acc: 0.375000]\n",
      "2301: [D loss: 0.690832, acc: 0.519531]: [A loss: 0.724805, acc: 0.367188]\n",
      "2302: [D loss: 0.687701, acc: 0.544922]: [A loss: 0.714572, acc: 0.394531]\n",
      "2303: [D loss: 0.693591, acc: 0.486328]: [A loss: 0.748125, acc: 0.250000]\n",
      "2304: [D loss: 0.689731, acc: 0.544922]: [A loss: 0.672540, acc: 0.628906]\n",
      "2305: [D loss: 0.701022, acc: 0.488281]: [A loss: 0.791752, acc: 0.148438]\n",
      "2306: [D loss: 0.694758, acc: 0.529297]: [A loss: 0.679466, acc: 0.585938]\n",
      "2307: [D loss: 0.693395, acc: 0.525391]: [A loss: 0.731900, acc: 0.304688]\n",
      "2308: [D loss: 0.691452, acc: 0.529297]: [A loss: 0.747866, acc: 0.277344]\n",
      "2309: [D loss: 0.688289, acc: 0.552734]: [A loss: 0.674021, acc: 0.609375]\n",
      "2310: [D loss: 0.695412, acc: 0.517578]: [A loss: 0.767152, acc: 0.187500]\n",
      "2311: [D loss: 0.697281, acc: 0.500000]: [A loss: 0.701626, acc: 0.457031]\n",
      "2312: [D loss: 0.694086, acc: 0.498047]: [A loss: 0.735191, acc: 0.324219]\n",
      "2313: [D loss: 0.691931, acc: 0.525391]: [A loss: 0.723759, acc: 0.339844]\n",
      "2314: [D loss: 0.700610, acc: 0.509766]: [A loss: 0.745989, acc: 0.230469]\n",
      "2315: [D loss: 0.699734, acc: 0.519531]: [A loss: 0.733811, acc: 0.343750]\n",
      "2316: [D loss: 0.699134, acc: 0.503906]: [A loss: 0.683305, acc: 0.527344]\n",
      "2317: [D loss: 0.692592, acc: 0.527344]: [A loss: 0.784797, acc: 0.156250]\n",
      "2318: [D loss: 0.695539, acc: 0.521484]: [A loss: 0.656654, acc: 0.699219]\n",
      "2319: [D loss: 0.708207, acc: 0.494141]: [A loss: 0.772574, acc: 0.160156]\n",
      "2320: [D loss: 0.686623, acc: 0.576172]: [A loss: 0.688909, acc: 0.554688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2321: [D loss: 0.692613, acc: 0.531250]: [A loss: 0.707650, acc: 0.441406]\n",
      "2322: [D loss: 0.698686, acc: 0.503906]: [A loss: 0.719149, acc: 0.390625]\n",
      "2323: [D loss: 0.695706, acc: 0.531250]: [A loss: 0.734829, acc: 0.300781]\n",
      "2324: [D loss: 0.696401, acc: 0.498047]: [A loss: 0.735917, acc: 0.296875]\n",
      "2325: [D loss: 0.700577, acc: 0.490234]: [A loss: 0.745305, acc: 0.281250]\n",
      "2326: [D loss: 0.697975, acc: 0.478516]: [A loss: 0.685093, acc: 0.535156]\n",
      "2327: [D loss: 0.701603, acc: 0.513672]: [A loss: 0.792436, acc: 0.125000]\n",
      "2328: [D loss: 0.694426, acc: 0.503906]: [A loss: 0.678515, acc: 0.585938]\n",
      "2329: [D loss: 0.700066, acc: 0.521484]: [A loss: 0.764938, acc: 0.179688]\n",
      "2330: [D loss: 0.691185, acc: 0.523438]: [A loss: 0.693667, acc: 0.484375]\n",
      "2331: [D loss: 0.699127, acc: 0.509766]: [A loss: 0.746873, acc: 0.246094]\n",
      "2332: [D loss: 0.692175, acc: 0.500000]: [A loss: 0.727590, acc: 0.308594]\n",
      "2333: [D loss: 0.688983, acc: 0.546875]: [A loss: 0.735459, acc: 0.277344]\n",
      "2334: [D loss: 0.700737, acc: 0.505859]: [A loss: 0.715412, acc: 0.394531]\n",
      "2335: [D loss: 0.691730, acc: 0.548828]: [A loss: 0.725766, acc: 0.382812]\n",
      "2336: [D loss: 0.685111, acc: 0.552734]: [A loss: 0.713211, acc: 0.378906]\n",
      "2337: [D loss: 0.698522, acc: 0.500000]: [A loss: 0.729602, acc: 0.324219]\n",
      "2338: [D loss: 0.692011, acc: 0.535156]: [A loss: 0.740485, acc: 0.285156]\n",
      "2339: [D loss: 0.695120, acc: 0.505859]: [A loss: 0.715494, acc: 0.406250]\n",
      "2340: [D loss: 0.695786, acc: 0.507812]: [A loss: 0.741475, acc: 0.292969]\n",
      "2341: [D loss: 0.690397, acc: 0.550781]: [A loss: 0.751374, acc: 0.242188]\n",
      "2342: [D loss: 0.695527, acc: 0.488281]: [A loss: 0.738158, acc: 0.312500]\n",
      "2343: [D loss: 0.698860, acc: 0.480469]: [A loss: 0.728986, acc: 0.332031]\n",
      "2344: [D loss: 0.695947, acc: 0.488281]: [A loss: 0.680242, acc: 0.574219]\n",
      "2345: [D loss: 0.695206, acc: 0.492188]: [A loss: 0.731833, acc: 0.316406]\n",
      "2346: [D loss: 0.695993, acc: 0.515625]: [A loss: 0.716158, acc: 0.398438]\n",
      "2347: [D loss: 0.699096, acc: 0.505859]: [A loss: 0.722117, acc: 0.355469]\n",
      "2348: [D loss: 0.695380, acc: 0.515625]: [A loss: 0.718534, acc: 0.382812]\n",
      "2349: [D loss: 0.693576, acc: 0.509766]: [A loss: 0.742580, acc: 0.250000]\n",
      "2350: [D loss: 0.689441, acc: 0.531250]: [A loss: 0.709970, acc: 0.390625]\n",
      "2351: [D loss: 0.682393, acc: 0.583984]: [A loss: 0.734485, acc: 0.316406]\n",
      "2352: [D loss: 0.690365, acc: 0.523438]: [A loss: 0.708602, acc: 0.425781]\n",
      "2353: [D loss: 0.693150, acc: 0.492188]: [A loss: 0.720714, acc: 0.343750]\n",
      "2354: [D loss: 0.697128, acc: 0.498047]: [A loss: 0.736039, acc: 0.316406]\n",
      "2355: [D loss: 0.698362, acc: 0.492188]: [A loss: 0.752890, acc: 0.222656]\n",
      "2356: [D loss: 0.692259, acc: 0.523438]: [A loss: 0.724124, acc: 0.324219]\n",
      "2357: [D loss: 0.692053, acc: 0.531250]: [A loss: 0.713707, acc: 0.398438]\n",
      "2358: [D loss: 0.687828, acc: 0.548828]: [A loss: 0.723039, acc: 0.324219]\n",
      "2359: [D loss: 0.693261, acc: 0.525391]: [A loss: 0.764951, acc: 0.222656]\n",
      "2360: [D loss: 0.699796, acc: 0.460938]: [A loss: 0.683218, acc: 0.558594]\n",
      "2361: [D loss: 0.689984, acc: 0.523438]: [A loss: 0.735381, acc: 0.300781]\n",
      "2362: [D loss: 0.690466, acc: 0.527344]: [A loss: 0.672319, acc: 0.597656]\n",
      "2363: [D loss: 0.698747, acc: 0.505859]: [A loss: 0.772443, acc: 0.160156]\n",
      "2364: [D loss: 0.698103, acc: 0.496094]: [A loss: 0.686044, acc: 0.562500]\n",
      "2365: [D loss: 0.700030, acc: 0.501953]: [A loss: 0.752356, acc: 0.242188]\n",
      "2366: [D loss: 0.697548, acc: 0.511719]: [A loss: 0.742646, acc: 0.257812]\n",
      "2367: [D loss: 0.697319, acc: 0.486328]: [A loss: 0.721667, acc: 0.371094]\n",
      "2368: [D loss: 0.695952, acc: 0.494141]: [A loss: 0.718280, acc: 0.375000]\n",
      "2369: [D loss: 0.700238, acc: 0.517578]: [A loss: 0.717718, acc: 0.359375]\n",
      "2370: [D loss: 0.687414, acc: 0.537109]: [A loss: 0.761203, acc: 0.214844]\n",
      "2371: [D loss: 0.694750, acc: 0.525391]: [A loss: 0.710823, acc: 0.417969]\n",
      "2372: [D loss: 0.688765, acc: 0.560547]: [A loss: 0.734847, acc: 0.328125]\n",
      "2373: [D loss: 0.703318, acc: 0.476562]: [A loss: 0.723706, acc: 0.316406]\n",
      "2374: [D loss: 0.698193, acc: 0.490234]: [A loss: 0.780958, acc: 0.144531]\n",
      "2375: [D loss: 0.693412, acc: 0.519531]: [A loss: 0.705802, acc: 0.410156]\n",
      "2376: [D loss: 0.695771, acc: 0.503906]: [A loss: 0.748705, acc: 0.265625]\n",
      "2377: [D loss: 0.692153, acc: 0.505859]: [A loss: 0.703180, acc: 0.457031]\n",
      "2378: [D loss: 0.689637, acc: 0.531250]: [A loss: 0.731116, acc: 0.343750]\n",
      "2379: [D loss: 0.694153, acc: 0.505859]: [A loss: 0.688341, acc: 0.507812]\n",
      "2380: [D loss: 0.696126, acc: 0.513672]: [A loss: 0.742470, acc: 0.281250]\n",
      "2381: [D loss: 0.697863, acc: 0.484375]: [A loss: 0.739924, acc: 0.289062]\n",
      "2382: [D loss: 0.695886, acc: 0.501953]: [A loss: 0.692147, acc: 0.507812]\n",
      "2383: [D loss: 0.698704, acc: 0.505859]: [A loss: 0.723123, acc: 0.363281]\n",
      "2384: [D loss: 0.695142, acc: 0.498047]: [A loss: 0.698237, acc: 0.460938]\n",
      "2385: [D loss: 0.697243, acc: 0.513672]: [A loss: 0.783218, acc: 0.164062]\n",
      "2386: [D loss: 0.695499, acc: 0.484375]: [A loss: 0.701849, acc: 0.453125]\n",
      "2387: [D loss: 0.696622, acc: 0.505859]: [A loss: 0.723539, acc: 0.351562]\n",
      "2388: [D loss: 0.692089, acc: 0.505859]: [A loss: 0.715120, acc: 0.390625]\n",
      "2389: [D loss: 0.696928, acc: 0.521484]: [A loss: 0.735886, acc: 0.281250]\n",
      "2390: [D loss: 0.695324, acc: 0.480469]: [A loss: 0.679655, acc: 0.589844]\n",
      "2391: [D loss: 0.694261, acc: 0.492188]: [A loss: 0.755125, acc: 0.222656]\n",
      "2392: [D loss: 0.689726, acc: 0.533203]: [A loss: 0.689027, acc: 0.531250]\n",
      "2393: [D loss: 0.695172, acc: 0.507812]: [A loss: 0.723203, acc: 0.347656]\n",
      "2394: [D loss: 0.697925, acc: 0.482422]: [A loss: 0.715560, acc: 0.375000]\n",
      "2395: [D loss: 0.699176, acc: 0.482422]: [A loss: 0.725120, acc: 0.339844]\n",
      "2396: [D loss: 0.691730, acc: 0.521484]: [A loss: 0.696637, acc: 0.507812]\n",
      "2397: [D loss: 0.710378, acc: 0.484375]: [A loss: 0.789795, acc: 0.128906]\n",
      "2398: [D loss: 0.698163, acc: 0.462891]: [A loss: 0.682221, acc: 0.574219]\n",
      "2399: [D loss: 0.695858, acc: 0.525391]: [A loss: 0.735070, acc: 0.269531]\n",
      "2400: [D loss: 0.692305, acc: 0.521484]: [A loss: 0.719577, acc: 0.363281]\n",
      "2401: [D loss: 0.693048, acc: 0.533203]: [A loss: 0.724750, acc: 0.347656]\n",
      "2402: [D loss: 0.701080, acc: 0.480469]: [A loss: 0.703649, acc: 0.453125]\n",
      "2403: [D loss: 0.697416, acc: 0.488281]: [A loss: 0.700994, acc: 0.464844]\n",
      "2404: [D loss: 0.697366, acc: 0.478516]: [A loss: 0.735208, acc: 0.304688]\n",
      "2405: [D loss: 0.694418, acc: 0.509766]: [A loss: 0.756907, acc: 0.207031]\n",
      "2406: [D loss: 0.695661, acc: 0.521484]: [A loss: 0.717407, acc: 0.335938]\n",
      "2407: [D loss: 0.686558, acc: 0.562500]: [A loss: 0.716287, acc: 0.394531]\n",
      "2408: [D loss: 0.699594, acc: 0.496094]: [A loss: 0.760846, acc: 0.218750]\n",
      "2409: [D loss: 0.694499, acc: 0.498047]: [A loss: 0.699226, acc: 0.460938]\n",
      "2410: [D loss: 0.698757, acc: 0.505859]: [A loss: 0.794227, acc: 0.113281]\n",
      "2411: [D loss: 0.695475, acc: 0.517578]: [A loss: 0.674458, acc: 0.539062]\n",
      "2412: [D loss: 0.696566, acc: 0.521484]: [A loss: 0.741801, acc: 0.273438]\n",
      "2413: [D loss: 0.700933, acc: 0.468750]: [A loss: 0.676926, acc: 0.617188]\n",
      "2414: [D loss: 0.697006, acc: 0.521484]: [A loss: 0.720656, acc: 0.390625]\n",
      "2415: [D loss: 0.699273, acc: 0.496094]: [A loss: 0.724100, acc: 0.332031]\n",
      "2416: [D loss: 0.687662, acc: 0.535156]: [A loss: 0.747836, acc: 0.246094]\n",
      "2417: [D loss: 0.693162, acc: 0.509766]: [A loss: 0.679880, acc: 0.566406]\n",
      "2418: [D loss: 0.701069, acc: 0.472656]: [A loss: 0.780500, acc: 0.148438]\n",
      "2419: [D loss: 0.699546, acc: 0.462891]: [A loss: 0.687441, acc: 0.519531]\n",
      "2420: [D loss: 0.703076, acc: 0.478516]: [A loss: 0.749432, acc: 0.257812]\n",
      "2421: [D loss: 0.687779, acc: 0.503906]: [A loss: 0.719954, acc: 0.363281]\n",
      "2422: [D loss: 0.699489, acc: 0.513672]: [A loss: 0.722488, acc: 0.367188]\n",
      "2423: [D loss: 0.699293, acc: 0.484375]: [A loss: 0.722975, acc: 0.359375]\n",
      "2424: [D loss: 0.697465, acc: 0.513672]: [A loss: 0.720816, acc: 0.378906]\n",
      "2425: [D loss: 0.694787, acc: 0.500000]: [A loss: 0.731512, acc: 0.328125]\n",
      "2426: [D loss: 0.700878, acc: 0.484375]: [A loss: 0.702614, acc: 0.464844]\n",
      "2427: [D loss: 0.700899, acc: 0.486328]: [A loss: 0.756922, acc: 0.195312]\n",
      "2428: [D loss: 0.693476, acc: 0.509766]: [A loss: 0.678990, acc: 0.570312]\n",
      "2429: [D loss: 0.702030, acc: 0.527344]: [A loss: 0.745586, acc: 0.242188]\n",
      "2430: [D loss: 0.695526, acc: 0.472656]: [A loss: 0.732271, acc: 0.316406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431: [D loss: 0.684867, acc: 0.564453]: [A loss: 0.683787, acc: 0.570312]\n",
      "2432: [D loss: 0.699820, acc: 0.521484]: [A loss: 0.715543, acc: 0.417969]\n",
      "2433: [D loss: 0.701590, acc: 0.478516]: [A loss: 0.708843, acc: 0.414062]\n",
      "2434: [D loss: 0.696862, acc: 0.539062]: [A loss: 0.781748, acc: 0.148438]\n",
      "2435: [D loss: 0.693467, acc: 0.521484]: [A loss: 0.693422, acc: 0.484375]\n",
      "2436: [D loss: 0.693773, acc: 0.531250]: [A loss: 0.718801, acc: 0.414062]\n",
      "2437: [D loss: 0.695736, acc: 0.507812]: [A loss: 0.719398, acc: 0.375000]\n",
      "2438: [D loss: 0.693542, acc: 0.519531]: [A loss: 0.714675, acc: 0.417969]\n",
      "2439: [D loss: 0.694628, acc: 0.513672]: [A loss: 0.730394, acc: 0.332031]\n",
      "2440: [D loss: 0.699263, acc: 0.492188]: [A loss: 0.729174, acc: 0.304688]\n",
      "2441: [D loss: 0.698867, acc: 0.500000]: [A loss: 0.700317, acc: 0.472656]\n",
      "2442: [D loss: 0.693228, acc: 0.509766]: [A loss: 0.729225, acc: 0.304688]\n",
      "2443: [D loss: 0.688325, acc: 0.546875]: [A loss: 0.714445, acc: 0.433594]\n",
      "2444: [D loss: 0.696936, acc: 0.498047]: [A loss: 0.765391, acc: 0.195312]\n",
      "2445: [D loss: 0.688408, acc: 0.548828]: [A loss: 0.714944, acc: 0.390625]\n",
      "2446: [D loss: 0.690563, acc: 0.513672]: [A loss: 0.717843, acc: 0.390625]\n",
      "2447: [D loss: 0.695337, acc: 0.527344]: [A loss: 0.692331, acc: 0.535156]\n",
      "2448: [D loss: 0.691700, acc: 0.537109]: [A loss: 0.734141, acc: 0.308594]\n",
      "2449: [D loss: 0.689629, acc: 0.533203]: [A loss: 0.692149, acc: 0.542969]\n",
      "2450: [D loss: 0.697986, acc: 0.525391]: [A loss: 0.767527, acc: 0.203125]\n",
      "2451: [D loss: 0.694995, acc: 0.521484]: [A loss: 0.722603, acc: 0.375000]\n",
      "2452: [D loss: 0.693915, acc: 0.503906]: [A loss: 0.736306, acc: 0.355469]\n",
      "2453: [D loss: 0.699354, acc: 0.503906]: [A loss: 0.764400, acc: 0.230469]\n",
      "2454: [D loss: 0.697968, acc: 0.480469]: [A loss: 0.699358, acc: 0.488281]\n",
      "2455: [D loss: 0.695803, acc: 0.521484]: [A loss: 0.706527, acc: 0.457031]\n",
      "2456: [D loss: 0.693146, acc: 0.529297]: [A loss: 0.704161, acc: 0.464844]\n",
      "2457: [D loss: 0.695143, acc: 0.509766]: [A loss: 0.744389, acc: 0.285156]\n",
      "2458: [D loss: 0.697995, acc: 0.529297]: [A loss: 0.684071, acc: 0.562500]\n",
      "2459: [D loss: 0.699035, acc: 0.505859]: [A loss: 0.725711, acc: 0.332031]\n",
      "2460: [D loss: 0.697653, acc: 0.513672]: [A loss: 0.711020, acc: 0.449219]\n",
      "2461: [D loss: 0.691836, acc: 0.521484]: [A loss: 0.715299, acc: 0.378906]\n",
      "2462: [D loss: 0.698047, acc: 0.490234]: [A loss: 0.718991, acc: 0.371094]\n",
      "2463: [D loss: 0.701147, acc: 0.488281]: [A loss: 0.722081, acc: 0.371094]\n",
      "2464: [D loss: 0.691752, acc: 0.517578]: [A loss: 0.750071, acc: 0.257812]\n",
      "2465: [D loss: 0.694642, acc: 0.484375]: [A loss: 0.719411, acc: 0.347656]\n",
      "2466: [D loss: 0.695238, acc: 0.496094]: [A loss: 0.732266, acc: 0.328125]\n",
      "2467: [D loss: 0.693857, acc: 0.509766]: [A loss: 0.705264, acc: 0.421875]\n",
      "2468: [D loss: 0.702319, acc: 0.503906]: [A loss: 0.721941, acc: 0.378906]\n",
      "2469: [D loss: 0.691294, acc: 0.509766]: [A loss: 0.725979, acc: 0.347656]\n",
      "2470: [D loss: 0.698822, acc: 0.488281]: [A loss: 0.710763, acc: 0.425781]\n",
      "2471: [D loss: 0.695799, acc: 0.501953]: [A loss: 0.700669, acc: 0.457031]\n",
      "2472: [D loss: 0.699383, acc: 0.474609]: [A loss: 0.731519, acc: 0.296875]\n",
      "2473: [D loss: 0.694990, acc: 0.511719]: [A loss: 0.709034, acc: 0.445312]\n",
      "2474: [D loss: 0.694723, acc: 0.480469]: [A loss: 0.716915, acc: 0.410156]\n",
      "2475: [D loss: 0.699227, acc: 0.482422]: [A loss: 0.785303, acc: 0.101562]\n",
      "2476: [D loss: 0.695364, acc: 0.523438]: [A loss: 0.704430, acc: 0.453125]\n",
      "2477: [D loss: 0.704201, acc: 0.466797]: [A loss: 0.735389, acc: 0.285156]\n",
      "2478: [D loss: 0.697325, acc: 0.500000]: [A loss: 0.709991, acc: 0.406250]\n",
      "2479: [D loss: 0.696869, acc: 0.537109]: [A loss: 0.742808, acc: 0.218750]\n",
      "2480: [D loss: 0.694107, acc: 0.527344]: [A loss: 0.724781, acc: 0.343750]\n",
      "2481: [D loss: 0.694804, acc: 0.496094]: [A loss: 0.698972, acc: 0.472656]\n",
      "2482: [D loss: 0.691304, acc: 0.527344]: [A loss: 0.748999, acc: 0.234375]\n",
      "2483: [D loss: 0.694108, acc: 0.539062]: [A loss: 0.670901, acc: 0.585938]\n",
      "2484: [D loss: 0.704395, acc: 0.507812]: [A loss: 0.745200, acc: 0.253906]\n",
      "2485: [D loss: 0.693401, acc: 0.505859]: [A loss: 0.719614, acc: 0.367188]\n",
      "2486: [D loss: 0.694022, acc: 0.527344]: [A loss: 0.725669, acc: 0.328125]\n",
      "2487: [D loss: 0.694843, acc: 0.523438]: [A loss: 0.713570, acc: 0.375000]\n",
      "2488: [D loss: 0.691283, acc: 0.519531]: [A loss: 0.714655, acc: 0.375000]\n",
      "2489: [D loss: 0.692098, acc: 0.535156]: [A loss: 0.729034, acc: 0.320312]\n",
      "2490: [D loss: 0.688208, acc: 0.558594]: [A loss: 0.700801, acc: 0.437500]\n",
      "2491: [D loss: 0.693548, acc: 0.511719]: [A loss: 0.706650, acc: 0.414062]\n",
      "2492: [D loss: 0.690550, acc: 0.535156]: [A loss: 0.759628, acc: 0.234375]\n",
      "2493: [D loss: 0.691971, acc: 0.531250]: [A loss: 0.724214, acc: 0.371094]\n",
      "2494: [D loss: 0.698850, acc: 0.498047]: [A loss: 0.718185, acc: 0.371094]\n",
      "2495: [D loss: 0.690868, acc: 0.496094]: [A loss: 0.733630, acc: 0.292969]\n",
      "2496: [D loss: 0.696857, acc: 0.503906]: [A loss: 0.765400, acc: 0.218750]\n",
      "2497: [D loss: 0.692527, acc: 0.519531]: [A loss: 0.697639, acc: 0.488281]\n",
      "2498: [D loss: 0.691105, acc: 0.515625]: [A loss: 0.773866, acc: 0.179688]\n",
      "2499: [D loss: 0.696127, acc: 0.513672]: [A loss: 0.697084, acc: 0.515625]\n",
      "2500: [D loss: 0.691499, acc: 0.515625]: [A loss: 0.737517, acc: 0.269531]\n",
      "2501: [D loss: 0.693187, acc: 0.531250]: [A loss: 0.703264, acc: 0.472656]\n",
      "2502: [D loss: 0.685602, acc: 0.542969]: [A loss: 0.694351, acc: 0.472656]\n",
      "2503: [D loss: 0.699540, acc: 0.498047]: [A loss: 0.739846, acc: 0.312500]\n",
      "2504: [D loss: 0.693752, acc: 0.503906]: [A loss: 0.698144, acc: 0.523438]\n",
      "2505: [D loss: 0.701576, acc: 0.500000]: [A loss: 0.766255, acc: 0.210938]\n",
      "2506: [D loss: 0.697488, acc: 0.472656]: [A loss: 0.740679, acc: 0.277344]\n",
      "2507: [D loss: 0.694084, acc: 0.490234]: [A loss: 0.755330, acc: 0.203125]\n",
      "2508: [D loss: 0.690893, acc: 0.519531]: [A loss: 0.724362, acc: 0.339844]\n",
      "2509: [D loss: 0.695003, acc: 0.511719]: [A loss: 0.720104, acc: 0.429688]\n",
      "2510: [D loss: 0.698882, acc: 0.492188]: [A loss: 0.720980, acc: 0.359375]\n",
      "2511: [D loss: 0.700262, acc: 0.476562]: [A loss: 0.701771, acc: 0.441406]\n",
      "2512: [D loss: 0.689168, acc: 0.515625]: [A loss: 0.727452, acc: 0.355469]\n",
      "2513: [D loss: 0.695017, acc: 0.503906]: [A loss: 0.678659, acc: 0.570312]\n",
      "2514: [D loss: 0.695083, acc: 0.503906]: [A loss: 0.778960, acc: 0.160156]\n",
      "2515: [D loss: 0.693923, acc: 0.521484]: [A loss: 0.722715, acc: 0.332031]\n",
      "2516: [D loss: 0.691233, acc: 0.541016]: [A loss: 0.732039, acc: 0.324219]\n",
      "2517: [D loss: 0.697837, acc: 0.505859]: [A loss: 0.773491, acc: 0.164062]\n",
      "2518: [D loss: 0.696231, acc: 0.480469]: [A loss: 0.690890, acc: 0.503906]\n",
      "2519: [D loss: 0.698792, acc: 0.500000]: [A loss: 0.714858, acc: 0.394531]\n",
      "2520: [D loss: 0.686122, acc: 0.529297]: [A loss: 0.706654, acc: 0.445312]\n",
      "2521: [D loss: 0.698917, acc: 0.492188]: [A loss: 0.756238, acc: 0.230469]\n",
      "2522: [D loss: 0.694205, acc: 0.531250]: [A loss: 0.690579, acc: 0.496094]\n",
      "2523: [D loss: 0.695608, acc: 0.474609]: [A loss: 0.729023, acc: 0.343750]\n",
      "2524: [D loss: 0.697142, acc: 0.486328]: [A loss: 0.732556, acc: 0.308594]\n",
      "2525: [D loss: 0.695874, acc: 0.517578]: [A loss: 0.744376, acc: 0.238281]\n",
      "2526: [D loss: 0.703582, acc: 0.472656]: [A loss: 0.686307, acc: 0.531250]\n",
      "2527: [D loss: 0.694896, acc: 0.519531]: [A loss: 0.708271, acc: 0.406250]\n",
      "2528: [D loss: 0.689716, acc: 0.535156]: [A loss: 0.755862, acc: 0.207031]\n",
      "2529: [D loss: 0.690739, acc: 0.548828]: [A loss: 0.732150, acc: 0.316406]\n",
      "2530: [D loss: 0.692089, acc: 0.529297]: [A loss: 0.736545, acc: 0.289062]\n",
      "2531: [D loss: 0.693864, acc: 0.544922]: [A loss: 0.722128, acc: 0.347656]\n",
      "2532: [D loss: 0.689888, acc: 0.544922]: [A loss: 0.707966, acc: 0.417969]\n",
      "2533: [D loss: 0.697441, acc: 0.503906]: [A loss: 0.754974, acc: 0.203125]\n",
      "2534: [D loss: 0.689098, acc: 0.519531]: [A loss: 0.697159, acc: 0.535156]\n",
      "2535: [D loss: 0.700733, acc: 0.503906]: [A loss: 0.750445, acc: 0.214844]\n",
      "2536: [D loss: 0.694067, acc: 0.511719]: [A loss: 0.740533, acc: 0.257812]\n",
      "2537: [D loss: 0.688211, acc: 0.537109]: [A loss: 0.685097, acc: 0.546875]\n",
      "2538: [D loss: 0.694843, acc: 0.501953]: [A loss: 0.769604, acc: 0.191406]\n",
      "2539: [D loss: 0.689040, acc: 0.515625]: [A loss: 0.685824, acc: 0.546875]\n",
      "2540: [D loss: 0.696030, acc: 0.519531]: [A loss: 0.747864, acc: 0.253906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541: [D loss: 0.697552, acc: 0.501953]: [A loss: 0.698239, acc: 0.468750]\n",
      "2542: [D loss: 0.706560, acc: 0.507812]: [A loss: 0.778414, acc: 0.132812]\n",
      "2543: [D loss: 0.691313, acc: 0.500000]: [A loss: 0.682513, acc: 0.574219]\n",
      "2544: [D loss: 0.697496, acc: 0.527344]: [A loss: 0.722436, acc: 0.359375]\n",
      "2545: [D loss: 0.695303, acc: 0.500000]: [A loss: 0.731122, acc: 0.304688]\n",
      "2546: [D loss: 0.693070, acc: 0.505859]: [A loss: 0.720523, acc: 0.371094]\n",
      "2547: [D loss: 0.696246, acc: 0.503906]: [A loss: 0.740530, acc: 0.296875]\n",
      "2548: [D loss: 0.695713, acc: 0.500000]: [A loss: 0.722935, acc: 0.375000]\n",
      "2549: [D loss: 0.700025, acc: 0.511719]: [A loss: 0.711622, acc: 0.417969]\n",
      "2550: [D loss: 0.694555, acc: 0.509766]: [A loss: 0.747681, acc: 0.226562]\n",
      "2551: [D loss: 0.702294, acc: 0.476562]: [A loss: 0.710641, acc: 0.390625]\n",
      "2552: [D loss: 0.690089, acc: 0.535156]: [A loss: 0.691677, acc: 0.511719]\n",
      "2553: [D loss: 0.701406, acc: 0.501953]: [A loss: 0.760803, acc: 0.203125]\n",
      "2554: [D loss: 0.692632, acc: 0.517578]: [A loss: 0.695991, acc: 0.500000]\n",
      "2555: [D loss: 0.693336, acc: 0.529297]: [A loss: 0.719013, acc: 0.367188]\n",
      "2556: [D loss: 0.696289, acc: 0.501953]: [A loss: 0.727877, acc: 0.355469]\n",
      "2557: [D loss: 0.695666, acc: 0.511719]: [A loss: 0.719037, acc: 0.375000]\n",
      "2558: [D loss: 0.695526, acc: 0.507812]: [A loss: 0.739574, acc: 0.289062]\n",
      "2559: [D loss: 0.694294, acc: 0.525391]: [A loss: 0.704145, acc: 0.464844]\n",
      "2560: [D loss: 0.700224, acc: 0.503906]: [A loss: 0.735063, acc: 0.257812]\n",
      "2561: [D loss: 0.690531, acc: 0.529297]: [A loss: 0.738949, acc: 0.277344]\n",
      "2562: [D loss: 0.693166, acc: 0.494141]: [A loss: 0.708482, acc: 0.429688]\n",
      "2563: [D loss: 0.702837, acc: 0.478516]: [A loss: 0.712576, acc: 0.410156]\n",
      "2564: [D loss: 0.694438, acc: 0.515625]: [A loss: 0.730726, acc: 0.335938]\n",
      "2565: [D loss: 0.700237, acc: 0.482422]: [A loss: 0.735004, acc: 0.277344]\n",
      "2566: [D loss: 0.697729, acc: 0.500000]: [A loss: 0.740061, acc: 0.308594]\n",
      "2567: [D loss: 0.703850, acc: 0.482422]: [A loss: 0.726895, acc: 0.300781]\n",
      "2568: [D loss: 0.692628, acc: 0.492188]: [A loss: 0.731166, acc: 0.324219]\n",
      "2569: [D loss: 0.691246, acc: 0.517578]: [A loss: 0.710724, acc: 0.375000]\n",
      "2570: [D loss: 0.692142, acc: 0.517578]: [A loss: 0.708679, acc: 0.453125]\n",
      "2571: [D loss: 0.694097, acc: 0.533203]: [A loss: 0.745102, acc: 0.277344]\n",
      "2572: [D loss: 0.696431, acc: 0.501953]: [A loss: 0.706427, acc: 0.433594]\n",
      "2573: [D loss: 0.695090, acc: 0.519531]: [A loss: 0.735885, acc: 0.281250]\n",
      "2574: [D loss: 0.686857, acc: 0.548828]: [A loss: 0.685275, acc: 0.570312]\n",
      "2575: [D loss: 0.703200, acc: 0.509766]: [A loss: 0.770076, acc: 0.164062]\n",
      "2576: [D loss: 0.691641, acc: 0.533203]: [A loss: 0.717362, acc: 0.390625]\n",
      "2577: [D loss: 0.696105, acc: 0.517578]: [A loss: 0.761530, acc: 0.199219]\n",
      "2578: [D loss: 0.689380, acc: 0.537109]: [A loss: 0.658343, acc: 0.656250]\n",
      "2579: [D loss: 0.711299, acc: 0.498047]: [A loss: 0.791403, acc: 0.140625]\n",
      "2580: [D loss: 0.694381, acc: 0.531250]: [A loss: 0.699345, acc: 0.527344]\n",
      "2581: [D loss: 0.701916, acc: 0.494141]: [A loss: 0.725025, acc: 0.371094]\n",
      "2582: [D loss: 0.694151, acc: 0.525391]: [A loss: 0.731010, acc: 0.320312]\n",
      "2583: [D loss: 0.693374, acc: 0.496094]: [A loss: 0.715539, acc: 0.425781]\n",
      "2584: [D loss: 0.697744, acc: 0.507812]: [A loss: 0.719070, acc: 0.382812]\n",
      "2585: [D loss: 0.694906, acc: 0.529297]: [A loss: 0.715323, acc: 0.410156]\n",
      "2586: [D loss: 0.691078, acc: 0.531250]: [A loss: 0.707634, acc: 0.414062]\n",
      "2587: [D loss: 0.696301, acc: 0.494141]: [A loss: 0.708281, acc: 0.425781]\n",
      "2588: [D loss: 0.693130, acc: 0.515625]: [A loss: 0.754470, acc: 0.234375]\n",
      "2589: [D loss: 0.688590, acc: 0.552734]: [A loss: 0.733512, acc: 0.308594]\n",
      "2590: [D loss: 0.694839, acc: 0.505859]: [A loss: 0.732697, acc: 0.324219]\n",
      "2591: [D loss: 0.694082, acc: 0.517578]: [A loss: 0.711724, acc: 0.398438]\n",
      "2592: [D loss: 0.691422, acc: 0.527344]: [A loss: 0.695327, acc: 0.464844]\n",
      "2593: [D loss: 0.698629, acc: 0.503906]: [A loss: 0.735464, acc: 0.296875]\n",
      "2594: [D loss: 0.688309, acc: 0.539062]: [A loss: 0.714890, acc: 0.367188]\n",
      "2595: [D loss: 0.694215, acc: 0.519531]: [A loss: 0.718399, acc: 0.386719]\n",
      "2596: [D loss: 0.696300, acc: 0.507812]: [A loss: 0.702866, acc: 0.449219]\n",
      "2597: [D loss: 0.705109, acc: 0.437500]: [A loss: 0.742761, acc: 0.226562]\n",
      "2598: [D loss: 0.692991, acc: 0.513672]: [A loss: 0.704576, acc: 0.441406]\n",
      "2599: [D loss: 0.701931, acc: 0.503906]: [A loss: 0.765547, acc: 0.203125]\n",
      "2600: [D loss: 0.690763, acc: 0.541016]: [A loss: 0.700610, acc: 0.445312]\n",
      "2601: [D loss: 0.696671, acc: 0.519531]: [A loss: 0.689448, acc: 0.527344]\n",
      "2602: [D loss: 0.698503, acc: 0.531250]: [A loss: 0.735306, acc: 0.253906]\n",
      "2603: [D loss: 0.699371, acc: 0.490234]: [A loss: 0.691952, acc: 0.496094]\n",
      "2604: [D loss: 0.703057, acc: 0.509766]: [A loss: 0.716146, acc: 0.433594]\n",
      "2605: [D loss: 0.696628, acc: 0.496094]: [A loss: 0.723745, acc: 0.320312]\n",
      "2606: [D loss: 0.695806, acc: 0.513672]: [A loss: 0.723133, acc: 0.335938]\n",
      "2607: [D loss: 0.694145, acc: 0.525391]: [A loss: 0.717645, acc: 0.328125]\n",
      "2608: [D loss: 0.694880, acc: 0.527344]: [A loss: 0.712184, acc: 0.375000]\n",
      "2609: [D loss: 0.699988, acc: 0.480469]: [A loss: 0.722259, acc: 0.335938]\n",
      "2610: [D loss: 0.693096, acc: 0.531250]: [A loss: 0.709996, acc: 0.445312]\n",
      "2611: [D loss: 0.698646, acc: 0.523438]: [A loss: 0.724344, acc: 0.324219]\n",
      "2612: [D loss: 0.689668, acc: 0.535156]: [A loss: 0.692868, acc: 0.503906]\n",
      "2613: [D loss: 0.696736, acc: 0.525391]: [A loss: 0.736619, acc: 0.277344]\n",
      "2614: [D loss: 0.690483, acc: 0.546875]: [A loss: 0.735982, acc: 0.269531]\n",
      "2615: [D loss: 0.695850, acc: 0.507812]: [A loss: 0.719314, acc: 0.355469]\n",
      "2616: [D loss: 0.694977, acc: 0.517578]: [A loss: 0.708994, acc: 0.425781]\n",
      "2617: [D loss: 0.696054, acc: 0.507812]: [A loss: 0.743024, acc: 0.253906]\n",
      "2618: [D loss: 0.694840, acc: 0.513672]: [A loss: 0.704333, acc: 0.468750]\n",
      "2619: [D loss: 0.697642, acc: 0.486328]: [A loss: 0.737704, acc: 0.246094]\n",
      "2620: [D loss: 0.691023, acc: 0.541016]: [A loss: 0.721112, acc: 0.339844]\n",
      "2621: [D loss: 0.700259, acc: 0.494141]: [A loss: 0.728419, acc: 0.289062]\n",
      "2622: [D loss: 0.694454, acc: 0.527344]: [A loss: 0.730934, acc: 0.292969]\n",
      "2623: [D loss: 0.696399, acc: 0.496094]: [A loss: 0.693065, acc: 0.515625]\n",
      "2624: [D loss: 0.690762, acc: 0.539062]: [A loss: 0.696557, acc: 0.488281]\n",
      "2625: [D loss: 0.708787, acc: 0.449219]: [A loss: 0.769168, acc: 0.144531]\n",
      "2626: [D loss: 0.694892, acc: 0.498047]: [A loss: 0.709078, acc: 0.398438]\n",
      "2627: [D loss: 0.700890, acc: 0.480469]: [A loss: 0.731193, acc: 0.300781]\n",
      "2628: [D loss: 0.692409, acc: 0.529297]: [A loss: 0.745269, acc: 0.253906]\n",
      "2629: [D loss: 0.690245, acc: 0.556641]: [A loss: 0.689535, acc: 0.500000]\n",
      "2630: [D loss: 0.692466, acc: 0.507812]: [A loss: 0.712010, acc: 0.417969]\n",
      "2631: [D loss: 0.694124, acc: 0.515625]: [A loss: 0.726594, acc: 0.363281]\n",
      "2632: [D loss: 0.693633, acc: 0.541016]: [A loss: 0.732433, acc: 0.289062]\n",
      "2633: [D loss: 0.698678, acc: 0.494141]: [A loss: 0.730618, acc: 0.304688]\n",
      "2634: [D loss: 0.697130, acc: 0.464844]: [A loss: 0.736870, acc: 0.292969]\n",
      "2635: [D loss: 0.695569, acc: 0.507812]: [A loss: 0.678890, acc: 0.585938]\n",
      "2636: [D loss: 0.693395, acc: 0.492188]: [A loss: 0.741970, acc: 0.273438]\n",
      "2637: [D loss: 0.693395, acc: 0.535156]: [A loss: 0.698982, acc: 0.496094]\n",
      "2638: [D loss: 0.702938, acc: 0.515625]: [A loss: 0.727659, acc: 0.312500]\n",
      "2639: [D loss: 0.692420, acc: 0.527344]: [A loss: 0.713550, acc: 0.406250]\n",
      "2640: [D loss: 0.688923, acc: 0.527344]: [A loss: 0.708058, acc: 0.460938]\n",
      "2641: [D loss: 0.685270, acc: 0.566406]: [A loss: 0.721269, acc: 0.390625]\n",
      "2642: [D loss: 0.696637, acc: 0.519531]: [A loss: 0.719761, acc: 0.394531]\n",
      "2643: [D loss: 0.694488, acc: 0.509766]: [A loss: 0.721583, acc: 0.394531]\n",
      "2644: [D loss: 0.700869, acc: 0.500000]: [A loss: 0.716897, acc: 0.382812]\n",
      "2645: [D loss: 0.694038, acc: 0.541016]: [A loss: 0.701569, acc: 0.445312]\n",
      "2646: [D loss: 0.701085, acc: 0.472656]: [A loss: 0.783141, acc: 0.128906]\n",
      "2647: [D loss: 0.696353, acc: 0.498047]: [A loss: 0.694989, acc: 0.519531]\n",
      "2648: [D loss: 0.695171, acc: 0.515625]: [A loss: 0.702351, acc: 0.476562]\n",
      "2649: [D loss: 0.694532, acc: 0.507812]: [A loss: 0.690723, acc: 0.515625]\n",
      "2650: [D loss: 0.694810, acc: 0.507812]: [A loss: 0.749145, acc: 0.226562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651: [D loss: 0.695393, acc: 0.492188]: [A loss: 0.721012, acc: 0.332031]\n",
      "2652: [D loss: 0.693579, acc: 0.519531]: [A loss: 0.706456, acc: 0.441406]\n",
      "2653: [D loss: 0.698532, acc: 0.500000]: [A loss: 0.755789, acc: 0.207031]\n",
      "2654: [D loss: 0.690606, acc: 0.525391]: [A loss: 0.718755, acc: 0.363281]\n",
      "2655: [D loss: 0.695578, acc: 0.529297]: [A loss: 0.733634, acc: 0.292969]\n",
      "2656: [D loss: 0.696504, acc: 0.505859]: [A loss: 0.747962, acc: 0.246094]\n",
      "2657: [D loss: 0.693663, acc: 0.517578]: [A loss: 0.696435, acc: 0.460938]\n",
      "2658: [D loss: 0.696516, acc: 0.507812]: [A loss: 0.741023, acc: 0.265625]\n",
      "2659: [D loss: 0.692663, acc: 0.513672]: [A loss: 0.699013, acc: 0.496094]\n",
      "2660: [D loss: 0.696439, acc: 0.521484]: [A loss: 0.765103, acc: 0.210938]\n",
      "2661: [D loss: 0.699641, acc: 0.472656]: [A loss: 0.702766, acc: 0.480469]\n",
      "2662: [D loss: 0.694712, acc: 0.537109]: [A loss: 0.750442, acc: 0.246094]\n",
      "2663: [D loss: 0.688700, acc: 0.537109]: [A loss: 0.700149, acc: 0.460938]\n",
      "2664: [D loss: 0.690888, acc: 0.517578]: [A loss: 0.744054, acc: 0.250000]\n",
      "2665: [D loss: 0.694242, acc: 0.480469]: [A loss: 0.701231, acc: 0.457031]\n",
      "2666: [D loss: 0.695642, acc: 0.515625]: [A loss: 0.727429, acc: 0.347656]\n",
      "2667: [D loss: 0.701520, acc: 0.466797]: [A loss: 0.738980, acc: 0.281250]\n",
      "2668: [D loss: 0.690829, acc: 0.505859]: [A loss: 0.753003, acc: 0.214844]\n",
      "2669: [D loss: 0.700069, acc: 0.468750]: [A loss: 0.711167, acc: 0.414062]\n",
      "2670: [D loss: 0.697193, acc: 0.501953]: [A loss: 0.724117, acc: 0.351562]\n",
      "2671: [D loss: 0.687766, acc: 0.529297]: [A loss: 0.744987, acc: 0.242188]\n",
      "2672: [D loss: 0.686151, acc: 0.548828]: [A loss: 0.706569, acc: 0.445312]\n",
      "2673: [D loss: 0.700343, acc: 0.476562]: [A loss: 0.712341, acc: 0.425781]\n",
      "2674: [D loss: 0.690779, acc: 0.505859]: [A loss: 0.694833, acc: 0.488281]\n",
      "2675: [D loss: 0.698097, acc: 0.498047]: [A loss: 0.778458, acc: 0.121094]\n",
      "2676: [D loss: 0.687454, acc: 0.541016]: [A loss: 0.731253, acc: 0.320312]\n",
      "2677: [D loss: 0.688049, acc: 0.556641]: [A loss: 0.758367, acc: 0.152344]\n",
      "2678: [D loss: 0.692238, acc: 0.515625]: [A loss: 0.692650, acc: 0.503906]\n",
      "2679: [D loss: 0.700353, acc: 0.503906]: [A loss: 0.754022, acc: 0.210938]\n",
      "2680: [D loss: 0.693034, acc: 0.501953]: [A loss: 0.705481, acc: 0.437500]\n",
      "2681: [D loss: 0.695166, acc: 0.531250]: [A loss: 0.708586, acc: 0.425781]\n",
      "2682: [D loss: 0.691721, acc: 0.535156]: [A loss: 0.740617, acc: 0.253906]\n",
      "2683: [D loss: 0.695646, acc: 0.513672]: [A loss: 0.721440, acc: 0.398438]\n",
      "2684: [D loss: 0.698898, acc: 0.501953]: [A loss: 0.749494, acc: 0.234375]\n",
      "2685: [D loss: 0.692304, acc: 0.515625]: [A loss: 0.761307, acc: 0.191406]\n",
      "2686: [D loss: 0.693865, acc: 0.511719]: [A loss: 0.709134, acc: 0.433594]\n",
      "2687: [D loss: 0.693305, acc: 0.490234]: [A loss: 0.726003, acc: 0.332031]\n",
      "2688: [D loss: 0.695935, acc: 0.501953]: [A loss: 0.732678, acc: 0.296875]\n",
      "2689: [D loss: 0.698466, acc: 0.511719]: [A loss: 0.732756, acc: 0.312500]\n",
      "2690: [D loss: 0.697085, acc: 0.521484]: [A loss: 0.772334, acc: 0.199219]\n",
      "2691: [D loss: 0.700700, acc: 0.458984]: [A loss: 0.679065, acc: 0.566406]\n",
      "2692: [D loss: 0.695893, acc: 0.494141]: [A loss: 0.739186, acc: 0.300781]\n",
      "2693: [D loss: 0.693940, acc: 0.507812]: [A loss: 0.713292, acc: 0.406250]\n",
      "2694: [D loss: 0.699253, acc: 0.490234]: [A loss: 0.706061, acc: 0.402344]\n",
      "2695: [D loss: 0.687512, acc: 0.533203]: [A loss: 0.723988, acc: 0.339844]\n",
      "2696: [D loss: 0.699994, acc: 0.486328]: [A loss: 0.724103, acc: 0.347656]\n",
      "2697: [D loss: 0.702391, acc: 0.482422]: [A loss: 0.702103, acc: 0.449219]\n",
      "2698: [D loss: 0.692614, acc: 0.535156]: [A loss: 0.740768, acc: 0.308594]\n",
      "2699: [D loss: 0.689509, acc: 0.513672]: [A loss: 0.694153, acc: 0.511719]\n",
      "2700: [D loss: 0.697333, acc: 0.511719]: [A loss: 0.738514, acc: 0.300781]\n",
      "2701: [D loss: 0.695842, acc: 0.474609]: [A loss: 0.704789, acc: 0.460938]\n",
      "2702: [D loss: 0.700108, acc: 0.480469]: [A loss: 0.698374, acc: 0.484375]\n",
      "2703: [D loss: 0.707261, acc: 0.447266]: [A loss: 0.765053, acc: 0.171875]\n",
      "2704: [D loss: 0.688372, acc: 0.539062]: [A loss: 0.739228, acc: 0.308594]\n",
      "2705: [D loss: 0.703251, acc: 0.478516]: [A loss: 0.753848, acc: 0.207031]\n",
      "2706: [D loss: 0.697945, acc: 0.482422]: [A loss: 0.714832, acc: 0.386719]\n",
      "2707: [D loss: 0.694445, acc: 0.490234]: [A loss: 0.694828, acc: 0.511719]\n",
      "2708: [D loss: 0.697767, acc: 0.517578]: [A loss: 0.719017, acc: 0.363281]\n",
      "2709: [D loss: 0.696615, acc: 0.486328]: [A loss: 0.717872, acc: 0.378906]\n",
      "2710: [D loss: 0.692529, acc: 0.544922]: [A loss: 0.742348, acc: 0.253906]\n",
      "2711: [D loss: 0.691315, acc: 0.539062]: [A loss: 0.685191, acc: 0.511719]\n",
      "2712: [D loss: 0.689471, acc: 0.539062]: [A loss: 0.746104, acc: 0.257812]\n",
      "2713: [D loss: 0.696179, acc: 0.519531]: [A loss: 0.726633, acc: 0.355469]\n",
      "2714: [D loss: 0.696773, acc: 0.515625]: [A loss: 0.759762, acc: 0.183594]\n",
      "2715: [D loss: 0.696633, acc: 0.482422]: [A loss: 0.699596, acc: 0.457031]\n",
      "2716: [D loss: 0.699763, acc: 0.500000]: [A loss: 0.735497, acc: 0.320312]\n",
      "2717: [D loss: 0.696176, acc: 0.490234]: [A loss: 0.707802, acc: 0.410156]\n",
      "2718: [D loss: 0.694233, acc: 0.525391]: [A loss: 0.734364, acc: 0.308594]\n",
      "2719: [D loss: 0.696985, acc: 0.474609]: [A loss: 0.678504, acc: 0.589844]\n",
      "2720: [D loss: 0.700215, acc: 0.500000]: [A loss: 0.778980, acc: 0.144531]\n",
      "2721: [D loss: 0.693019, acc: 0.550781]: [A loss: 0.695206, acc: 0.492188]\n",
      "2722: [D loss: 0.692941, acc: 0.515625]: [A loss: 0.698446, acc: 0.472656]\n",
      "2723: [D loss: 0.697583, acc: 0.494141]: [A loss: 0.770398, acc: 0.167969]\n",
      "2724: [D loss: 0.694759, acc: 0.509766]: [A loss: 0.685575, acc: 0.542969]\n",
      "2725: [D loss: 0.695574, acc: 0.515625]: [A loss: 0.766285, acc: 0.179688]\n",
      "2726: [D loss: 0.694446, acc: 0.541016]: [A loss: 0.673452, acc: 0.617188]\n",
      "2727: [D loss: 0.700605, acc: 0.501953]: [A loss: 0.743447, acc: 0.242188]\n",
      "2728: [D loss: 0.695975, acc: 0.503906]: [A loss: 0.730074, acc: 0.312500]\n",
      "2729: [D loss: 0.693923, acc: 0.537109]: [A loss: 0.720110, acc: 0.367188]\n",
      "2730: [D loss: 0.705800, acc: 0.482422]: [A loss: 0.749110, acc: 0.230469]\n",
      "2731: [D loss: 0.697186, acc: 0.501953]: [A loss: 0.688653, acc: 0.511719]\n",
      "2732: [D loss: 0.696241, acc: 0.500000]: [A loss: 0.742772, acc: 0.277344]\n",
      "2733: [D loss: 0.700069, acc: 0.486328]: [A loss: 0.712989, acc: 0.429688]\n",
      "2734: [D loss: 0.702056, acc: 0.501953]: [A loss: 0.721172, acc: 0.351562]\n",
      "2735: [D loss: 0.694379, acc: 0.523438]: [A loss: 0.748935, acc: 0.253906]\n",
      "2736: [D loss: 0.696894, acc: 0.505859]: [A loss: 0.711101, acc: 0.398438]\n",
      "2737: [D loss: 0.700006, acc: 0.498047]: [A loss: 0.757196, acc: 0.183594]\n",
      "2738: [D loss: 0.693884, acc: 0.503906]: [A loss: 0.718496, acc: 0.371094]\n",
      "2739: [D loss: 0.695773, acc: 0.531250]: [A loss: 0.706502, acc: 0.453125]\n",
      "2740: [D loss: 0.695414, acc: 0.529297]: [A loss: 0.735851, acc: 0.296875]\n",
      "2741: [D loss: 0.695543, acc: 0.482422]: [A loss: 0.683457, acc: 0.570312]\n",
      "2742: [D loss: 0.691569, acc: 0.515625]: [A loss: 0.784404, acc: 0.132812]\n",
      "2743: [D loss: 0.691722, acc: 0.525391]: [A loss: 0.697801, acc: 0.503906]\n",
      "2744: [D loss: 0.698883, acc: 0.511719]: [A loss: 0.750618, acc: 0.230469]\n",
      "2745: [D loss: 0.693030, acc: 0.513672]: [A loss: 0.692735, acc: 0.500000]\n",
      "2746: [D loss: 0.693255, acc: 0.513672]: [A loss: 0.721938, acc: 0.359375]\n",
      "2747: [D loss: 0.690591, acc: 0.521484]: [A loss: 0.724287, acc: 0.332031]\n",
      "2748: [D loss: 0.693334, acc: 0.525391]: [A loss: 0.757739, acc: 0.199219]\n",
      "2749: [D loss: 0.694910, acc: 0.515625]: [A loss: 0.720186, acc: 0.363281]\n",
      "2750: [D loss: 0.702241, acc: 0.474609]: [A loss: 0.701833, acc: 0.453125]\n",
      "2751: [D loss: 0.697057, acc: 0.498047]: [A loss: 0.724606, acc: 0.300781]\n",
      "2752: [D loss: 0.692790, acc: 0.546875]: [A loss: 0.716138, acc: 0.390625]\n",
      "2753: [D loss: 0.695655, acc: 0.496094]: [A loss: 0.720928, acc: 0.378906]\n",
      "2754: [D loss: 0.703512, acc: 0.486328]: [A loss: 0.723224, acc: 0.343750]\n",
      "2755: [D loss: 0.695448, acc: 0.486328]: [A loss: 0.695449, acc: 0.484375]\n",
      "2756: [D loss: 0.695550, acc: 0.509766]: [A loss: 0.737714, acc: 0.308594]\n",
      "2757: [D loss: 0.697674, acc: 0.478516]: [A loss: 0.723844, acc: 0.375000]\n",
      "2758: [D loss: 0.698918, acc: 0.486328]: [A loss: 0.676561, acc: 0.593750]\n",
      "2759: [D loss: 0.698833, acc: 0.498047]: [A loss: 0.779673, acc: 0.144531]\n",
      "2760: [D loss: 0.698616, acc: 0.490234]: [A loss: 0.695469, acc: 0.492188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2761: [D loss: 0.703449, acc: 0.513672]: [A loss: 0.740314, acc: 0.261719]\n",
      "2762: [D loss: 0.695830, acc: 0.515625]: [A loss: 0.720405, acc: 0.371094]\n",
      "2763: [D loss: 0.696540, acc: 0.503906]: [A loss: 0.692303, acc: 0.507812]\n",
      "2764: [D loss: 0.695752, acc: 0.509766]: [A loss: 0.746969, acc: 0.230469]\n",
      "2765: [D loss: 0.689673, acc: 0.546875]: [A loss: 0.701415, acc: 0.433594]\n",
      "2766: [D loss: 0.702813, acc: 0.503906]: [A loss: 0.749821, acc: 0.230469]\n",
      "2767: [D loss: 0.686667, acc: 0.546875]: [A loss: 0.700955, acc: 0.472656]\n",
      "2768: [D loss: 0.695926, acc: 0.517578]: [A loss: 0.716107, acc: 0.386719]\n",
      "2769: [D loss: 0.688848, acc: 0.533203]: [A loss: 0.705315, acc: 0.406250]\n",
      "2770: [D loss: 0.699219, acc: 0.513672]: [A loss: 0.746566, acc: 0.253906]\n",
      "2771: [D loss: 0.697917, acc: 0.513672]: [A loss: 0.719548, acc: 0.359375]\n",
      "2772: [D loss: 0.699967, acc: 0.494141]: [A loss: 0.726485, acc: 0.289062]\n",
      "2773: [D loss: 0.688185, acc: 0.529297]: [A loss: 0.726828, acc: 0.320312]\n",
      "2774: [D loss: 0.690427, acc: 0.541016]: [A loss: 0.730993, acc: 0.304688]\n",
      "2775: [D loss: 0.699527, acc: 0.509766]: [A loss: 0.723005, acc: 0.359375]\n",
      "2776: [D loss: 0.694063, acc: 0.517578]: [A loss: 0.741410, acc: 0.257812]\n",
      "2777: [D loss: 0.695552, acc: 0.515625]: [A loss: 0.734383, acc: 0.261719]\n",
      "2778: [D loss: 0.696412, acc: 0.503906]: [A loss: 0.729192, acc: 0.312500]\n",
      "2779: [D loss: 0.691624, acc: 0.535156]: [A loss: 0.723581, acc: 0.339844]\n",
      "2780: [D loss: 0.689911, acc: 0.539062]: [A loss: 0.696899, acc: 0.488281]\n",
      "2781: [D loss: 0.696154, acc: 0.505859]: [A loss: 0.745309, acc: 0.296875]\n",
      "2782: [D loss: 0.696897, acc: 0.476562]: [A loss: 0.719235, acc: 0.347656]\n",
      "2783: [D loss: 0.696517, acc: 0.544922]: [A loss: 0.767794, acc: 0.175781]\n",
      "2784: [D loss: 0.691209, acc: 0.527344]: [A loss: 0.683593, acc: 0.535156]\n",
      "2785: [D loss: 0.696499, acc: 0.529297]: [A loss: 0.731905, acc: 0.328125]\n",
      "2786: [D loss: 0.691690, acc: 0.525391]: [A loss: 0.708726, acc: 0.398438]\n",
      "2787: [D loss: 0.698240, acc: 0.496094]: [A loss: 0.710463, acc: 0.402344]\n",
      "2788: [D loss: 0.699184, acc: 0.494141]: [A loss: 0.768342, acc: 0.191406]\n",
      "2789: [D loss: 0.696895, acc: 0.501953]: [A loss: 0.688792, acc: 0.535156]\n",
      "2790: [D loss: 0.702755, acc: 0.498047]: [A loss: 0.753971, acc: 0.230469]\n",
      "2791: [D loss: 0.693785, acc: 0.521484]: [A loss: 0.714392, acc: 0.375000]\n",
      "2792: [D loss: 0.693857, acc: 0.519531]: [A loss: 0.709996, acc: 0.433594]\n",
      "2793: [D loss: 0.693657, acc: 0.519531]: [A loss: 0.754272, acc: 0.167969]\n",
      "2794: [D loss: 0.697481, acc: 0.468750]: [A loss: 0.704286, acc: 0.406250]\n",
      "2795: [D loss: 0.695456, acc: 0.519531]: [A loss: 0.741060, acc: 0.226562]\n",
      "2796: [D loss: 0.694252, acc: 0.496094]: [A loss: 0.660211, acc: 0.714844]\n",
      "2797: [D loss: 0.700439, acc: 0.509766]: [A loss: 0.754856, acc: 0.171875]\n",
      "2798: [D loss: 0.694384, acc: 0.501953]: [A loss: 0.685875, acc: 0.507812]\n",
      "2799: [D loss: 0.697932, acc: 0.494141]: [A loss: 0.712674, acc: 0.402344]\n",
      "2800: [D loss: 0.692155, acc: 0.503906]: [A loss: 0.694168, acc: 0.531250]\n",
      "2801: [D loss: 0.697493, acc: 0.503906]: [A loss: 0.731474, acc: 0.304688]\n",
      "2802: [D loss: 0.689612, acc: 0.515625]: [A loss: 0.725576, acc: 0.312500]\n",
      "2803: [D loss: 0.689876, acc: 0.531250]: [A loss: 0.723445, acc: 0.335938]\n",
      "2804: [D loss: 0.697338, acc: 0.505859]: [A loss: 0.682697, acc: 0.566406]\n",
      "2805: [D loss: 0.694904, acc: 0.507812]: [A loss: 0.732875, acc: 0.269531]\n",
      "2806: [D loss: 0.691518, acc: 0.515625]: [A loss: 0.704410, acc: 0.421875]\n",
      "2807: [D loss: 0.696343, acc: 0.500000]: [A loss: 0.732720, acc: 0.289062]\n",
      "2808: [D loss: 0.696030, acc: 0.498047]: [A loss: 0.688635, acc: 0.550781]\n",
      "2809: [D loss: 0.701167, acc: 0.488281]: [A loss: 0.757588, acc: 0.199219]\n",
      "2810: [D loss: 0.696412, acc: 0.500000]: [A loss: 0.705189, acc: 0.445312]\n",
      "2811: [D loss: 0.694667, acc: 0.517578]: [A loss: 0.740644, acc: 0.253906]\n",
      "2812: [D loss: 0.699238, acc: 0.458984]: [A loss: 0.695500, acc: 0.468750]\n",
      "2813: [D loss: 0.690975, acc: 0.527344]: [A loss: 0.708213, acc: 0.457031]\n",
      "2814: [D loss: 0.695429, acc: 0.496094]: [A loss: 0.715260, acc: 0.375000]\n",
      "2815: [D loss: 0.700078, acc: 0.486328]: [A loss: 0.738105, acc: 0.230469]\n",
      "2816: [D loss: 0.694665, acc: 0.511719]: [A loss: 0.714598, acc: 0.402344]\n",
      "2817: [D loss: 0.692597, acc: 0.523438]: [A loss: 0.736921, acc: 0.242188]\n",
      "2818: [D loss: 0.696119, acc: 0.480469]: [A loss: 0.719396, acc: 0.332031]\n",
      "2819: [D loss: 0.690250, acc: 0.523438]: [A loss: 0.705346, acc: 0.433594]\n",
      "2820: [D loss: 0.697124, acc: 0.492188]: [A loss: 0.700191, acc: 0.464844]\n",
      "2821: [D loss: 0.702308, acc: 0.472656]: [A loss: 0.762233, acc: 0.156250]\n",
      "2822: [D loss: 0.692528, acc: 0.521484]: [A loss: 0.695553, acc: 0.511719]\n",
      "2823: [D loss: 0.690525, acc: 0.564453]: [A loss: 0.706873, acc: 0.414062]\n",
      "2824: [D loss: 0.700532, acc: 0.478516]: [A loss: 0.748251, acc: 0.238281]\n",
      "2825: [D loss: 0.699265, acc: 0.482422]: [A loss: 0.720383, acc: 0.355469]\n",
      "2826: [D loss: 0.688377, acc: 0.527344]: [A loss: 0.717085, acc: 0.398438]\n",
      "2827: [D loss: 0.702706, acc: 0.509766]: [A loss: 0.754630, acc: 0.214844]\n",
      "2828: [D loss: 0.694320, acc: 0.472656]: [A loss: 0.678618, acc: 0.550781]\n",
      "2829: [D loss: 0.704015, acc: 0.496094]: [A loss: 0.764897, acc: 0.136719]\n",
      "2830: [D loss: 0.692097, acc: 0.521484]: [A loss: 0.695049, acc: 0.503906]\n",
      "2831: [D loss: 0.693518, acc: 0.525391]: [A loss: 0.714616, acc: 0.386719]\n",
      "2832: [D loss: 0.695940, acc: 0.505859]: [A loss: 0.716149, acc: 0.394531]\n",
      "2833: [D loss: 0.692482, acc: 0.523438]: [A loss: 0.727764, acc: 0.304688]\n",
      "2834: [D loss: 0.699531, acc: 0.484375]: [A loss: 0.705845, acc: 0.429688]\n",
      "2835: [D loss: 0.694011, acc: 0.523438]: [A loss: 0.728922, acc: 0.332031]\n",
      "2836: [D loss: 0.693678, acc: 0.517578]: [A loss: 0.683769, acc: 0.566406]\n",
      "2837: [D loss: 0.699700, acc: 0.511719]: [A loss: 0.732867, acc: 0.339844]\n",
      "2838: [D loss: 0.700047, acc: 0.466797]: [A loss: 0.745663, acc: 0.214844]\n",
      "2839: [D loss: 0.694583, acc: 0.490234]: [A loss: 0.716216, acc: 0.382812]\n",
      "2840: [D loss: 0.696329, acc: 0.503906]: [A loss: 0.733018, acc: 0.300781]\n",
      "2841: [D loss: 0.696124, acc: 0.525391]: [A loss: 0.731035, acc: 0.277344]\n",
      "2842: [D loss: 0.694506, acc: 0.548828]: [A loss: 0.698111, acc: 0.460938]\n",
      "2843: [D loss: 0.699062, acc: 0.484375]: [A loss: 0.759640, acc: 0.191406]\n",
      "2844: [D loss: 0.698290, acc: 0.484375]: [A loss: 0.662094, acc: 0.679688]\n",
      "2845: [D loss: 0.699256, acc: 0.507812]: [A loss: 0.745546, acc: 0.191406]\n",
      "2846: [D loss: 0.691229, acc: 0.515625]: [A loss: 0.674157, acc: 0.640625]\n",
      "2847: [D loss: 0.700614, acc: 0.500000]: [A loss: 0.759331, acc: 0.199219]\n",
      "2848: [D loss: 0.692450, acc: 0.509766]: [A loss: 0.711695, acc: 0.371094]\n",
      "2849: [D loss: 0.699613, acc: 0.486328]: [A loss: 0.723909, acc: 0.312500]\n",
      "2850: [D loss: 0.692431, acc: 0.539062]: [A loss: 0.720492, acc: 0.320312]\n",
      "2851: [D loss: 0.694493, acc: 0.521484]: [A loss: 0.705038, acc: 0.457031]\n",
      "2852: [D loss: 0.694281, acc: 0.517578]: [A loss: 0.746883, acc: 0.234375]\n",
      "2853: [D loss: 0.690111, acc: 0.521484]: [A loss: 0.691237, acc: 0.515625]\n",
      "2854: [D loss: 0.697992, acc: 0.509766]: [A loss: 0.755695, acc: 0.179688]\n",
      "2855: [D loss: 0.694866, acc: 0.490234]: [A loss: 0.720955, acc: 0.363281]\n",
      "2856: [D loss: 0.699038, acc: 0.501953]: [A loss: 0.702107, acc: 0.433594]\n",
      "2857: [D loss: 0.699090, acc: 0.488281]: [A loss: 0.734533, acc: 0.261719]\n",
      "2858: [D loss: 0.689555, acc: 0.523438]: [A loss: 0.694673, acc: 0.484375]\n",
      "2859: [D loss: 0.692319, acc: 0.519531]: [A loss: 0.751166, acc: 0.187500]\n",
      "2860: [D loss: 0.693589, acc: 0.509766]: [A loss: 0.710547, acc: 0.410156]\n",
      "2861: [D loss: 0.691509, acc: 0.519531]: [A loss: 0.701417, acc: 0.441406]\n",
      "2862: [D loss: 0.696718, acc: 0.494141]: [A loss: 0.756635, acc: 0.175781]\n",
      "2863: [D loss: 0.694524, acc: 0.519531]: [A loss: 0.713637, acc: 0.386719]\n",
      "2864: [D loss: 0.695580, acc: 0.519531]: [A loss: 0.711179, acc: 0.390625]\n",
      "2865: [D loss: 0.695928, acc: 0.515625]: [A loss: 0.702600, acc: 0.445312]\n",
      "2866: [D loss: 0.696253, acc: 0.515625]: [A loss: 0.733372, acc: 0.261719]\n",
      "2867: [D loss: 0.689433, acc: 0.539062]: [A loss: 0.721810, acc: 0.351562]\n",
      "2868: [D loss: 0.688791, acc: 0.548828]: [A loss: 0.716555, acc: 0.394531]\n",
      "2869: [D loss: 0.691085, acc: 0.531250]: [A loss: 0.737894, acc: 0.285156]\n",
      "2870: [D loss: 0.692400, acc: 0.544922]: [A loss: 0.730884, acc: 0.320312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2871: [D loss: 0.694990, acc: 0.505859]: [A loss: 0.684983, acc: 0.593750]\n",
      "2872: [D loss: 0.701524, acc: 0.511719]: [A loss: 0.776925, acc: 0.121094]\n",
      "2873: [D loss: 0.696237, acc: 0.468750]: [A loss: 0.667600, acc: 0.683594]\n",
      "2874: [D loss: 0.697682, acc: 0.501953]: [A loss: 0.754391, acc: 0.199219]\n",
      "2875: [D loss: 0.691271, acc: 0.521484]: [A loss: 0.684812, acc: 0.546875]\n",
      "2876: [D loss: 0.695516, acc: 0.517578]: [A loss: 0.737866, acc: 0.246094]\n",
      "2877: [D loss: 0.689731, acc: 0.539062]: [A loss: 0.702100, acc: 0.468750]\n",
      "2878: [D loss: 0.698839, acc: 0.478516]: [A loss: 0.688850, acc: 0.507812]\n",
      "2879: [D loss: 0.694253, acc: 0.511719]: [A loss: 0.731359, acc: 0.269531]\n",
      "2880: [D loss: 0.692176, acc: 0.544922]: [A loss: 0.732363, acc: 0.261719]\n",
      "2881: [D loss: 0.696439, acc: 0.498047]: [A loss: 0.710243, acc: 0.406250]\n",
      "2882: [D loss: 0.687634, acc: 0.554688]: [A loss: 0.692491, acc: 0.503906]\n",
      "2883: [D loss: 0.696303, acc: 0.501953]: [A loss: 0.744208, acc: 0.214844]\n",
      "2884: [D loss: 0.695764, acc: 0.505859]: [A loss: 0.711448, acc: 0.382812]\n",
      "2885: [D loss: 0.694270, acc: 0.492188]: [A loss: 0.721942, acc: 0.312500]\n",
      "2886: [D loss: 0.690449, acc: 0.550781]: [A loss: 0.711549, acc: 0.390625]\n",
      "2887: [D loss: 0.692539, acc: 0.509766]: [A loss: 0.710489, acc: 0.386719]\n",
      "2888: [D loss: 0.692561, acc: 0.486328]: [A loss: 0.732935, acc: 0.257812]\n",
      "2889: [D loss: 0.693703, acc: 0.501953]: [A loss: 0.695583, acc: 0.476562]\n",
      "2890: [D loss: 0.701852, acc: 0.500000]: [A loss: 0.734559, acc: 0.296875]\n",
      "2891: [D loss: 0.693236, acc: 0.511719]: [A loss: 0.689387, acc: 0.488281]\n",
      "2892: [D loss: 0.696541, acc: 0.523438]: [A loss: 0.728795, acc: 0.292969]\n",
      "2893: [D loss: 0.693554, acc: 0.531250]: [A loss: 0.709879, acc: 0.441406]\n",
      "2894: [D loss: 0.693641, acc: 0.523438]: [A loss: 0.687936, acc: 0.539062]\n",
      "2895: [D loss: 0.695621, acc: 0.531250]: [A loss: 0.713771, acc: 0.371094]\n",
      "2896: [D loss: 0.698171, acc: 0.513672]: [A loss: 0.731191, acc: 0.277344]\n",
      "2897: [D loss: 0.698658, acc: 0.480469]: [A loss: 0.752191, acc: 0.195312]\n",
      "2898: [D loss: 0.699062, acc: 0.496094]: [A loss: 0.683246, acc: 0.574219]\n",
      "2899: [D loss: 0.701570, acc: 0.466797]: [A loss: 0.738585, acc: 0.222656]\n",
      "2900: [D loss: 0.692180, acc: 0.517578]: [A loss: 0.717961, acc: 0.320312]\n",
      "2901: [D loss: 0.700119, acc: 0.472656]: [A loss: 0.699987, acc: 0.445312]\n",
      "2902: [D loss: 0.692973, acc: 0.505859]: [A loss: 0.690070, acc: 0.554688]\n",
      "2903: [D loss: 0.695898, acc: 0.484375]: [A loss: 0.744659, acc: 0.187500]\n",
      "2904: [D loss: 0.694666, acc: 0.527344]: [A loss: 0.716857, acc: 0.355469]\n",
      "2905: [D loss: 0.697002, acc: 0.511719]: [A loss: 0.701577, acc: 0.445312]\n",
      "2906: [D loss: 0.697321, acc: 0.488281]: [A loss: 0.742370, acc: 0.238281]\n",
      "2907: [D loss: 0.694402, acc: 0.511719]: [A loss: 0.720606, acc: 0.324219]\n",
      "2908: [D loss: 0.692210, acc: 0.517578]: [A loss: 0.691498, acc: 0.539062]\n",
      "2909: [D loss: 0.700719, acc: 0.509766]: [A loss: 0.714032, acc: 0.371094]\n",
      "2910: [D loss: 0.692961, acc: 0.517578]: [A loss: 0.719597, acc: 0.328125]\n",
      "2911: [D loss: 0.699904, acc: 0.501953]: [A loss: 0.729150, acc: 0.281250]\n",
      "2912: [D loss: 0.694447, acc: 0.486328]: [A loss: 0.699126, acc: 0.437500]\n",
      "2913: [D loss: 0.693312, acc: 0.517578]: [A loss: 0.726431, acc: 0.257812]\n",
      "2914: [D loss: 0.691026, acc: 0.496094]: [A loss: 0.713381, acc: 0.378906]\n",
      "2915: [D loss: 0.689234, acc: 0.542969]: [A loss: 0.676613, acc: 0.566406]\n",
      "2916: [D loss: 0.697841, acc: 0.507812]: [A loss: 0.766139, acc: 0.136719]\n",
      "2917: [D loss: 0.693021, acc: 0.507812]: [A loss: 0.678933, acc: 0.589844]\n",
      "2918: [D loss: 0.692594, acc: 0.513672]: [A loss: 0.739156, acc: 0.250000]\n",
      "2919: [D loss: 0.688637, acc: 0.546875]: [A loss: 0.698085, acc: 0.472656]\n",
      "2920: [D loss: 0.694654, acc: 0.517578]: [A loss: 0.689090, acc: 0.542969]\n",
      "2921: [D loss: 0.693267, acc: 0.515625]: [A loss: 0.731393, acc: 0.285156]\n",
      "2922: [D loss: 0.688315, acc: 0.531250]: [A loss: 0.696423, acc: 0.492188]\n",
      "2923: [D loss: 0.696000, acc: 0.509766]: [A loss: 0.732996, acc: 0.257812]\n",
      "2924: [D loss: 0.691146, acc: 0.523438]: [A loss: 0.710558, acc: 0.363281]\n",
      "2925: [D loss: 0.696530, acc: 0.509766]: [A loss: 0.739651, acc: 0.210938]\n",
      "2926: [D loss: 0.695401, acc: 0.511719]: [A loss: 0.708963, acc: 0.378906]\n",
      "2927: [D loss: 0.695739, acc: 0.509766]: [A loss: 0.744926, acc: 0.210938]\n",
      "2928: [D loss: 0.692058, acc: 0.521484]: [A loss: 0.726378, acc: 0.304688]\n",
      "2929: [D loss: 0.693188, acc: 0.513672]: [A loss: 0.700098, acc: 0.445312]\n",
      "2930: [D loss: 0.697341, acc: 0.496094]: [A loss: 0.728087, acc: 0.277344]\n",
      "2931: [D loss: 0.692283, acc: 0.527344]: [A loss: 0.717862, acc: 0.343750]\n",
      "2932: [D loss: 0.692763, acc: 0.515625]: [A loss: 0.736315, acc: 0.257812]\n",
      "2933: [D loss: 0.695878, acc: 0.486328]: [A loss: 0.739875, acc: 0.210938]\n",
      "2934: [D loss: 0.691936, acc: 0.531250]: [A loss: 0.695327, acc: 0.468750]\n",
      "2935: [D loss: 0.696381, acc: 0.523438]: [A loss: 0.710338, acc: 0.406250]\n",
      "2936: [D loss: 0.694227, acc: 0.515625]: [A loss: 0.700046, acc: 0.476562]\n",
      "2937: [D loss: 0.695423, acc: 0.519531]: [A loss: 0.732091, acc: 0.285156]\n",
      "2938: [D loss: 0.693249, acc: 0.507812]: [A loss: 0.715767, acc: 0.339844]\n",
      "2939: [D loss: 0.694854, acc: 0.503906]: [A loss: 0.734628, acc: 0.269531]\n",
      "2940: [D loss: 0.693539, acc: 0.488281]: [A loss: 0.752519, acc: 0.152344]\n",
      "2941: [D loss: 0.690123, acc: 0.517578]: [A loss: 0.738192, acc: 0.222656]\n",
      "2942: [D loss: 0.689896, acc: 0.541016]: [A loss: 0.715605, acc: 0.359375]\n",
      "2943: [D loss: 0.694450, acc: 0.515625]: [A loss: 0.702869, acc: 0.441406]\n",
      "2944: [D loss: 0.702981, acc: 0.492188]: [A loss: 0.744323, acc: 0.210938]\n",
      "2945: [D loss: 0.695562, acc: 0.482422]: [A loss: 0.664783, acc: 0.671875]\n",
      "2946: [D loss: 0.697157, acc: 0.521484]: [A loss: 0.755053, acc: 0.148438]\n",
      "2947: [D loss: 0.693550, acc: 0.496094]: [A loss: 0.695650, acc: 0.476562]\n",
      "2948: [D loss: 0.697508, acc: 0.513672]: [A loss: 0.726087, acc: 0.285156]\n",
      "2949: [D loss: 0.695099, acc: 0.490234]: [A loss: 0.732759, acc: 0.199219]\n",
      "2950: [D loss: 0.696922, acc: 0.482422]: [A loss: 0.708317, acc: 0.425781]\n",
      "2951: [D loss: 0.697837, acc: 0.480469]: [A loss: 0.744296, acc: 0.187500]\n",
      "2952: [D loss: 0.694942, acc: 0.490234]: [A loss: 0.688747, acc: 0.503906]\n",
      "2953: [D loss: 0.693816, acc: 0.505859]: [A loss: 0.701708, acc: 0.445312]\n",
      "2954: [D loss: 0.693143, acc: 0.503906]: [A loss: 0.694422, acc: 0.457031]\n",
      "2955: [D loss: 0.694680, acc: 0.505859]: [A loss: 0.725044, acc: 0.308594]\n",
      "2956: [D loss: 0.696100, acc: 0.521484]: [A loss: 0.707529, acc: 0.421875]\n",
      "2957: [D loss: 0.699036, acc: 0.482422]: [A loss: 0.714933, acc: 0.312500]\n",
      "2958: [D loss: 0.692543, acc: 0.539062]: [A loss: 0.686654, acc: 0.539062]\n",
      "2959: [D loss: 0.697166, acc: 0.517578]: [A loss: 0.737228, acc: 0.230469]\n",
      "2960: [D loss: 0.695492, acc: 0.488281]: [A loss: 0.713457, acc: 0.351562]\n",
      "2961: [D loss: 0.697815, acc: 0.490234]: [A loss: 0.743444, acc: 0.230469]\n",
      "2962: [D loss: 0.691165, acc: 0.531250]: [A loss: 0.692206, acc: 0.515625]\n",
      "2963: [D loss: 0.699282, acc: 0.513672]: [A loss: 0.713976, acc: 0.363281]\n",
      "2964: [D loss: 0.692114, acc: 0.509766]: [A loss: 0.691854, acc: 0.507812]\n",
      "2965: [D loss: 0.703382, acc: 0.476562]: [A loss: 0.751534, acc: 0.167969]\n",
      "2966: [D loss: 0.692484, acc: 0.517578]: [A loss: 0.705944, acc: 0.417969]\n",
      "2967: [D loss: 0.692158, acc: 0.517578]: [A loss: 0.739055, acc: 0.191406]\n",
      "2968: [D loss: 0.693913, acc: 0.482422]: [A loss: 0.707291, acc: 0.398438]\n",
      "2969: [D loss: 0.692532, acc: 0.529297]: [A loss: 0.737475, acc: 0.226562]\n",
      "2970: [D loss: 0.694945, acc: 0.507812]: [A loss: 0.676032, acc: 0.609375]\n",
      "2971: [D loss: 0.695686, acc: 0.498047]: [A loss: 0.747975, acc: 0.167969]\n",
      "2972: [D loss: 0.694226, acc: 0.488281]: [A loss: 0.722412, acc: 0.312500]\n",
      "2973: [D loss: 0.697995, acc: 0.513672]: [A loss: 0.726847, acc: 0.292969]\n",
      "2974: [D loss: 0.695569, acc: 0.494141]: [A loss: 0.703983, acc: 0.414062]\n",
      "2975: [D loss: 0.690462, acc: 0.523438]: [A loss: 0.704081, acc: 0.437500]\n",
      "2976: [D loss: 0.693026, acc: 0.503906]: [A loss: 0.698578, acc: 0.484375]\n",
      "2977: [D loss: 0.693294, acc: 0.521484]: [A loss: 0.704914, acc: 0.417969]\n",
      "2978: [D loss: 0.694585, acc: 0.519531]: [A loss: 0.707605, acc: 0.406250]\n",
      "2979: [D loss: 0.693791, acc: 0.501953]: [A loss: 0.709381, acc: 0.359375]\n",
      "2980: [D loss: 0.692461, acc: 0.494141]: [A loss: 0.704295, acc: 0.398438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2981: [D loss: 0.693130, acc: 0.525391]: [A loss: 0.730940, acc: 0.253906]\n",
      "2982: [D loss: 0.691204, acc: 0.521484]: [A loss: 0.693963, acc: 0.468750]\n",
      "2983: [D loss: 0.696721, acc: 0.488281]: [A loss: 0.697192, acc: 0.488281]\n",
      "2984: [D loss: 0.700283, acc: 0.466797]: [A loss: 0.747933, acc: 0.144531]\n",
      "2985: [D loss: 0.691871, acc: 0.527344]: [A loss: 0.699630, acc: 0.445312]\n",
      "2986: [D loss: 0.695198, acc: 0.490234]: [A loss: 0.734182, acc: 0.234375]\n",
      "2987: [D loss: 0.692494, acc: 0.500000]: [A loss: 0.698010, acc: 0.460938]\n",
      "2988: [D loss: 0.691757, acc: 0.511719]: [A loss: 0.697676, acc: 0.468750]\n",
      "2989: [D loss: 0.692529, acc: 0.486328]: [A loss: 0.699925, acc: 0.476562]\n",
      "2990: [D loss: 0.693369, acc: 0.509766]: [A loss: 0.702663, acc: 0.437500]\n",
      "2991: [D loss: 0.699222, acc: 0.505859]: [A loss: 0.737577, acc: 0.218750]\n",
      "2992: [D loss: 0.688927, acc: 0.548828]: [A loss: 0.739493, acc: 0.230469]\n",
      "2993: [D loss: 0.695479, acc: 0.517578]: [A loss: 0.705086, acc: 0.378906]\n",
      "2994: [D loss: 0.695758, acc: 0.535156]: [A loss: 0.742878, acc: 0.246094]\n",
      "2995: [D loss: 0.688908, acc: 0.529297]: [A loss: 0.726023, acc: 0.308594]\n",
      "2996: [D loss: 0.695775, acc: 0.482422]: [A loss: 0.712663, acc: 0.378906]\n",
      "2997: [D loss: 0.695292, acc: 0.498047]: [A loss: 0.738016, acc: 0.214844]\n",
      "2998: [D loss: 0.689088, acc: 0.554688]: [A loss: 0.695747, acc: 0.492188]\n",
      "2999: [D loss: 0.692125, acc: 0.517578]: [A loss: 0.725356, acc: 0.292969]\n",
      "3000: [D loss: 0.690929, acc: 0.507812]: [A loss: 0.702524, acc: 0.394531]\n",
      "3001: [D loss: 0.691653, acc: 0.533203]: [A loss: 0.714587, acc: 0.375000]\n",
      "3002: [D loss: 0.696670, acc: 0.494141]: [A loss: 0.727053, acc: 0.285156]\n",
      "3003: [D loss: 0.693328, acc: 0.492188]: [A loss: 0.675955, acc: 0.593750]\n",
      "3004: [D loss: 0.692248, acc: 0.527344]: [A loss: 0.692219, acc: 0.496094]\n",
      "3005: [D loss: 0.702162, acc: 0.480469]: [A loss: 0.709733, acc: 0.371094]\n",
      "3006: [D loss: 0.693175, acc: 0.488281]: [A loss: 0.723738, acc: 0.300781]\n",
      "3007: [D loss: 0.690695, acc: 0.519531]: [A loss: 0.747038, acc: 0.179688]\n",
      "3008: [D loss: 0.702234, acc: 0.447266]: [A loss: 0.727742, acc: 0.289062]\n",
      "3009: [D loss: 0.693473, acc: 0.503906]: [A loss: 0.739375, acc: 0.214844]\n",
      "3010: [D loss: 0.693727, acc: 0.521484]: [A loss: 0.705348, acc: 0.390625]\n",
      "3011: [D loss: 0.712097, acc: 0.453125]: [A loss: 0.738085, acc: 0.226562]\n",
      "3012: [D loss: 0.690949, acc: 0.539062]: [A loss: 0.683481, acc: 0.562500]\n",
      "3013: [D loss: 0.692185, acc: 0.515625]: [A loss: 0.714359, acc: 0.359375]\n",
      "3014: [D loss: 0.693659, acc: 0.513672]: [A loss: 0.730912, acc: 0.253906]\n",
      "3015: [D loss: 0.698637, acc: 0.468750]: [A loss: 0.686871, acc: 0.500000]\n",
      "3016: [D loss: 0.699221, acc: 0.494141]: [A loss: 0.734154, acc: 0.234375]\n",
      "3017: [D loss: 0.695299, acc: 0.496094]: [A loss: 0.705527, acc: 0.390625]\n",
      "3018: [D loss: 0.693908, acc: 0.509766]: [A loss: 0.685652, acc: 0.535156]\n",
      "3019: [D loss: 0.691312, acc: 0.529297]: [A loss: 0.710190, acc: 0.410156]\n",
      "3020: [D loss: 0.699010, acc: 0.490234]: [A loss: 0.735786, acc: 0.234375]\n",
      "3021: [D loss: 0.694450, acc: 0.529297]: [A loss: 0.715973, acc: 0.332031]\n",
      "3022: [D loss: 0.688310, acc: 0.541016]: [A loss: 0.677640, acc: 0.609375]\n",
      "3023: [D loss: 0.693581, acc: 0.515625]: [A loss: 0.714606, acc: 0.343750]\n",
      "3024: [D loss: 0.694802, acc: 0.486328]: [A loss: 0.698120, acc: 0.464844]\n",
      "3025: [D loss: 0.693638, acc: 0.503906]: [A loss: 0.725182, acc: 0.246094]\n",
      "3026: [D loss: 0.693447, acc: 0.511719]: [A loss: 0.717210, acc: 0.316406]\n",
      "3027: [D loss: 0.697969, acc: 0.482422]: [A loss: 0.722668, acc: 0.332031]\n",
      "3028: [D loss: 0.692213, acc: 0.484375]: [A loss: 0.689740, acc: 0.523438]\n",
      "3029: [D loss: 0.695347, acc: 0.509766]: [A loss: 0.739169, acc: 0.222656]\n",
      "3030: [D loss: 0.695275, acc: 0.488281]: [A loss: 0.681093, acc: 0.554688]\n",
      "3031: [D loss: 0.693823, acc: 0.494141]: [A loss: 0.721686, acc: 0.285156]\n",
      "3032: [D loss: 0.694138, acc: 0.496094]: [A loss: 0.689287, acc: 0.519531]\n",
      "3033: [D loss: 0.697884, acc: 0.509766]: [A loss: 0.724659, acc: 0.257812]\n",
      "3034: [D loss: 0.698997, acc: 0.484375]: [A loss: 0.746238, acc: 0.175781]\n",
      "3035: [D loss: 0.687614, acc: 0.566406]: [A loss: 0.693520, acc: 0.488281]\n",
      "3036: [D loss: 0.701433, acc: 0.472656]: [A loss: 0.706491, acc: 0.386719]\n",
      "3037: [D loss: 0.693730, acc: 0.517578]: [A loss: 0.698052, acc: 0.464844]\n",
      "3038: [D loss: 0.698683, acc: 0.500000]: [A loss: 0.742488, acc: 0.167969]\n",
      "3039: [D loss: 0.691138, acc: 0.539062]: [A loss: 0.737789, acc: 0.226562]\n",
      "3040: [D loss: 0.691142, acc: 0.511719]: [A loss: 0.683148, acc: 0.562500]\n",
      "3041: [D loss: 0.695412, acc: 0.503906]: [A loss: 0.723304, acc: 0.308594]\n",
      "3042: [D loss: 0.698995, acc: 0.474609]: [A loss: 0.686558, acc: 0.566406]\n",
      "3043: [D loss: 0.697356, acc: 0.482422]: [A loss: 0.722274, acc: 0.296875]\n",
      "3044: [D loss: 0.690369, acc: 0.523438]: [A loss: 0.722410, acc: 0.300781]\n",
      "3045: [D loss: 0.691781, acc: 0.523438]: [A loss: 0.688306, acc: 0.562500]\n",
      "3046: [D loss: 0.704019, acc: 0.470703]: [A loss: 0.696361, acc: 0.511719]\n",
      "3047: [D loss: 0.692923, acc: 0.509766]: [A loss: 0.693337, acc: 0.523438]\n",
      "3048: [D loss: 0.692727, acc: 0.521484]: [A loss: 0.687823, acc: 0.539062]\n",
      "3049: [D loss: 0.693894, acc: 0.507812]: [A loss: 0.723113, acc: 0.269531]\n",
      "3050: [D loss: 0.697689, acc: 0.470703]: [A loss: 0.707624, acc: 0.386719]\n",
      "3051: [D loss: 0.695761, acc: 0.503906]: [A loss: 0.740315, acc: 0.203125]\n",
      "3052: [D loss: 0.692771, acc: 0.496094]: [A loss: 0.678283, acc: 0.574219]\n",
      "3053: [D loss: 0.692547, acc: 0.521484]: [A loss: 0.712241, acc: 0.359375]\n",
      "3054: [D loss: 0.687929, acc: 0.537109]: [A loss: 0.700532, acc: 0.480469]\n",
      "3055: [D loss: 0.696228, acc: 0.498047]: [A loss: 0.697712, acc: 0.457031]\n",
      "3056: [D loss: 0.693329, acc: 0.492188]: [A loss: 0.708551, acc: 0.406250]\n",
      "3057: [D loss: 0.689843, acc: 0.513672]: [A loss: 0.711344, acc: 0.406250]\n",
      "3058: [D loss: 0.695928, acc: 0.503906]: [A loss: 0.716915, acc: 0.332031]\n",
      "3059: [D loss: 0.692303, acc: 0.515625]: [A loss: 0.692048, acc: 0.503906]\n",
      "3060: [D loss: 0.694532, acc: 0.505859]: [A loss: 0.734718, acc: 0.210938]\n",
      "3061: [D loss: 0.697039, acc: 0.484375]: [A loss: 0.718113, acc: 0.324219]\n",
      "3062: [D loss: 0.692224, acc: 0.523438]: [A loss: 0.701422, acc: 0.406250]\n",
      "3063: [D loss: 0.697717, acc: 0.529297]: [A loss: 0.741181, acc: 0.179688]\n",
      "3064: [D loss: 0.688278, acc: 0.541016]: [A loss: 0.676017, acc: 0.574219]\n",
      "3065: [D loss: 0.700443, acc: 0.496094]: [A loss: 0.739644, acc: 0.230469]\n",
      "3066: [D loss: 0.694843, acc: 0.509766]: [A loss: 0.663808, acc: 0.687500]\n",
      "3067: [D loss: 0.693360, acc: 0.511719]: [A loss: 0.695448, acc: 0.511719]\n",
      "3068: [D loss: 0.697532, acc: 0.505859]: [A loss: 0.726459, acc: 0.304688]\n",
      "3069: [D loss: 0.694855, acc: 0.488281]: [A loss: 0.720387, acc: 0.324219]\n",
      "3070: [D loss: 0.688314, acc: 0.525391]: [A loss: 0.677087, acc: 0.601562]\n",
      "3071: [D loss: 0.705775, acc: 0.488281]: [A loss: 0.749469, acc: 0.171875]\n",
      "3072: [D loss: 0.692921, acc: 0.523438]: [A loss: 0.694964, acc: 0.496094]\n",
      "3073: [D loss: 0.696730, acc: 0.486328]: [A loss: 0.696924, acc: 0.492188]\n",
      "3074: [D loss: 0.691826, acc: 0.533203]: [A loss: 0.686931, acc: 0.539062]\n",
      "3075: [D loss: 0.700662, acc: 0.486328]: [A loss: 0.708571, acc: 0.378906]\n",
      "3076: [D loss: 0.690837, acc: 0.529297]: [A loss: 0.700300, acc: 0.449219]\n",
      "3077: [D loss: 0.693868, acc: 0.505859]: [A loss: 0.711240, acc: 0.382812]\n",
      "3078: [D loss: 0.698055, acc: 0.503906]: [A loss: 0.740808, acc: 0.203125]\n",
      "3079: [D loss: 0.692460, acc: 0.490234]: [A loss: 0.672992, acc: 0.632812]\n",
      "3080: [D loss: 0.694866, acc: 0.513672]: [A loss: 0.674690, acc: 0.628906]\n",
      "3081: [D loss: 0.698362, acc: 0.523438]: [A loss: 0.706817, acc: 0.398438]\n",
      "3082: [D loss: 0.696624, acc: 0.503906]: [A loss: 0.709465, acc: 0.382812]\n",
      "3083: [D loss: 0.697911, acc: 0.509766]: [A loss: 0.709987, acc: 0.332031]\n",
      "3084: [D loss: 0.695984, acc: 0.492188]: [A loss: 0.700173, acc: 0.457031]\n",
      "3085: [D loss: 0.693867, acc: 0.527344]: [A loss: 0.737301, acc: 0.207031]\n",
      "3086: [D loss: 0.692109, acc: 0.480469]: [A loss: 0.696544, acc: 0.457031]\n",
      "3087: [D loss: 0.691875, acc: 0.529297]: [A loss: 0.723442, acc: 0.289062]\n",
      "3088: [D loss: 0.688093, acc: 0.535156]: [A loss: 0.689985, acc: 0.515625]\n",
      "3089: [D loss: 0.694092, acc: 0.519531]: [A loss: 0.725679, acc: 0.285156]\n",
      "3090: [D loss: 0.687873, acc: 0.568359]: [A loss: 0.661661, acc: 0.667969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3091: [D loss: 0.701929, acc: 0.498047]: [A loss: 0.751308, acc: 0.144531]\n",
      "3092: [D loss: 0.694471, acc: 0.494141]: [A loss: 0.709187, acc: 0.390625]\n",
      "3093: [D loss: 0.693441, acc: 0.505859]: [A loss: 0.725720, acc: 0.296875]\n",
      "3094: [D loss: 0.691527, acc: 0.535156]: [A loss: 0.703080, acc: 0.460938]\n",
      "3095: [D loss: 0.693844, acc: 0.507812]: [A loss: 0.699110, acc: 0.449219]\n",
      "3096: [D loss: 0.694728, acc: 0.527344]: [A loss: 0.709721, acc: 0.382812]\n",
      "3097: [D loss: 0.694597, acc: 0.505859]: [A loss: 0.688172, acc: 0.523438]\n",
      "3098: [D loss: 0.693796, acc: 0.505859]: [A loss: 0.683590, acc: 0.566406]\n",
      "3099: [D loss: 0.691078, acc: 0.529297]: [A loss: 0.676245, acc: 0.617188]\n",
      "3100: [D loss: 0.698478, acc: 0.492188]: [A loss: 0.717452, acc: 0.332031]\n",
      "3101: [D loss: 0.695094, acc: 0.505859]: [A loss: 0.704714, acc: 0.441406]\n",
      "3102: [D loss: 0.695123, acc: 0.492188]: [A loss: 0.712481, acc: 0.371094]\n",
      "3103: [D loss: 0.693626, acc: 0.517578]: [A loss: 0.719762, acc: 0.300781]\n",
      "3104: [D loss: 0.691953, acc: 0.535156]: [A loss: 0.712198, acc: 0.402344]\n",
      "3105: [D loss: 0.693896, acc: 0.503906]: [A loss: 0.712484, acc: 0.378906]\n",
      "3106: [D loss: 0.690731, acc: 0.533203]: [A loss: 0.683086, acc: 0.582031]\n",
      "3107: [D loss: 0.693545, acc: 0.501953]: [A loss: 0.723352, acc: 0.316406]\n",
      "3108: [D loss: 0.692176, acc: 0.503906]: [A loss: 0.698396, acc: 0.453125]\n",
      "3109: [D loss: 0.690835, acc: 0.529297]: [A loss: 0.701109, acc: 0.457031]\n",
      "3110: [D loss: 0.690270, acc: 0.533203]: [A loss: 0.712135, acc: 0.425781]\n",
      "3111: [D loss: 0.692739, acc: 0.513672]: [A loss: 0.705005, acc: 0.433594]\n",
      "3112: [D loss: 0.689618, acc: 0.542969]: [A loss: 0.724890, acc: 0.316406]\n",
      "3113: [D loss: 0.699430, acc: 0.470703]: [A loss: 0.677704, acc: 0.542969]\n",
      "3114: [D loss: 0.701922, acc: 0.490234]: [A loss: 0.763373, acc: 0.117188]\n",
      "3115: [D loss: 0.693292, acc: 0.535156]: [A loss: 0.719708, acc: 0.324219]\n",
      "3116: [D loss: 0.692250, acc: 0.517578]: [A loss: 0.694546, acc: 0.492188]\n",
      "3117: [D loss: 0.699742, acc: 0.498047]: [A loss: 0.709339, acc: 0.382812]\n",
      "3118: [D loss: 0.693795, acc: 0.507812]: [A loss: 0.718791, acc: 0.367188]\n",
      "3119: [D loss: 0.696407, acc: 0.511719]: [A loss: 0.722631, acc: 0.312500]\n",
      "3120: [D loss: 0.690746, acc: 0.535156]: [A loss: 0.700457, acc: 0.457031]\n",
      "3121: [D loss: 0.693463, acc: 0.503906]: [A loss: 0.706518, acc: 0.398438]\n",
      "3122: [D loss: 0.700437, acc: 0.501953]: [A loss: 0.719158, acc: 0.289062]\n",
      "3123: [D loss: 0.693352, acc: 0.537109]: [A loss: 0.720967, acc: 0.320312]\n",
      "3124: [D loss: 0.697322, acc: 0.474609]: [A loss: 0.682157, acc: 0.621094]\n",
      "3125: [D loss: 0.693639, acc: 0.511719]: [A loss: 0.694139, acc: 0.507812]\n",
      "3126: [D loss: 0.692154, acc: 0.535156]: [A loss: 0.681618, acc: 0.574219]\n",
      "3127: [D loss: 0.694025, acc: 0.513672]: [A loss: 0.691330, acc: 0.484375]\n",
      "3128: [D loss: 0.696844, acc: 0.503906]: [A loss: 0.722947, acc: 0.316406]\n",
      "3129: [D loss: 0.694594, acc: 0.476562]: [A loss: 0.736831, acc: 0.207031]\n",
      "3130: [D loss: 0.692550, acc: 0.505859]: [A loss: 0.695575, acc: 0.460938]\n",
      "3131: [D loss: 0.694398, acc: 0.525391]: [A loss: 0.719009, acc: 0.339844]\n",
      "3132: [D loss: 0.695768, acc: 0.472656]: [A loss: 0.715780, acc: 0.347656]\n",
      "3133: [D loss: 0.693581, acc: 0.507812]: [A loss: 0.706766, acc: 0.402344]\n",
      "3134: [D loss: 0.694728, acc: 0.503906]: [A loss: 0.714943, acc: 0.347656]\n",
      "3135: [D loss: 0.693588, acc: 0.521484]: [A loss: 0.700427, acc: 0.441406]\n",
      "3136: [D loss: 0.699852, acc: 0.498047]: [A loss: 0.716923, acc: 0.339844]\n",
      "3137: [D loss: 0.693706, acc: 0.523438]: [A loss: 0.676718, acc: 0.550781]\n",
      "3138: [D loss: 0.696368, acc: 0.509766]: [A loss: 0.752415, acc: 0.175781]\n",
      "3139: [D loss: 0.699634, acc: 0.472656]: [A loss: 0.712942, acc: 0.335938]\n",
      "3140: [D loss: 0.697321, acc: 0.470703]: [A loss: 0.703231, acc: 0.378906]\n",
      "3141: [D loss: 0.697742, acc: 0.509766]: [A loss: 0.722307, acc: 0.296875]\n",
      "3142: [D loss: 0.695363, acc: 0.511719]: [A loss: 0.711203, acc: 0.367188]\n",
      "3143: [D loss: 0.693385, acc: 0.523438]: [A loss: 0.728949, acc: 0.257812]\n",
      "3144: [D loss: 0.689440, acc: 0.521484]: [A loss: 0.719480, acc: 0.320312]\n",
      "3145: [D loss: 0.692174, acc: 0.509766]: [A loss: 0.690510, acc: 0.507812]\n",
      "3146: [D loss: 0.697941, acc: 0.501953]: [A loss: 0.709291, acc: 0.351562]\n",
      "3147: [D loss: 0.692592, acc: 0.535156]: [A loss: 0.705019, acc: 0.414062]\n",
      "3148: [D loss: 0.689718, acc: 0.537109]: [A loss: 0.689026, acc: 0.542969]\n",
      "3149: [D loss: 0.691954, acc: 0.507812]: [A loss: 0.705018, acc: 0.460938]\n",
      "3150: [D loss: 0.698546, acc: 0.472656]: [A loss: 0.694250, acc: 0.492188]\n",
      "3151: [D loss: 0.692690, acc: 0.505859]: [A loss: 0.699263, acc: 0.425781]\n",
      "3152: [D loss: 0.693237, acc: 0.503906]: [A loss: 0.709872, acc: 0.355469]\n",
      "3153: [D loss: 0.696245, acc: 0.498047]: [A loss: 0.718165, acc: 0.289062]\n",
      "3154: [D loss: 0.689352, acc: 0.548828]: [A loss: 0.694050, acc: 0.496094]\n",
      "3155: [D loss: 0.692036, acc: 0.486328]: [A loss: 0.701452, acc: 0.445312]\n",
      "3156: [D loss: 0.693402, acc: 0.509766]: [A loss: 0.715207, acc: 0.359375]\n",
      "3157: [D loss: 0.694176, acc: 0.470703]: [A loss: 0.697556, acc: 0.496094]\n",
      "3158: [D loss: 0.690967, acc: 0.511719]: [A loss: 0.692720, acc: 0.468750]\n",
      "3159: [D loss: 0.699168, acc: 0.515625]: [A loss: 0.745577, acc: 0.156250]\n",
      "3160: [D loss: 0.693190, acc: 0.498047]: [A loss: 0.677809, acc: 0.597656]\n",
      "3161: [D loss: 0.694927, acc: 0.505859]: [A loss: 0.668143, acc: 0.675781]\n",
      "3162: [D loss: 0.701190, acc: 0.511719]: [A loss: 0.714325, acc: 0.351562]\n",
      "3163: [D loss: 0.693918, acc: 0.501953]: [A loss: 0.687916, acc: 0.507812]\n",
      "3164: [D loss: 0.693435, acc: 0.515625]: [A loss: 0.730579, acc: 0.222656]\n",
      "3165: [D loss: 0.692617, acc: 0.511719]: [A loss: 0.714128, acc: 0.324219]\n",
      "3166: [D loss: 0.695655, acc: 0.515625]: [A loss: 0.741494, acc: 0.226562]\n",
      "3167: [D loss: 0.694793, acc: 0.503906]: [A loss: 0.701809, acc: 0.468750]\n",
      "3168: [D loss: 0.692636, acc: 0.521484]: [A loss: 0.694901, acc: 0.519531]\n",
      "3169: [D loss: 0.694865, acc: 0.503906]: [A loss: 0.716174, acc: 0.339844]\n",
      "3170: [D loss: 0.690009, acc: 0.533203]: [A loss: 0.704173, acc: 0.464844]\n",
      "3171: [D loss: 0.692980, acc: 0.505859]: [A loss: 0.688839, acc: 0.468750]\n",
      "3172: [D loss: 0.698644, acc: 0.484375]: [A loss: 0.718161, acc: 0.339844]\n",
      "3173: [D loss: 0.696327, acc: 0.480469]: [A loss: 0.710185, acc: 0.382812]\n",
      "3174: [D loss: 0.697058, acc: 0.482422]: [A loss: 0.695158, acc: 0.496094]\n",
      "3175: [D loss: 0.699770, acc: 0.498047]: [A loss: 0.721181, acc: 0.312500]\n",
      "3176: [D loss: 0.696459, acc: 0.482422]: [A loss: 0.712957, acc: 0.351562]\n",
      "3177: [D loss: 0.692727, acc: 0.541016]: [A loss: 0.690191, acc: 0.515625]\n",
      "3178: [D loss: 0.696097, acc: 0.535156]: [A loss: 0.718777, acc: 0.296875]\n",
      "3179: [D loss: 0.692416, acc: 0.511719]: [A loss: 0.707827, acc: 0.371094]\n",
      "3180: [D loss: 0.699395, acc: 0.496094]: [A loss: 0.728961, acc: 0.277344]\n",
      "3181: [D loss: 0.693302, acc: 0.505859]: [A loss: 0.697931, acc: 0.515625]\n",
      "3182: [D loss: 0.702200, acc: 0.468750]: [A loss: 0.694539, acc: 0.496094]\n",
      "3183: [D loss: 0.693472, acc: 0.494141]: [A loss: 0.722332, acc: 0.312500]\n",
      "3184: [D loss: 0.688895, acc: 0.529297]: [A loss: 0.708814, acc: 0.355469]\n",
      "3185: [D loss: 0.694208, acc: 0.513672]: [A loss: 0.713899, acc: 0.355469]\n",
      "3186: [D loss: 0.695372, acc: 0.535156]: [A loss: 0.718254, acc: 0.285156]\n",
      "3187: [D loss: 0.695764, acc: 0.494141]: [A loss: 0.696428, acc: 0.472656]\n",
      "3188: [D loss: 0.692795, acc: 0.517578]: [A loss: 0.690627, acc: 0.531250]\n",
      "3189: [D loss: 0.695159, acc: 0.490234]: [A loss: 0.710500, acc: 0.375000]\n",
      "3190: [D loss: 0.691426, acc: 0.527344]: [A loss: 0.696429, acc: 0.492188]\n",
      "3191: [D loss: 0.694925, acc: 0.498047]: [A loss: 0.695970, acc: 0.460938]\n",
      "3192: [D loss: 0.695587, acc: 0.498047]: [A loss: 0.712615, acc: 0.382812]\n",
      "3193: [D loss: 0.697242, acc: 0.486328]: [A loss: 0.717909, acc: 0.324219]\n",
      "3194: [D loss: 0.699335, acc: 0.482422]: [A loss: 0.706308, acc: 0.445312]\n",
      "3195: [D loss: 0.696685, acc: 0.482422]: [A loss: 0.712548, acc: 0.332031]\n",
      "3196: [D loss: 0.693600, acc: 0.515625]: [A loss: 0.718477, acc: 0.324219]\n",
      "3197: [D loss: 0.693820, acc: 0.498047]: [A loss: 0.704815, acc: 0.398438]\n",
      "3198: [D loss: 0.692535, acc: 0.517578]: [A loss: 0.691418, acc: 0.492188]\n",
      "3199: [D loss: 0.692844, acc: 0.533203]: [A loss: 0.741048, acc: 0.226562]\n",
      "3200: [D loss: 0.690568, acc: 0.546875]: [A loss: 0.676580, acc: 0.601562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3201: [D loss: 0.698855, acc: 0.490234]: [A loss: 0.718088, acc: 0.328125]\n",
      "3202: [D loss: 0.695561, acc: 0.501953]: [A loss: 0.698332, acc: 0.476562]\n",
      "3203: [D loss: 0.694688, acc: 0.533203]: [A loss: 0.677371, acc: 0.613281]\n",
      "3204: [D loss: 0.697959, acc: 0.500000]: [A loss: 0.705266, acc: 0.402344]\n",
      "3205: [D loss: 0.698298, acc: 0.501953]: [A loss: 0.733467, acc: 0.218750]\n",
      "3206: [D loss: 0.690933, acc: 0.531250]: [A loss: 0.709812, acc: 0.343750]\n",
      "3207: [D loss: 0.691444, acc: 0.521484]: [A loss: 0.721880, acc: 0.312500]\n",
      "3208: [D loss: 0.692743, acc: 0.511719]: [A loss: 0.689634, acc: 0.484375]\n",
      "3209: [D loss: 0.697859, acc: 0.486328]: [A loss: 0.738064, acc: 0.203125]\n",
      "3210: [D loss: 0.691664, acc: 0.498047]: [A loss: 0.691608, acc: 0.496094]\n",
      "3211: [D loss: 0.696775, acc: 0.496094]: [A loss: 0.714978, acc: 0.351562]\n",
      "3212: [D loss: 0.692310, acc: 0.517578]: [A loss: 0.677223, acc: 0.636719]\n",
      "3213: [D loss: 0.692321, acc: 0.501953]: [A loss: 0.682373, acc: 0.582031]\n",
      "3214: [D loss: 0.697200, acc: 0.507812]: [A loss: 0.756158, acc: 0.125000]\n",
      "3215: [D loss: 0.692919, acc: 0.513672]: [A loss: 0.720949, acc: 0.343750]\n",
      "3216: [D loss: 0.689782, acc: 0.539062]: [A loss: 0.691419, acc: 0.488281]\n",
      "3217: [D loss: 0.695105, acc: 0.503906]: [A loss: 0.705279, acc: 0.414062]\n",
      "3218: [D loss: 0.694555, acc: 0.513672]: [A loss: 0.695990, acc: 0.457031]\n",
      "3219: [D loss: 0.697105, acc: 0.482422]: [A loss: 0.719605, acc: 0.328125]\n",
      "3220: [D loss: 0.698171, acc: 0.494141]: [A loss: 0.695614, acc: 0.523438]\n",
      "3221: [D loss: 0.695492, acc: 0.505859]: [A loss: 0.703984, acc: 0.445312]\n",
      "3222: [D loss: 0.696737, acc: 0.513672]: [A loss: 0.700947, acc: 0.417969]\n",
      "3223: [D loss: 0.692399, acc: 0.521484]: [A loss: 0.704595, acc: 0.445312]\n",
      "3224: [D loss: 0.696757, acc: 0.486328]: [A loss: 0.708954, acc: 0.375000]\n",
      "3225: [D loss: 0.696659, acc: 0.500000]: [A loss: 0.703884, acc: 0.410156]\n",
      "3226: [D loss: 0.696544, acc: 0.484375]: [A loss: 0.735904, acc: 0.230469]\n",
      "3227: [D loss: 0.690318, acc: 0.525391]: [A loss: 0.698383, acc: 0.492188]\n",
      "3228: [D loss: 0.697364, acc: 0.503906]: [A loss: 0.687043, acc: 0.597656]\n",
      "3229: [D loss: 0.698578, acc: 0.505859]: [A loss: 0.689465, acc: 0.546875]\n",
      "3230: [D loss: 0.694671, acc: 0.507812]: [A loss: 0.693971, acc: 0.511719]\n",
      "3231: [D loss: 0.696735, acc: 0.501953]: [A loss: 0.709467, acc: 0.351562]\n",
      "3232: [D loss: 0.696247, acc: 0.480469]: [A loss: 0.697341, acc: 0.457031]\n",
      "3233: [D loss: 0.697101, acc: 0.490234]: [A loss: 0.701675, acc: 0.441406]\n",
      "3234: [D loss: 0.699994, acc: 0.476562]: [A loss: 0.710087, acc: 0.332031]\n",
      "3235: [D loss: 0.691987, acc: 0.490234]: [A loss: 0.671055, acc: 0.613281]\n",
      "3236: [D loss: 0.697472, acc: 0.513672]: [A loss: 0.726394, acc: 0.238281]\n",
      "3237: [D loss: 0.693178, acc: 0.517578]: [A loss: 0.693523, acc: 0.492188]\n",
      "3238: [D loss: 0.700214, acc: 0.472656]: [A loss: 0.711951, acc: 0.375000]\n",
      "3239: [D loss: 0.699389, acc: 0.472656]: [A loss: 0.690809, acc: 0.457031]\n",
      "3240: [D loss: 0.698369, acc: 0.507812]: [A loss: 0.713541, acc: 0.339844]\n",
      "3241: [D loss: 0.693566, acc: 0.501953]: [A loss: 0.700846, acc: 0.437500]\n",
      "3242: [D loss: 0.695861, acc: 0.507812]: [A loss: 0.702052, acc: 0.417969]\n",
      "3243: [D loss: 0.694575, acc: 0.515625]: [A loss: 0.703545, acc: 0.410156]\n",
      "3244: [D loss: 0.695230, acc: 0.509766]: [A loss: 0.698812, acc: 0.460938]\n",
      "3245: [D loss: 0.692948, acc: 0.533203]: [A loss: 0.701945, acc: 0.441406]\n",
      "3246: [D loss: 0.695504, acc: 0.513672]: [A loss: 0.696941, acc: 0.500000]\n",
      "3247: [D loss: 0.696058, acc: 0.519531]: [A loss: 0.713674, acc: 0.386719]\n",
      "3248: [D loss: 0.687149, acc: 0.533203]: [A loss: 0.696948, acc: 0.468750]\n",
      "3249: [D loss: 0.690774, acc: 0.519531]: [A loss: 0.701464, acc: 0.441406]\n",
      "3250: [D loss: 0.694877, acc: 0.509766]: [A loss: 0.711279, acc: 0.378906]\n",
      "3251: [D loss: 0.694977, acc: 0.515625]: [A loss: 0.752091, acc: 0.191406]\n",
      "3252: [D loss: 0.698354, acc: 0.492188]: [A loss: 0.707577, acc: 0.382812]\n",
      "3253: [D loss: 0.695138, acc: 0.486328]: [A loss: 0.679934, acc: 0.562500]\n",
      "3254: [D loss: 0.695687, acc: 0.527344]: [A loss: 0.706890, acc: 0.433594]\n",
      "3255: [D loss: 0.697310, acc: 0.521484]: [A loss: 0.688773, acc: 0.566406]\n",
      "3256: [D loss: 0.698548, acc: 0.488281]: [A loss: 0.697725, acc: 0.457031]\n",
      "3257: [D loss: 0.696335, acc: 0.521484]: [A loss: 0.678693, acc: 0.613281]\n",
      "3258: [D loss: 0.694129, acc: 0.537109]: [A loss: 0.688742, acc: 0.503906]\n",
      "3259: [D loss: 0.695044, acc: 0.503906]: [A loss: 0.709885, acc: 0.390625]\n",
      "3260: [D loss: 0.694350, acc: 0.492188]: [A loss: 0.698320, acc: 0.453125]\n",
      "3261: [D loss: 0.697420, acc: 0.498047]: [A loss: 0.716196, acc: 0.292969]\n",
      "3262: [D loss: 0.689606, acc: 0.521484]: [A loss: 0.704133, acc: 0.398438]\n",
      "3263: [D loss: 0.689954, acc: 0.511719]: [A loss: 0.708497, acc: 0.382812]\n",
      "3264: [D loss: 0.692976, acc: 0.523438]: [A loss: 0.712438, acc: 0.351562]\n",
      "3265: [D loss: 0.695933, acc: 0.490234]: [A loss: 0.727595, acc: 0.253906]\n",
      "3266: [D loss: 0.691853, acc: 0.539062]: [A loss: 0.690701, acc: 0.503906]\n",
      "3267: [D loss: 0.695059, acc: 0.505859]: [A loss: 0.700756, acc: 0.460938]\n",
      "3268: [D loss: 0.698406, acc: 0.480469]: [A loss: 0.708361, acc: 0.386719]\n",
      "3269: [D loss: 0.693099, acc: 0.550781]: [A loss: 0.678234, acc: 0.593750]\n",
      "3270: [D loss: 0.699735, acc: 0.498047]: [A loss: 0.709890, acc: 0.347656]\n",
      "3271: [D loss: 0.698286, acc: 0.507812]: [A loss: 0.730916, acc: 0.214844]\n",
      "3272: [D loss: 0.696394, acc: 0.505859]: [A loss: 0.715736, acc: 0.324219]\n",
      "3273: [D loss: 0.697190, acc: 0.478516]: [A loss: 0.672359, acc: 0.605469]\n",
      "3274: [D loss: 0.701579, acc: 0.507812]: [A loss: 0.741731, acc: 0.210938]\n",
      "3275: [D loss: 0.694200, acc: 0.513672]: [A loss: 0.701395, acc: 0.386719]\n",
      "3276: [D loss: 0.694010, acc: 0.505859]: [A loss: 0.700693, acc: 0.457031]\n",
      "3277: [D loss: 0.693050, acc: 0.529297]: [A loss: 0.697347, acc: 0.445312]\n",
      "3278: [D loss: 0.699008, acc: 0.466797]: [A loss: 0.700147, acc: 0.441406]\n",
      "3279: [D loss: 0.693046, acc: 0.505859]: [A loss: 0.696566, acc: 0.480469]\n",
      "3280: [D loss: 0.691404, acc: 0.523438]: [A loss: 0.680314, acc: 0.566406]\n",
      "3281: [D loss: 0.698036, acc: 0.494141]: [A loss: 0.742021, acc: 0.199219]\n",
      "3282: [D loss: 0.695044, acc: 0.486328]: [A loss: 0.692468, acc: 0.511719]\n",
      "3283: [D loss: 0.695473, acc: 0.517578]: [A loss: 0.697490, acc: 0.441406]\n",
      "3284: [D loss: 0.692758, acc: 0.515625]: [A loss: 0.683957, acc: 0.566406]\n",
      "3285: [D loss: 0.696712, acc: 0.501953]: [A loss: 0.702256, acc: 0.417969]\n",
      "3286: [D loss: 0.690577, acc: 0.542969]: [A loss: 0.676951, acc: 0.589844]\n",
      "3287: [D loss: 0.696226, acc: 0.496094]: [A loss: 0.727922, acc: 0.261719]\n",
      "3288: [D loss: 0.693490, acc: 0.505859]: [A loss: 0.711500, acc: 0.347656]\n",
      "3289: [D loss: 0.691123, acc: 0.529297]: [A loss: 0.678057, acc: 0.589844]\n",
      "3290: [D loss: 0.694170, acc: 0.507812]: [A loss: 0.690165, acc: 0.519531]\n",
      "3291: [D loss: 0.696453, acc: 0.505859]: [A loss: 0.697803, acc: 0.472656]\n",
      "3292: [D loss: 0.697870, acc: 0.521484]: [A loss: 0.706559, acc: 0.425781]\n",
      "3293: [D loss: 0.702135, acc: 0.449219]: [A loss: 0.716318, acc: 0.289062]\n",
      "3294: [D loss: 0.696726, acc: 0.501953]: [A loss: 0.692734, acc: 0.488281]\n",
      "3295: [D loss: 0.697075, acc: 0.468750]: [A loss: 0.699613, acc: 0.433594]\n",
      "3296: [D loss: 0.696317, acc: 0.527344]: [A loss: 0.728161, acc: 0.250000]\n",
      "3297: [D loss: 0.690342, acc: 0.560547]: [A loss: 0.682476, acc: 0.578125]\n",
      "3298: [D loss: 0.695123, acc: 0.500000]: [A loss: 0.724399, acc: 0.304688]\n",
      "3299: [D loss: 0.695200, acc: 0.486328]: [A loss: 0.693036, acc: 0.511719]\n",
      "3300: [D loss: 0.690047, acc: 0.513672]: [A loss: 0.698086, acc: 0.437500]\n",
      "3301: [D loss: 0.692746, acc: 0.492188]: [A loss: 0.695867, acc: 0.468750]\n",
      "3302: [D loss: 0.696950, acc: 0.507812]: [A loss: 0.706852, acc: 0.402344]\n",
      "3303: [D loss: 0.694751, acc: 0.505859]: [A loss: 0.695526, acc: 0.460938]\n",
      "3304: [D loss: 0.698238, acc: 0.498047]: [A loss: 0.713544, acc: 0.312500]\n",
      "3305: [D loss: 0.692258, acc: 0.515625]: [A loss: 0.701108, acc: 0.437500]\n",
      "3306: [D loss: 0.689914, acc: 0.537109]: [A loss: 0.722630, acc: 0.328125]\n",
      "3307: [D loss: 0.691246, acc: 0.523438]: [A loss: 0.709102, acc: 0.394531]\n",
      "3308: [D loss: 0.695338, acc: 0.486328]: [A loss: 0.700320, acc: 0.457031]\n",
      "3309: [D loss: 0.693593, acc: 0.517578]: [A loss: 0.701259, acc: 0.425781]\n",
      "3310: [D loss: 0.697948, acc: 0.472656]: [A loss: 0.692225, acc: 0.492188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3311: [D loss: 0.700647, acc: 0.509766]: [A loss: 0.714516, acc: 0.363281]\n",
      "3312: [D loss: 0.695491, acc: 0.511719]: [A loss: 0.706155, acc: 0.386719]\n",
      "3313: [D loss: 0.694767, acc: 0.511719]: [A loss: 0.749965, acc: 0.148438]\n",
      "3314: [D loss: 0.692781, acc: 0.498047]: [A loss: 0.689902, acc: 0.484375]\n",
      "3315: [D loss: 0.694606, acc: 0.509766]: [A loss: 0.693304, acc: 0.492188]\n",
      "3316: [D loss: 0.693722, acc: 0.515625]: [A loss: 0.708466, acc: 0.390625]\n",
      "3317: [D loss: 0.699213, acc: 0.505859]: [A loss: 0.718919, acc: 0.339844]\n",
      "3318: [D loss: 0.693591, acc: 0.515625]: [A loss: 0.701909, acc: 0.429688]\n",
      "3319: [D loss: 0.694394, acc: 0.509766]: [A loss: 0.710269, acc: 0.351562]\n",
      "3320: [D loss: 0.695159, acc: 0.498047]: [A loss: 0.672786, acc: 0.613281]\n",
      "3321: [D loss: 0.697434, acc: 0.500000]: [A loss: 0.741718, acc: 0.187500]\n",
      "3322: [D loss: 0.698213, acc: 0.494141]: [A loss: 0.699989, acc: 0.441406]\n",
      "3323: [D loss: 0.695014, acc: 0.511719]: [A loss: 0.703346, acc: 0.410156]\n",
      "3324: [D loss: 0.689935, acc: 0.541016]: [A loss: 0.695959, acc: 0.476562]\n",
      "3325: [D loss: 0.690785, acc: 0.541016]: [A loss: 0.699555, acc: 0.488281]\n",
      "3326: [D loss: 0.696221, acc: 0.492188]: [A loss: 0.703774, acc: 0.394531]\n",
      "3327: [D loss: 0.698022, acc: 0.494141]: [A loss: 0.733550, acc: 0.238281]\n",
      "3328: [D loss: 0.688374, acc: 0.541016]: [A loss: 0.676921, acc: 0.593750]\n",
      "3329: [D loss: 0.700403, acc: 0.480469]: [A loss: 0.714608, acc: 0.343750]\n",
      "3330: [D loss: 0.696130, acc: 0.482422]: [A loss: 0.723024, acc: 0.304688]\n",
      "3331: [D loss: 0.694383, acc: 0.490234]: [A loss: 0.716795, acc: 0.359375]\n",
      "3332: [D loss: 0.693325, acc: 0.529297]: [A loss: 0.681315, acc: 0.601562]\n",
      "3333: [D loss: 0.694523, acc: 0.505859]: [A loss: 0.721707, acc: 0.316406]\n",
      "3334: [D loss: 0.693947, acc: 0.511719]: [A loss: 0.696673, acc: 0.429688]\n",
      "3335: [D loss: 0.693732, acc: 0.541016]: [A loss: 0.710566, acc: 0.390625]\n",
      "3336: [D loss: 0.692966, acc: 0.517578]: [A loss: 0.694415, acc: 0.476562]\n",
      "3337: [D loss: 0.698527, acc: 0.488281]: [A loss: 0.728402, acc: 0.292969]\n",
      "3338: [D loss: 0.696482, acc: 0.517578]: [A loss: 0.712965, acc: 0.371094]\n",
      "3339: [D loss: 0.697567, acc: 0.498047]: [A loss: 0.714943, acc: 0.332031]\n",
      "3340: [D loss: 0.697513, acc: 0.501953]: [A loss: 0.721385, acc: 0.304688]\n",
      "3341: [D loss: 0.697627, acc: 0.470703]: [A loss: 0.676716, acc: 0.609375]\n",
      "3342: [D loss: 0.696559, acc: 0.496094]: [A loss: 0.719758, acc: 0.316406]\n",
      "3343: [D loss: 0.696344, acc: 0.486328]: [A loss: 0.707622, acc: 0.437500]\n",
      "3344: [D loss: 0.696049, acc: 0.513672]: [A loss: 0.709372, acc: 0.371094]\n",
      "3345: [D loss: 0.696797, acc: 0.500000]: [A loss: 0.705040, acc: 0.410156]\n",
      "3346: [D loss: 0.695166, acc: 0.507812]: [A loss: 0.731243, acc: 0.218750]\n",
      "3347: [D loss: 0.690300, acc: 0.529297]: [A loss: 0.701824, acc: 0.437500]\n",
      "3348: [D loss: 0.695431, acc: 0.500000]: [A loss: 0.720737, acc: 0.289062]\n",
      "3349: [D loss: 0.691364, acc: 0.525391]: [A loss: 0.692653, acc: 0.496094]\n",
      "3350: [D loss: 0.694197, acc: 0.501953]: [A loss: 0.716808, acc: 0.324219]\n",
      "3351: [D loss: 0.694974, acc: 0.490234]: [A loss: 0.716827, acc: 0.324219]\n",
      "3352: [D loss: 0.692141, acc: 0.500000]: [A loss: 0.676937, acc: 0.582031]\n",
      "3353: [D loss: 0.701062, acc: 0.509766]: [A loss: 0.732657, acc: 0.246094]\n",
      "3354: [D loss: 0.696436, acc: 0.509766]: [A loss: 0.710480, acc: 0.402344]\n",
      "3355: [D loss: 0.695929, acc: 0.501953]: [A loss: 0.726941, acc: 0.265625]\n",
      "3356: [D loss: 0.689405, acc: 0.554688]: [A loss: 0.693888, acc: 0.464844]\n",
      "3357: [D loss: 0.697055, acc: 0.482422]: [A loss: 0.726199, acc: 0.289062]\n",
      "3358: [D loss: 0.693706, acc: 0.500000]: [A loss: 0.696423, acc: 0.437500]\n",
      "3359: [D loss: 0.692681, acc: 0.539062]: [A loss: 0.698932, acc: 0.468750]\n",
      "3360: [D loss: 0.695391, acc: 0.527344]: [A loss: 0.707539, acc: 0.394531]\n",
      "3361: [D loss: 0.697134, acc: 0.498047]: [A loss: 0.702210, acc: 0.406250]\n",
      "3362: [D loss: 0.694938, acc: 0.494141]: [A loss: 0.671052, acc: 0.664062]\n",
      "3363: [D loss: 0.698889, acc: 0.509766]: [A loss: 0.712289, acc: 0.367188]\n",
      "3364: [D loss: 0.694176, acc: 0.515625]: [A loss: 0.699355, acc: 0.464844]\n",
      "3365: [D loss: 0.699856, acc: 0.484375]: [A loss: 0.710184, acc: 0.363281]\n",
      "3366: [D loss: 0.697209, acc: 0.517578]: [A loss: 0.706454, acc: 0.347656]\n",
      "3367: [D loss: 0.693699, acc: 0.517578]: [A loss: 0.684760, acc: 0.550781]\n",
      "3368: [D loss: 0.695429, acc: 0.507812]: [A loss: 0.709144, acc: 0.382812]\n",
      "3369: [D loss: 0.693474, acc: 0.535156]: [A loss: 0.700904, acc: 0.421875]\n",
      "3370: [D loss: 0.693950, acc: 0.525391]: [A loss: 0.699840, acc: 0.453125]\n",
      "3371: [D loss: 0.694449, acc: 0.494141]: [A loss: 0.675268, acc: 0.625000]\n",
      "3372: [D loss: 0.695129, acc: 0.537109]: [A loss: 0.720324, acc: 0.300781]\n",
      "3373: [D loss: 0.692833, acc: 0.535156]: [A loss: 0.709012, acc: 0.406250]\n",
      "3374: [D loss: 0.693822, acc: 0.500000]: [A loss: 0.702978, acc: 0.406250]\n",
      "3375: [D loss: 0.692284, acc: 0.535156]: [A loss: 0.696149, acc: 0.453125]\n",
      "3376: [D loss: 0.697571, acc: 0.517578]: [A loss: 0.730810, acc: 0.242188]\n",
      "3377: [D loss: 0.693767, acc: 0.523438]: [A loss: 0.720011, acc: 0.312500]\n",
      "3378: [D loss: 0.695644, acc: 0.517578]: [A loss: 0.710733, acc: 0.339844]\n",
      "3379: [D loss: 0.692756, acc: 0.509766]: [A loss: 0.689438, acc: 0.515625]\n",
      "3380: [D loss: 0.695032, acc: 0.501953]: [A loss: 0.705258, acc: 0.402344]\n",
      "3381: [D loss: 0.692804, acc: 0.529297]: [A loss: 0.695346, acc: 0.464844]\n",
      "3382: [D loss: 0.695877, acc: 0.496094]: [A loss: 0.695531, acc: 0.500000]\n",
      "3383: [D loss: 0.693510, acc: 0.517578]: [A loss: 0.697581, acc: 0.476562]\n",
      "3384: [D loss: 0.695202, acc: 0.501953]: [A loss: 0.715849, acc: 0.359375]\n",
      "3385: [D loss: 0.694153, acc: 0.488281]: [A loss: 0.703585, acc: 0.410156]\n",
      "3386: [D loss: 0.694167, acc: 0.515625]: [A loss: 0.718346, acc: 0.304688]\n",
      "3387: [D loss: 0.693654, acc: 0.501953]: [A loss: 0.720206, acc: 0.320312]\n",
      "3388: [D loss: 0.694832, acc: 0.498047]: [A loss: 0.690934, acc: 0.523438]\n",
      "3389: [D loss: 0.696355, acc: 0.500000]: [A loss: 0.699468, acc: 0.449219]\n",
      "3390: [D loss: 0.696717, acc: 0.486328]: [A loss: 0.739216, acc: 0.222656]\n",
      "3391: [D loss: 0.699924, acc: 0.439453]: [A loss: 0.717189, acc: 0.339844]\n",
      "3392: [D loss: 0.693453, acc: 0.511719]: [A loss: 0.713145, acc: 0.382812]\n",
      "3393: [D loss: 0.695091, acc: 0.513672]: [A loss: 0.701384, acc: 0.445312]\n",
      "3394: [D loss: 0.689672, acc: 0.517578]: [A loss: 0.711347, acc: 0.363281]\n",
      "3395: [D loss: 0.696697, acc: 0.472656]: [A loss: 0.692101, acc: 0.488281]\n",
      "3396: [D loss: 0.694554, acc: 0.521484]: [A loss: 0.706572, acc: 0.402344]\n",
      "3397: [D loss: 0.694326, acc: 0.511719]: [A loss: 0.700910, acc: 0.441406]\n",
      "3398: [D loss: 0.692976, acc: 0.521484]: [A loss: 0.693776, acc: 0.476562]\n",
      "3399: [D loss: 0.692337, acc: 0.505859]: [A loss: 0.683785, acc: 0.542969]\n",
      "3400: [D loss: 0.693263, acc: 0.519531]: [A loss: 0.717834, acc: 0.328125]\n",
      "3401: [D loss: 0.688138, acc: 0.515625]: [A loss: 0.681082, acc: 0.574219]\n",
      "3402: [D loss: 0.699177, acc: 0.496094]: [A loss: 0.706881, acc: 0.382812]\n",
      "3403: [D loss: 0.694708, acc: 0.494141]: [A loss: 0.695499, acc: 0.464844]\n",
      "3404: [D loss: 0.698148, acc: 0.484375]: [A loss: 0.704774, acc: 0.402344]\n",
      "3405: [D loss: 0.691195, acc: 0.519531]: [A loss: 0.706225, acc: 0.378906]\n",
      "3406: [D loss: 0.696417, acc: 0.498047]: [A loss: 0.740835, acc: 0.164062]\n",
      "3407: [D loss: 0.689372, acc: 0.550781]: [A loss: 0.698790, acc: 0.445312]\n",
      "3408: [D loss: 0.692335, acc: 0.515625]: [A loss: 0.684501, acc: 0.558594]\n",
      "3409: [D loss: 0.693704, acc: 0.517578]: [A loss: 0.687380, acc: 0.531250]\n",
      "3410: [D loss: 0.701357, acc: 0.500000]: [A loss: 0.729848, acc: 0.238281]\n",
      "3411: [D loss: 0.693139, acc: 0.511719]: [A loss: 0.712859, acc: 0.351562]\n",
      "3412: [D loss: 0.702645, acc: 0.457031]: [A loss: 0.723228, acc: 0.269531]\n",
      "3413: [D loss: 0.695959, acc: 0.501953]: [A loss: 0.697388, acc: 0.441406]\n",
      "3414: [D loss: 0.692552, acc: 0.517578]: [A loss: 0.705335, acc: 0.402344]\n",
      "3415: [D loss: 0.690943, acc: 0.539062]: [A loss: 0.685404, acc: 0.531250]\n",
      "3416: [D loss: 0.699215, acc: 0.527344]: [A loss: 0.710327, acc: 0.355469]\n",
      "3417: [D loss: 0.689348, acc: 0.531250]: [A loss: 0.673992, acc: 0.628906]\n",
      "3418: [D loss: 0.698307, acc: 0.501953]: [A loss: 0.728011, acc: 0.230469]\n",
      "3419: [D loss: 0.698758, acc: 0.486328]: [A loss: 0.714383, acc: 0.320312]\n",
      "3420: [D loss: 0.690655, acc: 0.496094]: [A loss: 0.713222, acc: 0.328125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3421: [D loss: 0.699045, acc: 0.494141]: [A loss: 0.728030, acc: 0.234375]\n",
      "3422: [D loss: 0.693307, acc: 0.535156]: [A loss: 0.707615, acc: 0.371094]\n",
      "3423: [D loss: 0.693116, acc: 0.496094]: [A loss: 0.700117, acc: 0.453125]\n",
      "3424: [D loss: 0.693665, acc: 0.523438]: [A loss: 0.728656, acc: 0.218750]\n",
      "3425: [D loss: 0.690304, acc: 0.533203]: [A loss: 0.689998, acc: 0.531250]\n",
      "3426: [D loss: 0.694264, acc: 0.521484]: [A loss: 0.694677, acc: 0.476562]\n",
      "3427: [D loss: 0.697783, acc: 0.496094]: [A loss: 0.742320, acc: 0.191406]\n",
      "3428: [D loss: 0.694602, acc: 0.500000]: [A loss: 0.714449, acc: 0.371094]\n",
      "3429: [D loss: 0.693925, acc: 0.501953]: [A loss: 0.724367, acc: 0.250000]\n",
      "3430: [D loss: 0.695144, acc: 0.525391]: [A loss: 0.705426, acc: 0.402344]\n",
      "3431: [D loss: 0.689240, acc: 0.548828]: [A loss: 0.701122, acc: 0.449219]\n",
      "3432: [D loss: 0.697911, acc: 0.490234]: [A loss: 0.700544, acc: 0.445312]\n",
      "3433: [D loss: 0.693902, acc: 0.496094]: [A loss: 0.699151, acc: 0.449219]\n",
      "3434: [D loss: 0.695648, acc: 0.501953]: [A loss: 0.706469, acc: 0.406250]\n",
      "3435: [D loss: 0.692235, acc: 0.525391]: [A loss: 0.718581, acc: 0.285156]\n",
      "3436: [D loss: 0.692813, acc: 0.480469]: [A loss: 0.722587, acc: 0.253906]\n",
      "3437: [D loss: 0.693946, acc: 0.541016]: [A loss: 0.685506, acc: 0.531250]\n",
      "3438: [D loss: 0.700070, acc: 0.500000]: [A loss: 0.724317, acc: 0.281250]\n",
      "3439: [D loss: 0.694612, acc: 0.523438]: [A loss: 0.711601, acc: 0.355469]\n",
      "3440: [D loss: 0.694299, acc: 0.515625]: [A loss: 0.695824, acc: 0.476562]\n",
      "3441: [D loss: 0.699204, acc: 0.476562]: [A loss: 0.730390, acc: 0.234375]\n",
      "3442: [D loss: 0.694519, acc: 0.511719]: [A loss: 0.707091, acc: 0.359375]\n",
      "3443: [D loss: 0.697310, acc: 0.466797]: [A loss: 0.735063, acc: 0.171875]\n",
      "3444: [D loss: 0.688746, acc: 0.519531]: [A loss: 0.691191, acc: 0.488281]\n",
      "3445: [D loss: 0.695349, acc: 0.505859]: [A loss: 0.723188, acc: 0.304688]\n",
      "3446: [D loss: 0.692138, acc: 0.529297]: [A loss: 0.702101, acc: 0.410156]\n",
      "3447: [D loss: 0.694191, acc: 0.490234]: [A loss: 0.713014, acc: 0.347656]\n",
      "3448: [D loss: 0.691281, acc: 0.529297]: [A loss: 0.705887, acc: 0.371094]\n",
      "3449: [D loss: 0.694283, acc: 0.500000]: [A loss: 0.709214, acc: 0.378906]\n",
      "3450: [D loss: 0.694517, acc: 0.496094]: [A loss: 0.681722, acc: 0.550781]\n",
      "3451: [D loss: 0.694805, acc: 0.529297]: [A loss: 0.701865, acc: 0.441406]\n",
      "3452: [D loss: 0.697532, acc: 0.490234]: [A loss: 0.696090, acc: 0.496094]\n",
      "3453: [D loss: 0.692488, acc: 0.541016]: [A loss: 0.719390, acc: 0.300781]\n",
      "3454: [D loss: 0.691731, acc: 0.523438]: [A loss: 0.690743, acc: 0.523438]\n",
      "3455: [D loss: 0.696535, acc: 0.478516]: [A loss: 0.726954, acc: 0.285156]\n",
      "3456: [D loss: 0.695831, acc: 0.523438]: [A loss: 0.719154, acc: 0.296875]\n",
      "3457: [D loss: 0.693564, acc: 0.490234]: [A loss: 0.687292, acc: 0.550781]\n",
      "3458: [D loss: 0.691661, acc: 0.542969]: [A loss: 0.711150, acc: 0.355469]\n",
      "3459: [D loss: 0.696114, acc: 0.517578]: [A loss: 0.694825, acc: 0.480469]\n",
      "3460: [D loss: 0.693469, acc: 0.519531]: [A loss: 0.727769, acc: 0.253906]\n",
      "3461: [D loss: 0.691257, acc: 0.541016]: [A loss: 0.673720, acc: 0.609375]\n",
      "3462: [D loss: 0.693611, acc: 0.505859]: [A loss: 0.724496, acc: 0.250000]\n",
      "3463: [D loss: 0.689752, acc: 0.523438]: [A loss: 0.696823, acc: 0.480469]\n",
      "3464: [D loss: 0.698720, acc: 0.507812]: [A loss: 0.725949, acc: 0.257812]\n",
      "3465: [D loss: 0.693964, acc: 0.500000]: [A loss: 0.700588, acc: 0.453125]\n",
      "3466: [D loss: 0.694943, acc: 0.486328]: [A loss: 0.702507, acc: 0.453125]\n",
      "3467: [D loss: 0.696250, acc: 0.482422]: [A loss: 0.711407, acc: 0.328125]\n",
      "3468: [D loss: 0.697977, acc: 0.472656]: [A loss: 0.726021, acc: 0.230469]\n",
      "3469: [D loss: 0.691878, acc: 0.519531]: [A loss: 0.684343, acc: 0.542969]\n",
      "3470: [D loss: 0.699663, acc: 0.513672]: [A loss: 0.734470, acc: 0.230469]\n",
      "3471: [D loss: 0.695154, acc: 0.523438]: [A loss: 0.710581, acc: 0.371094]\n",
      "3472: [D loss: 0.689680, acc: 0.558594]: [A loss: 0.680595, acc: 0.593750]\n",
      "3473: [D loss: 0.692787, acc: 0.501953]: [A loss: 0.698766, acc: 0.488281]\n",
      "3474: [D loss: 0.696320, acc: 0.501953]: [A loss: 0.717842, acc: 0.296875]\n",
      "3475: [D loss: 0.699424, acc: 0.498047]: [A loss: 0.725838, acc: 0.292969]\n",
      "3476: [D loss: 0.695124, acc: 0.501953]: [A loss: 0.711066, acc: 0.382812]\n",
      "3477: [D loss: 0.695917, acc: 0.496094]: [A loss: 0.721679, acc: 0.269531]\n",
      "3478: [D loss: 0.693408, acc: 0.480469]: [A loss: 0.715368, acc: 0.312500]\n",
      "3479: [D loss: 0.696698, acc: 0.529297]: [A loss: 0.712624, acc: 0.367188]\n",
      "3480: [D loss: 0.695018, acc: 0.492188]: [A loss: 0.694148, acc: 0.492188]\n",
      "3481: [D loss: 0.692320, acc: 0.533203]: [A loss: 0.697685, acc: 0.457031]\n",
      "3482: [D loss: 0.696694, acc: 0.521484]: [A loss: 0.698711, acc: 0.425781]\n",
      "3483: [D loss: 0.691510, acc: 0.527344]: [A loss: 0.677198, acc: 0.597656]\n",
      "3484: [D loss: 0.705218, acc: 0.511719]: [A loss: 0.749913, acc: 0.160156]\n",
      "3485: [D loss: 0.695889, acc: 0.507812]: [A loss: 0.710252, acc: 0.402344]\n",
      "3486: [D loss: 0.698192, acc: 0.466797]: [A loss: 0.704108, acc: 0.421875]\n",
      "3487: [D loss: 0.693789, acc: 0.509766]: [A loss: 0.680098, acc: 0.605469]\n",
      "3488: [D loss: 0.693447, acc: 0.521484]: [A loss: 0.711216, acc: 0.347656]\n",
      "3489: [D loss: 0.691698, acc: 0.521484]: [A loss: 0.671213, acc: 0.609375]\n",
      "3490: [D loss: 0.701449, acc: 0.496094]: [A loss: 0.735159, acc: 0.191406]\n",
      "3491: [D loss: 0.692933, acc: 0.533203]: [A loss: 0.699324, acc: 0.472656]\n",
      "3492: [D loss: 0.697570, acc: 0.507812]: [A loss: 0.686019, acc: 0.562500]\n",
      "3493: [D loss: 0.697755, acc: 0.494141]: [A loss: 0.708064, acc: 0.371094]\n",
      "3494: [D loss: 0.696546, acc: 0.507812]: [A loss: 0.720128, acc: 0.277344]\n",
      "3495: [D loss: 0.694464, acc: 0.500000]: [A loss: 0.704430, acc: 0.390625]\n",
      "3496: [D loss: 0.692901, acc: 0.523438]: [A loss: 0.697510, acc: 0.464844]\n",
      "3497: [D loss: 0.699808, acc: 0.464844]: [A loss: 0.702843, acc: 0.406250]\n",
      "3498: [D loss: 0.693045, acc: 0.505859]: [A loss: 0.704672, acc: 0.402344]\n",
      "3499: [D loss: 0.692502, acc: 0.519531]: [A loss: 0.717946, acc: 0.312500]\n",
      "3500: [D loss: 0.699682, acc: 0.468750]: [A loss: 0.724805, acc: 0.242188]\n",
      "3501: [D loss: 0.688622, acc: 0.542969]: [A loss: 0.687348, acc: 0.562500]\n",
      "3502: [D loss: 0.694369, acc: 0.515625]: [A loss: 0.705017, acc: 0.394531]\n",
      "3503: [D loss: 0.690994, acc: 0.515625]: [A loss: 0.685948, acc: 0.523438]\n",
      "3504: [D loss: 0.697808, acc: 0.490234]: [A loss: 0.695469, acc: 0.503906]\n",
      "3505: [D loss: 0.695631, acc: 0.500000]: [A loss: 0.709583, acc: 0.382812]\n",
      "3506: [D loss: 0.692776, acc: 0.515625]: [A loss: 0.709905, acc: 0.359375]\n",
      "3507: [D loss: 0.694120, acc: 0.498047]: [A loss: 0.709887, acc: 0.406250]\n",
      "3508: [D loss: 0.693610, acc: 0.533203]: [A loss: 0.702819, acc: 0.429688]\n",
      "3509: [D loss: 0.700577, acc: 0.480469]: [A loss: 0.726705, acc: 0.246094]\n",
      "3510: [D loss: 0.700004, acc: 0.464844]: [A loss: 0.701767, acc: 0.406250]\n",
      "3511: [D loss: 0.694026, acc: 0.503906]: [A loss: 0.754121, acc: 0.125000]\n",
      "3512: [D loss: 0.694499, acc: 0.498047]: [A loss: 0.684708, acc: 0.566406]\n",
      "3513: [D loss: 0.694808, acc: 0.500000]: [A loss: 0.690339, acc: 0.515625]\n",
      "3514: [D loss: 0.692518, acc: 0.531250]: [A loss: 0.700926, acc: 0.433594]\n",
      "3515: [D loss: 0.693574, acc: 0.525391]: [A loss: 0.685177, acc: 0.542969]\n",
      "3516: [D loss: 0.696226, acc: 0.511719]: [A loss: 0.695719, acc: 0.492188]\n",
      "3517: [D loss: 0.697203, acc: 0.486328]: [A loss: 0.692267, acc: 0.484375]\n",
      "3518: [D loss: 0.695224, acc: 0.501953]: [A loss: 0.716605, acc: 0.312500]\n",
      "3519: [D loss: 0.694904, acc: 0.503906]: [A loss: 0.712539, acc: 0.390625]\n",
      "3520: [D loss: 0.695030, acc: 0.525391]: [A loss: 0.683901, acc: 0.546875]\n",
      "3521: [D loss: 0.695954, acc: 0.496094]: [A loss: 0.720781, acc: 0.332031]\n",
      "3522: [D loss: 0.695929, acc: 0.486328]: [A loss: 0.722516, acc: 0.285156]\n",
      "3523: [D loss: 0.696069, acc: 0.480469]: [A loss: 0.704451, acc: 0.386719]\n",
      "3524: [D loss: 0.693737, acc: 0.500000]: [A loss: 0.703649, acc: 0.414062]\n",
      "3525: [D loss: 0.694128, acc: 0.496094]: [A loss: 0.676290, acc: 0.601562]\n",
      "3526: [D loss: 0.692563, acc: 0.519531]: [A loss: 0.735160, acc: 0.230469]\n",
      "3527: [D loss: 0.689487, acc: 0.507812]: [A loss: 0.686924, acc: 0.519531]\n",
      "3528: [D loss: 0.695508, acc: 0.507812]: [A loss: 0.720017, acc: 0.292969]\n",
      "3529: [D loss: 0.689098, acc: 0.542969]: [A loss: 0.708919, acc: 0.367188]\n",
      "3530: [D loss: 0.692501, acc: 0.519531]: [A loss: 0.690477, acc: 0.531250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3531: [D loss: 0.697801, acc: 0.490234]: [A loss: 0.720263, acc: 0.292969]\n",
      "3532: [D loss: 0.696426, acc: 0.480469]: [A loss: 0.683646, acc: 0.523438]\n",
      "3533: [D loss: 0.695744, acc: 0.523438]: [A loss: 0.734869, acc: 0.195312]\n",
      "3534: [D loss: 0.693169, acc: 0.523438]: [A loss: 0.687441, acc: 0.539062]\n",
      "3535: [D loss: 0.696575, acc: 0.509766]: [A loss: 0.717860, acc: 0.312500]\n",
      "3536: [D loss: 0.690854, acc: 0.511719]: [A loss: 0.698586, acc: 0.441406]\n",
      "3537: [D loss: 0.696216, acc: 0.490234]: [A loss: 0.709495, acc: 0.398438]\n",
      "3538: [D loss: 0.692573, acc: 0.527344]: [A loss: 0.716369, acc: 0.324219]\n",
      "3539: [D loss: 0.694776, acc: 0.511719]: [A loss: 0.698289, acc: 0.460938]\n",
      "3540: [D loss: 0.695659, acc: 0.517578]: [A loss: 0.703892, acc: 0.429688]\n",
      "3541: [D loss: 0.693582, acc: 0.500000]: [A loss: 0.707580, acc: 0.367188]\n",
      "3542: [D loss: 0.691404, acc: 0.525391]: [A loss: 0.704346, acc: 0.429688]\n",
      "3543: [D loss: 0.694957, acc: 0.517578]: [A loss: 0.699388, acc: 0.406250]\n",
      "3544: [D loss: 0.695111, acc: 0.498047]: [A loss: 0.718105, acc: 0.332031]\n",
      "3545: [D loss: 0.692536, acc: 0.515625]: [A loss: 0.719700, acc: 0.273438]\n",
      "3546: [D loss: 0.692823, acc: 0.519531]: [A loss: 0.688216, acc: 0.527344]\n",
      "3547: [D loss: 0.698242, acc: 0.494141]: [A loss: 0.723000, acc: 0.316406]\n",
      "3548: [D loss: 0.695466, acc: 0.501953]: [A loss: 0.704635, acc: 0.425781]\n",
      "3549: [D loss: 0.698461, acc: 0.505859]: [A loss: 0.728940, acc: 0.218750]\n",
      "3550: [D loss: 0.689970, acc: 0.550781]: [A loss: 0.690013, acc: 0.484375]\n",
      "3551: [D loss: 0.694787, acc: 0.507812]: [A loss: 0.688416, acc: 0.492188]\n",
      "3552: [D loss: 0.697082, acc: 0.525391]: [A loss: 0.723649, acc: 0.281250]\n",
      "3553: [D loss: 0.701055, acc: 0.482422]: [A loss: 0.693502, acc: 0.507812]\n",
      "3554: [D loss: 0.698438, acc: 0.498047]: [A loss: 0.719796, acc: 0.339844]\n",
      "3555: [D loss: 0.692844, acc: 0.527344]: [A loss: 0.718402, acc: 0.296875]\n",
      "3556: [D loss: 0.696272, acc: 0.484375]: [A loss: 0.691653, acc: 0.480469]\n",
      "3557: [D loss: 0.692190, acc: 0.519531]: [A loss: 0.725531, acc: 0.238281]\n",
      "3558: [D loss: 0.695227, acc: 0.511719]: [A loss: 0.687641, acc: 0.539062]\n",
      "3559: [D loss: 0.697048, acc: 0.509766]: [A loss: 0.709010, acc: 0.378906]\n",
      "3560: [D loss: 0.695774, acc: 0.503906]: [A loss: 0.697755, acc: 0.472656]\n",
      "3561: [D loss: 0.697201, acc: 0.503906]: [A loss: 0.711818, acc: 0.347656]\n",
      "3562: [D loss: 0.694687, acc: 0.517578]: [A loss: 0.689882, acc: 0.519531]\n",
      "3563: [D loss: 0.693670, acc: 0.509766]: [A loss: 0.717581, acc: 0.339844]\n",
      "3564: [D loss: 0.692181, acc: 0.554688]: [A loss: 0.704654, acc: 0.398438]\n",
      "3565: [D loss: 0.693945, acc: 0.511719]: [A loss: 0.718430, acc: 0.347656]\n",
      "3566: [D loss: 0.693269, acc: 0.492188]: [A loss: 0.710259, acc: 0.363281]\n",
      "3567: [D loss: 0.697482, acc: 0.496094]: [A loss: 0.708439, acc: 0.390625]\n",
      "3568: [D loss: 0.694085, acc: 0.511719]: [A loss: 0.713270, acc: 0.351562]\n",
      "3569: [D loss: 0.692792, acc: 0.480469]: [A loss: 0.698607, acc: 0.417969]\n",
      "3570: [D loss: 0.690309, acc: 0.535156]: [A loss: 0.680495, acc: 0.546875]\n",
      "3571: [D loss: 0.699195, acc: 0.501953]: [A loss: 0.711866, acc: 0.339844]\n",
      "3572: [D loss: 0.694781, acc: 0.503906]: [A loss: 0.694338, acc: 0.468750]\n",
      "3573: [D loss: 0.694682, acc: 0.509766]: [A loss: 0.696838, acc: 0.472656]\n",
      "3574: [D loss: 0.693222, acc: 0.501953]: [A loss: 0.698685, acc: 0.449219]\n",
      "3575: [D loss: 0.701395, acc: 0.480469]: [A loss: 0.699348, acc: 0.417969]\n",
      "3576: [D loss: 0.691672, acc: 0.498047]: [A loss: 0.707429, acc: 0.359375]\n",
      "3577: [D loss: 0.695100, acc: 0.501953]: [A loss: 0.727131, acc: 0.253906]\n",
      "3578: [D loss: 0.694827, acc: 0.525391]: [A loss: 0.701011, acc: 0.382812]\n",
      "3579: [D loss: 0.688040, acc: 0.537109]: [A loss: 0.683306, acc: 0.562500]\n",
      "3580: [D loss: 0.698710, acc: 0.500000]: [A loss: 0.724736, acc: 0.238281]\n",
      "3581: [D loss: 0.689325, acc: 0.533203]: [A loss: 0.691252, acc: 0.515625]\n",
      "3582: [D loss: 0.690238, acc: 0.519531]: [A loss: 0.682513, acc: 0.554688]\n",
      "3583: [D loss: 0.699931, acc: 0.478516]: [A loss: 0.695373, acc: 0.457031]\n",
      "3584: [D loss: 0.690856, acc: 0.513672]: [A loss: 0.715413, acc: 0.328125]\n",
      "3585: [D loss: 0.694726, acc: 0.503906]: [A loss: 0.687099, acc: 0.507812]\n",
      "3586: [D loss: 0.705427, acc: 0.500000]: [A loss: 0.713004, acc: 0.320312]\n",
      "3587: [D loss: 0.695290, acc: 0.511719]: [A loss: 0.701667, acc: 0.437500]\n",
      "3588: [D loss: 0.696449, acc: 0.505859]: [A loss: 0.700094, acc: 0.445312]\n",
      "3589: [D loss: 0.698453, acc: 0.496094]: [A loss: 0.700931, acc: 0.429688]\n",
      "3590: [D loss: 0.697373, acc: 0.468750]: [A loss: 0.719920, acc: 0.285156]\n",
      "3591: [D loss: 0.698825, acc: 0.480469]: [A loss: 0.699719, acc: 0.445312]\n",
      "3592: [D loss: 0.695088, acc: 0.523438]: [A loss: 0.689143, acc: 0.539062]\n",
      "3593: [D loss: 0.696852, acc: 0.511719]: [A loss: 0.714817, acc: 0.335938]\n",
      "3594: [D loss: 0.696518, acc: 0.490234]: [A loss: 0.696738, acc: 0.457031]\n",
      "3595: [D loss: 0.697350, acc: 0.500000]: [A loss: 0.711721, acc: 0.328125]\n",
      "3596: [D loss: 0.694554, acc: 0.509766]: [A loss: 0.700755, acc: 0.445312]\n",
      "3597: [D loss: 0.692634, acc: 0.529297]: [A loss: 0.713154, acc: 0.328125]\n",
      "3598: [D loss: 0.693421, acc: 0.531250]: [A loss: 0.711123, acc: 0.351562]\n",
      "3599: [D loss: 0.693458, acc: 0.511719]: [A loss: 0.729296, acc: 0.195312]\n",
      "3600: [D loss: 0.691136, acc: 0.509766]: [A loss: 0.702801, acc: 0.410156]\n",
      "3601: [D loss: 0.695672, acc: 0.515625]: [A loss: 0.702203, acc: 0.433594]\n",
      "3602: [D loss: 0.697560, acc: 0.484375]: [A loss: 0.669469, acc: 0.640625]\n",
      "3603: [D loss: 0.698738, acc: 0.500000]: [A loss: 0.692528, acc: 0.500000]\n",
      "3604: [D loss: 0.695837, acc: 0.505859]: [A loss: 0.700836, acc: 0.417969]\n",
      "3605: [D loss: 0.698244, acc: 0.500000]: [A loss: 0.691830, acc: 0.523438]\n",
      "3606: [D loss: 0.694537, acc: 0.511719]: [A loss: 0.700601, acc: 0.414062]\n",
      "3607: [D loss: 0.697623, acc: 0.490234]: [A loss: 0.715050, acc: 0.277344]\n",
      "3608: [D loss: 0.694309, acc: 0.531250]: [A loss: 0.699032, acc: 0.414062]\n",
      "3609: [D loss: 0.691386, acc: 0.529297]: [A loss: 0.689566, acc: 0.515625]\n",
      "3610: [D loss: 0.693754, acc: 0.515625]: [A loss: 0.707573, acc: 0.382812]\n",
      "3611: [D loss: 0.691366, acc: 0.529297]: [A loss: 0.698149, acc: 0.476562]\n",
      "3612: [D loss: 0.695130, acc: 0.513672]: [A loss: 0.697996, acc: 0.449219]\n",
      "3613: [D loss: 0.695028, acc: 0.513672]: [A loss: 0.722911, acc: 0.257812]\n",
      "3614: [D loss: 0.700514, acc: 0.482422]: [A loss: 0.704664, acc: 0.371094]\n",
      "3615: [D loss: 0.695193, acc: 0.478516]: [A loss: 0.677263, acc: 0.609375]\n",
      "3616: [D loss: 0.692839, acc: 0.511719]: [A loss: 0.712899, acc: 0.339844]\n",
      "3617: [D loss: 0.695845, acc: 0.492188]: [A loss: 0.677144, acc: 0.582031]\n",
      "3618: [D loss: 0.695669, acc: 0.505859]: [A loss: 0.724748, acc: 0.277344]\n",
      "3619: [D loss: 0.693289, acc: 0.533203]: [A loss: 0.686146, acc: 0.476562]\n",
      "3620: [D loss: 0.699464, acc: 0.500000]: [A loss: 0.716444, acc: 0.335938]\n",
      "3621: [D loss: 0.696494, acc: 0.515625]: [A loss: 0.688382, acc: 0.539062]\n",
      "3622: [D loss: 0.693089, acc: 0.482422]: [A loss: 0.668511, acc: 0.656250]\n",
      "3623: [D loss: 0.692648, acc: 0.500000]: [A loss: 0.746182, acc: 0.140625]\n",
      "3624: [D loss: 0.691394, acc: 0.517578]: [A loss: 0.677082, acc: 0.601562]\n",
      "3625: [D loss: 0.696475, acc: 0.509766]: [A loss: 0.716788, acc: 0.359375]\n",
      "3626: [D loss: 0.694912, acc: 0.480469]: [A loss: 0.711434, acc: 0.375000]\n",
      "3627: [D loss: 0.690745, acc: 0.529297]: [A loss: 0.688608, acc: 0.507812]\n",
      "3628: [D loss: 0.694293, acc: 0.525391]: [A loss: 0.703470, acc: 0.398438]\n",
      "3629: [D loss: 0.697109, acc: 0.494141]: [A loss: 0.692281, acc: 0.464844]\n",
      "3630: [D loss: 0.698843, acc: 0.480469]: [A loss: 0.713197, acc: 0.304688]\n",
      "3631: [D loss: 0.695122, acc: 0.496094]: [A loss: 0.707403, acc: 0.394531]\n",
      "3632: [D loss: 0.695025, acc: 0.501953]: [A loss: 0.689493, acc: 0.507812]\n",
      "3633: [D loss: 0.695100, acc: 0.488281]: [A loss: 0.691256, acc: 0.472656]\n",
      "3634: [D loss: 0.695166, acc: 0.474609]: [A loss: 0.687429, acc: 0.523438]\n",
      "3635: [D loss: 0.693774, acc: 0.486328]: [A loss: 0.707734, acc: 0.402344]\n",
      "3636: [D loss: 0.694455, acc: 0.501953]: [A loss: 0.706559, acc: 0.371094]\n",
      "3637: [D loss: 0.694682, acc: 0.525391]: [A loss: 0.697737, acc: 0.460938]\n",
      "3638: [D loss: 0.698040, acc: 0.486328]: [A loss: 0.729494, acc: 0.207031]\n",
      "3639: [D loss: 0.697157, acc: 0.494141]: [A loss: 0.701618, acc: 0.417969]\n",
      "3640: [D loss: 0.692302, acc: 0.505859]: [A loss: 0.716705, acc: 0.328125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641: [D loss: 0.695110, acc: 0.484375]: [A loss: 0.721183, acc: 0.296875]\n",
      "3642: [D loss: 0.693816, acc: 0.509766]: [A loss: 0.715246, acc: 0.320312]\n",
      "3643: [D loss: 0.694672, acc: 0.509766]: [A loss: 0.719726, acc: 0.296875]\n",
      "3644: [D loss: 0.692764, acc: 0.503906]: [A loss: 0.674012, acc: 0.652344]\n",
      "3645: [D loss: 0.691958, acc: 0.519531]: [A loss: 0.704211, acc: 0.378906]\n",
      "3646: [D loss: 0.699087, acc: 0.468750]: [A loss: 0.716580, acc: 0.304688]\n",
      "3647: [D loss: 0.693222, acc: 0.521484]: [A loss: 0.695892, acc: 0.449219]\n",
      "3648: [D loss: 0.698396, acc: 0.484375]: [A loss: 0.718347, acc: 0.312500]\n",
      "3649: [D loss: 0.692198, acc: 0.542969]: [A loss: 0.699770, acc: 0.453125]\n",
      "3650: [D loss: 0.693738, acc: 0.515625]: [A loss: 0.688828, acc: 0.527344]\n",
      "3651: [D loss: 0.695773, acc: 0.509766]: [A loss: 0.682900, acc: 0.582031]\n",
      "3652: [D loss: 0.697900, acc: 0.511719]: [A loss: 0.684904, acc: 0.574219]\n",
      "3653: [D loss: 0.698799, acc: 0.500000]: [A loss: 0.714299, acc: 0.355469]\n",
      "3654: [D loss: 0.694665, acc: 0.513672]: [A loss: 0.710879, acc: 0.343750]\n",
      "3655: [D loss: 0.694592, acc: 0.492188]: [A loss: 0.699396, acc: 0.414062]\n",
      "3656: [D loss: 0.696898, acc: 0.496094]: [A loss: 0.719405, acc: 0.265625]\n",
      "3657: [D loss: 0.694507, acc: 0.503906]: [A loss: 0.694275, acc: 0.468750]\n",
      "3658: [D loss: 0.694014, acc: 0.492188]: [A loss: 0.692583, acc: 0.492188]\n",
      "3659: [D loss: 0.691720, acc: 0.531250]: [A loss: 0.682809, acc: 0.539062]\n",
      "3660: [D loss: 0.697196, acc: 0.501953]: [A loss: 0.720208, acc: 0.300781]\n",
      "3661: [D loss: 0.694214, acc: 0.515625]: [A loss: 0.693849, acc: 0.472656]\n",
      "3662: [D loss: 0.694180, acc: 0.488281]: [A loss: 0.722013, acc: 0.265625]\n",
      "3663: [D loss: 0.695826, acc: 0.500000]: [A loss: 0.710725, acc: 0.332031]\n",
      "3664: [D loss: 0.700712, acc: 0.492188]: [A loss: 0.733397, acc: 0.164062]\n",
      "3665: [D loss: 0.695366, acc: 0.492188]: [A loss: 0.697149, acc: 0.472656]\n",
      "3666: [D loss: 0.692527, acc: 0.507812]: [A loss: 0.686335, acc: 0.531250]\n",
      "3667: [D loss: 0.696890, acc: 0.476562]: [A loss: 0.719674, acc: 0.300781]\n",
      "3668: [D loss: 0.698367, acc: 0.466797]: [A loss: 0.703811, acc: 0.406250]\n",
      "3669: [D loss: 0.699220, acc: 0.494141]: [A loss: 0.695840, acc: 0.433594]\n",
      "3670: [D loss: 0.695818, acc: 0.498047]: [A loss: 0.719174, acc: 0.234375]\n",
      "3671: [D loss: 0.694439, acc: 0.517578]: [A loss: 0.690532, acc: 0.523438]\n",
      "3672: [D loss: 0.701896, acc: 0.474609]: [A loss: 0.716994, acc: 0.300781]\n",
      "3673: [D loss: 0.695888, acc: 0.501953]: [A loss: 0.710867, acc: 0.324219]\n",
      "3674: [D loss: 0.694282, acc: 0.500000]: [A loss: 0.687249, acc: 0.589844]\n",
      "3675: [D loss: 0.697504, acc: 0.507812]: [A loss: 0.677098, acc: 0.621094]\n",
      "3676: [D loss: 0.695848, acc: 0.500000]: [A loss: 0.695793, acc: 0.441406]\n",
      "3677: [D loss: 0.694903, acc: 0.509766]: [A loss: 0.697534, acc: 0.421875]\n",
      "3678: [D loss: 0.697071, acc: 0.507812]: [A loss: 0.718132, acc: 0.285156]\n",
      "3679: [D loss: 0.694571, acc: 0.515625]: [A loss: 0.695571, acc: 0.457031]\n",
      "3680: [D loss: 0.695967, acc: 0.507812]: [A loss: 0.705384, acc: 0.367188]\n",
      "3681: [D loss: 0.695663, acc: 0.517578]: [A loss: 0.738170, acc: 0.179688]\n",
      "3682: [D loss: 0.693981, acc: 0.509766]: [A loss: 0.717897, acc: 0.312500]\n",
      "3683: [D loss: 0.693281, acc: 0.519531]: [A loss: 0.689339, acc: 0.515625]\n",
      "3684: [D loss: 0.696061, acc: 0.511719]: [A loss: 0.706917, acc: 0.363281]\n",
      "3685: [D loss: 0.695306, acc: 0.482422]: [A loss: 0.693588, acc: 0.476562]\n",
      "3686: [D loss: 0.693132, acc: 0.523438]: [A loss: 0.715607, acc: 0.328125]\n",
      "3687: [D loss: 0.693340, acc: 0.486328]: [A loss: 0.694886, acc: 0.496094]\n",
      "3688: [D loss: 0.695045, acc: 0.500000]: [A loss: 0.735946, acc: 0.171875]\n",
      "3689: [D loss: 0.693170, acc: 0.503906]: [A loss: 0.686747, acc: 0.535156]\n",
      "3690: [D loss: 0.693001, acc: 0.523438]: [A loss: 0.697765, acc: 0.410156]\n",
      "3691: [D loss: 0.696347, acc: 0.498047]: [A loss: 0.691995, acc: 0.472656]\n",
      "3692: [D loss: 0.690893, acc: 0.519531]: [A loss: 0.682637, acc: 0.546875]\n",
      "3693: [D loss: 0.696841, acc: 0.498047]: [A loss: 0.687972, acc: 0.539062]\n",
      "3694: [D loss: 0.691824, acc: 0.539062]: [A loss: 0.686867, acc: 0.550781]\n",
      "3695: [D loss: 0.703692, acc: 0.462891]: [A loss: 0.682317, acc: 0.554688]\n",
      "3696: [D loss: 0.699902, acc: 0.484375]: [A loss: 0.723889, acc: 0.230469]\n",
      "3697: [D loss: 0.692306, acc: 0.519531]: [A loss: 0.686669, acc: 0.527344]\n",
      "3698: [D loss: 0.702843, acc: 0.464844]: [A loss: 0.715516, acc: 0.300781]\n",
      "3699: [D loss: 0.691346, acc: 0.535156]: [A loss: 0.694324, acc: 0.500000]\n",
      "3700: [D loss: 0.698224, acc: 0.492188]: [A loss: 0.694844, acc: 0.453125]\n",
      "3701: [D loss: 0.690716, acc: 0.521484]: [A loss: 0.657320, acc: 0.695312]\n",
      "3702: [D loss: 0.700299, acc: 0.500000]: [A loss: 0.733092, acc: 0.203125]\n",
      "3703: [D loss: 0.693668, acc: 0.498047]: [A loss: 0.697027, acc: 0.453125]\n",
      "3704: [D loss: 0.694744, acc: 0.527344]: [A loss: 0.691761, acc: 0.519531]\n",
      "3705: [D loss: 0.691312, acc: 0.531250]: [A loss: 0.702822, acc: 0.421875]\n",
      "3706: [D loss: 0.696656, acc: 0.482422]: [A loss: 0.712508, acc: 0.343750]\n",
      "3707: [D loss: 0.694575, acc: 0.509766]: [A loss: 0.693488, acc: 0.464844]\n",
      "3708: [D loss: 0.693937, acc: 0.484375]: [A loss: 0.707663, acc: 0.355469]\n",
      "3709: [D loss: 0.693359, acc: 0.539062]: [A loss: 0.724707, acc: 0.265625]\n",
      "3710: [D loss: 0.692093, acc: 0.515625]: [A loss: 0.678227, acc: 0.605469]\n",
      "3711: [D loss: 0.704796, acc: 0.486328]: [A loss: 0.724765, acc: 0.253906]\n",
      "3712: [D loss: 0.694777, acc: 0.482422]: [A loss: 0.704532, acc: 0.378906]\n",
      "3713: [D loss: 0.692483, acc: 0.527344]: [A loss: 0.696585, acc: 0.457031]\n",
      "3714: [D loss: 0.691951, acc: 0.531250]: [A loss: 0.694013, acc: 0.468750]\n",
      "3715: [D loss: 0.695499, acc: 0.496094]: [A loss: 0.697281, acc: 0.472656]\n",
      "3716: [D loss: 0.690404, acc: 0.501953]: [A loss: 0.686623, acc: 0.515625]\n",
      "3717: [D loss: 0.690601, acc: 0.560547]: [A loss: 0.689061, acc: 0.515625]\n",
      "3718: [D loss: 0.699420, acc: 0.500000]: [A loss: 0.709033, acc: 0.359375]\n",
      "3719: [D loss: 0.694508, acc: 0.517578]: [A loss: 0.702978, acc: 0.394531]\n",
      "3720: [D loss: 0.698231, acc: 0.482422]: [A loss: 0.717689, acc: 0.292969]\n",
      "3721: [D loss: 0.688727, acc: 0.521484]: [A loss: 0.689752, acc: 0.496094]\n",
      "3722: [D loss: 0.699943, acc: 0.517578]: [A loss: 0.761619, acc: 0.128906]\n",
      "3723: [D loss: 0.693581, acc: 0.505859]: [A loss: 0.695956, acc: 0.429688]\n",
      "3724: [D loss: 0.690172, acc: 0.531250]: [A loss: 0.703162, acc: 0.417969]\n",
      "3725: [D loss: 0.688493, acc: 0.548828]: [A loss: 0.698280, acc: 0.468750]\n",
      "3726: [D loss: 0.697669, acc: 0.496094]: [A loss: 0.708543, acc: 0.363281]\n",
      "3727: [D loss: 0.697041, acc: 0.488281]: [A loss: 0.725695, acc: 0.250000]\n",
      "3728: [D loss: 0.694566, acc: 0.486328]: [A loss: 0.697953, acc: 0.460938]\n",
      "3729: [D loss: 0.691584, acc: 0.513672]: [A loss: 0.692340, acc: 0.480469]\n",
      "3730: [D loss: 0.695894, acc: 0.503906]: [A loss: 0.716882, acc: 0.289062]\n",
      "3731: [D loss: 0.692461, acc: 0.511719]: [A loss: 0.680512, acc: 0.546875]\n",
      "3732: [D loss: 0.697191, acc: 0.515625]: [A loss: 0.714644, acc: 0.324219]\n",
      "3733: [D loss: 0.694627, acc: 0.513672]: [A loss: 0.719442, acc: 0.308594]\n",
      "3734: [D loss: 0.691633, acc: 0.533203]: [A loss: 0.703020, acc: 0.402344]\n",
      "3735: [D loss: 0.695278, acc: 0.492188]: [A loss: 0.719844, acc: 0.289062]\n",
      "3736: [D loss: 0.694811, acc: 0.480469]: [A loss: 0.706013, acc: 0.394531]\n",
      "3737: [D loss: 0.693460, acc: 0.525391]: [A loss: 0.699954, acc: 0.421875]\n",
      "3738: [D loss: 0.693426, acc: 0.531250]: [A loss: 0.694694, acc: 0.480469]\n",
      "3739: [D loss: 0.690561, acc: 0.529297]: [A loss: 0.688222, acc: 0.531250]\n",
      "3740: [D loss: 0.692465, acc: 0.523438]: [A loss: 0.684877, acc: 0.574219]\n",
      "3741: [D loss: 0.696997, acc: 0.492188]: [A loss: 0.729592, acc: 0.246094]\n",
      "3742: [D loss: 0.694321, acc: 0.482422]: [A loss: 0.690642, acc: 0.539062]\n",
      "3743: [D loss: 0.692782, acc: 0.513672]: [A loss: 0.695278, acc: 0.488281]\n",
      "3744: [D loss: 0.692062, acc: 0.507812]: [A loss: 0.709622, acc: 0.382812]\n",
      "3745: [D loss: 0.695948, acc: 0.529297]: [A loss: 0.720820, acc: 0.273438]\n",
      "3746: [D loss: 0.694335, acc: 0.500000]: [A loss: 0.693519, acc: 0.484375]\n",
      "3747: [D loss: 0.693516, acc: 0.509766]: [A loss: 0.708926, acc: 0.347656]\n",
      "3748: [D loss: 0.691873, acc: 0.519531]: [A loss: 0.689139, acc: 0.488281]\n",
      "3749: [D loss: 0.707219, acc: 0.490234]: [A loss: 0.770131, acc: 0.058594]\n",
      "3750: [D loss: 0.695568, acc: 0.501953]: [A loss: 0.708100, acc: 0.375000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3751: [D loss: 0.699439, acc: 0.466797]: [A loss: 0.705759, acc: 0.390625]\n",
      "3752: [D loss: 0.695612, acc: 0.492188]: [A loss: 0.695599, acc: 0.472656]\n",
      "3753: [D loss: 0.694894, acc: 0.503906]: [A loss: 0.690559, acc: 0.476562]\n",
      "3754: [D loss: 0.696796, acc: 0.505859]: [A loss: 0.715235, acc: 0.304688]\n",
      "3755: [D loss: 0.697623, acc: 0.511719]: [A loss: 0.701376, acc: 0.453125]\n",
      "3756: [D loss: 0.690870, acc: 0.503906]: [A loss: 0.705282, acc: 0.406250]\n",
      "3757: [D loss: 0.692039, acc: 0.511719]: [A loss: 0.691218, acc: 0.484375]\n",
      "3758: [D loss: 0.696078, acc: 0.500000]: [A loss: 0.756006, acc: 0.125000]\n",
      "3759: [D loss: 0.694977, acc: 0.511719]: [A loss: 0.711862, acc: 0.335938]\n",
      "3760: [D loss: 0.695024, acc: 0.486328]: [A loss: 0.709600, acc: 0.371094]\n",
      "3761: [D loss: 0.698515, acc: 0.484375]: [A loss: 0.711719, acc: 0.390625]\n",
      "3762: [D loss: 0.693550, acc: 0.503906]: [A loss: 0.698287, acc: 0.449219]\n",
      "3763: [D loss: 0.692347, acc: 0.513672]: [A loss: 0.689617, acc: 0.496094]\n",
      "3764: [D loss: 0.693179, acc: 0.486328]: [A loss: 0.722388, acc: 0.281250]\n",
      "3765: [D loss: 0.691025, acc: 0.537109]: [A loss: 0.718991, acc: 0.304688]\n",
      "3766: [D loss: 0.696381, acc: 0.490234]: [A loss: 0.708693, acc: 0.375000]\n",
      "3767: [D loss: 0.697617, acc: 0.490234]: [A loss: 0.708840, acc: 0.335938]\n",
      "3768: [D loss: 0.697553, acc: 0.474609]: [A loss: 0.718278, acc: 0.269531]\n",
      "3769: [D loss: 0.694644, acc: 0.500000]: [A loss: 0.686768, acc: 0.535156]\n",
      "3770: [D loss: 0.693710, acc: 0.507812]: [A loss: 0.708331, acc: 0.355469]\n",
      "3771: [D loss: 0.693462, acc: 0.517578]: [A loss: 0.673603, acc: 0.621094]\n",
      "3772: [D loss: 0.695965, acc: 0.513672]: [A loss: 0.729586, acc: 0.242188]\n",
      "3773: [D loss: 0.697594, acc: 0.488281]: [A loss: 0.705975, acc: 0.394531]\n",
      "3774: [D loss: 0.698349, acc: 0.511719]: [A loss: 0.722436, acc: 0.246094]\n",
      "3775: [D loss: 0.690745, acc: 0.533203]: [A loss: 0.690184, acc: 0.523438]\n",
      "3776: [D loss: 0.689882, acc: 0.517578]: [A loss: 0.710061, acc: 0.359375]\n",
      "3777: [D loss: 0.699034, acc: 0.511719]: [A loss: 0.686178, acc: 0.550781]\n",
      "3778: [D loss: 0.698788, acc: 0.503906]: [A loss: 0.707367, acc: 0.355469]\n",
      "3779: [D loss: 0.692953, acc: 0.509766]: [A loss: 0.712175, acc: 0.351562]\n",
      "3780: [D loss: 0.697972, acc: 0.482422]: [A loss: 0.711014, acc: 0.339844]\n",
      "3781: [D loss: 0.694048, acc: 0.501953]: [A loss: 0.703239, acc: 0.429688]\n",
      "3782: [D loss: 0.699340, acc: 0.500000]: [A loss: 0.711480, acc: 0.359375]\n",
      "3783: [D loss: 0.695122, acc: 0.496094]: [A loss: 0.704437, acc: 0.421875]\n",
      "3784: [D loss: 0.696175, acc: 0.482422]: [A loss: 0.704244, acc: 0.386719]\n",
      "3785: [D loss: 0.698552, acc: 0.464844]: [A loss: 0.717400, acc: 0.285156]\n",
      "3786: [D loss: 0.692842, acc: 0.535156]: [A loss: 0.713557, acc: 0.320312]\n",
      "3787: [D loss: 0.695734, acc: 0.496094]: [A loss: 0.696134, acc: 0.464844]\n",
      "3788: [D loss: 0.697839, acc: 0.500000]: [A loss: 0.708750, acc: 0.378906]\n",
      "3789: [D loss: 0.695230, acc: 0.496094]: [A loss: 0.704739, acc: 0.402344]\n",
      "3790: [D loss: 0.694836, acc: 0.521484]: [A loss: 0.715572, acc: 0.343750]\n",
      "3791: [D loss: 0.695424, acc: 0.490234]: [A loss: 0.698587, acc: 0.433594]\n",
      "3792: [D loss: 0.694450, acc: 0.523438]: [A loss: 0.704617, acc: 0.386719]\n",
      "3793: [D loss: 0.697530, acc: 0.472656]: [A loss: 0.718646, acc: 0.308594]\n",
      "3794: [D loss: 0.695444, acc: 0.501953]: [A loss: 0.705940, acc: 0.414062]\n",
      "3795: [D loss: 0.693413, acc: 0.498047]: [A loss: 0.687990, acc: 0.503906]\n",
      "3796: [D loss: 0.698797, acc: 0.486328]: [A loss: 0.757609, acc: 0.101562]\n",
      "3797: [D loss: 0.690417, acc: 0.511719]: [A loss: 0.693412, acc: 0.457031]\n",
      "3798: [D loss: 0.695211, acc: 0.531250]: [A loss: 0.702751, acc: 0.406250]\n",
      "3799: [D loss: 0.699264, acc: 0.492188]: [A loss: 0.720552, acc: 0.273438]\n",
      "3800: [D loss: 0.697238, acc: 0.511719]: [A loss: 0.714991, acc: 0.335938]\n",
      "3801: [D loss: 0.693717, acc: 0.507812]: [A loss: 0.670493, acc: 0.617188]\n",
      "3802: [D loss: 0.698742, acc: 0.501953]: [A loss: 0.762038, acc: 0.085938]\n",
      "3803: [D loss: 0.691984, acc: 0.511719]: [A loss: 0.700403, acc: 0.464844]\n",
      "3804: [D loss: 0.699565, acc: 0.496094]: [A loss: 0.709414, acc: 0.363281]\n",
      "3805: [D loss: 0.696680, acc: 0.470703]: [A loss: 0.688119, acc: 0.535156]\n",
      "3806: [D loss: 0.695678, acc: 0.509766]: [A loss: 0.705187, acc: 0.406250]\n",
      "3807: [D loss: 0.693260, acc: 0.503906]: [A loss: 0.689247, acc: 0.531250]\n",
      "3808: [D loss: 0.696835, acc: 0.498047]: [A loss: 0.705755, acc: 0.359375]\n",
      "3809: [D loss: 0.692198, acc: 0.515625]: [A loss: 0.699251, acc: 0.406250]\n",
      "3810: [D loss: 0.692709, acc: 0.494141]: [A loss: 0.712007, acc: 0.343750]\n",
      "3811: [D loss: 0.692018, acc: 0.548828]: [A loss: 0.719603, acc: 0.269531]\n",
      "3812: [D loss: 0.695691, acc: 0.513672]: [A loss: 0.699878, acc: 0.453125]\n",
      "3813: [D loss: 0.697250, acc: 0.509766]: [A loss: 0.706259, acc: 0.363281]\n",
      "3814: [D loss: 0.693824, acc: 0.509766]: [A loss: 0.696410, acc: 0.496094]\n",
      "3815: [D loss: 0.693613, acc: 0.531250]: [A loss: 0.697065, acc: 0.421875]\n",
      "3816: [D loss: 0.696564, acc: 0.513672]: [A loss: 0.697342, acc: 0.464844]\n",
      "3817: [D loss: 0.693971, acc: 0.498047]: [A loss: 0.689151, acc: 0.542969]\n",
      "3818: [D loss: 0.693461, acc: 0.511719]: [A loss: 0.702987, acc: 0.437500]\n",
      "3819: [D loss: 0.698418, acc: 0.484375]: [A loss: 0.703524, acc: 0.417969]\n",
      "3820: [D loss: 0.692596, acc: 0.509766]: [A loss: 0.717397, acc: 0.308594]\n",
      "3821: [D loss: 0.693157, acc: 0.517578]: [A loss: 0.703534, acc: 0.394531]\n",
      "3822: [D loss: 0.690666, acc: 0.523438]: [A loss: 0.686577, acc: 0.566406]\n",
      "3823: [D loss: 0.693637, acc: 0.509766]: [A loss: 0.734834, acc: 0.253906]\n",
      "3824: [D loss: 0.691987, acc: 0.525391]: [A loss: 0.715269, acc: 0.320312]\n",
      "3825: [D loss: 0.699196, acc: 0.476562]: [A loss: 0.707766, acc: 0.371094]\n",
      "3826: [D loss: 0.699486, acc: 0.490234]: [A loss: 0.705136, acc: 0.378906]\n",
      "3827: [D loss: 0.691951, acc: 0.523438]: [A loss: 0.723237, acc: 0.277344]\n",
      "3828: [D loss: 0.695029, acc: 0.503906]: [A loss: 0.694537, acc: 0.472656]\n",
      "3829: [D loss: 0.695338, acc: 0.494141]: [A loss: 0.709996, acc: 0.355469]\n",
      "3830: [D loss: 0.694659, acc: 0.494141]: [A loss: 0.702245, acc: 0.429688]\n",
      "3831: [D loss: 0.696760, acc: 0.486328]: [A loss: 0.717241, acc: 0.304688]\n",
      "3832: [D loss: 0.696447, acc: 0.480469]: [A loss: 0.716962, acc: 0.292969]\n",
      "3833: [D loss: 0.695739, acc: 0.500000]: [A loss: 0.715947, acc: 0.328125]\n",
      "3834: [D loss: 0.693786, acc: 0.488281]: [A loss: 0.709465, acc: 0.371094]\n",
      "3835: [D loss: 0.698407, acc: 0.498047]: [A loss: 0.709456, acc: 0.378906]\n",
      "3836: [D loss: 0.696026, acc: 0.494141]: [A loss: 0.713319, acc: 0.320312]\n",
      "3837: [D loss: 0.694804, acc: 0.494141]: [A loss: 0.705090, acc: 0.410156]\n",
      "3838: [D loss: 0.697907, acc: 0.457031]: [A loss: 0.714141, acc: 0.304688]\n",
      "3839: [D loss: 0.693420, acc: 0.513672]: [A loss: 0.698221, acc: 0.441406]\n",
      "3840: [D loss: 0.696975, acc: 0.496094]: [A loss: 0.667122, acc: 0.660156]\n",
      "3841: [D loss: 0.699773, acc: 0.488281]: [A loss: 0.707768, acc: 0.355469]\n",
      "3842: [D loss: 0.698510, acc: 0.484375]: [A loss: 0.709334, acc: 0.343750]\n",
      "3843: [D loss: 0.695884, acc: 0.496094]: [A loss: 0.702689, acc: 0.394531]\n",
      "3844: [D loss: 0.690303, acc: 0.505859]: [A loss: 0.715160, acc: 0.324219]\n",
      "3845: [D loss: 0.694430, acc: 0.501953]: [A loss: 0.713149, acc: 0.347656]\n",
      "3846: [D loss: 0.697046, acc: 0.492188]: [A loss: 0.722537, acc: 0.296875]\n",
      "3847: [D loss: 0.694477, acc: 0.482422]: [A loss: 0.705971, acc: 0.375000]\n",
      "3848: [D loss: 0.695193, acc: 0.515625]: [A loss: 0.732528, acc: 0.222656]\n",
      "3849: [D loss: 0.695817, acc: 0.476562]: [A loss: 0.683379, acc: 0.515625]\n",
      "3850: [D loss: 0.703861, acc: 0.515625]: [A loss: 0.771649, acc: 0.070312]\n",
      "3851: [D loss: 0.689995, acc: 0.541016]: [A loss: 0.695086, acc: 0.484375]\n",
      "3852: [D loss: 0.691300, acc: 0.535156]: [A loss: 0.690173, acc: 0.511719]\n",
      "3853: [D loss: 0.695652, acc: 0.521484]: [A loss: 0.680902, acc: 0.566406]\n",
      "3854: [D loss: 0.694291, acc: 0.523438]: [A loss: 0.699311, acc: 0.441406]\n",
      "3855: [D loss: 0.697663, acc: 0.478516]: [A loss: 0.680831, acc: 0.578125]\n",
      "3856: [D loss: 0.699569, acc: 0.492188]: [A loss: 0.714301, acc: 0.316406]\n",
      "3857: [D loss: 0.698035, acc: 0.488281]: [A loss: 0.717767, acc: 0.277344]\n",
      "3858: [D loss: 0.697480, acc: 0.501953]: [A loss: 0.689747, acc: 0.496094]\n",
      "3859: [D loss: 0.694377, acc: 0.513672]: [A loss: 0.696166, acc: 0.457031]\n",
      "3860: [D loss: 0.694934, acc: 0.500000]: [A loss: 0.704471, acc: 0.394531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3861: [D loss: 0.695988, acc: 0.482422]: [A loss: 0.704543, acc: 0.390625]\n",
      "3862: [D loss: 0.695924, acc: 0.490234]: [A loss: 0.715128, acc: 0.289062]\n",
      "3863: [D loss: 0.691884, acc: 0.498047]: [A loss: 0.700272, acc: 0.445312]\n",
      "3864: [D loss: 0.693637, acc: 0.519531]: [A loss: 0.713426, acc: 0.308594]\n",
      "3865: [D loss: 0.694272, acc: 0.500000]: [A loss: 0.724593, acc: 0.296875]\n",
      "3866: [D loss: 0.692750, acc: 0.517578]: [A loss: 0.702508, acc: 0.394531]\n",
      "3867: [D loss: 0.698290, acc: 0.480469]: [A loss: 0.717878, acc: 0.289062]\n",
      "3868: [D loss: 0.693620, acc: 0.513672]: [A loss: 0.695422, acc: 0.488281]\n",
      "3869: [D loss: 0.703844, acc: 0.443359]: [A loss: 0.714437, acc: 0.339844]\n",
      "3870: [D loss: 0.695119, acc: 0.507812]: [A loss: 0.704693, acc: 0.378906]\n",
      "3871: [D loss: 0.697203, acc: 0.501953]: [A loss: 0.710432, acc: 0.332031]\n",
      "3872: [D loss: 0.688702, acc: 0.541016]: [A loss: 0.710465, acc: 0.378906]\n",
      "3873: [D loss: 0.691912, acc: 0.511719]: [A loss: 0.703733, acc: 0.386719]\n",
      "3874: [D loss: 0.698482, acc: 0.505859]: [A loss: 0.724591, acc: 0.273438]\n",
      "3875: [D loss: 0.700796, acc: 0.476562]: [A loss: 0.720824, acc: 0.300781]\n",
      "3876: [D loss: 0.694755, acc: 0.503906]: [A loss: 0.702023, acc: 0.429688]\n",
      "3877: [D loss: 0.694180, acc: 0.517578]: [A loss: 0.698198, acc: 0.480469]\n",
      "3878: [D loss: 0.696471, acc: 0.525391]: [A loss: 0.714340, acc: 0.347656]\n",
      "3879: [D loss: 0.696065, acc: 0.476562]: [A loss: 0.703399, acc: 0.386719]\n",
      "3880: [D loss: 0.694363, acc: 0.476562]: [A loss: 0.713669, acc: 0.292969]\n",
      "3881: [D loss: 0.696450, acc: 0.482422]: [A loss: 0.700901, acc: 0.421875]\n",
      "3882: [D loss: 0.692115, acc: 0.505859]: [A loss: 0.690654, acc: 0.503906]\n",
      "3883: [D loss: 0.691058, acc: 0.527344]: [A loss: 0.707528, acc: 0.355469]\n",
      "3884: [D loss: 0.690511, acc: 0.529297]: [A loss: 0.678201, acc: 0.601562]\n",
      "3885: [D loss: 0.697189, acc: 0.511719]: [A loss: 0.724906, acc: 0.246094]\n",
      "3886: [D loss: 0.694862, acc: 0.501953]: [A loss: 0.703102, acc: 0.375000]\n",
      "3887: [D loss: 0.697566, acc: 0.525391]: [A loss: 0.704915, acc: 0.382812]\n",
      "3888: [D loss: 0.692857, acc: 0.513672]: [A loss: 0.694260, acc: 0.507812]\n",
      "3889: [D loss: 0.696650, acc: 0.498047]: [A loss: 0.725978, acc: 0.234375]\n",
      "3890: [D loss: 0.692193, acc: 0.517578]: [A loss: 0.692729, acc: 0.496094]\n",
      "3891: [D loss: 0.694866, acc: 0.556641]: [A loss: 0.714831, acc: 0.316406]\n",
      "3892: [D loss: 0.692859, acc: 0.519531]: [A loss: 0.700771, acc: 0.445312]\n",
      "3893: [D loss: 0.694244, acc: 0.496094]: [A loss: 0.712606, acc: 0.347656]\n",
      "3894: [D loss: 0.693524, acc: 0.511719]: [A loss: 0.695983, acc: 0.476562]\n",
      "3895: [D loss: 0.698482, acc: 0.494141]: [A loss: 0.735727, acc: 0.222656]\n",
      "3896: [D loss: 0.688814, acc: 0.556641]: [A loss: 0.666795, acc: 0.648438]\n",
      "3897: [D loss: 0.701544, acc: 0.500000]: [A loss: 0.744395, acc: 0.152344]\n",
      "3898: [D loss: 0.693448, acc: 0.494141]: [A loss: 0.701366, acc: 0.429688]\n",
      "3899: [D loss: 0.694314, acc: 0.513672]: [A loss: 0.702759, acc: 0.371094]\n",
      "3900: [D loss: 0.694632, acc: 0.529297]: [A loss: 0.705315, acc: 0.390625]\n",
      "3901: [D loss: 0.696339, acc: 0.517578]: [A loss: 0.703055, acc: 0.386719]\n",
      "3902: [D loss: 0.696463, acc: 0.501953]: [A loss: 0.693890, acc: 0.460938]\n",
      "3903: [D loss: 0.695784, acc: 0.521484]: [A loss: 0.713249, acc: 0.324219]\n",
      "3904: [D loss: 0.692454, acc: 0.511719]: [A loss: 0.723753, acc: 0.277344]\n",
      "3905: [D loss: 0.696104, acc: 0.517578]: [A loss: 0.719847, acc: 0.332031]\n",
      "3906: [D loss: 0.690328, acc: 0.523438]: [A loss: 0.684706, acc: 0.535156]\n",
      "3907: [D loss: 0.697859, acc: 0.513672]: [A loss: 0.714386, acc: 0.371094]\n",
      "3908: [D loss: 0.698081, acc: 0.472656]: [A loss: 0.709734, acc: 0.355469]\n",
      "3909: [D loss: 0.695756, acc: 0.476562]: [A loss: 0.712796, acc: 0.351562]\n",
      "3910: [D loss: 0.691160, acc: 0.498047]: [A loss: 0.723943, acc: 0.246094]\n",
      "3911: [D loss: 0.694638, acc: 0.511719]: [A loss: 0.721026, acc: 0.328125]\n",
      "3912: [D loss: 0.695146, acc: 0.496094]: [A loss: 0.716061, acc: 0.332031]\n",
      "3913: [D loss: 0.690837, acc: 0.531250]: [A loss: 0.689423, acc: 0.523438]\n",
      "3914: [D loss: 0.698170, acc: 0.498047]: [A loss: 0.727703, acc: 0.269531]\n",
      "3915: [D loss: 0.689387, acc: 0.550781]: [A loss: 0.701783, acc: 0.406250]\n",
      "3916: [D loss: 0.699823, acc: 0.484375]: [A loss: 0.723351, acc: 0.257812]\n",
      "3917: [D loss: 0.694431, acc: 0.503906]: [A loss: 0.716011, acc: 0.339844]\n",
      "3918: [D loss: 0.690301, acc: 0.509766]: [A loss: 0.724967, acc: 0.257812]\n",
      "3919: [D loss: 0.700977, acc: 0.484375]: [A loss: 0.718886, acc: 0.289062]\n",
      "3920: [D loss: 0.695326, acc: 0.500000]: [A loss: 0.694367, acc: 0.437500]\n",
      "3921: [D loss: 0.695469, acc: 0.515625]: [A loss: 0.725375, acc: 0.230469]\n",
      "3922: [D loss: 0.694417, acc: 0.513672]: [A loss: 0.690395, acc: 0.535156]\n",
      "3923: [D loss: 0.697532, acc: 0.484375]: [A loss: 0.699122, acc: 0.417969]\n",
      "3924: [D loss: 0.698309, acc: 0.511719]: [A loss: 0.721153, acc: 0.281250]\n",
      "3925: [D loss: 0.696562, acc: 0.501953]: [A loss: 0.701639, acc: 0.394531]\n",
      "3926: [D loss: 0.695367, acc: 0.498047]: [A loss: 0.699449, acc: 0.414062]\n",
      "3927: [D loss: 0.698335, acc: 0.515625]: [A loss: 0.715762, acc: 0.316406]\n",
      "3928: [D loss: 0.695191, acc: 0.501953]: [A loss: 0.706608, acc: 0.402344]\n",
      "3929: [D loss: 0.694067, acc: 0.525391]: [A loss: 0.695768, acc: 0.464844]\n",
      "3930: [D loss: 0.694635, acc: 0.515625]: [A loss: 0.719001, acc: 0.292969]\n",
      "3931: [D loss: 0.697329, acc: 0.498047]: [A loss: 0.721390, acc: 0.296875]\n",
      "3932: [D loss: 0.692265, acc: 0.505859]: [A loss: 0.751883, acc: 0.136719]\n",
      "3933: [D loss: 0.692734, acc: 0.517578]: [A loss: 0.730019, acc: 0.242188]\n",
      "3934: [D loss: 0.697514, acc: 0.482422]: [A loss: 0.698653, acc: 0.445312]\n",
      "3935: [D loss: 0.694670, acc: 0.501953]: [A loss: 0.716263, acc: 0.308594]\n",
      "3936: [D loss: 0.694090, acc: 0.507812]: [A loss: 0.703106, acc: 0.394531]\n",
      "3937: [D loss: 0.697438, acc: 0.484375]: [A loss: 0.714430, acc: 0.351562]\n",
      "3938: [D loss: 0.694908, acc: 0.494141]: [A loss: 0.695811, acc: 0.429688]\n",
      "3939: [D loss: 0.702778, acc: 0.474609]: [A loss: 0.753438, acc: 0.136719]\n",
      "3940: [D loss: 0.693793, acc: 0.517578]: [A loss: 0.714200, acc: 0.355469]\n",
      "3941: [D loss: 0.695438, acc: 0.500000]: [A loss: 0.692996, acc: 0.476562]\n",
      "3942: [D loss: 0.694936, acc: 0.509766]: [A loss: 0.700448, acc: 0.433594]\n",
      "3943: [D loss: 0.695021, acc: 0.490234]: [A loss: 0.717774, acc: 0.296875]\n",
      "3944: [D loss: 0.694012, acc: 0.507812]: [A loss: 0.688730, acc: 0.527344]\n",
      "3945: [D loss: 0.693271, acc: 0.527344]: [A loss: 0.706051, acc: 0.433594]\n",
      "3946: [D loss: 0.695718, acc: 0.507812]: [A loss: 0.697753, acc: 0.468750]\n",
      "3947: [D loss: 0.690741, acc: 0.525391]: [A loss: 0.697997, acc: 0.476562]\n",
      "3948: [D loss: 0.695002, acc: 0.511719]: [A loss: 0.699180, acc: 0.441406]\n",
      "3949: [D loss: 0.695777, acc: 0.501953]: [A loss: 0.709157, acc: 0.386719]\n",
      "3950: [D loss: 0.695232, acc: 0.509766]: [A loss: 0.703425, acc: 0.363281]\n",
      "3951: [D loss: 0.698117, acc: 0.488281]: [A loss: 0.715996, acc: 0.269531]\n",
      "3952: [D loss: 0.693592, acc: 0.517578]: [A loss: 0.710662, acc: 0.347656]\n",
      "3953: [D loss: 0.688872, acc: 0.525391]: [A loss: 0.687207, acc: 0.527344]\n",
      "3954: [D loss: 0.700613, acc: 0.488281]: [A loss: 0.744269, acc: 0.128906]\n",
      "3955: [D loss: 0.695325, acc: 0.472656]: [A loss: 0.686723, acc: 0.542969]\n",
      "3956: [D loss: 0.707257, acc: 0.507812]: [A loss: 0.759190, acc: 0.109375]\n",
      "3957: [D loss: 0.696228, acc: 0.498047]: [A loss: 0.708449, acc: 0.371094]\n",
      "3958: [D loss: 0.693052, acc: 0.527344]: [A loss: 0.687338, acc: 0.542969]\n",
      "3959: [D loss: 0.693909, acc: 0.511719]: [A loss: 0.697403, acc: 0.433594]\n",
      "3960: [D loss: 0.697782, acc: 0.480469]: [A loss: 0.695345, acc: 0.484375]\n",
      "3961: [D loss: 0.696811, acc: 0.519531]: [A loss: 0.704944, acc: 0.375000]\n",
      "3962: [D loss: 0.694896, acc: 0.501953]: [A loss: 0.729822, acc: 0.226562]\n",
      "3963: [D loss: 0.695325, acc: 0.500000]: [A loss: 0.703014, acc: 0.359375]\n",
      "3964: [D loss: 0.693537, acc: 0.503906]: [A loss: 0.707425, acc: 0.375000]\n",
      "3965: [D loss: 0.693115, acc: 0.507812]: [A loss: 0.702109, acc: 0.457031]\n",
      "3966: [D loss: 0.694708, acc: 0.515625]: [A loss: 0.704572, acc: 0.421875]\n",
      "3967: [D loss: 0.699370, acc: 0.486328]: [A loss: 0.717411, acc: 0.304688]\n",
      "3968: [D loss: 0.694854, acc: 0.505859]: [A loss: 0.715654, acc: 0.367188]\n",
      "3969: [D loss: 0.693534, acc: 0.525391]: [A loss: 0.733863, acc: 0.226562]\n",
      "3970: [D loss: 0.696899, acc: 0.464844]: [A loss: 0.732178, acc: 0.234375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3971: [D loss: 0.690424, acc: 0.515625]: [A loss: 0.697589, acc: 0.429688]\n",
      "3972: [D loss: 0.691516, acc: 0.517578]: [A loss: 0.687295, acc: 0.519531]\n",
      "3973: [D loss: 0.696991, acc: 0.507812]: [A loss: 0.705976, acc: 0.402344]\n",
      "3974: [D loss: 0.695593, acc: 0.464844]: [A loss: 0.691706, acc: 0.503906]\n",
      "3975: [D loss: 0.696322, acc: 0.496094]: [A loss: 0.715299, acc: 0.332031]\n",
      "3976: [D loss: 0.697854, acc: 0.500000]: [A loss: 0.721268, acc: 0.296875]\n",
      "3977: [D loss: 0.695411, acc: 0.519531]: [A loss: 0.732569, acc: 0.234375]\n",
      "3978: [D loss: 0.696851, acc: 0.505859]: [A loss: 0.713756, acc: 0.324219]\n",
      "3979: [D loss: 0.698527, acc: 0.474609]: [A loss: 0.731444, acc: 0.214844]\n",
      "3980: [D loss: 0.694168, acc: 0.513672]: [A loss: 0.706076, acc: 0.433594]\n",
      "3981: [D loss: 0.692844, acc: 0.519531]: [A loss: 0.716108, acc: 0.316406]\n",
      "3982: [D loss: 0.694419, acc: 0.490234]: [A loss: 0.677264, acc: 0.585938]\n",
      "3983: [D loss: 0.700205, acc: 0.519531]: [A loss: 0.736151, acc: 0.179688]\n",
      "3984: [D loss: 0.693543, acc: 0.488281]: [A loss: 0.682998, acc: 0.539062]\n",
      "3985: [D loss: 0.693200, acc: 0.513672]: [A loss: 0.705836, acc: 0.417969]\n",
      "3986: [D loss: 0.694714, acc: 0.492188]: [A loss: 0.718981, acc: 0.292969]\n",
      "3987: [D loss: 0.693114, acc: 0.517578]: [A loss: 0.708355, acc: 0.343750]\n",
      "3988: [D loss: 0.695555, acc: 0.476562]: [A loss: 0.696800, acc: 0.445312]\n",
      "3989: [D loss: 0.691923, acc: 0.505859]: [A loss: 0.706683, acc: 0.394531]\n",
      "3990: [D loss: 0.696432, acc: 0.501953]: [A loss: 0.716227, acc: 0.347656]\n",
      "3991: [D loss: 0.694639, acc: 0.525391]: [A loss: 0.696036, acc: 0.437500]\n",
      "3992: [D loss: 0.695201, acc: 0.519531]: [A loss: 0.715297, acc: 0.312500]\n",
      "3993: [D loss: 0.690209, acc: 0.523438]: [A loss: 0.680702, acc: 0.542969]\n",
      "3994: [D loss: 0.699058, acc: 0.488281]: [A loss: 0.724467, acc: 0.292969]\n",
      "3995: [D loss: 0.701286, acc: 0.458984]: [A loss: 0.707244, acc: 0.375000]\n",
      "3996: [D loss: 0.692396, acc: 0.507812]: [A loss: 0.715716, acc: 0.355469]\n",
      "3997: [D loss: 0.698017, acc: 0.492188]: [A loss: 0.720043, acc: 0.292969]\n",
      "3998: [D loss: 0.691244, acc: 0.523438]: [A loss: 0.703643, acc: 0.406250]\n",
      "3999: [D loss: 0.698197, acc: 0.484375]: [A loss: 0.712175, acc: 0.335938]\n",
      "4000: [D loss: 0.698507, acc: 0.476562]: [A loss: 0.717562, acc: 0.292969]\n",
      "4001: [D loss: 0.697796, acc: 0.494141]: [A loss: 0.706523, acc: 0.375000]\n",
      "4002: [D loss: 0.704696, acc: 0.462891]: [A loss: 0.738794, acc: 0.164062]\n",
      "4003: [D loss: 0.692381, acc: 0.521484]: [A loss: 0.684420, acc: 0.562500]\n",
      "4004: [D loss: 0.701042, acc: 0.494141]: [A loss: 0.748841, acc: 0.136719]\n",
      "4005: [D loss: 0.693117, acc: 0.515625]: [A loss: 0.705514, acc: 0.382812]\n",
      "4006: [D loss: 0.697078, acc: 0.488281]: [A loss: 0.706772, acc: 0.332031]\n",
      "4007: [D loss: 0.695896, acc: 0.496094]: [A loss: 0.693241, acc: 0.480469]\n",
      "4008: [D loss: 0.693358, acc: 0.511719]: [A loss: 0.698203, acc: 0.449219]\n",
      "4009: [D loss: 0.695630, acc: 0.503906]: [A loss: 0.711674, acc: 0.363281]\n",
      "4010: [D loss: 0.697165, acc: 0.505859]: [A loss: 0.714644, acc: 0.355469]\n",
      "4011: [D loss: 0.692055, acc: 0.542969]: [A loss: 0.684874, acc: 0.539062]\n",
      "4012: [D loss: 0.698182, acc: 0.509766]: [A loss: 0.750791, acc: 0.144531]\n",
      "4013: [D loss: 0.693339, acc: 0.521484]: [A loss: 0.702409, acc: 0.457031]\n",
      "4014: [D loss: 0.695398, acc: 0.474609]: [A loss: 0.712388, acc: 0.359375]\n",
      "4015: [D loss: 0.694750, acc: 0.511719]: [A loss: 0.698117, acc: 0.476562]\n",
      "4016: [D loss: 0.698113, acc: 0.478516]: [A loss: 0.710167, acc: 0.371094]\n",
      "4017: [D loss: 0.697499, acc: 0.486328]: [A loss: 0.692336, acc: 0.500000]\n",
      "4018: [D loss: 0.702338, acc: 0.484375]: [A loss: 0.715035, acc: 0.289062]\n",
      "4019: [D loss: 0.695746, acc: 0.533203]: [A loss: 0.707429, acc: 0.363281]\n",
      "4020: [D loss: 0.698743, acc: 0.515625]: [A loss: 0.716421, acc: 0.308594]\n",
      "4021: [D loss: 0.691464, acc: 0.525391]: [A loss: 0.715845, acc: 0.289062]\n",
      "4022: [D loss: 0.695212, acc: 0.517578]: [A loss: 0.696413, acc: 0.441406]\n",
      "4023: [D loss: 0.691542, acc: 0.527344]: [A loss: 0.697922, acc: 0.453125]\n",
      "4024: [D loss: 0.698149, acc: 0.484375]: [A loss: 0.740609, acc: 0.160156]\n",
      "4025: [D loss: 0.692164, acc: 0.535156]: [A loss: 0.706302, acc: 0.390625]\n",
      "4026: [D loss: 0.693812, acc: 0.478516]: [A loss: 0.690763, acc: 0.503906]\n",
      "4027: [D loss: 0.690421, acc: 0.529297]: [A loss: 0.683305, acc: 0.574219]\n",
      "4028: [D loss: 0.696376, acc: 0.492188]: [A loss: 0.715157, acc: 0.304688]\n",
      "4029: [D loss: 0.691206, acc: 0.548828]: [A loss: 0.700629, acc: 0.421875]\n",
      "4030: [D loss: 0.696115, acc: 0.507812]: [A loss: 0.717308, acc: 0.281250]\n",
      "4031: [D loss: 0.692335, acc: 0.525391]: [A loss: 0.719345, acc: 0.269531]\n",
      "4032: [D loss: 0.693161, acc: 0.517578]: [A loss: 0.683293, acc: 0.574219]\n",
      "4033: [D loss: 0.699343, acc: 0.501953]: [A loss: 0.744898, acc: 0.136719]\n",
      "4034: [D loss: 0.695007, acc: 0.515625]: [A loss: 0.713695, acc: 0.359375]\n",
      "4035: [D loss: 0.698404, acc: 0.464844]: [A loss: 0.708038, acc: 0.382812]\n",
      "4036: [D loss: 0.697126, acc: 0.511719]: [A loss: 0.713382, acc: 0.339844]\n",
      "4037: [D loss: 0.692391, acc: 0.521484]: [A loss: 0.710114, acc: 0.363281]\n",
      "4038: [D loss: 0.697558, acc: 0.492188]: [A loss: 0.705116, acc: 0.355469]\n",
      "4039: [D loss: 0.698443, acc: 0.488281]: [A loss: 0.697723, acc: 0.464844]\n",
      "4040: [D loss: 0.698599, acc: 0.460938]: [A loss: 0.686435, acc: 0.488281]\n",
      "4041: [D loss: 0.694243, acc: 0.509766]: [A loss: 0.690289, acc: 0.523438]\n",
      "4042: [D loss: 0.697938, acc: 0.513672]: [A loss: 0.735898, acc: 0.160156]\n",
      "4043: [D loss: 0.696376, acc: 0.474609]: [A loss: 0.712362, acc: 0.339844]\n",
      "4044: [D loss: 0.695741, acc: 0.513672]: [A loss: 0.738384, acc: 0.230469]\n",
      "4045: [D loss: 0.691456, acc: 0.513672]: [A loss: 0.706159, acc: 0.410156]\n",
      "4046: [D loss: 0.698762, acc: 0.482422]: [A loss: 0.741185, acc: 0.152344]\n",
      "4047: [D loss: 0.695140, acc: 0.513672]: [A loss: 0.715258, acc: 0.328125]\n",
      "4048: [D loss: 0.693412, acc: 0.503906]: [A loss: 0.680303, acc: 0.601562]\n",
      "4049: [D loss: 0.694796, acc: 0.505859]: [A loss: 0.705493, acc: 0.406250]\n",
      "4050: [D loss: 0.693486, acc: 0.523438]: [A loss: 0.710359, acc: 0.359375]\n",
      "4051: [D loss: 0.701324, acc: 0.476562]: [A loss: 0.727178, acc: 0.242188]\n",
      "4052: [D loss: 0.693531, acc: 0.496094]: [A loss: 0.692739, acc: 0.492188]\n",
      "4053: [D loss: 0.700830, acc: 0.503906]: [A loss: 0.756254, acc: 0.082031]\n",
      "4054: [D loss: 0.695377, acc: 0.484375]: [A loss: 0.716098, acc: 0.339844]\n",
      "4055: [D loss: 0.695286, acc: 0.501953]: [A loss: 0.708227, acc: 0.367188]\n",
      "4056: [D loss: 0.694104, acc: 0.515625]: [A loss: 0.719020, acc: 0.277344]\n",
      "4057: [D loss: 0.696047, acc: 0.500000]: [A loss: 0.716073, acc: 0.320312]\n",
      "4058: [D loss: 0.695614, acc: 0.501953]: [A loss: 0.709403, acc: 0.375000]\n",
      "4059: [D loss: 0.697433, acc: 0.492188]: [A loss: 0.724274, acc: 0.269531]\n",
      "4060: [D loss: 0.691399, acc: 0.515625]: [A loss: 0.709082, acc: 0.347656]\n",
      "4061: [D loss: 0.693317, acc: 0.509766]: [A loss: 0.710978, acc: 0.332031]\n",
      "4062: [D loss: 0.698589, acc: 0.476562]: [A loss: 0.695748, acc: 0.457031]\n",
      "4063: [D loss: 0.699805, acc: 0.474609]: [A loss: 0.705971, acc: 0.367188]\n",
      "4064: [D loss: 0.697324, acc: 0.490234]: [A loss: 0.703574, acc: 0.382812]\n",
      "4065: [D loss: 0.691477, acc: 0.542969]: [A loss: 0.697537, acc: 0.468750]\n",
      "4066: [D loss: 0.695681, acc: 0.503906]: [A loss: 0.717698, acc: 0.308594]\n",
      "4067: [D loss: 0.690404, acc: 0.517578]: [A loss: 0.715333, acc: 0.363281]\n",
      "4068: [D loss: 0.689869, acc: 0.529297]: [A loss: 0.676043, acc: 0.589844]\n",
      "4069: [D loss: 0.701015, acc: 0.509766]: [A loss: 0.730877, acc: 0.218750]\n",
      "4070: [D loss: 0.693148, acc: 0.515625]: [A loss: 0.694154, acc: 0.507812]\n",
      "4071: [D loss: 0.694469, acc: 0.531250]: [A loss: 0.705774, acc: 0.367188]\n",
      "4072: [D loss: 0.694352, acc: 0.517578]: [A loss: 0.716603, acc: 0.285156]\n",
      "4073: [D loss: 0.693846, acc: 0.525391]: [A loss: 0.694359, acc: 0.453125]\n",
      "4074: [D loss: 0.698382, acc: 0.498047]: [A loss: 0.712078, acc: 0.343750]\n",
      "4075: [D loss: 0.697395, acc: 0.484375]: [A loss: 0.714779, acc: 0.343750]\n",
      "4076: [D loss: 0.692553, acc: 0.529297]: [A loss: 0.712489, acc: 0.332031]\n",
      "4077: [D loss: 0.691390, acc: 0.500000]: [A loss: 0.671403, acc: 0.632812]\n",
      "4078: [D loss: 0.706814, acc: 0.492188]: [A loss: 0.750717, acc: 0.089844]\n",
      "4079: [D loss: 0.697372, acc: 0.494141]: [A loss: 0.711321, acc: 0.312500]\n",
      "4080: [D loss: 0.691194, acc: 0.542969]: [A loss: 0.675133, acc: 0.644531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4081: [D loss: 0.692613, acc: 0.535156]: [A loss: 0.709854, acc: 0.343750]\n",
      "4082: [D loss: 0.693614, acc: 0.531250]: [A loss: 0.701474, acc: 0.394531]\n",
      "4083: [D loss: 0.694187, acc: 0.529297]: [A loss: 0.700625, acc: 0.417969]\n",
      "4084: [D loss: 0.695472, acc: 0.480469]: [A loss: 0.698963, acc: 0.460938]\n",
      "4085: [D loss: 0.694215, acc: 0.525391]: [A loss: 0.695054, acc: 0.453125]\n",
      "4086: [D loss: 0.695868, acc: 0.484375]: [A loss: 0.713007, acc: 0.378906]\n",
      "4087: [D loss: 0.691760, acc: 0.529297]: [A loss: 0.694375, acc: 0.488281]\n",
      "4088: [D loss: 0.697254, acc: 0.500000]: [A loss: 0.706152, acc: 0.378906]\n",
      "4089: [D loss: 0.693034, acc: 0.501953]: [A loss: 0.691466, acc: 0.515625]\n",
      "4090: [D loss: 0.699918, acc: 0.519531]: [A loss: 0.729259, acc: 0.250000]\n",
      "4091: [D loss: 0.695142, acc: 0.507812]: [A loss: 0.724822, acc: 0.269531]\n",
      "4092: [D loss: 0.694509, acc: 0.503906]: [A loss: 0.711220, acc: 0.316406]\n",
      "4093: [D loss: 0.691760, acc: 0.533203]: [A loss: 0.702621, acc: 0.417969]\n",
      "4094: [D loss: 0.691932, acc: 0.546875]: [A loss: 0.702535, acc: 0.371094]\n",
      "4095: [D loss: 0.692468, acc: 0.531250]: [A loss: 0.697909, acc: 0.464844]\n",
      "4096: [D loss: 0.696967, acc: 0.496094]: [A loss: 0.699108, acc: 0.464844]\n",
      "4097: [D loss: 0.691287, acc: 0.525391]: [A loss: 0.692076, acc: 0.472656]\n",
      "4098: [D loss: 0.693856, acc: 0.519531]: [A loss: 0.738099, acc: 0.144531]\n",
      "4099: [D loss: 0.690529, acc: 0.542969]: [A loss: 0.681776, acc: 0.539062]\n",
      "4100: [D loss: 0.695706, acc: 0.548828]: [A loss: 0.736002, acc: 0.195312]\n",
      "4101: [D loss: 0.693515, acc: 0.498047]: [A loss: 0.709512, acc: 0.347656]\n",
      "4102: [D loss: 0.694121, acc: 0.511719]: [A loss: 0.684944, acc: 0.535156]\n",
      "4103: [D loss: 0.696154, acc: 0.513672]: [A loss: 0.721680, acc: 0.281250]\n",
      "4104: [D loss: 0.697885, acc: 0.486328]: [A loss: 0.719608, acc: 0.300781]\n",
      "4105: [D loss: 0.697233, acc: 0.494141]: [A loss: 0.740261, acc: 0.175781]\n",
      "4106: [D loss: 0.694481, acc: 0.507812]: [A loss: 0.699022, acc: 0.410156]\n",
      "4107: [D loss: 0.692768, acc: 0.517578]: [A loss: 0.709333, acc: 0.382812]\n",
      "4108: [D loss: 0.697843, acc: 0.494141]: [A loss: 0.719108, acc: 0.296875]\n",
      "4109: [D loss: 0.697073, acc: 0.470703]: [A loss: 0.692025, acc: 0.484375]\n",
      "4110: [D loss: 0.693776, acc: 0.517578]: [A loss: 0.686368, acc: 0.546875]\n",
      "4111: [D loss: 0.693274, acc: 0.517578]: [A loss: 0.706287, acc: 0.425781]\n",
      "4112: [D loss: 0.695780, acc: 0.486328]: [A loss: 0.690833, acc: 0.519531]\n",
      "4113: [D loss: 0.701550, acc: 0.490234]: [A loss: 0.745510, acc: 0.164062]\n",
      "4114: [D loss: 0.690997, acc: 0.517578]: [A loss: 0.688630, acc: 0.523438]\n",
      "4115: [D loss: 0.695395, acc: 0.509766]: [A loss: 0.711846, acc: 0.332031]\n",
      "4116: [D loss: 0.691725, acc: 0.501953]: [A loss: 0.703842, acc: 0.390625]\n",
      "4117: [D loss: 0.699380, acc: 0.507812]: [A loss: 0.715797, acc: 0.304688]\n",
      "4118: [D loss: 0.699385, acc: 0.494141]: [A loss: 0.699982, acc: 0.441406]\n",
      "4119: [D loss: 0.692469, acc: 0.509766]: [A loss: 0.719795, acc: 0.300781]\n",
      "4120: [D loss: 0.694153, acc: 0.507812]: [A loss: 0.697418, acc: 0.457031]\n",
      "4121: [D loss: 0.690659, acc: 0.521484]: [A loss: 0.689911, acc: 0.464844]\n",
      "4122: [D loss: 0.696430, acc: 0.507812]: [A loss: 0.721764, acc: 0.253906]\n",
      "4123: [D loss: 0.698673, acc: 0.460938]: [A loss: 0.710201, acc: 0.359375]\n",
      "4124: [D loss: 0.696277, acc: 0.505859]: [A loss: 0.715703, acc: 0.320312]\n",
      "4125: [D loss: 0.691829, acc: 0.517578]: [A loss: 0.699091, acc: 0.460938]\n",
      "4126: [D loss: 0.697885, acc: 0.470703]: [A loss: 0.687141, acc: 0.527344]\n",
      "4127: [D loss: 0.695378, acc: 0.509766]: [A loss: 0.694424, acc: 0.468750]\n",
      "4128: [D loss: 0.697069, acc: 0.503906]: [A loss: 0.710320, acc: 0.332031]\n",
      "4129: [D loss: 0.694085, acc: 0.503906]: [A loss: 0.715676, acc: 0.292969]\n",
      "4130: [D loss: 0.694677, acc: 0.500000]: [A loss: 0.695610, acc: 0.457031]\n",
      "4131: [D loss: 0.700102, acc: 0.478516]: [A loss: 0.736136, acc: 0.234375]\n",
      "4132: [D loss: 0.689922, acc: 0.550781]: [A loss: 0.715332, acc: 0.324219]\n",
      "4133: [D loss: 0.697887, acc: 0.490234]: [A loss: 0.708581, acc: 0.363281]\n",
      "4134: [D loss: 0.696111, acc: 0.488281]: [A loss: 0.695394, acc: 0.496094]\n",
      "4135: [D loss: 0.692466, acc: 0.505859]: [A loss: 0.706286, acc: 0.398438]\n",
      "4136: [D loss: 0.694000, acc: 0.501953]: [A loss: 0.667938, acc: 0.675781]\n",
      "4137: [D loss: 0.700096, acc: 0.505859]: [A loss: 0.733435, acc: 0.222656]\n",
      "4138: [D loss: 0.691112, acc: 0.492188]: [A loss: 0.690349, acc: 0.519531]\n",
      "4139: [D loss: 0.694096, acc: 0.503906]: [A loss: 0.688812, acc: 0.546875]\n",
      "4140: [D loss: 0.696368, acc: 0.513672]: [A loss: 0.710404, acc: 0.359375]\n",
      "4141: [D loss: 0.689621, acc: 0.574219]: [A loss: 0.700382, acc: 0.382812]\n",
      "4142: [D loss: 0.696834, acc: 0.480469]: [A loss: 0.710093, acc: 0.347656]\n",
      "4143: [D loss: 0.696262, acc: 0.496094]: [A loss: 0.688345, acc: 0.472656]\n",
      "4144: [D loss: 0.697441, acc: 0.515625]: [A loss: 0.705585, acc: 0.394531]\n",
      "4145: [D loss: 0.695090, acc: 0.515625]: [A loss: 0.712950, acc: 0.343750]\n",
      "4146: [D loss: 0.697472, acc: 0.492188]: [A loss: 0.717189, acc: 0.316406]\n",
      "4147: [D loss: 0.688892, acc: 0.541016]: [A loss: 0.675417, acc: 0.597656]\n",
      "4148: [D loss: 0.698022, acc: 0.511719]: [A loss: 0.751536, acc: 0.152344]\n",
      "4149: [D loss: 0.693092, acc: 0.517578]: [A loss: 0.698952, acc: 0.421875]\n",
      "4150: [D loss: 0.691800, acc: 0.521484]: [A loss: 0.699129, acc: 0.417969]\n",
      "4151: [D loss: 0.693924, acc: 0.507812]: [A loss: 0.714421, acc: 0.335938]\n",
      "4152: [D loss: 0.691246, acc: 0.517578]: [A loss: 0.680374, acc: 0.574219]\n",
      "4153: [D loss: 0.702773, acc: 0.488281]: [A loss: 0.732464, acc: 0.203125]\n",
      "4154: [D loss: 0.691920, acc: 0.527344]: [A loss: 0.695465, acc: 0.472656]\n",
      "4155: [D loss: 0.694790, acc: 0.525391]: [A loss: 0.682271, acc: 0.589844]\n",
      "4156: [D loss: 0.697367, acc: 0.509766]: [A loss: 0.707991, acc: 0.367188]\n",
      "4157: [D loss: 0.696553, acc: 0.472656]: [A loss: 0.694654, acc: 0.468750]\n",
      "4158: [D loss: 0.696839, acc: 0.482422]: [A loss: 0.705224, acc: 0.355469]\n",
      "4159: [D loss: 0.689291, acc: 0.554688]: [A loss: 0.690629, acc: 0.500000]\n",
      "4160: [D loss: 0.696384, acc: 0.505859]: [A loss: 0.726496, acc: 0.269531]\n",
      "4161: [D loss: 0.694208, acc: 0.533203]: [A loss: 0.721187, acc: 0.308594]\n",
      "4162: [D loss: 0.699709, acc: 0.494141]: [A loss: 0.701984, acc: 0.378906]\n",
      "4163: [D loss: 0.698497, acc: 0.496094]: [A loss: 0.708311, acc: 0.328125]\n",
      "4164: [D loss: 0.693491, acc: 0.521484]: [A loss: 0.694353, acc: 0.511719]\n",
      "4165: [D loss: 0.697862, acc: 0.500000]: [A loss: 0.718593, acc: 0.292969]\n",
      "4166: [D loss: 0.695504, acc: 0.498047]: [A loss: 0.685180, acc: 0.523438]\n",
      "4167: [D loss: 0.697001, acc: 0.501953]: [A loss: 0.719655, acc: 0.339844]\n",
      "4168: [D loss: 0.694345, acc: 0.505859]: [A loss: 0.709811, acc: 0.394531]\n",
      "4169: [D loss: 0.694523, acc: 0.515625]: [A loss: 0.734345, acc: 0.218750]\n",
      "4170: [D loss: 0.695163, acc: 0.523438]: [A loss: 0.696889, acc: 0.468750]\n",
      "4171: [D loss: 0.698427, acc: 0.478516]: [A loss: 0.712904, acc: 0.308594]\n",
      "4172: [D loss: 0.695513, acc: 0.507812]: [A loss: 0.715418, acc: 0.312500]\n",
      "4173: [D loss: 0.696161, acc: 0.505859]: [A loss: 0.689989, acc: 0.484375]\n",
      "4174: [D loss: 0.700022, acc: 0.503906]: [A loss: 0.746278, acc: 0.164062]\n",
      "4175: [D loss: 0.694585, acc: 0.507812]: [A loss: 0.696091, acc: 0.433594]\n",
      "4176: [D loss: 0.697262, acc: 0.486328]: [A loss: 0.704293, acc: 0.402344]\n",
      "4177: [D loss: 0.691140, acc: 0.519531]: [A loss: 0.686477, acc: 0.519531]\n",
      "4178: [D loss: 0.695357, acc: 0.492188]: [A loss: 0.709715, acc: 0.355469]\n",
      "4179: [D loss: 0.699842, acc: 0.458984]: [A loss: 0.723280, acc: 0.265625]\n",
      "4180: [D loss: 0.694527, acc: 0.507812]: [A loss: 0.705382, acc: 0.367188]\n",
      "4181: [D loss: 0.698094, acc: 0.482422]: [A loss: 0.711833, acc: 0.359375]\n",
      "4182: [D loss: 0.695551, acc: 0.546875]: [A loss: 0.715277, acc: 0.339844]\n",
      "4183: [D loss: 0.694154, acc: 0.517578]: [A loss: 0.719294, acc: 0.257812]\n",
      "4184: [D loss: 0.693792, acc: 0.472656]: [A loss: 0.706404, acc: 0.355469]\n",
      "4185: [D loss: 0.693219, acc: 0.492188]: [A loss: 0.728989, acc: 0.199219]\n",
      "4186: [D loss: 0.695711, acc: 0.515625]: [A loss: 0.718145, acc: 0.277344]\n",
      "4187: [D loss: 0.697411, acc: 0.498047]: [A loss: 0.726581, acc: 0.246094]\n",
      "4188: [D loss: 0.694339, acc: 0.521484]: [A loss: 0.724053, acc: 0.257812]\n",
      "4189: [D loss: 0.697184, acc: 0.498047]: [A loss: 0.706351, acc: 0.417969]\n",
      "4190: [D loss: 0.690574, acc: 0.531250]: [A loss: 0.691368, acc: 0.515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4191: [D loss: 0.692530, acc: 0.513672]: [A loss: 0.720671, acc: 0.285156]\n",
      "4192: [D loss: 0.690552, acc: 0.505859]: [A loss: 0.692522, acc: 0.460938]\n",
      "4193: [D loss: 0.696906, acc: 0.513672]: [A loss: 0.731256, acc: 0.226562]\n",
      "4194: [D loss: 0.691785, acc: 0.533203]: [A loss: 0.701254, acc: 0.429688]\n",
      "4195: [D loss: 0.691500, acc: 0.541016]: [A loss: 0.704550, acc: 0.375000]\n",
      "4196: [D loss: 0.694959, acc: 0.494141]: [A loss: 0.694166, acc: 0.488281]\n",
      "4197: [D loss: 0.690280, acc: 0.498047]: [A loss: 0.668967, acc: 0.687500]\n",
      "4198: [D loss: 0.696568, acc: 0.492188]: [A loss: 0.725447, acc: 0.230469]\n",
      "4199: [D loss: 0.693125, acc: 0.513672]: [A loss: 0.712803, acc: 0.351562]\n",
      "4200: [D loss: 0.692103, acc: 0.509766]: [A loss: 0.704261, acc: 0.406250]\n",
      "4201: [D loss: 0.697576, acc: 0.498047]: [A loss: 0.712851, acc: 0.324219]\n",
      "4202: [D loss: 0.695777, acc: 0.515625]: [A loss: 0.713930, acc: 0.328125]\n",
      "4203: [D loss: 0.696545, acc: 0.500000]: [A loss: 0.712751, acc: 0.312500]\n",
      "4204: [D loss: 0.693431, acc: 0.505859]: [A loss: 0.691652, acc: 0.511719]\n",
      "4205: [D loss: 0.696176, acc: 0.527344]: [A loss: 0.727940, acc: 0.253906]\n",
      "4206: [D loss: 0.693444, acc: 0.519531]: [A loss: 0.692478, acc: 0.472656]\n",
      "4207: [D loss: 0.694198, acc: 0.523438]: [A loss: 0.688687, acc: 0.546875]\n",
      "4208: [D loss: 0.695224, acc: 0.541016]: [A loss: 0.718728, acc: 0.296875]\n",
      "4209: [D loss: 0.696558, acc: 0.496094]: [A loss: 0.700411, acc: 0.445312]\n",
      "4210: [D loss: 0.693869, acc: 0.501953]: [A loss: 0.713416, acc: 0.355469]\n",
      "4211: [D loss: 0.696277, acc: 0.501953]: [A loss: 0.742636, acc: 0.167969]\n",
      "4212: [D loss: 0.690670, acc: 0.552734]: [A loss: 0.690628, acc: 0.492188]\n",
      "4213: [D loss: 0.695481, acc: 0.525391]: [A loss: 0.692851, acc: 0.476562]\n",
      "4214: [D loss: 0.697940, acc: 0.478516]: [A loss: 0.694889, acc: 0.480469]\n",
      "4215: [D loss: 0.696082, acc: 0.494141]: [A loss: 0.708956, acc: 0.363281]\n",
      "4216: [D loss: 0.696852, acc: 0.484375]: [A loss: 0.699664, acc: 0.421875]\n",
      "4217: [D loss: 0.693303, acc: 0.521484]: [A loss: 0.685178, acc: 0.539062]\n",
      "4218: [D loss: 0.703154, acc: 0.501953]: [A loss: 0.758367, acc: 0.085938]\n",
      "4219: [D loss: 0.691389, acc: 0.517578]: [A loss: 0.707929, acc: 0.378906]\n",
      "4220: [D loss: 0.697511, acc: 0.492188]: [A loss: 0.703718, acc: 0.410156]\n",
      "4221: [D loss: 0.699244, acc: 0.478516]: [A loss: 0.711728, acc: 0.367188]\n",
      "4222: [D loss: 0.697871, acc: 0.478516]: [A loss: 0.706282, acc: 0.394531]\n",
      "4223: [D loss: 0.695117, acc: 0.509766]: [A loss: 0.688371, acc: 0.535156]\n",
      "4224: [D loss: 0.695241, acc: 0.486328]: [A loss: 0.706205, acc: 0.386719]\n",
      "4225: [D loss: 0.692437, acc: 0.503906]: [A loss: 0.703315, acc: 0.394531]\n",
      "4226: [D loss: 0.700532, acc: 0.488281]: [A loss: 0.712807, acc: 0.363281]\n",
      "4227: [D loss: 0.694967, acc: 0.517578]: [A loss: 0.690507, acc: 0.472656]\n",
      "4228: [D loss: 0.694056, acc: 0.507812]: [A loss: 0.702036, acc: 0.417969]\n",
      "4229: [D loss: 0.690131, acc: 0.535156]: [A loss: 0.688527, acc: 0.519531]\n",
      "4230: [D loss: 0.696772, acc: 0.500000]: [A loss: 0.760405, acc: 0.089844]\n",
      "4231: [D loss: 0.694477, acc: 0.474609]: [A loss: 0.701738, acc: 0.355469]\n",
      "4232: [D loss: 0.696342, acc: 0.496094]: [A loss: 0.688999, acc: 0.484375]\n",
      "4233: [D loss: 0.699302, acc: 0.472656]: [A loss: 0.702199, acc: 0.382812]\n",
      "4234: [D loss: 0.700290, acc: 0.464844]: [A loss: 0.726483, acc: 0.261719]\n",
      "4235: [D loss: 0.694550, acc: 0.513672]: [A loss: 0.705935, acc: 0.367188]\n",
      "4236: [D loss: 0.696238, acc: 0.482422]: [A loss: 0.704426, acc: 0.402344]\n",
      "4237: [D loss: 0.695698, acc: 0.470703]: [A loss: 0.705608, acc: 0.386719]\n",
      "4238: [D loss: 0.694487, acc: 0.509766]: [A loss: 0.700227, acc: 0.453125]\n",
      "4239: [D loss: 0.699537, acc: 0.498047]: [A loss: 0.708796, acc: 0.382812]\n",
      "4240: [D loss: 0.694010, acc: 0.488281]: [A loss: 0.693035, acc: 0.472656]\n",
      "4241: [D loss: 0.695737, acc: 0.519531]: [A loss: 0.718370, acc: 0.273438]\n",
      "4242: [D loss: 0.695003, acc: 0.527344]: [A loss: 0.707188, acc: 0.394531]\n",
      "4243: [D loss: 0.698718, acc: 0.474609]: [A loss: 0.700753, acc: 0.449219]\n",
      "4244: [D loss: 0.702335, acc: 0.498047]: [A loss: 0.733583, acc: 0.195312]\n",
      "4245: [D loss: 0.695178, acc: 0.490234]: [A loss: 0.699008, acc: 0.425781]\n",
      "4246: [D loss: 0.696656, acc: 0.490234]: [A loss: 0.710785, acc: 0.335938]\n",
      "4247: [D loss: 0.698281, acc: 0.513672]: [A loss: 0.713977, acc: 0.335938]\n",
      "4248: [D loss: 0.696638, acc: 0.505859]: [A loss: 0.712338, acc: 0.371094]\n",
      "4249: [D loss: 0.694512, acc: 0.523438]: [A loss: 0.694986, acc: 0.472656]\n",
      "4250: [D loss: 0.693038, acc: 0.501953]: [A loss: 0.695893, acc: 0.449219]\n",
      "4251: [D loss: 0.696827, acc: 0.505859]: [A loss: 0.731269, acc: 0.207031]\n",
      "4252: [D loss: 0.693207, acc: 0.509766]: [A loss: 0.687462, acc: 0.460938]\n",
      "4253: [D loss: 0.692397, acc: 0.521484]: [A loss: 0.676840, acc: 0.582031]\n",
      "4254: [D loss: 0.696818, acc: 0.488281]: [A loss: 0.725944, acc: 0.261719]\n",
      "4255: [D loss: 0.692421, acc: 0.511719]: [A loss: 0.678454, acc: 0.609375]\n",
      "4256: [D loss: 0.699376, acc: 0.494141]: [A loss: 0.707266, acc: 0.375000]\n",
      "4257: [D loss: 0.692471, acc: 0.531250]: [A loss: 0.710333, acc: 0.425781]\n",
      "4258: [D loss: 0.694378, acc: 0.500000]: [A loss: 0.707632, acc: 0.378906]\n",
      "4259: [D loss: 0.692328, acc: 0.517578]: [A loss: 0.699814, acc: 0.429688]\n",
      "4260: [D loss: 0.699861, acc: 0.501953]: [A loss: 0.740553, acc: 0.128906]\n",
      "4261: [D loss: 0.692168, acc: 0.519531]: [A loss: 0.700239, acc: 0.394531]\n",
      "4262: [D loss: 0.697644, acc: 0.494141]: [A loss: 0.712885, acc: 0.320312]\n",
      "4263: [D loss: 0.689637, acc: 0.533203]: [A loss: 0.677777, acc: 0.593750]\n",
      "4264: [D loss: 0.695026, acc: 0.513672]: [A loss: 0.690643, acc: 0.515625]\n",
      "4265: [D loss: 0.694358, acc: 0.480469]: [A loss: 0.700683, acc: 0.425781]\n",
      "4266: [D loss: 0.694814, acc: 0.519531]: [A loss: 0.714893, acc: 0.320312]\n",
      "4267: [D loss: 0.697442, acc: 0.492188]: [A loss: 0.722120, acc: 0.292969]\n",
      "4268: [D loss: 0.694143, acc: 0.527344]: [A loss: 0.712604, acc: 0.343750]\n",
      "4269: [D loss: 0.698158, acc: 0.482422]: [A loss: 0.742100, acc: 0.195312]\n",
      "4270: [D loss: 0.697594, acc: 0.486328]: [A loss: 0.701828, acc: 0.449219]\n",
      "4271: [D loss: 0.698704, acc: 0.498047]: [A loss: 0.701182, acc: 0.394531]\n",
      "4272: [D loss: 0.695835, acc: 0.486328]: [A loss: 0.702873, acc: 0.414062]\n",
      "4273: [D loss: 0.691769, acc: 0.537109]: [A loss: 0.687827, acc: 0.515625]\n",
      "4274: [D loss: 0.697435, acc: 0.492188]: [A loss: 0.700596, acc: 0.464844]\n",
      "4275: [D loss: 0.694391, acc: 0.525391]: [A loss: 0.717436, acc: 0.339844]\n",
      "4276: [D loss: 0.695120, acc: 0.474609]: [A loss: 0.699582, acc: 0.437500]\n",
      "4277: [D loss: 0.697178, acc: 0.503906]: [A loss: 0.732773, acc: 0.230469]\n",
      "4278: [D loss: 0.697486, acc: 0.490234]: [A loss: 0.717105, acc: 0.316406]\n",
      "4279: [D loss: 0.694410, acc: 0.505859]: [A loss: 0.697631, acc: 0.480469]\n",
      "4280: [D loss: 0.695438, acc: 0.492188]: [A loss: 0.697669, acc: 0.437500]\n",
      "4281: [D loss: 0.694597, acc: 0.480469]: [A loss: 0.704323, acc: 0.410156]\n",
      "4282: [D loss: 0.697970, acc: 0.484375]: [A loss: 0.738079, acc: 0.187500]\n",
      "4283: [D loss: 0.694936, acc: 0.492188]: [A loss: 0.681002, acc: 0.562500]\n",
      "4284: [D loss: 0.696236, acc: 0.498047]: [A loss: 0.727426, acc: 0.242188]\n",
      "4285: [D loss: 0.698520, acc: 0.498047]: [A loss: 0.704622, acc: 0.367188]\n",
      "4286: [D loss: 0.699888, acc: 0.478516]: [A loss: 0.685584, acc: 0.507812]\n",
      "4287: [D loss: 0.699858, acc: 0.498047]: [A loss: 0.717149, acc: 0.289062]\n",
      "4288: [D loss: 0.695489, acc: 0.486328]: [A loss: 0.720277, acc: 0.261719]\n",
      "4289: [D loss: 0.699027, acc: 0.455078]: [A loss: 0.703422, acc: 0.410156]\n",
      "4290: [D loss: 0.693344, acc: 0.515625]: [A loss: 0.690022, acc: 0.515625]\n",
      "4291: [D loss: 0.699575, acc: 0.492188]: [A loss: 0.709657, acc: 0.316406]\n",
      "4292: [D loss: 0.696751, acc: 0.484375]: [A loss: 0.730075, acc: 0.242188]\n",
      "4293: [D loss: 0.692615, acc: 0.537109]: [A loss: 0.703011, acc: 0.390625]\n",
      "4294: [D loss: 0.701224, acc: 0.494141]: [A loss: 0.706523, acc: 0.367188]\n",
      "4295: [D loss: 0.691422, acc: 0.523438]: [A loss: 0.708564, acc: 0.351562]\n",
      "4296: [D loss: 0.691172, acc: 0.535156]: [A loss: 0.703472, acc: 0.371094]\n",
      "4297: [D loss: 0.690065, acc: 0.535156]: [A loss: 0.703444, acc: 0.398438]\n",
      "4298: [D loss: 0.691110, acc: 0.546875]: [A loss: 0.715557, acc: 0.343750]\n",
      "4299: [D loss: 0.691643, acc: 0.517578]: [A loss: 0.709665, acc: 0.371094]\n",
      "4300: [D loss: 0.690695, acc: 0.503906]: [A loss: 0.716998, acc: 0.277344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4301: [D loss: 0.692445, acc: 0.507812]: [A loss: 0.706489, acc: 0.390625]\n",
      "4302: [D loss: 0.691429, acc: 0.517578]: [A loss: 0.684541, acc: 0.539062]\n",
      "4303: [D loss: 0.694378, acc: 0.513672]: [A loss: 0.686209, acc: 0.527344]\n",
      "4304: [D loss: 0.697065, acc: 0.507812]: [A loss: 0.722857, acc: 0.234375]\n",
      "4305: [D loss: 0.697445, acc: 0.507812]: [A loss: 0.719011, acc: 0.296875]\n",
      "4306: [D loss: 0.694895, acc: 0.488281]: [A loss: 0.696048, acc: 0.449219]\n",
      "4307: [D loss: 0.697755, acc: 0.478516]: [A loss: 0.728349, acc: 0.210938]\n",
      "4308: [D loss: 0.696886, acc: 0.494141]: [A loss: 0.717483, acc: 0.289062]\n",
      "4309: [D loss: 0.694169, acc: 0.511719]: [A loss: 0.719800, acc: 0.296875]\n",
      "4310: [D loss: 0.693440, acc: 0.539062]: [A loss: 0.740761, acc: 0.183594]\n",
      "4311: [D loss: 0.691944, acc: 0.507812]: [A loss: 0.692148, acc: 0.507812]\n",
      "4312: [D loss: 0.694683, acc: 0.527344]: [A loss: 0.753361, acc: 0.179688]\n",
      "4313: [D loss: 0.696000, acc: 0.515625]: [A loss: 0.708322, acc: 0.351562]\n",
      "4314: [D loss: 0.692837, acc: 0.521484]: [A loss: 0.705380, acc: 0.410156]\n",
      "4315: [D loss: 0.695249, acc: 0.511719]: [A loss: 0.712606, acc: 0.347656]\n",
      "4316: [D loss: 0.692912, acc: 0.535156]: [A loss: 0.690979, acc: 0.496094]\n",
      "4317: [D loss: 0.699610, acc: 0.505859]: [A loss: 0.720580, acc: 0.242188]\n",
      "4318: [D loss: 0.691189, acc: 0.533203]: [A loss: 0.711292, acc: 0.343750]\n",
      "4319: [D loss: 0.694802, acc: 0.503906]: [A loss: 0.710483, acc: 0.312500]\n",
      "4320: [D loss: 0.695358, acc: 0.505859]: [A loss: 0.723987, acc: 0.304688]\n",
      "4321: [D loss: 0.697413, acc: 0.494141]: [A loss: 0.735837, acc: 0.195312]\n",
      "4322: [D loss: 0.694190, acc: 0.496094]: [A loss: 0.712505, acc: 0.328125]\n",
      "4323: [D loss: 0.695779, acc: 0.507812]: [A loss: 0.714310, acc: 0.343750]\n",
      "4324: [D loss: 0.696198, acc: 0.521484]: [A loss: 0.702964, acc: 0.433594]\n",
      "4325: [D loss: 0.700828, acc: 0.478516]: [A loss: 0.726945, acc: 0.257812]\n",
      "4326: [D loss: 0.691048, acc: 0.527344]: [A loss: 0.700762, acc: 0.429688]\n",
      "4327: [D loss: 0.696259, acc: 0.501953]: [A loss: 0.740847, acc: 0.167969]\n",
      "4328: [D loss: 0.691713, acc: 0.515625]: [A loss: 0.712348, acc: 0.343750]\n",
      "4329: [D loss: 0.697243, acc: 0.474609]: [A loss: 0.701813, acc: 0.425781]\n",
      "4330: [D loss: 0.701511, acc: 0.513672]: [A loss: 0.751866, acc: 0.156250]\n",
      "4331: [D loss: 0.694633, acc: 0.494141]: [A loss: 0.691204, acc: 0.472656]\n",
      "4332: [D loss: 0.697832, acc: 0.494141]: [A loss: 0.692717, acc: 0.488281]\n",
      "4333: [D loss: 0.698150, acc: 0.498047]: [A loss: 0.687241, acc: 0.523438]\n",
      "4334: [D loss: 0.699553, acc: 0.478516]: [A loss: 0.738699, acc: 0.210938]\n",
      "4335: [D loss: 0.694499, acc: 0.490234]: [A loss: 0.715358, acc: 0.320312]\n",
      "4336: [D loss: 0.699086, acc: 0.480469]: [A loss: 0.726986, acc: 0.242188]\n",
      "4337: [D loss: 0.699212, acc: 0.486328]: [A loss: 0.722667, acc: 0.269531]\n",
      "4338: [D loss: 0.694424, acc: 0.500000]: [A loss: 0.706747, acc: 0.406250]\n",
      "4339: [D loss: 0.695162, acc: 0.503906]: [A loss: 0.715910, acc: 0.300781]\n",
      "4340: [D loss: 0.690572, acc: 0.535156]: [A loss: 0.715310, acc: 0.316406]\n",
      "4341: [D loss: 0.694296, acc: 0.503906]: [A loss: 0.721409, acc: 0.253906]\n",
      "4342: [D loss: 0.693038, acc: 0.484375]: [A loss: 0.698664, acc: 0.417969]\n",
      "4343: [D loss: 0.699181, acc: 0.513672]: [A loss: 0.722404, acc: 0.300781]\n",
      "4344: [D loss: 0.695189, acc: 0.488281]: [A loss: 0.715950, acc: 0.328125]\n",
      "4345: [D loss: 0.694730, acc: 0.484375]: [A loss: 0.708202, acc: 0.363281]\n",
      "4346: [D loss: 0.693536, acc: 0.521484]: [A loss: 0.714649, acc: 0.343750]\n",
      "4347: [D loss: 0.694714, acc: 0.490234]: [A loss: 0.720642, acc: 0.253906]\n",
      "4348: [D loss: 0.694224, acc: 0.490234]: [A loss: 0.686268, acc: 0.531250]\n",
      "4349: [D loss: 0.692512, acc: 0.507812]: [A loss: 0.727288, acc: 0.261719]\n",
      "4350: [D loss: 0.699889, acc: 0.490234]: [A loss: 0.713417, acc: 0.300781]\n",
      "4351: [D loss: 0.697005, acc: 0.500000]: [A loss: 0.731294, acc: 0.203125]\n",
      "4352: [D loss: 0.693719, acc: 0.513672]: [A loss: 0.709220, acc: 0.343750]\n",
      "4353: [D loss: 0.692582, acc: 0.511719]: [A loss: 0.675817, acc: 0.593750]\n",
      "4354: [D loss: 0.697331, acc: 0.507812]: [A loss: 0.706971, acc: 0.363281]\n",
      "4355: [D loss: 0.695408, acc: 0.500000]: [A loss: 0.712227, acc: 0.347656]\n",
      "4356: [D loss: 0.696398, acc: 0.490234]: [A loss: 0.706914, acc: 0.386719]\n",
      "4357: [D loss: 0.697180, acc: 0.474609]: [A loss: 0.718941, acc: 0.312500]\n",
      "4358: [D loss: 0.691681, acc: 0.500000]: [A loss: 0.682433, acc: 0.535156]\n",
      "4359: [D loss: 0.697911, acc: 0.480469]: [A loss: 0.722549, acc: 0.253906]\n",
      "4360: [D loss: 0.696204, acc: 0.457031]: [A loss: 0.724148, acc: 0.269531]\n",
      "4361: [D loss: 0.693354, acc: 0.505859]: [A loss: 0.690025, acc: 0.468750]\n",
      "4362: [D loss: 0.697210, acc: 0.486328]: [A loss: 0.734758, acc: 0.226562]\n",
      "4363: [D loss: 0.694175, acc: 0.507812]: [A loss: 0.710537, acc: 0.359375]\n",
      "4364: [D loss: 0.687053, acc: 0.527344]: [A loss: 0.692826, acc: 0.515625]\n",
      "4365: [D loss: 0.699139, acc: 0.494141]: [A loss: 0.701677, acc: 0.402344]\n",
      "4366: [D loss: 0.696247, acc: 0.496094]: [A loss: 0.696301, acc: 0.390625]\n",
      "4367: [D loss: 0.699960, acc: 0.478516]: [A loss: 0.695456, acc: 0.472656]\n",
      "4368: [D loss: 0.696979, acc: 0.482422]: [A loss: 0.734376, acc: 0.210938]\n",
      "4369: [D loss: 0.691912, acc: 0.533203]: [A loss: 0.685708, acc: 0.542969]\n",
      "4370: [D loss: 0.693757, acc: 0.523438]: [A loss: 0.731954, acc: 0.230469]\n",
      "4371: [D loss: 0.697801, acc: 0.482422]: [A loss: 0.714261, acc: 0.304688]\n",
      "4372: [D loss: 0.695245, acc: 0.464844]: [A loss: 0.688603, acc: 0.527344]\n",
      "4373: [D loss: 0.691619, acc: 0.529297]: [A loss: 0.722468, acc: 0.292969]\n",
      "4374: [D loss: 0.691029, acc: 0.513672]: [A loss: 0.682679, acc: 0.550781]\n",
      "4375: [D loss: 0.699211, acc: 0.488281]: [A loss: 0.754238, acc: 0.128906]\n",
      "4376: [D loss: 0.693384, acc: 0.515625]: [A loss: 0.704930, acc: 0.410156]\n",
      "4377: [D loss: 0.694164, acc: 0.511719]: [A loss: 0.698882, acc: 0.453125]\n",
      "4378: [D loss: 0.694206, acc: 0.494141]: [A loss: 0.713990, acc: 0.316406]\n",
      "4379: [D loss: 0.698510, acc: 0.484375]: [A loss: 0.701064, acc: 0.433594]\n",
      "4380: [D loss: 0.696410, acc: 0.503906]: [A loss: 0.718798, acc: 0.265625]\n",
      "4381: [D loss: 0.692831, acc: 0.509766]: [A loss: 0.704545, acc: 0.390625]\n",
      "4382: [D loss: 0.698849, acc: 0.468750]: [A loss: 0.725764, acc: 0.250000]\n",
      "4383: [D loss: 0.696390, acc: 0.505859]: [A loss: 0.716556, acc: 0.304688]\n",
      "4384: [D loss: 0.694339, acc: 0.513672]: [A loss: 0.725724, acc: 0.253906]\n",
      "4385: [D loss: 0.694505, acc: 0.482422]: [A loss: 0.695805, acc: 0.472656]\n",
      "4386: [D loss: 0.696418, acc: 0.488281]: [A loss: 0.714003, acc: 0.300781]\n",
      "4387: [D loss: 0.691614, acc: 0.529297]: [A loss: 0.686689, acc: 0.542969]\n",
      "4388: [D loss: 0.693707, acc: 0.507812]: [A loss: 0.688132, acc: 0.476562]\n",
      "4389: [D loss: 0.695560, acc: 0.505859]: [A loss: 0.732778, acc: 0.203125]\n",
      "4390: [D loss: 0.689704, acc: 0.529297]: [A loss: 0.684667, acc: 0.574219]\n",
      "4391: [D loss: 0.697083, acc: 0.490234]: [A loss: 0.759237, acc: 0.101562]\n",
      "4392: [D loss: 0.694452, acc: 0.478516]: [A loss: 0.697900, acc: 0.453125]\n",
      "4393: [D loss: 0.697857, acc: 0.507812]: [A loss: 0.719538, acc: 0.289062]\n",
      "4394: [D loss: 0.692418, acc: 0.503906]: [A loss: 0.729602, acc: 0.214844]\n",
      "4395: [D loss: 0.693268, acc: 0.523438]: [A loss: 0.715348, acc: 0.375000]\n",
      "4396: [D loss: 0.693177, acc: 0.513672]: [A loss: 0.726107, acc: 0.281250]\n",
      "4397: [D loss: 0.694900, acc: 0.527344]: [A loss: 0.699806, acc: 0.414062]\n",
      "4398: [D loss: 0.699488, acc: 0.447266]: [A loss: 0.714437, acc: 0.320312]\n",
      "4399: [D loss: 0.695088, acc: 0.511719]: [A loss: 0.703607, acc: 0.378906]\n",
      "4400: [D loss: 0.693966, acc: 0.523438]: [A loss: 0.707880, acc: 0.367188]\n",
      "4401: [D loss: 0.691213, acc: 0.529297]: [A loss: 0.714131, acc: 0.339844]\n",
      "4402: [D loss: 0.694786, acc: 0.478516]: [A loss: 0.723827, acc: 0.261719]\n",
      "4403: [D loss: 0.697138, acc: 0.494141]: [A loss: 0.701371, acc: 0.410156]\n",
      "4404: [D loss: 0.695182, acc: 0.494141]: [A loss: 0.751384, acc: 0.144531]\n",
      "4405: [D loss: 0.690419, acc: 0.509766]: [A loss: 0.701735, acc: 0.402344]\n",
      "4406: [D loss: 0.695409, acc: 0.505859]: [A loss: 0.720123, acc: 0.300781]\n",
      "4407: [D loss: 0.692341, acc: 0.531250]: [A loss: 0.691076, acc: 0.476562]\n",
      "4408: [D loss: 0.700083, acc: 0.496094]: [A loss: 0.755906, acc: 0.121094]\n",
      "4409: [D loss: 0.695028, acc: 0.500000]: [A loss: 0.721139, acc: 0.304688]\n",
      "4410: [D loss: 0.695351, acc: 0.503906]: [A loss: 0.708806, acc: 0.378906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4411: [D loss: 0.693460, acc: 0.494141]: [A loss: 0.732168, acc: 0.269531]\n",
      "4412: [D loss: 0.695677, acc: 0.482422]: [A loss: 0.691351, acc: 0.503906]\n",
      "4413: [D loss: 0.698469, acc: 0.496094]: [A loss: 0.721357, acc: 0.265625]\n",
      "4414: [D loss: 0.697635, acc: 0.500000]: [A loss: 0.722902, acc: 0.234375]\n",
      "4415: [D loss: 0.694469, acc: 0.498047]: [A loss: 0.726869, acc: 0.253906]\n",
      "4416: [D loss: 0.698162, acc: 0.494141]: [A loss: 0.716160, acc: 0.316406]\n",
      "4417: [D loss: 0.694641, acc: 0.501953]: [A loss: 0.699701, acc: 0.414062]\n",
      "4418: [D loss: 0.698283, acc: 0.490234]: [A loss: 0.712475, acc: 0.335938]\n",
      "4419: [D loss: 0.702022, acc: 0.466797]: [A loss: 0.747784, acc: 0.156250]\n",
      "4420: [D loss: 0.691417, acc: 0.513672]: [A loss: 0.685034, acc: 0.523438]\n",
      "4421: [D loss: 0.700275, acc: 0.500000]: [A loss: 0.742831, acc: 0.164062]\n",
      "4422: [D loss: 0.695664, acc: 0.488281]: [A loss: 0.702883, acc: 0.386719]\n",
      "4423: [D loss: 0.696399, acc: 0.505859]: [A loss: 0.730429, acc: 0.199219]\n",
      "4424: [D loss: 0.694458, acc: 0.503906]: [A loss: 0.693830, acc: 0.441406]\n",
      "4425: [D loss: 0.698547, acc: 0.503906]: [A loss: 0.735792, acc: 0.179688]\n",
      "4426: [D loss: 0.701805, acc: 0.457031]: [A loss: 0.722802, acc: 0.246094]\n",
      "4427: [D loss: 0.695789, acc: 0.484375]: [A loss: 0.670559, acc: 0.648438]\n",
      "4428: [D loss: 0.695559, acc: 0.503906]: [A loss: 0.755689, acc: 0.097656]\n",
      "4429: [D loss: 0.689317, acc: 0.519531]: [A loss: 0.678033, acc: 0.582031]\n",
      "4430: [D loss: 0.700307, acc: 0.484375]: [A loss: 0.756059, acc: 0.105469]\n",
      "4431: [D loss: 0.691785, acc: 0.546875]: [A loss: 0.697563, acc: 0.453125]\n",
      "4432: [D loss: 0.697313, acc: 0.486328]: [A loss: 0.729190, acc: 0.214844]\n",
      "4433: [D loss: 0.693999, acc: 0.500000]: [A loss: 0.701333, acc: 0.406250]\n",
      "4434: [D loss: 0.692039, acc: 0.529297]: [A loss: 0.689720, acc: 0.527344]\n",
      "4435: [D loss: 0.695426, acc: 0.513672]: [A loss: 0.725338, acc: 0.285156]\n",
      "4436: [D loss: 0.692757, acc: 0.523438]: [A loss: 0.721872, acc: 0.273438]\n",
      "4437: [D loss: 0.698386, acc: 0.494141]: [A loss: 0.714803, acc: 0.312500]\n",
      "4438: [D loss: 0.695239, acc: 0.517578]: [A loss: 0.718501, acc: 0.289062]\n",
      "4439: [D loss: 0.691968, acc: 0.529297]: [A loss: 0.695927, acc: 0.441406]\n",
      "4440: [D loss: 0.693991, acc: 0.496094]: [A loss: 0.708475, acc: 0.351562]\n",
      "4441: [D loss: 0.696261, acc: 0.480469]: [A loss: 0.702725, acc: 0.425781]\n",
      "4442: [D loss: 0.696271, acc: 0.496094]: [A loss: 0.696614, acc: 0.457031]\n",
      "4443: [D loss: 0.695761, acc: 0.519531]: [A loss: 0.705830, acc: 0.339844]\n",
      "4444: [D loss: 0.693757, acc: 0.523438]: [A loss: 0.697684, acc: 0.433594]\n",
      "4445: [D loss: 0.697753, acc: 0.496094]: [A loss: 0.711265, acc: 0.324219]\n",
      "4446: [D loss: 0.690994, acc: 0.525391]: [A loss: 0.704793, acc: 0.390625]\n",
      "4447: [D loss: 0.695130, acc: 0.521484]: [A loss: 0.729131, acc: 0.226562]\n",
      "4448: [D loss: 0.694003, acc: 0.507812]: [A loss: 0.695871, acc: 0.472656]\n",
      "4449: [D loss: 0.701061, acc: 0.478516]: [A loss: 0.733667, acc: 0.191406]\n",
      "4450: [D loss: 0.696702, acc: 0.525391]: [A loss: 0.721322, acc: 0.292969]\n",
      "4451: [D loss: 0.698550, acc: 0.484375]: [A loss: 0.726060, acc: 0.242188]\n",
      "4452: [D loss: 0.693710, acc: 0.503906]: [A loss: 0.703713, acc: 0.402344]\n",
      "4453: [D loss: 0.693708, acc: 0.503906]: [A loss: 0.718589, acc: 0.265625]\n",
      "4454: [D loss: 0.691769, acc: 0.525391]: [A loss: 0.693701, acc: 0.468750]\n",
      "4455: [D loss: 0.693584, acc: 0.541016]: [A loss: 0.709464, acc: 0.343750]\n",
      "4456: [D loss: 0.694253, acc: 0.501953]: [A loss: 0.696808, acc: 0.515625]\n",
      "4457: [D loss: 0.695519, acc: 0.501953]: [A loss: 0.755939, acc: 0.117188]\n",
      "4458: [D loss: 0.695281, acc: 0.500000]: [A loss: 0.690081, acc: 0.511719]\n",
      "4459: [D loss: 0.692630, acc: 0.517578]: [A loss: 0.691394, acc: 0.484375]\n",
      "4460: [D loss: 0.697498, acc: 0.498047]: [A loss: 0.715093, acc: 0.339844]\n",
      "4461: [D loss: 0.694988, acc: 0.509766]: [A loss: 0.699537, acc: 0.453125]\n",
      "4462: [D loss: 0.696321, acc: 0.517578]: [A loss: 0.718022, acc: 0.273438]\n",
      "4463: [D loss: 0.695273, acc: 0.511719]: [A loss: 0.730981, acc: 0.226562]\n",
      "4464: [D loss: 0.694219, acc: 0.531250]: [A loss: 0.726825, acc: 0.253906]\n",
      "4465: [D loss: 0.697853, acc: 0.488281]: [A loss: 0.742496, acc: 0.160156]\n",
      "4466: [D loss: 0.693356, acc: 0.507812]: [A loss: 0.708123, acc: 0.351562]\n",
      "4467: [D loss: 0.695877, acc: 0.517578]: [A loss: 0.715381, acc: 0.320312]\n",
      "4468: [D loss: 0.698390, acc: 0.480469]: [A loss: 0.696938, acc: 0.453125]\n",
      "4469: [D loss: 0.696213, acc: 0.474609]: [A loss: 0.688260, acc: 0.503906]\n",
      "4470: [D loss: 0.696664, acc: 0.505859]: [A loss: 0.725933, acc: 0.261719]\n",
      "4471: [D loss: 0.694047, acc: 0.472656]: [A loss: 0.685990, acc: 0.507812]\n",
      "4472: [D loss: 0.691373, acc: 0.513672]: [A loss: 0.690148, acc: 0.507812]\n",
      "4473: [D loss: 0.695651, acc: 0.486328]: [A loss: 0.712031, acc: 0.378906]\n",
      "4474: [D loss: 0.697793, acc: 0.486328]: [A loss: 0.729827, acc: 0.242188]\n",
      "4475: [D loss: 0.697422, acc: 0.472656]: [A loss: 0.716739, acc: 0.285156]\n",
      "4476: [D loss: 0.697413, acc: 0.472656]: [A loss: 0.710826, acc: 0.363281]\n",
      "4477: [D loss: 0.701658, acc: 0.478516]: [A loss: 0.714363, acc: 0.343750]\n",
      "4478: [D loss: 0.697399, acc: 0.507812]: [A loss: 0.744520, acc: 0.125000]\n",
      "4479: [D loss: 0.693541, acc: 0.511719]: [A loss: 0.700614, acc: 0.410156]\n",
      "4480: [D loss: 0.692809, acc: 0.511719]: [A loss: 0.708089, acc: 0.347656]\n",
      "4481: [D loss: 0.692881, acc: 0.523438]: [A loss: 0.695748, acc: 0.421875]\n",
      "4482: [D loss: 0.691582, acc: 0.535156]: [A loss: 0.703232, acc: 0.402344]\n",
      "4483: [D loss: 0.697306, acc: 0.509766]: [A loss: 0.717001, acc: 0.312500]\n",
      "4484: [D loss: 0.696385, acc: 0.505859]: [A loss: 0.712944, acc: 0.351562]\n",
      "4485: [D loss: 0.694177, acc: 0.500000]: [A loss: 0.712240, acc: 0.355469]\n",
      "4486: [D loss: 0.697435, acc: 0.513672]: [A loss: 0.748594, acc: 0.148438]\n",
      "4487: [D loss: 0.689759, acc: 0.503906]: [A loss: 0.669178, acc: 0.644531]\n",
      "4488: [D loss: 0.695706, acc: 0.501953]: [A loss: 0.739737, acc: 0.199219]\n",
      "4489: [D loss: 0.695410, acc: 0.466797]: [A loss: 0.697393, acc: 0.453125]\n",
      "4490: [D loss: 0.690831, acc: 0.511719]: [A loss: 0.690659, acc: 0.519531]\n",
      "4491: [D loss: 0.691966, acc: 0.527344]: [A loss: 0.707772, acc: 0.382812]\n",
      "4492: [D loss: 0.697937, acc: 0.482422]: [A loss: 0.719032, acc: 0.281250]\n",
      "4493: [D loss: 0.692818, acc: 0.525391]: [A loss: 0.685847, acc: 0.550781]\n",
      "4494: [D loss: 0.698455, acc: 0.507812]: [A loss: 0.717227, acc: 0.277344]\n",
      "4495: [D loss: 0.694831, acc: 0.482422]: [A loss: 0.688949, acc: 0.500000]\n",
      "4496: [D loss: 0.698590, acc: 0.484375]: [A loss: 0.711638, acc: 0.339844]\n",
      "4497: [D loss: 0.691384, acc: 0.529297]: [A loss: 0.710487, acc: 0.355469]\n",
      "4498: [D loss: 0.697133, acc: 0.503906]: [A loss: 0.743143, acc: 0.164062]\n",
      "4499: [D loss: 0.686572, acc: 0.552734]: [A loss: 0.701450, acc: 0.437500]\n",
      "4500: [D loss: 0.698382, acc: 0.482422]: [A loss: 0.713397, acc: 0.316406]\n",
      "4501: [D loss: 0.698157, acc: 0.490234]: [A loss: 0.715046, acc: 0.304688]\n",
      "4502: [D loss: 0.694139, acc: 0.521484]: [A loss: 0.693648, acc: 0.476562]\n",
      "4503: [D loss: 0.696251, acc: 0.517578]: [A loss: 0.686632, acc: 0.531250]\n",
      "4504: [D loss: 0.702081, acc: 0.488281]: [A loss: 0.732951, acc: 0.218750]\n",
      "4505: [D loss: 0.693044, acc: 0.501953]: [A loss: 0.729177, acc: 0.273438]\n",
      "4506: [D loss: 0.700511, acc: 0.472656]: [A loss: 0.752657, acc: 0.121094]\n",
      "4507: [D loss: 0.692405, acc: 0.525391]: [A loss: 0.694554, acc: 0.480469]\n",
      "4508: [D loss: 0.695320, acc: 0.513672]: [A loss: 0.719764, acc: 0.300781]\n",
      "4509: [D loss: 0.693051, acc: 0.482422]: [A loss: 0.683275, acc: 0.554688]\n",
      "4510: [D loss: 0.700266, acc: 0.496094]: [A loss: 0.708449, acc: 0.332031]\n",
      "4511: [D loss: 0.691677, acc: 0.515625]: [A loss: 0.687968, acc: 0.527344]\n",
      "4512: [D loss: 0.698304, acc: 0.490234]: [A loss: 0.718119, acc: 0.308594]\n",
      "4513: [D loss: 0.692885, acc: 0.494141]: [A loss: 0.711573, acc: 0.359375]\n",
      "4514: [D loss: 0.699422, acc: 0.478516]: [A loss: 0.716162, acc: 0.312500]\n",
      "4515: [D loss: 0.695254, acc: 0.501953]: [A loss: 0.705811, acc: 0.382812]\n",
      "4516: [D loss: 0.697420, acc: 0.507812]: [A loss: 0.747008, acc: 0.148438]\n",
      "4517: [D loss: 0.689618, acc: 0.541016]: [A loss: 0.694983, acc: 0.484375]\n",
      "4518: [D loss: 0.700726, acc: 0.496094]: [A loss: 0.727608, acc: 0.242188]\n",
      "4519: [D loss: 0.688069, acc: 0.546875]: [A loss: 0.666974, acc: 0.675781]\n",
      "4520: [D loss: 0.702970, acc: 0.498047]: [A loss: 0.733297, acc: 0.191406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4521: [D loss: 0.696456, acc: 0.484375]: [A loss: 0.704947, acc: 0.363281]\n",
      "4522: [D loss: 0.691132, acc: 0.513672]: [A loss: 0.703104, acc: 0.398438]\n",
      "4523: [D loss: 0.695822, acc: 0.488281]: [A loss: 0.710847, acc: 0.339844]\n",
      "4524: [D loss: 0.693657, acc: 0.496094]: [A loss: 0.712998, acc: 0.328125]\n",
      "4525: [D loss: 0.697464, acc: 0.492188]: [A loss: 0.717852, acc: 0.273438]\n",
      "4526: [D loss: 0.692218, acc: 0.517578]: [A loss: 0.700309, acc: 0.414062]\n",
      "4527: [D loss: 0.694496, acc: 0.503906]: [A loss: 0.716389, acc: 0.312500]\n",
      "4528: [D loss: 0.691127, acc: 0.509766]: [A loss: 0.688146, acc: 0.500000]\n",
      "4529: [D loss: 0.692091, acc: 0.527344]: [A loss: 0.726647, acc: 0.265625]\n",
      "4530: [D loss: 0.693356, acc: 0.515625]: [A loss: 0.698733, acc: 0.464844]\n",
      "4531: [D loss: 0.693235, acc: 0.503906]: [A loss: 0.695430, acc: 0.441406]\n",
      "4532: [D loss: 0.691480, acc: 0.539062]: [A loss: 0.700807, acc: 0.414062]\n",
      "4533: [D loss: 0.692012, acc: 0.521484]: [A loss: 0.717116, acc: 0.332031]\n",
      "4534: [D loss: 0.693619, acc: 0.515625]: [A loss: 0.709802, acc: 0.324219]\n",
      "4535: [D loss: 0.695916, acc: 0.492188]: [A loss: 0.707028, acc: 0.390625]\n",
      "4536: [D loss: 0.698298, acc: 0.462891]: [A loss: 0.707713, acc: 0.382812]\n",
      "4537: [D loss: 0.694587, acc: 0.539062]: [A loss: 0.731391, acc: 0.230469]\n",
      "4538: [D loss: 0.693332, acc: 0.519531]: [A loss: 0.715334, acc: 0.316406]\n",
      "4539: [D loss: 0.698378, acc: 0.478516]: [A loss: 0.712635, acc: 0.292969]\n",
      "4540: [D loss: 0.698184, acc: 0.501953]: [A loss: 0.711125, acc: 0.324219]\n",
      "4541: [D loss: 0.692607, acc: 0.509766]: [A loss: 0.694264, acc: 0.468750]\n",
      "4542: [D loss: 0.698028, acc: 0.474609]: [A loss: 0.720052, acc: 0.343750]\n",
      "4543: [D loss: 0.696453, acc: 0.496094]: [A loss: 0.703151, acc: 0.394531]\n",
      "4544: [D loss: 0.692607, acc: 0.511719]: [A loss: 0.696395, acc: 0.472656]\n",
      "4545: [D loss: 0.695025, acc: 0.503906]: [A loss: 0.732732, acc: 0.218750]\n",
      "4546: [D loss: 0.692235, acc: 0.500000]: [A loss: 0.690597, acc: 0.507812]\n",
      "4547: [D loss: 0.696245, acc: 0.501953]: [A loss: 0.720119, acc: 0.281250]\n",
      "4548: [D loss: 0.694680, acc: 0.501953]: [A loss: 0.734466, acc: 0.207031]\n",
      "4549: [D loss: 0.699443, acc: 0.458984]: [A loss: 0.711947, acc: 0.328125]\n",
      "4550: [D loss: 0.693008, acc: 0.478516]: [A loss: 0.699431, acc: 0.453125]\n",
      "4551: [D loss: 0.699811, acc: 0.484375]: [A loss: 0.720306, acc: 0.312500]\n",
      "4552: [D loss: 0.699090, acc: 0.498047]: [A loss: 0.736369, acc: 0.187500]\n",
      "4553: [D loss: 0.691408, acc: 0.527344]: [A loss: 0.695529, acc: 0.472656]\n",
      "4554: [D loss: 0.698323, acc: 0.490234]: [A loss: 0.725010, acc: 0.269531]\n",
      "4555: [D loss: 0.689993, acc: 0.531250]: [A loss: 0.675474, acc: 0.644531]\n",
      "4556: [D loss: 0.696857, acc: 0.501953]: [A loss: 0.738040, acc: 0.207031]\n",
      "4557: [D loss: 0.691217, acc: 0.541016]: [A loss: 0.683918, acc: 0.550781]\n",
      "4558: [D loss: 0.699378, acc: 0.505859]: [A loss: 0.733739, acc: 0.179688]\n",
      "4559: [D loss: 0.692861, acc: 0.500000]: [A loss: 0.695193, acc: 0.476562]\n",
      "4560: [D loss: 0.700415, acc: 0.492188]: [A loss: 0.725361, acc: 0.292969]\n",
      "4561: [D loss: 0.693474, acc: 0.498047]: [A loss: 0.691957, acc: 0.464844]\n",
      "4562: [D loss: 0.698917, acc: 0.498047]: [A loss: 0.699462, acc: 0.417969]\n",
      "4563: [D loss: 0.696123, acc: 0.482422]: [A loss: 0.697358, acc: 0.457031]\n",
      "4564: [D loss: 0.692875, acc: 0.533203]: [A loss: 0.697205, acc: 0.472656]\n",
      "4565: [D loss: 0.699293, acc: 0.478516]: [A loss: 0.703607, acc: 0.402344]\n",
      "4566: [D loss: 0.697345, acc: 0.482422]: [A loss: 0.726399, acc: 0.246094]\n",
      "4567: [D loss: 0.697698, acc: 0.478516]: [A loss: 0.718711, acc: 0.261719]\n",
      "4568: [D loss: 0.690940, acc: 0.525391]: [A loss: 0.685613, acc: 0.558594]\n",
      "4569: [D loss: 0.693798, acc: 0.498047]: [A loss: 0.702432, acc: 0.386719]\n",
      "4570: [D loss: 0.694546, acc: 0.503906]: [A loss: 0.696946, acc: 0.457031]\n",
      "4571: [D loss: 0.701173, acc: 0.466797]: [A loss: 0.695804, acc: 0.492188]\n",
      "4572: [D loss: 0.693450, acc: 0.494141]: [A loss: 0.693230, acc: 0.496094]\n",
      "4573: [D loss: 0.698116, acc: 0.498047]: [A loss: 0.703416, acc: 0.382812]\n",
      "4574: [D loss: 0.693463, acc: 0.511719]: [A loss: 0.709966, acc: 0.375000]\n",
      "4575: [D loss: 0.692339, acc: 0.525391]: [A loss: 0.709130, acc: 0.339844]\n",
      "4576: [D loss: 0.695715, acc: 0.484375]: [A loss: 0.706274, acc: 0.375000]\n",
      "4577: [D loss: 0.699349, acc: 0.498047]: [A loss: 0.718879, acc: 0.285156]\n",
      "4578: [D loss: 0.696966, acc: 0.515625]: [A loss: 0.716950, acc: 0.304688]\n",
      "4579: [D loss: 0.699473, acc: 0.492188]: [A loss: 0.732782, acc: 0.187500]\n",
      "4580: [D loss: 0.696203, acc: 0.492188]: [A loss: 0.707934, acc: 0.375000]\n",
      "4581: [D loss: 0.697295, acc: 0.503906]: [A loss: 0.698152, acc: 0.449219]\n",
      "4582: [D loss: 0.693458, acc: 0.527344]: [A loss: 0.696206, acc: 0.445312]\n",
      "4583: [D loss: 0.691560, acc: 0.509766]: [A loss: 0.703960, acc: 0.398438]\n",
      "4584: [D loss: 0.693387, acc: 0.517578]: [A loss: 0.717967, acc: 0.273438]\n",
      "4585: [D loss: 0.700597, acc: 0.460938]: [A loss: 0.753398, acc: 0.132812]\n",
      "4586: [D loss: 0.695908, acc: 0.484375]: [A loss: 0.707565, acc: 0.363281]\n",
      "4587: [D loss: 0.697083, acc: 0.484375]: [A loss: 0.702824, acc: 0.417969]\n",
      "4588: [D loss: 0.695037, acc: 0.539062]: [A loss: 0.727581, acc: 0.257812]\n",
      "4589: [D loss: 0.695385, acc: 0.521484]: [A loss: 0.713754, acc: 0.316406]\n",
      "4590: [D loss: 0.694154, acc: 0.494141]: [A loss: 0.698304, acc: 0.433594]\n",
      "4591: [D loss: 0.696329, acc: 0.513672]: [A loss: 0.707855, acc: 0.390625]\n",
      "4592: [D loss: 0.693490, acc: 0.535156]: [A loss: 0.724359, acc: 0.277344]\n",
      "4593: [D loss: 0.695146, acc: 0.507812]: [A loss: 0.690139, acc: 0.511719]\n",
      "4594: [D loss: 0.696655, acc: 0.494141]: [A loss: 0.704760, acc: 0.355469]\n",
      "4595: [D loss: 0.696207, acc: 0.486328]: [A loss: 0.702025, acc: 0.402344]\n",
      "4596: [D loss: 0.703912, acc: 0.464844]: [A loss: 0.708111, acc: 0.390625]\n",
      "4597: [D loss: 0.695582, acc: 0.513672]: [A loss: 0.742521, acc: 0.171875]\n",
      "4598: [D loss: 0.691664, acc: 0.513672]: [A loss: 0.710748, acc: 0.339844]\n",
      "4599: [D loss: 0.697125, acc: 0.466797]: [A loss: 0.696915, acc: 0.445312]\n",
      "4600: [D loss: 0.699787, acc: 0.498047]: [A loss: 0.728557, acc: 0.246094]\n",
      "4601: [D loss: 0.694274, acc: 0.537109]: [A loss: 0.698980, acc: 0.421875]\n",
      "4602: [D loss: 0.694610, acc: 0.494141]: [A loss: 0.694984, acc: 0.457031]\n",
      "4603: [D loss: 0.694384, acc: 0.513672]: [A loss: 0.691401, acc: 0.492188]\n",
      "4604: [D loss: 0.695488, acc: 0.513672]: [A loss: 0.709191, acc: 0.371094]\n",
      "4605: [D loss: 0.694277, acc: 0.496094]: [A loss: 0.709666, acc: 0.371094]\n",
      "4606: [D loss: 0.698465, acc: 0.515625]: [A loss: 0.713124, acc: 0.347656]\n",
      "4607: [D loss: 0.697950, acc: 0.480469]: [A loss: 0.724836, acc: 0.265625]\n",
      "4608: [D loss: 0.692176, acc: 0.505859]: [A loss: 0.716888, acc: 0.351562]\n",
      "4609: [D loss: 0.693678, acc: 0.517578]: [A loss: 0.715746, acc: 0.347656]\n",
      "4610: [D loss: 0.696758, acc: 0.498047]: [A loss: 0.734785, acc: 0.222656]\n",
      "4611: [D loss: 0.689808, acc: 0.546875]: [A loss: 0.663446, acc: 0.667969]\n",
      "4612: [D loss: 0.698144, acc: 0.501953]: [A loss: 0.744085, acc: 0.160156]\n",
      "4613: [D loss: 0.695745, acc: 0.500000]: [A loss: 0.706845, acc: 0.367188]\n",
      "4614: [D loss: 0.693685, acc: 0.515625]: [A loss: 0.670623, acc: 0.617188]\n",
      "4615: [D loss: 0.698526, acc: 0.521484]: [A loss: 0.709848, acc: 0.375000]\n",
      "4616: [D loss: 0.693379, acc: 0.523438]: [A loss: 0.700454, acc: 0.402344]\n",
      "4617: [D loss: 0.696935, acc: 0.492188]: [A loss: 0.709787, acc: 0.304688]\n",
      "4618: [D loss: 0.696606, acc: 0.503906]: [A loss: 0.701595, acc: 0.421875]\n",
      "4619: [D loss: 0.703760, acc: 0.496094]: [A loss: 0.743058, acc: 0.171875]\n",
      "4620: [D loss: 0.692824, acc: 0.519531]: [A loss: 0.698081, acc: 0.453125]\n",
      "4621: [D loss: 0.701289, acc: 0.492188]: [A loss: 0.726424, acc: 0.250000]\n",
      "4622: [D loss: 0.691004, acc: 0.537109]: [A loss: 0.691985, acc: 0.460938]\n",
      "4623: [D loss: 0.695691, acc: 0.480469]: [A loss: 0.719331, acc: 0.269531]\n",
      "4624: [D loss: 0.698994, acc: 0.507812]: [A loss: 0.699112, acc: 0.433594]\n",
      "4625: [D loss: 0.694775, acc: 0.519531]: [A loss: 0.701466, acc: 0.417969]\n",
      "4626: [D loss: 0.695501, acc: 0.503906]: [A loss: 0.715492, acc: 0.316406]\n",
      "4627: [D loss: 0.692863, acc: 0.521484]: [A loss: 0.696144, acc: 0.445312]\n",
      "4628: [D loss: 0.690148, acc: 0.513672]: [A loss: 0.687223, acc: 0.558594]\n",
      "4629: [D loss: 0.696313, acc: 0.503906]: [A loss: 0.729106, acc: 0.210938]\n",
      "4630: [D loss: 0.693889, acc: 0.507812]: [A loss: 0.703341, acc: 0.425781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4631: [D loss: 0.694128, acc: 0.513672]: [A loss: 0.699902, acc: 0.429688]\n",
      "4632: [D loss: 0.695290, acc: 0.501953]: [A loss: 0.717809, acc: 0.277344]\n",
      "4633: [D loss: 0.692590, acc: 0.531250]: [A loss: 0.701539, acc: 0.402344]\n",
      "4634: [D loss: 0.692352, acc: 0.527344]: [A loss: 0.725182, acc: 0.269531]\n",
      "4635: [D loss: 0.695423, acc: 0.509766]: [A loss: 0.740244, acc: 0.234375]\n",
      "4636: [D loss: 0.697003, acc: 0.478516]: [A loss: 0.719400, acc: 0.320312]\n",
      "4637: [D loss: 0.691292, acc: 0.527344]: [A loss: 0.707594, acc: 0.367188]\n",
      "4638: [D loss: 0.694565, acc: 0.531250]: [A loss: 0.703318, acc: 0.402344]\n",
      "4639: [D loss: 0.694446, acc: 0.531250]: [A loss: 0.738410, acc: 0.199219]\n",
      "4640: [D loss: 0.686159, acc: 0.550781]: [A loss: 0.656865, acc: 0.683594]\n",
      "4641: [D loss: 0.696035, acc: 0.503906]: [A loss: 0.756182, acc: 0.125000]\n",
      "4642: [D loss: 0.691441, acc: 0.505859]: [A loss: 0.686694, acc: 0.496094]\n",
      "4643: [D loss: 0.694057, acc: 0.523438]: [A loss: 0.727727, acc: 0.250000]\n",
      "4644: [D loss: 0.695780, acc: 0.476562]: [A loss: 0.706321, acc: 0.382812]\n",
      "4645: [D loss: 0.690716, acc: 0.523438]: [A loss: 0.716270, acc: 0.355469]\n",
      "4646: [D loss: 0.692648, acc: 0.511719]: [A loss: 0.724619, acc: 0.269531]\n",
      "4647: [D loss: 0.698367, acc: 0.500000]: [A loss: 0.731284, acc: 0.222656]\n",
      "4648: [D loss: 0.693043, acc: 0.511719]: [A loss: 0.691312, acc: 0.503906]\n",
      "4649: [D loss: 0.700890, acc: 0.488281]: [A loss: 0.729585, acc: 0.257812]\n",
      "4650: [D loss: 0.700093, acc: 0.460938]: [A loss: 0.716013, acc: 0.308594]\n",
      "4651: [D loss: 0.693888, acc: 0.503906]: [A loss: 0.706802, acc: 0.433594]\n",
      "4652: [D loss: 0.697681, acc: 0.503906]: [A loss: 0.745904, acc: 0.199219]\n",
      "4653: [D loss: 0.691508, acc: 0.537109]: [A loss: 0.657793, acc: 0.707031]\n",
      "4654: [D loss: 0.698123, acc: 0.525391]: [A loss: 0.722207, acc: 0.277344]\n",
      "4655: [D loss: 0.696434, acc: 0.462891]: [A loss: 0.702692, acc: 0.398438]\n",
      "4656: [D loss: 0.690118, acc: 0.527344]: [A loss: 0.704706, acc: 0.375000]\n",
      "4657: [D loss: 0.697907, acc: 0.521484]: [A loss: 0.724699, acc: 0.277344]\n",
      "4658: [D loss: 0.689222, acc: 0.539062]: [A loss: 0.677823, acc: 0.582031]\n",
      "4659: [D loss: 0.697368, acc: 0.505859]: [A loss: 0.700928, acc: 0.441406]\n",
      "4660: [D loss: 0.694376, acc: 0.525391]: [A loss: 0.707943, acc: 0.371094]\n",
      "4661: [D loss: 0.706590, acc: 0.451172]: [A loss: 0.755029, acc: 0.144531]\n",
      "4662: [D loss: 0.694594, acc: 0.503906]: [A loss: 0.710289, acc: 0.378906]\n",
      "4663: [D loss: 0.695249, acc: 0.496094]: [A loss: 0.721925, acc: 0.304688]\n",
      "4664: [D loss: 0.692811, acc: 0.500000]: [A loss: 0.716602, acc: 0.312500]\n",
      "4665: [D loss: 0.694458, acc: 0.511719]: [A loss: 0.700687, acc: 0.429688]\n",
      "4666: [D loss: 0.701264, acc: 0.501953]: [A loss: 0.694547, acc: 0.445312]\n",
      "4667: [D loss: 0.693863, acc: 0.496094]: [A loss: 0.693360, acc: 0.503906]\n",
      "4668: [D loss: 0.698286, acc: 0.501953]: [A loss: 0.721202, acc: 0.265625]\n",
      "4669: [D loss: 0.696920, acc: 0.494141]: [A loss: 0.733352, acc: 0.187500]\n",
      "4670: [D loss: 0.694447, acc: 0.521484]: [A loss: 0.738336, acc: 0.179688]\n",
      "4671: [D loss: 0.690902, acc: 0.531250]: [A loss: 0.715612, acc: 0.328125]\n",
      "4672: [D loss: 0.695224, acc: 0.494141]: [A loss: 0.716905, acc: 0.339844]\n",
      "4673: [D loss: 0.692956, acc: 0.507812]: [A loss: 0.719519, acc: 0.308594]\n",
      "4674: [D loss: 0.693745, acc: 0.542969]: [A loss: 0.703417, acc: 0.402344]\n",
      "4675: [D loss: 0.694169, acc: 0.513672]: [A loss: 0.740048, acc: 0.203125]\n",
      "4676: [D loss: 0.695433, acc: 0.501953]: [A loss: 0.731685, acc: 0.296875]\n",
      "4677: [D loss: 0.696710, acc: 0.484375]: [A loss: 0.693510, acc: 0.484375]\n",
      "4678: [D loss: 0.694576, acc: 0.494141]: [A loss: 0.712378, acc: 0.347656]\n",
      "4679: [D loss: 0.691573, acc: 0.521484]: [A loss: 0.734568, acc: 0.257812]\n",
      "4680: [D loss: 0.696089, acc: 0.529297]: [A loss: 0.730736, acc: 0.277344]\n",
      "4681: [D loss: 0.690684, acc: 0.552734]: [A loss: 0.686377, acc: 0.535156]\n",
      "4682: [D loss: 0.695322, acc: 0.509766]: [A loss: 0.743413, acc: 0.187500]\n",
      "4683: [D loss: 0.695098, acc: 0.501953]: [A loss: 0.703731, acc: 0.445312]\n",
      "4684: [D loss: 0.702203, acc: 0.457031]: [A loss: 0.715225, acc: 0.312500]\n",
      "4685: [D loss: 0.695152, acc: 0.486328]: [A loss: 0.736612, acc: 0.226562]\n",
      "4686: [D loss: 0.697952, acc: 0.457031]: [A loss: 0.729174, acc: 0.257812]\n",
      "4687: [D loss: 0.692318, acc: 0.507812]: [A loss: 0.676590, acc: 0.582031]\n",
      "4688: [D loss: 0.702873, acc: 0.515625]: [A loss: 0.748461, acc: 0.171875]\n",
      "4689: [D loss: 0.693664, acc: 0.500000]: [A loss: 0.693996, acc: 0.476562]\n",
      "4690: [D loss: 0.697792, acc: 0.474609]: [A loss: 0.711762, acc: 0.363281]\n",
      "4691: [D loss: 0.696131, acc: 0.511719]: [A loss: 0.700666, acc: 0.480469]\n",
      "4692: [D loss: 0.692173, acc: 0.529297]: [A loss: 0.709991, acc: 0.378906]\n",
      "4693: [D loss: 0.695123, acc: 0.515625]: [A loss: 0.698037, acc: 0.468750]\n",
      "4694: [D loss: 0.692063, acc: 0.531250]: [A loss: 0.690116, acc: 0.496094]\n",
      "4695: [D loss: 0.702422, acc: 0.494141]: [A loss: 0.768692, acc: 0.097656]\n",
      "4696: [D loss: 0.689324, acc: 0.542969]: [A loss: 0.673730, acc: 0.609375]\n",
      "4697: [D loss: 0.708765, acc: 0.482422]: [A loss: 0.731932, acc: 0.210938]\n",
      "4698: [D loss: 0.697841, acc: 0.476562]: [A loss: 0.711281, acc: 0.320312]\n",
      "4699: [D loss: 0.692847, acc: 0.519531]: [A loss: 0.700195, acc: 0.460938]\n",
      "4700: [D loss: 0.701667, acc: 0.496094]: [A loss: 0.750078, acc: 0.156250]\n",
      "4701: [D loss: 0.690888, acc: 0.531250]: [A loss: 0.709167, acc: 0.351562]\n",
      "4702: [D loss: 0.695811, acc: 0.509766]: [A loss: 0.699349, acc: 0.414062]\n",
      "4703: [D loss: 0.700126, acc: 0.482422]: [A loss: 0.709764, acc: 0.351562]\n",
      "4704: [D loss: 0.695001, acc: 0.515625]: [A loss: 0.704540, acc: 0.406250]\n",
      "4705: [D loss: 0.691042, acc: 0.535156]: [A loss: 0.730637, acc: 0.230469]\n",
      "4706: [D loss: 0.695989, acc: 0.488281]: [A loss: 0.733416, acc: 0.222656]\n",
      "4707: [D loss: 0.697508, acc: 0.472656]: [A loss: 0.725915, acc: 0.273438]\n",
      "4708: [D loss: 0.693991, acc: 0.496094]: [A loss: 0.737332, acc: 0.191406]\n",
      "4709: [D loss: 0.693273, acc: 0.515625]: [A loss: 0.692847, acc: 0.472656]\n",
      "4710: [D loss: 0.697552, acc: 0.488281]: [A loss: 0.713294, acc: 0.359375]\n",
      "4711: [D loss: 0.696797, acc: 0.484375]: [A loss: 0.704410, acc: 0.382812]\n",
      "4712: [D loss: 0.696765, acc: 0.494141]: [A loss: 0.737443, acc: 0.222656]\n",
      "4713: [D loss: 0.694441, acc: 0.513672]: [A loss: 0.734739, acc: 0.246094]\n",
      "4714: [D loss: 0.692742, acc: 0.505859]: [A loss: 0.739986, acc: 0.214844]\n",
      "4715: [D loss: 0.693173, acc: 0.519531]: [A loss: 0.692092, acc: 0.492188]\n",
      "4716: [D loss: 0.694532, acc: 0.513672]: [A loss: 0.733384, acc: 0.226562]\n",
      "4717: [D loss: 0.699497, acc: 0.470703]: [A loss: 0.724154, acc: 0.269531]\n",
      "4718: [D loss: 0.695897, acc: 0.515625]: [A loss: 0.707966, acc: 0.375000]\n",
      "4719: [D loss: 0.698005, acc: 0.496094]: [A loss: 0.717150, acc: 0.312500]\n",
      "4720: [D loss: 0.696290, acc: 0.500000]: [A loss: 0.749611, acc: 0.171875]\n",
      "4721: [D loss: 0.695398, acc: 0.484375]: [A loss: 0.687905, acc: 0.492188]\n",
      "4722: [D loss: 0.702255, acc: 0.498047]: [A loss: 0.741280, acc: 0.179688]\n",
      "4723: [D loss: 0.692686, acc: 0.519531]: [A loss: 0.697521, acc: 0.460938]\n",
      "4724: [D loss: 0.698212, acc: 0.480469]: [A loss: 0.716425, acc: 0.332031]\n",
      "4725: [D loss: 0.692398, acc: 0.537109]: [A loss: 0.706963, acc: 0.414062]\n",
      "4726: [D loss: 0.690504, acc: 0.521484]: [A loss: 0.706178, acc: 0.375000]\n",
      "4727: [D loss: 0.695602, acc: 0.490234]: [A loss: 0.723527, acc: 0.285156]\n",
      "4728: [D loss: 0.692500, acc: 0.521484]: [A loss: 0.719703, acc: 0.320312]\n",
      "4729: [D loss: 0.693059, acc: 0.521484]: [A loss: 0.718026, acc: 0.296875]\n",
      "4730: [D loss: 0.693356, acc: 0.531250]: [A loss: 0.720009, acc: 0.300781]\n",
      "4731: [D loss: 0.692023, acc: 0.548828]: [A loss: 0.690162, acc: 0.492188]\n",
      "4732: [D loss: 0.689538, acc: 0.527344]: [A loss: 0.708923, acc: 0.406250]\n",
      "4733: [D loss: 0.696275, acc: 0.515625]: [A loss: 0.711871, acc: 0.406250]\n",
      "4734: [D loss: 0.698244, acc: 0.498047]: [A loss: 0.708418, acc: 0.390625]\n",
      "4735: [D loss: 0.699512, acc: 0.503906]: [A loss: 0.768588, acc: 0.097656]\n",
      "4736: [D loss: 0.694392, acc: 0.541016]: [A loss: 0.704578, acc: 0.429688]\n",
      "4737: [D loss: 0.702720, acc: 0.470703]: [A loss: 0.720581, acc: 0.277344]\n",
      "4738: [D loss: 0.698475, acc: 0.466797]: [A loss: 0.720673, acc: 0.300781]\n",
      "4739: [D loss: 0.695446, acc: 0.503906]: [A loss: 0.696549, acc: 0.464844]\n",
      "4740: [D loss: 0.694196, acc: 0.539062]: [A loss: 0.718198, acc: 0.308594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4741: [D loss: 0.695627, acc: 0.478516]: [A loss: 0.723514, acc: 0.308594]\n",
      "4742: [D loss: 0.692173, acc: 0.533203]: [A loss: 0.709190, acc: 0.367188]\n",
      "4743: [D loss: 0.695318, acc: 0.509766]: [A loss: 0.730692, acc: 0.269531]\n",
      "4744: [D loss: 0.695573, acc: 0.519531]: [A loss: 0.731389, acc: 0.257812]\n",
      "4745: [D loss: 0.698618, acc: 0.470703]: [A loss: 0.739425, acc: 0.207031]\n",
      "4746: [D loss: 0.695171, acc: 0.478516]: [A loss: 0.716396, acc: 0.339844]\n",
      "4747: [D loss: 0.692738, acc: 0.509766]: [A loss: 0.739968, acc: 0.250000]\n",
      "4748: [D loss: 0.696758, acc: 0.498047]: [A loss: 0.731765, acc: 0.238281]\n",
      "4749: [D loss: 0.696612, acc: 0.507812]: [A loss: 0.709589, acc: 0.382812]\n",
      "4750: [D loss: 0.698997, acc: 0.500000]: [A loss: 0.712452, acc: 0.355469]\n",
      "4751: [D loss: 0.693804, acc: 0.513672]: [A loss: 0.715243, acc: 0.339844]\n",
      "4752: [D loss: 0.692292, acc: 0.521484]: [A loss: 0.727349, acc: 0.265625]\n",
      "4753: [D loss: 0.694411, acc: 0.519531]: [A loss: 0.710410, acc: 0.382812]\n",
      "4754: [D loss: 0.695847, acc: 0.503906]: [A loss: 0.750374, acc: 0.175781]\n",
      "4755: [D loss: 0.696709, acc: 0.498047]: [A loss: 0.699961, acc: 0.429688]\n",
      "4756: [D loss: 0.701960, acc: 0.474609]: [A loss: 0.746198, acc: 0.191406]\n",
      "4757: [D loss: 0.695023, acc: 0.482422]: [A loss: 0.698567, acc: 0.437500]\n",
      "4758: [D loss: 0.696389, acc: 0.511719]: [A loss: 0.747148, acc: 0.164062]\n",
      "4759: [D loss: 0.696733, acc: 0.492188]: [A loss: 0.711429, acc: 0.351562]\n",
      "4760: [D loss: 0.694746, acc: 0.490234]: [A loss: 0.702334, acc: 0.382812]\n",
      "4761: [D loss: 0.692735, acc: 0.521484]: [A loss: 0.701252, acc: 0.398438]\n",
      "4762: [D loss: 0.694781, acc: 0.511719]: [A loss: 0.683102, acc: 0.578125]\n",
      "4763: [D loss: 0.698236, acc: 0.494141]: [A loss: 0.754665, acc: 0.093750]\n",
      "4764: [D loss: 0.693048, acc: 0.505859]: [A loss: 0.721230, acc: 0.261719]\n",
      "4765: [D loss: 0.690853, acc: 0.537109]: [A loss: 0.693445, acc: 0.492188]\n",
      "4766: [D loss: 0.701112, acc: 0.486328]: [A loss: 0.776571, acc: 0.066406]\n",
      "4767: [D loss: 0.691989, acc: 0.500000]: [A loss: 0.707933, acc: 0.375000]\n",
      "4768: [D loss: 0.688888, acc: 0.541016]: [A loss: 0.709821, acc: 0.378906]\n",
      "4769: [D loss: 0.685950, acc: 0.548828]: [A loss: 0.709663, acc: 0.355469]\n",
      "4770: [D loss: 0.695232, acc: 0.507812]: [A loss: 0.746501, acc: 0.148438]\n",
      "4771: [D loss: 0.695657, acc: 0.503906]: [A loss: 0.693330, acc: 0.460938]\n",
      "4772: [D loss: 0.691677, acc: 0.525391]: [A loss: 0.712303, acc: 0.332031]\n",
      "4773: [D loss: 0.696305, acc: 0.503906]: [A loss: 0.717574, acc: 0.347656]\n",
      "4774: [D loss: 0.693580, acc: 0.505859]: [A loss: 0.733366, acc: 0.222656]\n",
      "4775: [D loss: 0.695273, acc: 0.496094]: [A loss: 0.726854, acc: 0.250000]\n",
      "4776: [D loss: 0.697835, acc: 0.470703]: [A loss: 0.685443, acc: 0.535156]\n",
      "4777: [D loss: 0.704466, acc: 0.480469]: [A loss: 0.731425, acc: 0.250000]\n",
      "4778: [D loss: 0.691340, acc: 0.517578]: [A loss: 0.690019, acc: 0.542969]\n",
      "4779: [D loss: 0.700368, acc: 0.498047]: [A loss: 0.741323, acc: 0.179688]\n",
      "4780: [D loss: 0.693220, acc: 0.521484]: [A loss: 0.702245, acc: 0.417969]\n",
      "4781: [D loss: 0.696416, acc: 0.509766]: [A loss: 0.747651, acc: 0.144531]\n",
      "4782: [D loss: 0.695345, acc: 0.468750]: [A loss: 0.700290, acc: 0.402344]\n",
      "4783: [D loss: 0.699917, acc: 0.501953]: [A loss: 0.728735, acc: 0.289062]\n",
      "4784: [D loss: 0.694460, acc: 0.511719]: [A loss: 0.682786, acc: 0.558594]\n",
      "4785: [D loss: 0.696450, acc: 0.482422]: [A loss: 0.734584, acc: 0.238281]\n",
      "4786: [D loss: 0.695726, acc: 0.503906]: [A loss: 0.718697, acc: 0.304688]\n",
      "4787: [D loss: 0.693846, acc: 0.511719]: [A loss: 0.707804, acc: 0.390625]\n",
      "4788: [D loss: 0.695918, acc: 0.511719]: [A loss: 0.712170, acc: 0.355469]\n",
      "4789: [D loss: 0.695027, acc: 0.525391]: [A loss: 0.741280, acc: 0.203125]\n",
      "4790: [D loss: 0.689478, acc: 0.548828]: [A loss: 0.713419, acc: 0.343750]\n",
      "4791: [D loss: 0.696184, acc: 0.503906]: [A loss: 0.720670, acc: 0.289062]\n",
      "4792: [D loss: 0.691794, acc: 0.531250]: [A loss: 0.696729, acc: 0.453125]\n",
      "4793: [D loss: 0.690603, acc: 0.527344]: [A loss: 0.711206, acc: 0.363281]\n",
      "4794: [D loss: 0.697650, acc: 0.511719]: [A loss: 0.713983, acc: 0.332031]\n",
      "4795: [D loss: 0.688566, acc: 0.568359]: [A loss: 0.686410, acc: 0.515625]\n",
      "4796: [D loss: 0.700675, acc: 0.494141]: [A loss: 0.768564, acc: 0.070312]\n",
      "4797: [D loss: 0.698598, acc: 0.460938]: [A loss: 0.693144, acc: 0.457031]\n",
      "4798: [D loss: 0.693350, acc: 0.503906]: [A loss: 0.705467, acc: 0.398438]\n",
      "4799: [D loss: 0.701018, acc: 0.457031]: [A loss: 0.715586, acc: 0.378906]\n",
      "4800: [D loss: 0.695153, acc: 0.484375]: [A loss: 0.711497, acc: 0.339844]\n",
      "4801: [D loss: 0.696848, acc: 0.509766]: [A loss: 0.719045, acc: 0.296875]\n",
      "4802: [D loss: 0.699866, acc: 0.484375]: [A loss: 0.749068, acc: 0.132812]\n",
      "4803: [D loss: 0.691703, acc: 0.525391]: [A loss: 0.695488, acc: 0.449219]\n",
      "4804: [D loss: 0.695649, acc: 0.533203]: [A loss: 0.780138, acc: 0.078125]\n",
      "4805: [D loss: 0.693152, acc: 0.496094]: [A loss: 0.683703, acc: 0.523438]\n",
      "4806: [D loss: 0.697869, acc: 0.494141]: [A loss: 0.727903, acc: 0.273438]\n",
      "4807: [D loss: 0.696866, acc: 0.494141]: [A loss: 0.727492, acc: 0.230469]\n",
      "4808: [D loss: 0.686871, acc: 0.517578]: [A loss: 0.698609, acc: 0.394531]\n",
      "4809: [D loss: 0.697321, acc: 0.492188]: [A loss: 0.736149, acc: 0.218750]\n",
      "4810: [D loss: 0.692459, acc: 0.537109]: [A loss: 0.702495, acc: 0.437500]\n",
      "4811: [D loss: 0.697877, acc: 0.498047]: [A loss: 0.732261, acc: 0.222656]\n",
      "4812: [D loss: 0.690085, acc: 0.513672]: [A loss: 0.707384, acc: 0.386719]\n",
      "4813: [D loss: 0.699775, acc: 0.494141]: [A loss: 0.748381, acc: 0.171875]\n",
      "4814: [D loss: 0.694047, acc: 0.523438]: [A loss: 0.711814, acc: 0.359375]\n",
      "4815: [D loss: 0.698238, acc: 0.501953]: [A loss: 0.701900, acc: 0.421875]\n",
      "4816: [D loss: 0.699505, acc: 0.490234]: [A loss: 0.729890, acc: 0.214844]\n",
      "4817: [D loss: 0.692182, acc: 0.496094]: [A loss: 0.696271, acc: 0.457031]\n",
      "4818: [D loss: 0.694157, acc: 0.501953]: [A loss: 0.726659, acc: 0.246094]\n",
      "4819: [D loss: 0.699281, acc: 0.484375]: [A loss: 0.735156, acc: 0.230469]\n",
      "4820: [D loss: 0.695354, acc: 0.488281]: [A loss: 0.724259, acc: 0.253906]\n",
      "4821: [D loss: 0.696437, acc: 0.515625]: [A loss: 0.716962, acc: 0.332031]\n",
      "4822: [D loss: 0.695231, acc: 0.509766]: [A loss: 0.751172, acc: 0.152344]\n",
      "4823: [D loss: 0.695985, acc: 0.496094]: [A loss: 0.704433, acc: 0.417969]\n",
      "4824: [D loss: 0.693115, acc: 0.507812]: [A loss: 0.702613, acc: 0.394531]\n",
      "4825: [D loss: 0.697409, acc: 0.511719]: [A loss: 0.717585, acc: 0.312500]\n",
      "4826: [D loss: 0.692196, acc: 0.529297]: [A loss: 0.695583, acc: 0.449219]\n",
      "4827: [D loss: 0.696115, acc: 0.509766]: [A loss: 0.727235, acc: 0.273438]\n",
      "4828: [D loss: 0.695235, acc: 0.492188]: [A loss: 0.694694, acc: 0.460938]\n",
      "4829: [D loss: 0.695507, acc: 0.498047]: [A loss: 0.780767, acc: 0.039062]\n",
      "4830: [D loss: 0.691051, acc: 0.509766]: [A loss: 0.686011, acc: 0.582031]\n",
      "4831: [D loss: 0.699500, acc: 0.503906]: [A loss: 0.723427, acc: 0.273438]\n",
      "4832: [D loss: 0.695660, acc: 0.492188]: [A loss: 0.688282, acc: 0.460938]\n",
      "4833: [D loss: 0.699561, acc: 0.507812]: [A loss: 0.758113, acc: 0.093750]\n",
      "4834: [D loss: 0.695538, acc: 0.474609]: [A loss: 0.695741, acc: 0.496094]\n",
      "4835: [D loss: 0.696961, acc: 0.498047]: [A loss: 0.730293, acc: 0.234375]\n",
      "4836: [D loss: 0.693616, acc: 0.515625]: [A loss: 0.708291, acc: 0.433594]\n",
      "4837: [D loss: 0.694376, acc: 0.492188]: [A loss: 0.740073, acc: 0.140625]\n",
      "4838: [D loss: 0.693723, acc: 0.494141]: [A loss: 0.707232, acc: 0.375000]\n",
      "4839: [D loss: 0.690027, acc: 0.527344]: [A loss: 0.735313, acc: 0.203125]\n",
      "4840: [D loss: 0.698928, acc: 0.468750]: [A loss: 0.713160, acc: 0.355469]\n",
      "4841: [D loss: 0.690897, acc: 0.531250]: [A loss: 0.720621, acc: 0.304688]\n",
      "4842: [D loss: 0.690822, acc: 0.537109]: [A loss: 0.714467, acc: 0.375000]\n",
      "4843: [D loss: 0.700744, acc: 0.474609]: [A loss: 0.725177, acc: 0.238281]\n",
      "4844: [D loss: 0.693714, acc: 0.500000]: [A loss: 0.721379, acc: 0.269531]\n",
      "4845: [D loss: 0.694861, acc: 0.513672]: [A loss: 0.716388, acc: 0.312500]\n",
      "4846: [D loss: 0.691542, acc: 0.527344]: [A loss: 0.701414, acc: 0.433594]\n",
      "4847: [D loss: 0.695184, acc: 0.529297]: [A loss: 0.724573, acc: 0.285156]\n",
      "4848: [D loss: 0.695950, acc: 0.484375]: [A loss: 0.700934, acc: 0.453125]\n",
      "4849: [D loss: 0.693232, acc: 0.527344]: [A loss: 0.705988, acc: 0.402344]\n",
      "4850: [D loss: 0.694733, acc: 0.503906]: [A loss: 0.710473, acc: 0.367188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4851: [D loss: 0.697934, acc: 0.484375]: [A loss: 0.753513, acc: 0.160156]\n",
      "4852: [D loss: 0.696370, acc: 0.500000]: [A loss: 0.693668, acc: 0.480469]\n",
      "4853: [D loss: 0.696564, acc: 0.490234]: [A loss: 0.733235, acc: 0.234375]\n",
      "4854: [D loss: 0.695834, acc: 0.490234]: [A loss: 0.728578, acc: 0.226562]\n",
      "4855: [D loss: 0.694365, acc: 0.496094]: [A loss: 0.686917, acc: 0.531250]\n",
      "4856: [D loss: 0.697938, acc: 0.521484]: [A loss: 0.693566, acc: 0.460938]\n",
      "4857: [D loss: 0.699072, acc: 0.478516]: [A loss: 0.724966, acc: 0.257812]\n",
      "4858: [D loss: 0.693290, acc: 0.537109]: [A loss: 0.724109, acc: 0.304688]\n",
      "4859: [D loss: 0.695948, acc: 0.519531]: [A loss: 0.732391, acc: 0.210938]\n",
      "4860: [D loss: 0.693222, acc: 0.544922]: [A loss: 0.709124, acc: 0.386719]\n",
      "4861: [D loss: 0.697563, acc: 0.488281]: [A loss: 0.770881, acc: 0.074219]\n",
      "4862: [D loss: 0.693258, acc: 0.517578]: [A loss: 0.682073, acc: 0.562500]\n",
      "4863: [D loss: 0.695205, acc: 0.490234]: [A loss: 0.729065, acc: 0.230469]\n",
      "4864: [D loss: 0.696492, acc: 0.509766]: [A loss: 0.696315, acc: 0.468750]\n",
      "4865: [D loss: 0.696065, acc: 0.515625]: [A loss: 0.712621, acc: 0.343750]\n",
      "4866: [D loss: 0.695179, acc: 0.490234]: [A loss: 0.721544, acc: 0.242188]\n",
      "4867: [D loss: 0.690875, acc: 0.519531]: [A loss: 0.707597, acc: 0.371094]\n",
      "4868: [D loss: 0.696310, acc: 0.513672]: [A loss: 0.703102, acc: 0.414062]\n",
      "4869: [D loss: 0.703220, acc: 0.500000]: [A loss: 0.788557, acc: 0.058594]\n",
      "4870: [D loss: 0.694903, acc: 0.490234]: [A loss: 0.713176, acc: 0.343750]\n",
      "4871: [D loss: 0.700267, acc: 0.490234]: [A loss: 0.733879, acc: 0.203125]\n",
      "4872: [D loss: 0.698054, acc: 0.482422]: [A loss: 0.700210, acc: 0.464844]\n",
      "4873: [D loss: 0.697081, acc: 0.492188]: [A loss: 0.731923, acc: 0.265625]\n",
      "4874: [D loss: 0.691589, acc: 0.535156]: [A loss: 0.723641, acc: 0.292969]\n",
      "4875: [D loss: 0.693169, acc: 0.527344]: [A loss: 0.729052, acc: 0.238281]\n",
      "4876: [D loss: 0.694208, acc: 0.494141]: [A loss: 0.721472, acc: 0.281250]\n",
      "4877: [D loss: 0.695394, acc: 0.503906]: [A loss: 0.724968, acc: 0.292969]\n",
      "4878: [D loss: 0.695215, acc: 0.500000]: [A loss: 0.719360, acc: 0.292969]\n",
      "4879: [D loss: 0.696223, acc: 0.486328]: [A loss: 0.723748, acc: 0.289062]\n",
      "4880: [D loss: 0.699877, acc: 0.482422]: [A loss: 0.756807, acc: 0.105469]\n",
      "4881: [D loss: 0.693163, acc: 0.501953]: [A loss: 0.711043, acc: 0.332031]\n",
      "4882: [D loss: 0.693178, acc: 0.513672]: [A loss: 0.697975, acc: 0.437500]\n",
      "4883: [D loss: 0.698640, acc: 0.507812]: [A loss: 0.750306, acc: 0.167969]\n",
      "4884: [D loss: 0.690322, acc: 0.537109]: [A loss: 0.689299, acc: 0.492188]\n",
      "4885: [D loss: 0.696059, acc: 0.501953]: [A loss: 0.721027, acc: 0.312500]\n",
      "4886: [D loss: 0.701103, acc: 0.511719]: [A loss: 0.767798, acc: 0.093750]\n",
      "4887: [D loss: 0.696911, acc: 0.478516]: [A loss: 0.732894, acc: 0.230469]\n",
      "4888: [D loss: 0.691603, acc: 0.521484]: [A loss: 0.709648, acc: 0.382812]\n",
      "4889: [D loss: 0.696803, acc: 0.525391]: [A loss: 0.723812, acc: 0.296875]\n",
      "4890: [D loss: 0.694991, acc: 0.513672]: [A loss: 0.688852, acc: 0.488281]\n",
      "4891: [D loss: 0.698083, acc: 0.488281]: [A loss: 0.729263, acc: 0.257812]\n",
      "4892: [D loss: 0.695597, acc: 0.490234]: [A loss: 0.704137, acc: 0.386719]\n",
      "4893: [D loss: 0.701079, acc: 0.486328]: [A loss: 0.723455, acc: 0.277344]\n",
      "4894: [D loss: 0.692305, acc: 0.498047]: [A loss: 0.691219, acc: 0.488281]\n",
      "4895: [D loss: 0.698506, acc: 0.513672]: [A loss: 0.761912, acc: 0.132812]\n",
      "4896: [D loss: 0.693127, acc: 0.513672]: [A loss: 0.736149, acc: 0.199219]\n",
      "4897: [D loss: 0.690324, acc: 0.527344]: [A loss: 0.717884, acc: 0.312500]\n",
      "4898: [D loss: 0.694250, acc: 0.513672]: [A loss: 0.712175, acc: 0.347656]\n",
      "4899: [D loss: 0.698185, acc: 0.468750]: [A loss: 0.724513, acc: 0.273438]\n",
      "4900: [D loss: 0.697005, acc: 0.490234]: [A loss: 0.691546, acc: 0.515625]\n",
      "4901: [D loss: 0.697419, acc: 0.501953]: [A loss: 0.759829, acc: 0.128906]\n",
      "4902: [D loss: 0.694198, acc: 0.505859]: [A loss: 0.692563, acc: 0.507812]\n",
      "4903: [D loss: 0.696184, acc: 0.519531]: [A loss: 0.710060, acc: 0.347656]\n",
      "4904: [D loss: 0.695784, acc: 0.505859]: [A loss: 0.727674, acc: 0.257812]\n",
      "4905: [D loss: 0.694812, acc: 0.492188]: [A loss: 0.709261, acc: 0.394531]\n",
      "4906: [D loss: 0.694706, acc: 0.498047]: [A loss: 0.716271, acc: 0.332031]\n",
      "4907: [D loss: 0.697152, acc: 0.496094]: [A loss: 0.724766, acc: 0.257812]\n",
      "4908: [D loss: 0.694006, acc: 0.515625]: [A loss: 0.716995, acc: 0.300781]\n",
      "4909: [D loss: 0.696918, acc: 0.486328]: [A loss: 0.704101, acc: 0.417969]\n",
      "4910: [D loss: 0.694945, acc: 0.494141]: [A loss: 0.724810, acc: 0.273438]\n",
      "4911: [D loss: 0.695229, acc: 0.503906]: [A loss: 0.708251, acc: 0.371094]\n",
      "4912: [D loss: 0.693664, acc: 0.505859]: [A loss: 0.716026, acc: 0.304688]\n",
      "4913: [D loss: 0.693536, acc: 0.498047]: [A loss: 0.677254, acc: 0.554688]\n",
      "4914: [D loss: 0.701585, acc: 0.517578]: [A loss: 0.761267, acc: 0.101562]\n",
      "4915: [D loss: 0.695785, acc: 0.509766]: [A loss: 0.696867, acc: 0.464844]\n",
      "4916: [D loss: 0.698171, acc: 0.494141]: [A loss: 0.702707, acc: 0.421875]\n",
      "4917: [D loss: 0.694090, acc: 0.517578]: [A loss: 0.719923, acc: 0.281250]\n",
      "4918: [D loss: 0.693396, acc: 0.539062]: [A loss: 0.735967, acc: 0.171875]\n",
      "4919: [D loss: 0.697475, acc: 0.490234]: [A loss: 0.726325, acc: 0.296875]\n",
      "4920: [D loss: 0.693129, acc: 0.494141]: [A loss: 0.709438, acc: 0.355469]\n",
      "4921: [D loss: 0.700147, acc: 0.498047]: [A loss: 0.714857, acc: 0.316406]\n",
      "4922: [D loss: 0.692913, acc: 0.521484]: [A loss: 0.694872, acc: 0.519531]\n",
      "4923: [D loss: 0.699888, acc: 0.500000]: [A loss: 0.719430, acc: 0.324219]\n",
      "4924: [D loss: 0.694322, acc: 0.498047]: [A loss: 0.714282, acc: 0.347656]\n",
      "4925: [D loss: 0.692208, acc: 0.521484]: [A loss: 0.730685, acc: 0.261719]\n",
      "4926: [D loss: 0.697952, acc: 0.482422]: [A loss: 0.730287, acc: 0.261719]\n",
      "4927: [D loss: 0.695692, acc: 0.519531]: [A loss: 0.706517, acc: 0.417969]\n",
      "4928: [D loss: 0.696513, acc: 0.517578]: [A loss: 0.742572, acc: 0.183594]\n",
      "4929: [D loss: 0.698538, acc: 0.462891]: [A loss: 0.765815, acc: 0.062500]\n",
      "4930: [D loss: 0.691207, acc: 0.535156]: [A loss: 0.715176, acc: 0.300781]\n",
      "4931: [D loss: 0.688844, acc: 0.562500]: [A loss: 0.712062, acc: 0.378906]\n",
      "4932: [D loss: 0.696191, acc: 0.521484]: [A loss: 0.722107, acc: 0.308594]\n",
      "4933: [D loss: 0.696357, acc: 0.498047]: [A loss: 0.698577, acc: 0.441406]\n",
      "4934: [D loss: 0.696536, acc: 0.515625]: [A loss: 0.725287, acc: 0.273438]\n",
      "4935: [D loss: 0.693972, acc: 0.509766]: [A loss: 0.697423, acc: 0.445312]\n",
      "4936: [D loss: 0.696351, acc: 0.503906]: [A loss: 0.719769, acc: 0.320312]\n",
      "4937: [D loss: 0.692716, acc: 0.505859]: [A loss: 0.690932, acc: 0.496094]\n",
      "4938: [D loss: 0.701969, acc: 0.500000]: [A loss: 0.762692, acc: 0.109375]\n",
      "4939: [D loss: 0.691581, acc: 0.503906]: [A loss: 0.694085, acc: 0.476562]\n",
      "4940: [D loss: 0.693401, acc: 0.525391]: [A loss: 0.690287, acc: 0.496094]\n",
      "4941: [D loss: 0.691650, acc: 0.519531]: [A loss: 0.732294, acc: 0.214844]\n",
      "4942: [D loss: 0.694892, acc: 0.494141]: [A loss: 0.725196, acc: 0.273438]\n",
      "4943: [D loss: 0.695586, acc: 0.515625]: [A loss: 0.723254, acc: 0.257812]\n",
      "4944: [D loss: 0.694248, acc: 0.527344]: [A loss: 0.707411, acc: 0.363281]\n",
      "4945: [D loss: 0.695155, acc: 0.513672]: [A loss: 0.694654, acc: 0.488281]\n",
      "4946: [D loss: 0.695374, acc: 0.498047]: [A loss: 0.707239, acc: 0.375000]\n",
      "4947: [D loss: 0.698601, acc: 0.500000]: [A loss: 0.725510, acc: 0.250000]\n",
      "4948: [D loss: 0.697076, acc: 0.492188]: [A loss: 0.721594, acc: 0.292969]\n",
      "4949: [D loss: 0.696105, acc: 0.468750]: [A loss: 0.713367, acc: 0.320312]\n",
      "4950: [D loss: 0.696364, acc: 0.472656]: [A loss: 0.755491, acc: 0.117188]\n",
      "4951: [D loss: 0.691695, acc: 0.525391]: [A loss: 0.689844, acc: 0.500000]\n",
      "4952: [D loss: 0.697762, acc: 0.498047]: [A loss: 0.758762, acc: 0.113281]\n",
      "4953: [D loss: 0.696099, acc: 0.482422]: [A loss: 0.689895, acc: 0.519531]\n",
      "4954: [D loss: 0.700989, acc: 0.503906]: [A loss: 0.721602, acc: 0.257812]\n",
      "4955: [D loss: 0.694148, acc: 0.556641]: [A loss: 0.736721, acc: 0.250000]\n",
      "4956: [D loss: 0.694441, acc: 0.500000]: [A loss: 0.720626, acc: 0.296875]\n",
      "4957: [D loss: 0.692021, acc: 0.533203]: [A loss: 0.706064, acc: 0.375000]\n",
      "4958: [D loss: 0.698897, acc: 0.517578]: [A loss: 0.745893, acc: 0.167969]\n",
      "4959: [D loss: 0.695858, acc: 0.507812]: [A loss: 0.714259, acc: 0.339844]\n",
      "4960: [D loss: 0.694816, acc: 0.488281]: [A loss: 0.716145, acc: 0.324219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4961: [D loss: 0.700179, acc: 0.505859]: [A loss: 0.693528, acc: 0.480469]\n",
      "4962: [D loss: 0.694816, acc: 0.517578]: [A loss: 0.741939, acc: 0.156250]\n",
      "4963: [D loss: 0.694069, acc: 0.525391]: [A loss: 0.704982, acc: 0.394531]\n",
      "4964: [D loss: 0.691514, acc: 0.539062]: [A loss: 0.673449, acc: 0.609375]\n",
      "4965: [D loss: 0.699889, acc: 0.494141]: [A loss: 0.758692, acc: 0.105469]\n",
      "4966: [D loss: 0.698703, acc: 0.466797]: [A loss: 0.707819, acc: 0.363281]\n",
      "4967: [D loss: 0.696028, acc: 0.488281]: [A loss: 0.700496, acc: 0.460938]\n",
      "4968: [D loss: 0.694874, acc: 0.517578]: [A loss: 0.703323, acc: 0.390625]\n",
      "4969: [D loss: 0.697209, acc: 0.462891]: [A loss: 0.729391, acc: 0.238281]\n",
      "4970: [D loss: 0.692862, acc: 0.529297]: [A loss: 0.711526, acc: 0.335938]\n",
      "4971: [D loss: 0.696355, acc: 0.484375]: [A loss: 0.701510, acc: 0.449219]\n",
      "4972: [D loss: 0.696645, acc: 0.513672]: [A loss: 0.724596, acc: 0.320312]\n",
      "4973: [D loss: 0.694078, acc: 0.513672]: [A loss: 0.698308, acc: 0.417969]\n",
      "4974: [D loss: 0.696818, acc: 0.511719]: [A loss: 0.724233, acc: 0.285156]\n",
      "4975: [D loss: 0.693530, acc: 0.498047]: [A loss: 0.691945, acc: 0.519531]\n",
      "4976: [D loss: 0.697068, acc: 0.509766]: [A loss: 0.753108, acc: 0.132812]\n",
      "4977: [D loss: 0.690126, acc: 0.539062]: [A loss: 0.682919, acc: 0.507812]\n",
      "4978: [D loss: 0.702396, acc: 0.492188]: [A loss: 0.765917, acc: 0.101562]\n",
      "4979: [D loss: 0.695175, acc: 0.501953]: [A loss: 0.713332, acc: 0.328125]\n",
      "4980: [D loss: 0.698911, acc: 0.476562]: [A loss: 0.721891, acc: 0.265625]\n",
      "4981: [D loss: 0.691169, acc: 0.523438]: [A loss: 0.709374, acc: 0.375000]\n",
      "4982: [D loss: 0.693699, acc: 0.529297]: [A loss: 0.721709, acc: 0.281250]\n",
      "4983: [D loss: 0.699668, acc: 0.496094]: [A loss: 0.747352, acc: 0.144531]\n",
      "4984: [D loss: 0.692396, acc: 0.501953]: [A loss: 0.702237, acc: 0.371094]\n",
      "4985: [D loss: 0.698505, acc: 0.488281]: [A loss: 0.730047, acc: 0.253906]\n",
      "4986: [D loss: 0.696003, acc: 0.480469]: [A loss: 0.734980, acc: 0.234375]\n",
      "4987: [D loss: 0.696209, acc: 0.500000]: [A loss: 0.728364, acc: 0.277344]\n",
      "4988: [D loss: 0.696184, acc: 0.482422]: [A loss: 0.704357, acc: 0.425781]\n",
      "4989: [D loss: 0.704542, acc: 0.513672]: [A loss: 0.778128, acc: 0.054688]\n",
      "4990: [D loss: 0.695542, acc: 0.486328]: [A loss: 0.703754, acc: 0.402344]\n",
      "4991: [D loss: 0.692048, acc: 0.513672]: [A loss: 0.694897, acc: 0.476562]\n",
      "4992: [D loss: 0.697604, acc: 0.496094]: [A loss: 0.713398, acc: 0.328125]\n",
      "4993: [D loss: 0.695977, acc: 0.501953]: [A loss: 0.710818, acc: 0.375000]\n",
      "4994: [D loss: 0.692618, acc: 0.525391]: [A loss: 0.708982, acc: 0.347656]\n",
      "4995: [D loss: 0.693857, acc: 0.484375]: [A loss: 0.709549, acc: 0.378906]\n",
      "4996: [D loss: 0.700336, acc: 0.503906]: [A loss: 0.743303, acc: 0.179688]\n",
      "4997: [D loss: 0.694753, acc: 0.500000]: [A loss: 0.701488, acc: 0.429688]\n",
      "4998: [D loss: 0.697360, acc: 0.500000]: [A loss: 0.763747, acc: 0.085938]\n",
      "4999: [D loss: 0.695713, acc: 0.507812]: [A loss: 0.704302, acc: 0.394531]\n",
      "5000: [D loss: 0.699523, acc: 0.498047]: [A loss: 0.702371, acc: 0.398438]\n",
      "5001: [D loss: 0.694632, acc: 0.501953]: [A loss: 0.696617, acc: 0.449219]\n",
      "5002: [D loss: 0.696526, acc: 0.519531]: [A loss: 0.700898, acc: 0.433594]\n",
      "5003: [D loss: 0.695344, acc: 0.513672]: [A loss: 0.692236, acc: 0.468750]\n",
      "5004: [D loss: 0.701976, acc: 0.509766]: [A loss: 0.754312, acc: 0.105469]\n",
      "5005: [D loss: 0.692321, acc: 0.519531]: [A loss: 0.713190, acc: 0.308594]\n",
      "5006: [D loss: 0.694790, acc: 0.523438]: [A loss: 0.751720, acc: 0.164062]\n",
      "5007: [D loss: 0.688645, acc: 0.566406]: [A loss: 0.704005, acc: 0.445312]\n",
      "5008: [D loss: 0.696128, acc: 0.503906]: [A loss: 0.745188, acc: 0.195312]\n",
      "5009: [D loss: 0.690908, acc: 0.550781]: [A loss: 0.713879, acc: 0.328125]\n",
      "5010: [D loss: 0.704382, acc: 0.478516]: [A loss: 0.737911, acc: 0.210938]\n",
      "5011: [D loss: 0.697666, acc: 0.466797]: [A loss: 0.716655, acc: 0.308594]\n",
      "5012: [D loss: 0.692512, acc: 0.529297]: [A loss: 0.748567, acc: 0.144531]\n",
      "5013: [D loss: 0.689255, acc: 0.523438]: [A loss: 0.686715, acc: 0.511719]\n",
      "5014: [D loss: 0.695974, acc: 0.503906]: [A loss: 0.707815, acc: 0.394531]\n",
      "5015: [D loss: 0.691506, acc: 0.503906]: [A loss: 0.699399, acc: 0.421875]\n",
      "5016: [D loss: 0.696264, acc: 0.515625]: [A loss: 0.734237, acc: 0.234375]\n",
      "5017: [D loss: 0.694773, acc: 0.490234]: [A loss: 0.716730, acc: 0.320312]\n",
      "5018: [D loss: 0.693790, acc: 0.500000]: [A loss: 0.726402, acc: 0.238281]\n",
      "5019: [D loss: 0.691335, acc: 0.515625]: [A loss: 0.718261, acc: 0.335938]\n",
      "5020: [D loss: 0.692880, acc: 0.500000]: [A loss: 0.704619, acc: 0.406250]\n",
      "5021: [D loss: 0.695590, acc: 0.517578]: [A loss: 0.728262, acc: 0.238281]\n",
      "5022: [D loss: 0.688280, acc: 0.539062]: [A loss: 0.678359, acc: 0.574219]\n",
      "5023: [D loss: 0.698173, acc: 0.498047]: [A loss: 0.757979, acc: 0.113281]\n",
      "5024: [D loss: 0.695313, acc: 0.503906]: [A loss: 0.696115, acc: 0.464844]\n",
      "5025: [D loss: 0.696445, acc: 0.529297]: [A loss: 0.760985, acc: 0.109375]\n",
      "5026: [D loss: 0.692987, acc: 0.521484]: [A loss: 0.705737, acc: 0.390625]\n",
      "5027: [D loss: 0.699855, acc: 0.476562]: [A loss: 0.708172, acc: 0.375000]\n",
      "5028: [D loss: 0.695042, acc: 0.511719]: [A loss: 0.702756, acc: 0.417969]\n",
      "5029: [D loss: 0.697222, acc: 0.521484]: [A loss: 0.737815, acc: 0.195312]\n",
      "5030: [D loss: 0.693483, acc: 0.482422]: [A loss: 0.694885, acc: 0.484375]\n",
      "5031: [D loss: 0.695981, acc: 0.503906]: [A loss: 0.707964, acc: 0.375000]\n",
      "5032: [D loss: 0.695324, acc: 0.505859]: [A loss: 0.729079, acc: 0.250000]\n",
      "5033: [D loss: 0.696591, acc: 0.472656]: [A loss: 0.738004, acc: 0.218750]\n",
      "5034: [D loss: 0.691055, acc: 0.533203]: [A loss: 0.729776, acc: 0.261719]\n",
      "5035: [D loss: 0.695253, acc: 0.492188]: [A loss: 0.727804, acc: 0.273438]\n",
      "5036: [D loss: 0.694997, acc: 0.511719]: [A loss: 0.728224, acc: 0.273438]\n",
      "5037: [D loss: 0.695782, acc: 0.470703]: [A loss: 0.721294, acc: 0.328125]\n",
      "5038: [D loss: 0.690657, acc: 0.535156]: [A loss: 0.732315, acc: 0.242188]\n",
      "5039: [D loss: 0.696685, acc: 0.500000]: [A loss: 0.720832, acc: 0.328125]\n",
      "5040: [D loss: 0.699053, acc: 0.505859]: [A loss: 0.726950, acc: 0.269531]\n",
      "5041: [D loss: 0.694825, acc: 0.494141]: [A loss: 0.730912, acc: 0.242188]\n",
      "5042: [D loss: 0.695363, acc: 0.501953]: [A loss: 0.695359, acc: 0.425781]\n",
      "5043: [D loss: 0.698751, acc: 0.505859]: [A loss: 0.727030, acc: 0.273438]\n",
      "5044: [D loss: 0.692508, acc: 0.513672]: [A loss: 0.720080, acc: 0.285156]\n",
      "5045: [D loss: 0.695413, acc: 0.496094]: [A loss: 0.739008, acc: 0.164062]\n",
      "5046: [D loss: 0.692763, acc: 0.492188]: [A loss: 0.714268, acc: 0.339844]\n",
      "5047: [D loss: 0.693942, acc: 0.496094]: [A loss: 0.731267, acc: 0.265625]\n",
      "5048: [D loss: 0.694404, acc: 0.509766]: [A loss: 0.717598, acc: 0.312500]\n",
      "5049: [D loss: 0.690298, acc: 0.533203]: [A loss: 0.674733, acc: 0.601562]\n",
      "5050: [D loss: 0.698824, acc: 0.505859]: [A loss: 0.806656, acc: 0.023438]\n",
      "5051: [D loss: 0.692277, acc: 0.507812]: [A loss: 0.704596, acc: 0.390625]\n",
      "5052: [D loss: 0.699116, acc: 0.501953]: [A loss: 0.734060, acc: 0.183594]\n",
      "5053: [D loss: 0.694742, acc: 0.505859]: [A loss: 0.714811, acc: 0.324219]\n",
      "5054: [D loss: 0.695114, acc: 0.500000]: [A loss: 0.722075, acc: 0.292969]\n",
      "5055: [D loss: 0.695307, acc: 0.523438]: [A loss: 0.713216, acc: 0.347656]\n",
      "5056: [D loss: 0.691680, acc: 0.525391]: [A loss: 0.722836, acc: 0.300781]\n",
      "5057: [D loss: 0.695083, acc: 0.462891]: [A loss: 0.727683, acc: 0.261719]\n",
      "5058: [D loss: 0.696429, acc: 0.509766]: [A loss: 0.724005, acc: 0.273438]\n",
      "5059: [D loss: 0.693504, acc: 0.509766]: [A loss: 0.713428, acc: 0.363281]\n",
      "5060: [D loss: 0.697455, acc: 0.513672]: [A loss: 0.724837, acc: 0.292969]\n",
      "5061: [D loss: 0.698053, acc: 0.496094]: [A loss: 0.723212, acc: 0.277344]\n",
      "5062: [D loss: 0.695925, acc: 0.474609]: [A loss: 0.700924, acc: 0.449219]\n",
      "5063: [D loss: 0.695094, acc: 0.507812]: [A loss: 0.724137, acc: 0.300781]\n",
      "5064: [D loss: 0.696386, acc: 0.498047]: [A loss: 0.722091, acc: 0.355469]\n",
      "5065: [D loss: 0.696223, acc: 0.507812]: [A loss: 0.718678, acc: 0.308594]\n",
      "5066: [D loss: 0.690630, acc: 0.531250]: [A loss: 0.724774, acc: 0.320312]\n",
      "5067: [D loss: 0.694307, acc: 0.501953]: [A loss: 0.701720, acc: 0.425781]\n",
      "5068: [D loss: 0.695862, acc: 0.498047]: [A loss: 0.744229, acc: 0.164062]\n",
      "5069: [D loss: 0.693073, acc: 0.501953]: [A loss: 0.714545, acc: 0.332031]\n",
      "5070: [D loss: 0.694092, acc: 0.515625]: [A loss: 0.737889, acc: 0.207031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5071: [D loss: 0.690473, acc: 0.529297]: [A loss: 0.711853, acc: 0.406250]\n",
      "5072: [D loss: 0.695640, acc: 0.529297]: [A loss: 0.734500, acc: 0.238281]\n",
      "5073: [D loss: 0.690204, acc: 0.519531]: [A loss: 0.695088, acc: 0.449219]\n",
      "5074: [D loss: 0.696062, acc: 0.513672]: [A loss: 0.737335, acc: 0.203125]\n",
      "5075: [D loss: 0.694566, acc: 0.494141]: [A loss: 0.719357, acc: 0.359375]\n",
      "5076: [D loss: 0.697719, acc: 0.486328]: [A loss: 0.730182, acc: 0.226562]\n",
      "5077: [D loss: 0.694414, acc: 0.505859]: [A loss: 0.695758, acc: 0.453125]\n",
      "5078: [D loss: 0.693157, acc: 0.482422]: [A loss: 0.723488, acc: 0.300781]\n",
      "5079: [D loss: 0.688164, acc: 0.548828]: [A loss: 0.696207, acc: 0.472656]\n",
      "5080: [D loss: 0.691831, acc: 0.507812]: [A loss: 0.730789, acc: 0.234375]\n",
      "5081: [D loss: 0.694995, acc: 0.498047]: [A loss: 0.745300, acc: 0.167969]\n",
      "5082: [D loss: 0.694339, acc: 0.507812]: [A loss: 0.724155, acc: 0.296875]\n",
      "5083: [D loss: 0.690612, acc: 0.537109]: [A loss: 0.707533, acc: 0.390625]\n",
      "5084: [D loss: 0.699806, acc: 0.482422]: [A loss: 0.760822, acc: 0.128906]\n",
      "5085: [D loss: 0.696390, acc: 0.511719]: [A loss: 0.717249, acc: 0.292969]\n",
      "5086: [D loss: 0.695687, acc: 0.478516]: [A loss: 0.699506, acc: 0.425781]\n",
      "5087: [D loss: 0.697983, acc: 0.490234]: [A loss: 0.719078, acc: 0.292969]\n",
      "5088: [D loss: 0.697943, acc: 0.478516]: [A loss: 0.728192, acc: 0.253906]\n",
      "5089: [D loss: 0.694302, acc: 0.525391]: [A loss: 0.752249, acc: 0.132812]\n",
      "5090: [D loss: 0.697664, acc: 0.466797]: [A loss: 0.713562, acc: 0.343750]\n",
      "5091: [D loss: 0.696786, acc: 0.525391]: [A loss: 0.748865, acc: 0.156250]\n",
      "5092: [D loss: 0.691186, acc: 0.529297]: [A loss: 0.686588, acc: 0.511719]\n",
      "5093: [D loss: 0.696418, acc: 0.474609]: [A loss: 0.734610, acc: 0.195312]\n",
      "5094: [D loss: 0.691746, acc: 0.527344]: [A loss: 0.744049, acc: 0.160156]\n",
      "5095: [D loss: 0.695789, acc: 0.509766]: [A loss: 0.732485, acc: 0.253906]\n",
      "5096: [D loss: 0.697147, acc: 0.492188]: [A loss: 0.760365, acc: 0.113281]\n",
      "5097: [D loss: 0.692368, acc: 0.484375]: [A loss: 0.703692, acc: 0.406250]\n",
      "5098: [D loss: 0.695645, acc: 0.507812]: [A loss: 0.750194, acc: 0.164062]\n",
      "5099: [D loss: 0.692190, acc: 0.501953]: [A loss: 0.702389, acc: 0.453125]\n",
      "5100: [D loss: 0.697241, acc: 0.494141]: [A loss: 0.757243, acc: 0.113281]\n",
      "5101: [D loss: 0.689634, acc: 0.542969]: [A loss: 0.687169, acc: 0.527344]\n",
      "5102: [D loss: 0.692203, acc: 0.503906]: [A loss: 0.705071, acc: 0.382812]\n",
      "5103: [D loss: 0.694679, acc: 0.511719]: [A loss: 0.733769, acc: 0.199219]\n",
      "5104: [D loss: 0.692309, acc: 0.515625]: [A loss: 0.693790, acc: 0.476562]\n",
      "5105: [D loss: 0.693523, acc: 0.523438]: [A loss: 0.718473, acc: 0.320312]\n",
      "5106: [D loss: 0.695071, acc: 0.509766]: [A loss: 0.720746, acc: 0.277344]\n",
      "5107: [D loss: 0.696705, acc: 0.500000]: [A loss: 0.741453, acc: 0.164062]\n",
      "5108: [D loss: 0.696054, acc: 0.503906]: [A loss: 0.708396, acc: 0.339844]\n",
      "5109: [D loss: 0.698083, acc: 0.453125]: [A loss: 0.733740, acc: 0.210938]\n",
      "5110: [D loss: 0.696497, acc: 0.511719]: [A loss: 0.686171, acc: 0.511719]\n",
      "5111: [D loss: 0.695581, acc: 0.517578]: [A loss: 0.771768, acc: 0.054688]\n",
      "5112: [D loss: 0.695613, acc: 0.490234]: [A loss: 0.712051, acc: 0.359375]\n",
      "5113: [D loss: 0.694767, acc: 0.513672]: [A loss: 0.727351, acc: 0.285156]\n",
      "5114: [D loss: 0.694291, acc: 0.515625]: [A loss: 0.724408, acc: 0.316406]\n",
      "5115: [D loss: 0.693748, acc: 0.519531]: [A loss: 0.744282, acc: 0.179688]\n",
      "5116: [D loss: 0.689451, acc: 0.541016]: [A loss: 0.690552, acc: 0.472656]\n",
      "5117: [D loss: 0.696987, acc: 0.503906]: [A loss: 0.762384, acc: 0.117188]\n",
      "5118: [D loss: 0.692474, acc: 0.531250]: [A loss: 0.684201, acc: 0.558594]\n",
      "5119: [D loss: 0.701817, acc: 0.501953]: [A loss: 0.779651, acc: 0.082031]\n",
      "5120: [D loss: 0.694168, acc: 0.509766]: [A loss: 0.705724, acc: 0.386719]\n",
      "5121: [D loss: 0.696260, acc: 0.517578]: [A loss: 0.719313, acc: 0.351562]\n",
      "5122: [D loss: 0.696417, acc: 0.521484]: [A loss: 0.731739, acc: 0.242188]\n",
      "5123: [D loss: 0.694847, acc: 0.505859]: [A loss: 0.715583, acc: 0.355469]\n",
      "5124: [D loss: 0.692413, acc: 0.513672]: [A loss: 0.696697, acc: 0.492188]\n",
      "5125: [D loss: 0.692602, acc: 0.537109]: [A loss: 0.735270, acc: 0.218750]\n",
      "5126: [D loss: 0.696000, acc: 0.517578]: [A loss: 0.741345, acc: 0.210938]\n",
      "5127: [D loss: 0.692004, acc: 0.521484]: [A loss: 0.687374, acc: 0.503906]\n",
      "5128: [D loss: 0.698846, acc: 0.498047]: [A loss: 0.728647, acc: 0.250000]\n",
      "5129: [D loss: 0.688265, acc: 0.527344]: [A loss: 0.696214, acc: 0.488281]\n",
      "5130: [D loss: 0.696849, acc: 0.513672]: [A loss: 0.718021, acc: 0.324219]\n",
      "5131: [D loss: 0.693664, acc: 0.513672]: [A loss: 0.709157, acc: 0.339844]\n",
      "5132: [D loss: 0.693531, acc: 0.517578]: [A loss: 0.708206, acc: 0.390625]\n",
      "5133: [D loss: 0.699219, acc: 0.500000]: [A loss: 0.765176, acc: 0.105469]\n",
      "5134: [D loss: 0.695291, acc: 0.501953]: [A loss: 0.722838, acc: 0.292969]\n",
      "5135: [D loss: 0.697876, acc: 0.460938]: [A loss: 0.741618, acc: 0.167969]\n",
      "5136: [D loss: 0.694052, acc: 0.517578]: [A loss: 0.726216, acc: 0.277344]\n",
      "5137: [D loss: 0.695667, acc: 0.507812]: [A loss: 0.714871, acc: 0.351562]\n",
      "5138: [D loss: 0.696817, acc: 0.494141]: [A loss: 0.709368, acc: 0.382812]\n",
      "5139: [D loss: 0.695022, acc: 0.507812]: [A loss: 0.738599, acc: 0.210938]\n",
      "5140: [D loss: 0.694726, acc: 0.501953]: [A loss: 0.718685, acc: 0.332031]\n",
      "5141: [D loss: 0.696648, acc: 0.453125]: [A loss: 0.691449, acc: 0.515625]\n",
      "5142: [D loss: 0.697863, acc: 0.507812]: [A loss: 0.721142, acc: 0.289062]\n",
      "5143: [D loss: 0.695014, acc: 0.529297]: [A loss: 0.711142, acc: 0.371094]\n",
      "5144: [D loss: 0.699190, acc: 0.474609]: [A loss: 0.708694, acc: 0.402344]\n",
      "5145: [D loss: 0.698872, acc: 0.513672]: [A loss: 0.726390, acc: 0.257812]\n",
      "5146: [D loss: 0.692039, acc: 0.519531]: [A loss: 0.703870, acc: 0.406250]\n",
      "5147: [D loss: 0.696007, acc: 0.515625]: [A loss: 0.732799, acc: 0.203125]\n",
      "5148: [D loss: 0.689560, acc: 0.537109]: [A loss: 0.712996, acc: 0.320312]\n",
      "5149: [D loss: 0.694481, acc: 0.509766]: [A loss: 0.742676, acc: 0.195312]\n",
      "5150: [D loss: 0.697898, acc: 0.478516]: [A loss: 0.710447, acc: 0.378906]\n",
      "5151: [D loss: 0.694175, acc: 0.507812]: [A loss: 0.711522, acc: 0.359375]\n",
      "5152: [D loss: 0.695567, acc: 0.478516]: [A loss: 0.725893, acc: 0.261719]\n",
      "5153: [D loss: 0.694990, acc: 0.507812]: [A loss: 0.721886, acc: 0.289062]\n",
      "5154: [D loss: 0.693194, acc: 0.523438]: [A loss: 0.697661, acc: 0.441406]\n",
      "5155: [D loss: 0.693793, acc: 0.505859]: [A loss: 0.696796, acc: 0.488281]\n",
      "5156: [D loss: 0.695833, acc: 0.519531]: [A loss: 0.803124, acc: 0.027344]\n",
      "5157: [D loss: 0.694177, acc: 0.529297]: [A loss: 0.705516, acc: 0.382812]\n",
      "5158: [D loss: 0.698718, acc: 0.492188]: [A loss: 0.713507, acc: 0.351562]\n",
      "5159: [D loss: 0.693801, acc: 0.500000]: [A loss: 0.707575, acc: 0.386719]\n",
      "5160: [D loss: 0.696046, acc: 0.498047]: [A loss: 0.733225, acc: 0.222656]\n",
      "5161: [D loss: 0.696833, acc: 0.466797]: [A loss: 0.672727, acc: 0.632812]\n",
      "5162: [D loss: 0.694825, acc: 0.509766]: [A loss: 0.719910, acc: 0.289062]\n",
      "5163: [D loss: 0.697409, acc: 0.498047]: [A loss: 0.723983, acc: 0.234375]\n",
      "5164: [D loss: 0.699747, acc: 0.494141]: [A loss: 0.722164, acc: 0.300781]\n",
      "5165: [D loss: 0.694808, acc: 0.515625]: [A loss: 0.723506, acc: 0.257812]\n",
      "5166: [D loss: 0.694422, acc: 0.513672]: [A loss: 0.693143, acc: 0.511719]\n",
      "5167: [D loss: 0.695200, acc: 0.513672]: [A loss: 0.742879, acc: 0.179688]\n",
      "5168: [D loss: 0.696418, acc: 0.490234]: [A loss: 0.707561, acc: 0.351562]\n",
      "5169: [D loss: 0.691150, acc: 0.501953]: [A loss: 0.702726, acc: 0.406250]\n",
      "5170: [D loss: 0.693051, acc: 0.529297]: [A loss: 0.735804, acc: 0.203125]\n",
      "5171: [D loss: 0.692306, acc: 0.527344]: [A loss: 0.728625, acc: 0.269531]\n",
      "5172: [D loss: 0.692123, acc: 0.517578]: [A loss: 0.638290, acc: 0.800781]\n",
      "5173: [D loss: 0.711225, acc: 0.505859]: [A loss: 0.785312, acc: 0.023438]\n",
      "5174: [D loss: 0.693503, acc: 0.509766]: [A loss: 0.693065, acc: 0.472656]\n",
      "5175: [D loss: 0.696259, acc: 0.505859]: [A loss: 0.695055, acc: 0.476562]\n",
      "5176: [D loss: 0.695104, acc: 0.517578]: [A loss: 0.706628, acc: 0.375000]\n",
      "5177: [D loss: 0.694985, acc: 0.515625]: [A loss: 0.698950, acc: 0.445312]\n",
      "5178: [D loss: 0.693617, acc: 0.503906]: [A loss: 0.732818, acc: 0.230469]\n",
      "5179: [D loss: 0.693965, acc: 0.458984]: [A loss: 0.722977, acc: 0.312500]\n",
      "5180: [D loss: 0.686497, acc: 0.566406]: [A loss: 0.689618, acc: 0.515625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5181: [D loss: 0.695253, acc: 0.523438]: [A loss: 0.705261, acc: 0.386719]\n",
      "5182: [D loss: 0.691148, acc: 0.533203]: [A loss: 0.674689, acc: 0.597656]\n",
      "5183: [D loss: 0.692251, acc: 0.539062]: [A loss: 0.684028, acc: 0.539062]\n",
      "5184: [D loss: 0.698993, acc: 0.505859]: [A loss: 0.696988, acc: 0.429688]\n",
      "5185: [D loss: 0.690575, acc: 0.523438]: [A loss: 0.686322, acc: 0.546875]\n",
      "5186: [D loss: 0.696845, acc: 0.521484]: [A loss: 0.756977, acc: 0.125000]\n",
      "5187: [D loss: 0.699239, acc: 0.451172]: [A loss: 0.690630, acc: 0.523438]\n",
      "5188: [D loss: 0.692143, acc: 0.531250]: [A loss: 0.691466, acc: 0.472656]\n",
      "5189: [D loss: 0.697937, acc: 0.511719]: [A loss: 0.717752, acc: 0.312500]\n",
      "5190: [D loss: 0.693000, acc: 0.513672]: [A loss: 0.711344, acc: 0.355469]\n",
      "5191: [D loss: 0.693140, acc: 0.515625]: [A loss: 0.693674, acc: 0.488281]\n",
      "5192: [D loss: 0.699401, acc: 0.498047]: [A loss: 0.723228, acc: 0.289062]\n",
      "5193: [D loss: 0.694788, acc: 0.509766]: [A loss: 0.701074, acc: 0.457031]\n",
      "5194: [D loss: 0.697648, acc: 0.507812]: [A loss: 0.702411, acc: 0.437500]\n",
      "5195: [D loss: 0.694755, acc: 0.511719]: [A loss: 0.714000, acc: 0.351562]\n",
      "5196: [D loss: 0.692609, acc: 0.539062]: [A loss: 0.700095, acc: 0.441406]\n",
      "5197: [D loss: 0.690713, acc: 0.521484]: [A loss: 0.716944, acc: 0.324219]\n",
      "5198: [D loss: 0.695744, acc: 0.523438]: [A loss: 0.730381, acc: 0.242188]\n",
      "5199: [D loss: 0.694809, acc: 0.511719]: [A loss: 0.724890, acc: 0.304688]\n",
      "5200: [D loss: 0.699295, acc: 0.468750]: [A loss: 0.718185, acc: 0.316406]\n",
      "5201: [D loss: 0.693791, acc: 0.513672]: [A loss: 0.712060, acc: 0.332031]\n",
      "5202: [D loss: 0.693658, acc: 0.521484]: [A loss: 0.702640, acc: 0.429688]\n",
      "5203: [D loss: 0.696571, acc: 0.505859]: [A loss: 0.713789, acc: 0.363281]\n",
      "5204: [D loss: 0.691974, acc: 0.533203]: [A loss: 0.706049, acc: 0.347656]\n",
      "5205: [D loss: 0.695754, acc: 0.523438]: [A loss: 0.722174, acc: 0.328125]\n",
      "5206: [D loss: 0.692817, acc: 0.535156]: [A loss: 0.713092, acc: 0.378906]\n",
      "5207: [D loss: 0.696730, acc: 0.480469]: [A loss: 0.724768, acc: 0.308594]\n",
      "5208: [D loss: 0.697317, acc: 0.501953]: [A loss: 0.743916, acc: 0.167969]\n",
      "5209: [D loss: 0.694183, acc: 0.509766]: [A loss: 0.714772, acc: 0.367188]\n",
      "5210: [D loss: 0.694782, acc: 0.525391]: [A loss: 0.737354, acc: 0.242188]\n",
      "5211: [D loss: 0.697341, acc: 0.494141]: [A loss: 0.716605, acc: 0.355469]\n",
      "5212: [D loss: 0.692005, acc: 0.505859]: [A loss: 0.719931, acc: 0.304688]\n",
      "5213: [D loss: 0.692464, acc: 0.519531]: [A loss: 0.755410, acc: 0.125000]\n",
      "5214: [D loss: 0.695000, acc: 0.513672]: [A loss: 0.706034, acc: 0.429688]\n",
      "5215: [D loss: 0.693662, acc: 0.531250]: [A loss: 0.707403, acc: 0.378906]\n",
      "5216: [D loss: 0.696054, acc: 0.486328]: [A loss: 0.721027, acc: 0.304688]\n",
      "5217: [D loss: 0.689223, acc: 0.511719]: [A loss: 0.714871, acc: 0.347656]\n",
      "5218: [D loss: 0.694806, acc: 0.490234]: [A loss: 0.705846, acc: 0.371094]\n",
      "5219: [D loss: 0.697164, acc: 0.513672]: [A loss: 0.718960, acc: 0.316406]\n",
      "5220: [D loss: 0.693138, acc: 0.537109]: [A loss: 0.694781, acc: 0.464844]\n",
      "5221: [D loss: 0.689957, acc: 0.509766]: [A loss: 0.729797, acc: 0.257812]\n",
      "5222: [D loss: 0.690599, acc: 0.513672]: [A loss: 0.719392, acc: 0.308594]\n",
      "5223: [D loss: 0.698357, acc: 0.472656]: [A loss: 0.721155, acc: 0.304688]\n",
      "5224: [D loss: 0.698682, acc: 0.501953]: [A loss: 0.750373, acc: 0.160156]\n",
      "5225: [D loss: 0.695926, acc: 0.490234]: [A loss: 0.738316, acc: 0.191406]\n",
      "5226: [D loss: 0.697825, acc: 0.494141]: [A loss: 0.716792, acc: 0.347656]\n",
      "5227: [D loss: 0.698913, acc: 0.474609]: [A loss: 0.719154, acc: 0.347656]\n",
      "5228: [D loss: 0.690580, acc: 0.505859]: [A loss: 0.691631, acc: 0.503906]\n",
      "5229: [D loss: 0.704105, acc: 0.492188]: [A loss: 0.732659, acc: 0.210938]\n",
      "5230: [D loss: 0.688563, acc: 0.544922]: [A loss: 0.667445, acc: 0.644531]\n",
      "5231: [D loss: 0.695998, acc: 0.494141]: [A loss: 0.746273, acc: 0.160156]\n",
      "5232: [D loss: 0.695599, acc: 0.496094]: [A loss: 0.694974, acc: 0.531250]\n",
      "5233: [D loss: 0.703692, acc: 0.478516]: [A loss: 0.748962, acc: 0.144531]\n",
      "5234: [D loss: 0.692939, acc: 0.505859]: [A loss: 0.729959, acc: 0.257812]\n",
      "5235: [D loss: 0.692247, acc: 0.531250]: [A loss: 0.716253, acc: 0.378906]\n",
      "5236: [D loss: 0.697245, acc: 0.470703]: [A loss: 0.727100, acc: 0.277344]\n",
      "5237: [D loss: 0.692045, acc: 0.542969]: [A loss: 0.706131, acc: 0.402344]\n",
      "5238: [D loss: 0.692955, acc: 0.535156]: [A loss: 0.714598, acc: 0.359375]\n",
      "5239: [D loss: 0.694431, acc: 0.507812]: [A loss: 0.714602, acc: 0.316406]\n",
      "5240: [D loss: 0.697038, acc: 0.492188]: [A loss: 0.717266, acc: 0.328125]\n",
      "5241: [D loss: 0.691341, acc: 0.535156]: [A loss: 0.700257, acc: 0.429688]\n",
      "5242: [D loss: 0.689658, acc: 0.541016]: [A loss: 0.707007, acc: 0.417969]\n",
      "5243: [D loss: 0.694362, acc: 0.519531]: [A loss: 0.723989, acc: 0.285156]\n",
      "5244: [D loss: 0.695447, acc: 0.496094]: [A loss: 0.706638, acc: 0.421875]\n",
      "5245: [D loss: 0.699466, acc: 0.494141]: [A loss: 0.706883, acc: 0.390625]\n",
      "5246: [D loss: 0.701828, acc: 0.472656]: [A loss: 0.729810, acc: 0.273438]\n",
      "5247: [D loss: 0.695414, acc: 0.482422]: [A loss: 0.709212, acc: 0.382812]\n",
      "5248: [D loss: 0.691421, acc: 0.544922]: [A loss: 0.716359, acc: 0.332031]\n",
      "5249: [D loss: 0.698284, acc: 0.496094]: [A loss: 0.717039, acc: 0.335938]\n",
      "5250: [D loss: 0.696458, acc: 0.478516]: [A loss: 0.717084, acc: 0.355469]\n",
      "5251: [D loss: 0.696780, acc: 0.494141]: [A loss: 0.750340, acc: 0.160156]\n",
      "5252: [D loss: 0.693216, acc: 0.521484]: [A loss: 0.692113, acc: 0.492188]\n",
      "5253: [D loss: 0.696836, acc: 0.494141]: [A loss: 0.712146, acc: 0.351562]\n",
      "5254: [D loss: 0.693677, acc: 0.517578]: [A loss: 0.743174, acc: 0.187500]\n",
      "5255: [D loss: 0.691718, acc: 0.531250]: [A loss: 0.679104, acc: 0.570312]\n",
      "5256: [D loss: 0.699472, acc: 0.523438]: [A loss: 0.779091, acc: 0.042969]\n",
      "5257: [D loss: 0.691331, acc: 0.519531]: [A loss: 0.693300, acc: 0.472656]\n",
      "5258: [D loss: 0.694750, acc: 0.505859]: [A loss: 0.713735, acc: 0.347656]\n",
      "5259: [D loss: 0.691347, acc: 0.531250]: [A loss: 0.706461, acc: 0.406250]\n",
      "5260: [D loss: 0.695163, acc: 0.488281]: [A loss: 0.704076, acc: 0.398438]\n",
      "5261: [D loss: 0.697077, acc: 0.521484]: [A loss: 0.741487, acc: 0.175781]\n",
      "5262: [D loss: 0.694239, acc: 0.511719]: [A loss: 0.703820, acc: 0.382812]\n",
      "5263: [D loss: 0.700668, acc: 0.498047]: [A loss: 0.718864, acc: 0.304688]\n",
      "5264: [D loss: 0.695011, acc: 0.521484]: [A loss: 0.723108, acc: 0.296875]\n",
      "5265: [D loss: 0.693764, acc: 0.498047]: [A loss: 0.744303, acc: 0.175781]\n",
      "5266: [D loss: 0.688257, acc: 0.531250]: [A loss: 0.689989, acc: 0.468750]\n",
      "5267: [D loss: 0.697021, acc: 0.492188]: [A loss: 0.737268, acc: 0.183594]\n",
      "5268: [D loss: 0.697571, acc: 0.474609]: [A loss: 0.712742, acc: 0.363281]\n",
      "5269: [D loss: 0.692586, acc: 0.511719]: [A loss: 0.697086, acc: 0.468750]\n",
      "5270: [D loss: 0.701518, acc: 0.496094]: [A loss: 0.698930, acc: 0.460938]\n",
      "5271: [D loss: 0.698686, acc: 0.498047]: [A loss: 0.772429, acc: 0.078125]\n",
      "5272: [D loss: 0.692823, acc: 0.486328]: [A loss: 0.724181, acc: 0.296875]\n",
      "5273: [D loss: 0.701030, acc: 0.466797]: [A loss: 0.718878, acc: 0.312500]\n",
      "5274: [D loss: 0.687860, acc: 0.566406]: [A loss: 0.684418, acc: 0.535156]\n",
      "5275: [D loss: 0.700188, acc: 0.503906]: [A loss: 0.735554, acc: 0.246094]\n",
      "5276: [D loss: 0.693893, acc: 0.505859]: [A loss: 0.698239, acc: 0.468750]\n",
      "5277: [D loss: 0.697140, acc: 0.494141]: [A loss: 0.738903, acc: 0.195312]\n",
      "5278: [D loss: 0.694593, acc: 0.494141]: [A loss: 0.717866, acc: 0.363281]\n",
      "5279: [D loss: 0.698433, acc: 0.472656]: [A loss: 0.755569, acc: 0.171875]\n",
      "5280: [D loss: 0.693250, acc: 0.509766]: [A loss: 0.696279, acc: 0.449219]\n",
      "5281: [D loss: 0.700406, acc: 0.517578]: [A loss: 0.724473, acc: 0.281250]\n",
      "5282: [D loss: 0.694290, acc: 0.515625]: [A loss: 0.712366, acc: 0.339844]\n",
      "5283: [D loss: 0.694270, acc: 0.521484]: [A loss: 0.722123, acc: 0.296875]\n",
      "5284: [D loss: 0.698095, acc: 0.490234]: [A loss: 0.739948, acc: 0.203125]\n",
      "5285: [D loss: 0.689081, acc: 0.564453]: [A loss: 0.691326, acc: 0.480469]\n",
      "5286: [D loss: 0.699895, acc: 0.500000]: [A loss: 0.769767, acc: 0.101562]\n",
      "5287: [D loss: 0.695130, acc: 0.503906]: [A loss: 0.698184, acc: 0.468750]\n",
      "5288: [D loss: 0.689380, acc: 0.535156]: [A loss: 0.705539, acc: 0.371094]\n",
      "5289: [D loss: 0.695640, acc: 0.503906]: [A loss: 0.718324, acc: 0.312500]\n",
      "5290: [D loss: 0.697224, acc: 0.527344]: [A loss: 0.719087, acc: 0.300781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5291: [D loss: 0.698223, acc: 0.476562]: [A loss: 0.710103, acc: 0.367188]\n",
      "5292: [D loss: 0.698616, acc: 0.486328]: [A loss: 0.717220, acc: 0.320312]\n",
      "5293: [D loss: 0.696048, acc: 0.500000]: [A loss: 0.746519, acc: 0.156250]\n",
      "5294: [D loss: 0.692238, acc: 0.535156]: [A loss: 0.690858, acc: 0.511719]\n",
      "5295: [D loss: 0.692714, acc: 0.519531]: [A loss: 0.742765, acc: 0.179688]\n",
      "5296: [D loss: 0.693806, acc: 0.519531]: [A loss: 0.705239, acc: 0.417969]\n",
      "5297: [D loss: 0.695586, acc: 0.498047]: [A loss: 0.703627, acc: 0.414062]\n",
      "5298: [D loss: 0.689108, acc: 0.558594]: [A loss: 0.694867, acc: 0.472656]\n",
      "5299: [D loss: 0.705229, acc: 0.484375]: [A loss: 0.749511, acc: 0.144531]\n",
      "5300: [D loss: 0.697092, acc: 0.484375]: [A loss: 0.734103, acc: 0.250000]\n",
      "5301: [D loss: 0.695189, acc: 0.500000]: [A loss: 0.717245, acc: 0.328125]\n",
      "5302: [D loss: 0.697545, acc: 0.515625]: [A loss: 0.716397, acc: 0.347656]\n",
      "5303: [D loss: 0.694999, acc: 0.511719]: [A loss: 0.713251, acc: 0.355469]\n",
      "5304: [D loss: 0.700706, acc: 0.503906]: [A loss: 0.751426, acc: 0.140625]\n",
      "5305: [D loss: 0.692071, acc: 0.511719]: [A loss: 0.706863, acc: 0.363281]\n",
      "5306: [D loss: 0.693148, acc: 0.529297]: [A loss: 0.713757, acc: 0.335938]\n",
      "5307: [D loss: 0.691094, acc: 0.523438]: [A loss: 0.715240, acc: 0.351562]\n",
      "5308: [D loss: 0.696731, acc: 0.486328]: [A loss: 0.718712, acc: 0.312500]\n",
      "5309: [D loss: 0.699074, acc: 0.494141]: [A loss: 0.771679, acc: 0.093750]\n",
      "5310: [D loss: 0.692127, acc: 0.533203]: [A loss: 0.685446, acc: 0.535156]\n",
      "5311: [D loss: 0.702573, acc: 0.500000]: [A loss: 0.775660, acc: 0.074219]\n",
      "5312: [D loss: 0.696098, acc: 0.474609]: [A loss: 0.688381, acc: 0.519531]\n",
      "5313: [D loss: 0.696423, acc: 0.500000]: [A loss: 0.722274, acc: 0.316406]\n",
      "5314: [D loss: 0.690724, acc: 0.533203]: [A loss: 0.685762, acc: 0.507812]\n",
      "5315: [D loss: 0.696660, acc: 0.507812]: [A loss: 0.726978, acc: 0.273438]\n",
      "5316: [D loss: 0.690727, acc: 0.517578]: [A loss: 0.703847, acc: 0.449219]\n",
      "5317: [D loss: 0.696871, acc: 0.498047]: [A loss: 0.746037, acc: 0.183594]\n",
      "5318: [D loss: 0.692904, acc: 0.525391]: [A loss: 0.713222, acc: 0.355469]\n",
      "5319: [D loss: 0.698904, acc: 0.511719]: [A loss: 0.759099, acc: 0.128906]\n",
      "5320: [D loss: 0.696685, acc: 0.474609]: [A loss: 0.692301, acc: 0.480469]\n",
      "5321: [D loss: 0.697517, acc: 0.505859]: [A loss: 0.721835, acc: 0.281250]\n",
      "5322: [D loss: 0.694754, acc: 0.521484]: [A loss: 0.741136, acc: 0.199219]\n",
      "5323: [D loss: 0.694916, acc: 0.535156]: [A loss: 0.718533, acc: 0.312500]\n",
      "5324: [D loss: 0.694481, acc: 0.496094]: [A loss: 0.729999, acc: 0.296875]\n",
      "5325: [D loss: 0.695285, acc: 0.488281]: [A loss: 0.716636, acc: 0.339844]\n",
      "5326: [D loss: 0.692013, acc: 0.533203]: [A loss: 0.715096, acc: 0.312500]\n",
      "5327: [D loss: 0.690217, acc: 0.550781]: [A loss: 0.697611, acc: 0.453125]\n",
      "5328: [D loss: 0.704031, acc: 0.457031]: [A loss: 0.758192, acc: 0.113281]\n",
      "5329: [D loss: 0.691514, acc: 0.523438]: [A loss: 0.670165, acc: 0.671875]\n",
      "5330: [D loss: 0.702211, acc: 0.492188]: [A loss: 0.741391, acc: 0.214844]\n",
      "5331: [D loss: 0.693198, acc: 0.486328]: [A loss: 0.710061, acc: 0.394531]\n",
      "5332: [D loss: 0.692213, acc: 0.521484]: [A loss: 0.692410, acc: 0.484375]\n",
      "5333: [D loss: 0.699026, acc: 0.521484]: [A loss: 0.758106, acc: 0.140625]\n",
      "5334: [D loss: 0.692823, acc: 0.519531]: [A loss: 0.701451, acc: 0.445312]\n",
      "5335: [D loss: 0.700124, acc: 0.490234]: [A loss: 0.697907, acc: 0.449219]\n",
      "5336: [D loss: 0.693908, acc: 0.507812]: [A loss: 0.692271, acc: 0.500000]\n",
      "5337: [D loss: 0.691628, acc: 0.521484]: [A loss: 0.702169, acc: 0.386719]\n",
      "5338: [D loss: 0.698660, acc: 0.482422]: [A loss: 0.707935, acc: 0.355469]\n",
      "5339: [D loss: 0.700843, acc: 0.482422]: [A loss: 0.716500, acc: 0.277344]\n",
      "5340: [D loss: 0.694843, acc: 0.519531]: [A loss: 0.702941, acc: 0.386719]\n",
      "5341: [D loss: 0.696291, acc: 0.503906]: [A loss: 0.718385, acc: 0.332031]\n",
      "5342: [D loss: 0.689723, acc: 0.548828]: [A loss: 0.709223, acc: 0.386719]\n",
      "5343: [D loss: 0.697714, acc: 0.484375]: [A loss: 0.702072, acc: 0.406250]\n",
      "5344: [D loss: 0.691430, acc: 0.539062]: [A loss: 0.705948, acc: 0.378906]\n",
      "5345: [D loss: 0.699980, acc: 0.482422]: [A loss: 0.730301, acc: 0.242188]\n",
      "5346: [D loss: 0.699724, acc: 0.494141]: [A loss: 0.718320, acc: 0.308594]\n",
      "5347: [D loss: 0.702943, acc: 0.457031]: [A loss: 0.712836, acc: 0.351562]\n",
      "5348: [D loss: 0.695335, acc: 0.542969]: [A loss: 0.686145, acc: 0.546875]\n",
      "5349: [D loss: 0.697356, acc: 0.494141]: [A loss: 0.764251, acc: 0.101562]\n",
      "5350: [D loss: 0.695721, acc: 0.501953]: [A loss: 0.744118, acc: 0.218750]\n",
      "5351: [D loss: 0.692885, acc: 0.511719]: [A loss: 0.716094, acc: 0.343750]\n",
      "5352: [D loss: 0.691452, acc: 0.531250]: [A loss: 0.710115, acc: 0.382812]\n",
      "5353: [D loss: 0.698838, acc: 0.472656]: [A loss: 0.715692, acc: 0.347656]\n",
      "5354: [D loss: 0.694678, acc: 0.500000]: [A loss: 0.724184, acc: 0.312500]\n",
      "5355: [D loss: 0.695405, acc: 0.478516]: [A loss: 0.722635, acc: 0.312500]\n",
      "5356: [D loss: 0.694895, acc: 0.500000]: [A loss: 0.699688, acc: 0.433594]\n",
      "5357: [D loss: 0.700084, acc: 0.501953]: [A loss: 0.729461, acc: 0.261719]\n",
      "5358: [D loss: 0.692894, acc: 0.496094]: [A loss: 0.700228, acc: 0.441406]\n",
      "5359: [D loss: 0.695567, acc: 0.486328]: [A loss: 0.694397, acc: 0.453125]\n",
      "5360: [D loss: 0.698631, acc: 0.496094]: [A loss: 0.738623, acc: 0.238281]\n",
      "5361: [D loss: 0.689990, acc: 0.529297]: [A loss: 0.683392, acc: 0.535156]\n",
      "5362: [D loss: 0.700118, acc: 0.492188]: [A loss: 0.735382, acc: 0.195312]\n",
      "5363: [D loss: 0.696714, acc: 0.474609]: [A loss: 0.733395, acc: 0.250000]\n",
      "5364: [D loss: 0.694128, acc: 0.509766]: [A loss: 0.704118, acc: 0.382812]\n",
      "5365: [D loss: 0.699070, acc: 0.494141]: [A loss: 0.770998, acc: 0.074219]\n",
      "5366: [D loss: 0.697143, acc: 0.500000]: [A loss: 0.705727, acc: 0.382812]\n",
      "5367: [D loss: 0.692826, acc: 0.521484]: [A loss: 0.715833, acc: 0.324219]\n",
      "5368: [D loss: 0.691712, acc: 0.513672]: [A loss: 0.692053, acc: 0.507812]\n",
      "5369: [D loss: 0.693656, acc: 0.511719]: [A loss: 0.735355, acc: 0.207031]\n",
      "5370: [D loss: 0.694301, acc: 0.494141]: [A loss: 0.713689, acc: 0.355469]\n",
      "5371: [D loss: 0.694559, acc: 0.511719]: [A loss: 0.700521, acc: 0.457031]\n",
      "5372: [D loss: 0.693263, acc: 0.521484]: [A loss: 0.737971, acc: 0.195312]\n",
      "5373: [D loss: 0.691536, acc: 0.533203]: [A loss: 0.698627, acc: 0.449219]\n",
      "5374: [D loss: 0.696353, acc: 0.488281]: [A loss: 0.761983, acc: 0.105469]\n",
      "5375: [D loss: 0.693913, acc: 0.488281]: [A loss: 0.690772, acc: 0.492188]\n",
      "5376: [D loss: 0.695275, acc: 0.496094]: [A loss: 0.731412, acc: 0.250000]\n",
      "5377: [D loss: 0.697485, acc: 0.515625]: [A loss: 0.731876, acc: 0.253906]\n",
      "5378: [D loss: 0.698597, acc: 0.490234]: [A loss: 0.739672, acc: 0.187500]\n",
      "5379: [D loss: 0.693629, acc: 0.513672]: [A loss: 0.714281, acc: 0.347656]\n",
      "5380: [D loss: 0.697438, acc: 0.482422]: [A loss: 0.731601, acc: 0.265625]\n",
      "5381: [D loss: 0.691493, acc: 0.519531]: [A loss: 0.701587, acc: 0.429688]\n",
      "5382: [D loss: 0.694937, acc: 0.517578]: [A loss: 0.709265, acc: 0.378906]\n",
      "5383: [D loss: 0.697294, acc: 0.500000]: [A loss: 0.722946, acc: 0.304688]\n",
      "5384: [D loss: 0.697656, acc: 0.486328]: [A loss: 0.736228, acc: 0.218750]\n",
      "5385: [D loss: 0.696859, acc: 0.492188]: [A loss: 0.701954, acc: 0.441406]\n",
      "5386: [D loss: 0.700607, acc: 0.503906]: [A loss: 0.738738, acc: 0.218750]\n",
      "5387: [D loss: 0.692404, acc: 0.513672]: [A loss: 0.706896, acc: 0.429688]\n",
      "5388: [D loss: 0.698950, acc: 0.455078]: [A loss: 0.735684, acc: 0.250000]\n",
      "5389: [D loss: 0.696662, acc: 0.494141]: [A loss: 0.714544, acc: 0.363281]\n",
      "5390: [D loss: 0.689343, acc: 0.544922]: [A loss: 0.737548, acc: 0.191406]\n",
      "5391: [D loss: 0.697886, acc: 0.482422]: [A loss: 0.708938, acc: 0.371094]\n",
      "5392: [D loss: 0.695160, acc: 0.500000]: [A loss: 0.711331, acc: 0.343750]\n",
      "5393: [D loss: 0.690714, acc: 0.529297]: [A loss: 0.723028, acc: 0.261719]\n",
      "5394: [D loss: 0.696637, acc: 0.496094]: [A loss: 0.726265, acc: 0.300781]\n",
      "5395: [D loss: 0.689999, acc: 0.535156]: [A loss: 0.697438, acc: 0.480469]\n",
      "5396: [D loss: 0.696253, acc: 0.505859]: [A loss: 0.780534, acc: 0.042969]\n",
      "5397: [D loss: 0.694553, acc: 0.505859]: [A loss: 0.719232, acc: 0.292969]\n",
      "5398: [D loss: 0.699588, acc: 0.476562]: [A loss: 0.729027, acc: 0.238281]\n",
      "5399: [D loss: 0.690750, acc: 0.529297]: [A loss: 0.708752, acc: 0.367188]\n",
      "5400: [D loss: 0.696071, acc: 0.517578]: [A loss: 0.733932, acc: 0.191406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5401: [D loss: 0.690213, acc: 0.560547]: [A loss: 0.705403, acc: 0.394531]\n",
      "5402: [D loss: 0.695983, acc: 0.511719]: [A loss: 0.756098, acc: 0.132812]\n",
      "5403: [D loss: 0.694340, acc: 0.494141]: [A loss: 0.690483, acc: 0.507812]\n",
      "5404: [D loss: 0.694895, acc: 0.500000]: [A loss: 0.736079, acc: 0.234375]\n",
      "5405: [D loss: 0.694878, acc: 0.519531]: [A loss: 0.723569, acc: 0.300781]\n",
      "5406: [D loss: 0.700107, acc: 0.498047]: [A loss: 0.716992, acc: 0.339844]\n",
      "5407: [D loss: 0.695158, acc: 0.488281]: [A loss: 0.716000, acc: 0.343750]\n",
      "5408: [D loss: 0.695893, acc: 0.515625]: [A loss: 0.704640, acc: 0.394531]\n",
      "5409: [D loss: 0.696230, acc: 0.503906]: [A loss: 0.724044, acc: 0.273438]\n",
      "5410: [D loss: 0.696280, acc: 0.513672]: [A loss: 0.708106, acc: 0.394531]\n",
      "5411: [D loss: 0.696308, acc: 0.517578]: [A loss: 0.716783, acc: 0.292969]\n",
      "5412: [D loss: 0.692599, acc: 0.537109]: [A loss: 0.709858, acc: 0.363281]\n",
      "5413: [D loss: 0.702599, acc: 0.484375]: [A loss: 0.723666, acc: 0.316406]\n",
      "5414: [D loss: 0.696021, acc: 0.507812]: [A loss: 0.753520, acc: 0.164062]\n",
      "5415: [D loss: 0.696805, acc: 0.482422]: [A loss: 0.730663, acc: 0.289062]\n",
      "5416: [D loss: 0.694129, acc: 0.503906]: [A loss: 0.738528, acc: 0.207031]\n",
      "5417: [D loss: 0.698762, acc: 0.482422]: [A loss: 0.747764, acc: 0.183594]\n",
      "5418: [D loss: 0.692436, acc: 0.513672]: [A loss: 0.692276, acc: 0.519531]\n",
      "5419: [D loss: 0.695816, acc: 0.509766]: [A loss: 0.719724, acc: 0.335938]\n",
      "5420: [D loss: 0.696821, acc: 0.505859]: [A loss: 0.723585, acc: 0.281250]\n",
      "5421: [D loss: 0.698300, acc: 0.509766]: [A loss: 0.748151, acc: 0.171875]\n",
      "5422: [D loss: 0.693750, acc: 0.505859]: [A loss: 0.740618, acc: 0.257812]\n",
      "5423: [D loss: 0.697542, acc: 0.517578]: [A loss: 0.766509, acc: 0.156250]\n",
      "5424: [D loss: 0.691186, acc: 0.511719]: [A loss: 0.725190, acc: 0.324219]\n",
      "5425: [D loss: 0.695991, acc: 0.511719]: [A loss: 0.726996, acc: 0.289062]\n",
      "5426: [D loss: 0.693455, acc: 0.525391]: [A loss: 0.751307, acc: 0.179688]\n",
      "5427: [D loss: 0.696364, acc: 0.492188]: [A loss: 0.723187, acc: 0.324219]\n",
      "5428: [D loss: 0.693197, acc: 0.511719]: [A loss: 0.728347, acc: 0.269531]\n",
      "5429: [D loss: 0.693262, acc: 0.507812]: [A loss: 0.697637, acc: 0.453125]\n",
      "5430: [D loss: 0.702890, acc: 0.482422]: [A loss: 0.751821, acc: 0.164062]\n",
      "5431: [D loss: 0.696457, acc: 0.472656]: [A loss: 0.705499, acc: 0.417969]\n",
      "5432: [D loss: 0.697489, acc: 0.500000]: [A loss: 0.727333, acc: 0.261719]\n",
      "5433: [D loss: 0.693186, acc: 0.500000]: [A loss: 0.709679, acc: 0.339844]\n",
      "5434: [D loss: 0.698968, acc: 0.519531]: [A loss: 0.712829, acc: 0.347656]\n",
      "5435: [D loss: 0.692354, acc: 0.544922]: [A loss: 0.702333, acc: 0.457031]\n",
      "5436: [D loss: 0.694696, acc: 0.480469]: [A loss: 0.710612, acc: 0.390625]\n",
      "5437: [D loss: 0.690147, acc: 0.511719]: [A loss: 0.709513, acc: 0.386719]\n",
      "5438: [D loss: 0.697424, acc: 0.503906]: [A loss: 0.720830, acc: 0.292969]\n",
      "5439: [D loss: 0.692357, acc: 0.537109]: [A loss: 0.719555, acc: 0.332031]\n",
      "5440: [D loss: 0.699238, acc: 0.486328]: [A loss: 0.725646, acc: 0.273438]\n",
      "5441: [D loss: 0.696176, acc: 0.501953]: [A loss: 0.779295, acc: 0.054688]\n",
      "5442: [D loss: 0.699477, acc: 0.462891]: [A loss: 0.706897, acc: 0.359375]\n",
      "5443: [D loss: 0.695562, acc: 0.496094]: [A loss: 0.741118, acc: 0.199219]\n",
      "5444: [D loss: 0.694954, acc: 0.494141]: [A loss: 0.680315, acc: 0.554688]\n",
      "5445: [D loss: 0.698851, acc: 0.507812]: [A loss: 0.753189, acc: 0.105469]\n",
      "5446: [D loss: 0.699267, acc: 0.460938]: [A loss: 0.699132, acc: 0.433594]\n",
      "5447: [D loss: 0.697833, acc: 0.486328]: [A loss: 0.705463, acc: 0.390625]\n",
      "5448: [D loss: 0.699865, acc: 0.484375]: [A loss: 0.730088, acc: 0.246094]\n",
      "5449: [D loss: 0.696410, acc: 0.494141]: [A loss: 0.717800, acc: 0.308594]\n",
      "5450: [D loss: 0.696513, acc: 0.505859]: [A loss: 0.691255, acc: 0.503906]\n",
      "5451: [D loss: 0.701707, acc: 0.466797]: [A loss: 0.780777, acc: 0.046875]\n",
      "5452: [D loss: 0.692450, acc: 0.515625]: [A loss: 0.694951, acc: 0.453125]\n",
      "5453: [D loss: 0.697791, acc: 0.492188]: [A loss: 0.708703, acc: 0.367188]\n",
      "5454: [D loss: 0.690959, acc: 0.515625]: [A loss: 0.716660, acc: 0.308594]\n",
      "5455: [D loss: 0.696082, acc: 0.490234]: [A loss: 0.722251, acc: 0.277344]\n",
      "5456: [D loss: 0.699010, acc: 0.451172]: [A loss: 0.707750, acc: 0.394531]\n",
      "5457: [D loss: 0.694719, acc: 0.496094]: [A loss: 0.711993, acc: 0.371094]\n",
      "5458: [D loss: 0.699926, acc: 0.519531]: [A loss: 0.739994, acc: 0.210938]\n",
      "5459: [D loss: 0.694175, acc: 0.517578]: [A loss: 0.692919, acc: 0.472656]\n",
      "5460: [D loss: 0.691522, acc: 0.511719]: [A loss: 0.755204, acc: 0.144531]\n",
      "5461: [D loss: 0.692393, acc: 0.505859]: [A loss: 0.722424, acc: 0.281250]\n",
      "5462: [D loss: 0.692032, acc: 0.527344]: [A loss: 0.759332, acc: 0.148438]\n",
      "5463: [D loss: 0.690254, acc: 0.531250]: [A loss: 0.681671, acc: 0.566406]\n",
      "5464: [D loss: 0.699727, acc: 0.509766]: [A loss: 0.764941, acc: 0.105469]\n",
      "5465: [D loss: 0.689420, acc: 0.529297]: [A loss: 0.691084, acc: 0.468750]\n",
      "5466: [D loss: 0.697279, acc: 0.513672]: [A loss: 0.722342, acc: 0.320312]\n",
      "5467: [D loss: 0.692241, acc: 0.501953]: [A loss: 0.706511, acc: 0.386719]\n",
      "5468: [D loss: 0.697284, acc: 0.492188]: [A loss: 0.721932, acc: 0.285156]\n",
      "5469: [D loss: 0.694743, acc: 0.501953]: [A loss: 0.725781, acc: 0.289062]\n",
      "5470: [D loss: 0.691540, acc: 0.523438]: [A loss: 0.706964, acc: 0.406250]\n",
      "5471: [D loss: 0.694013, acc: 0.541016]: [A loss: 0.725055, acc: 0.289062]\n",
      "5472: [D loss: 0.689640, acc: 0.535156]: [A loss: 0.697793, acc: 0.460938]\n",
      "5473: [D loss: 0.699925, acc: 0.494141]: [A loss: 0.730412, acc: 0.246094]\n",
      "5474: [D loss: 0.694421, acc: 0.498047]: [A loss: 0.695980, acc: 0.464844]\n",
      "5475: [D loss: 0.696026, acc: 0.509766]: [A loss: 0.737921, acc: 0.183594]\n",
      "5476: [D loss: 0.688317, acc: 0.552734]: [A loss: 0.674038, acc: 0.578125]\n",
      "5477: [D loss: 0.707608, acc: 0.482422]: [A loss: 0.762005, acc: 0.085938]\n",
      "5478: [D loss: 0.693360, acc: 0.500000]: [A loss: 0.690158, acc: 0.496094]\n",
      "5479: [D loss: 0.690778, acc: 0.529297]: [A loss: 0.702870, acc: 0.414062]\n",
      "5480: [D loss: 0.697387, acc: 0.505859]: [A loss: 0.744334, acc: 0.203125]\n",
      "5481: [D loss: 0.688468, acc: 0.537109]: [A loss: 0.693272, acc: 0.476562]\n",
      "5482: [D loss: 0.697706, acc: 0.513672]: [A loss: 0.717067, acc: 0.339844]\n",
      "5483: [D loss: 0.693489, acc: 0.519531]: [A loss: 0.712634, acc: 0.335938]\n",
      "5484: [D loss: 0.698001, acc: 0.492188]: [A loss: 0.703997, acc: 0.378906]\n",
      "5485: [D loss: 0.700356, acc: 0.480469]: [A loss: 0.728081, acc: 0.253906]\n",
      "5486: [D loss: 0.696573, acc: 0.490234]: [A loss: 0.720723, acc: 0.324219]\n",
      "5487: [D loss: 0.699245, acc: 0.470703]: [A loss: 0.708495, acc: 0.347656]\n",
      "5488: [D loss: 0.702539, acc: 0.494141]: [A loss: 0.722619, acc: 0.285156]\n",
      "5489: [D loss: 0.692778, acc: 0.541016]: [A loss: 0.688312, acc: 0.507812]\n",
      "5490: [D loss: 0.700074, acc: 0.509766]: [A loss: 0.737742, acc: 0.187500]\n",
      "5491: [D loss: 0.692200, acc: 0.511719]: [A loss: 0.707956, acc: 0.390625]\n",
      "5492: [D loss: 0.695683, acc: 0.490234]: [A loss: 0.707617, acc: 0.351562]\n",
      "5493: [D loss: 0.696213, acc: 0.509766]: [A loss: 0.737818, acc: 0.234375]\n",
      "5494: [D loss: 0.695938, acc: 0.527344]: [A loss: 0.732134, acc: 0.250000]\n",
      "5495: [D loss: 0.686557, acc: 0.558594]: [A loss: 0.670043, acc: 0.625000]\n",
      "5496: [D loss: 0.696568, acc: 0.509766]: [A loss: 0.758525, acc: 0.125000]\n",
      "5497: [D loss: 0.694600, acc: 0.500000]: [A loss: 0.691076, acc: 0.488281]\n",
      "5498: [D loss: 0.699688, acc: 0.494141]: [A loss: 0.742211, acc: 0.191406]\n",
      "5499: [D loss: 0.695201, acc: 0.492188]: [A loss: 0.698440, acc: 0.445312]\n",
      "5500: [D loss: 0.699439, acc: 0.500000]: [A loss: 0.704383, acc: 0.414062]\n",
      "5501: [D loss: 0.694264, acc: 0.507812]: [A loss: 0.713686, acc: 0.367188]\n",
      "5502: [D loss: 0.696916, acc: 0.515625]: [A loss: 0.751100, acc: 0.152344]\n",
      "5503: [D loss: 0.690121, acc: 0.531250]: [A loss: 0.702797, acc: 0.402344]\n",
      "5504: [D loss: 0.692934, acc: 0.521484]: [A loss: 0.733845, acc: 0.226562]\n",
      "5505: [D loss: 0.692444, acc: 0.513672]: [A loss: 0.701695, acc: 0.402344]\n",
      "5506: [D loss: 0.697129, acc: 0.531250]: [A loss: 0.724693, acc: 0.273438]\n",
      "5507: [D loss: 0.692054, acc: 0.533203]: [A loss: 0.707165, acc: 0.414062]\n",
      "5508: [D loss: 0.702572, acc: 0.462891]: [A loss: 0.740082, acc: 0.226562]\n",
      "5509: [D loss: 0.693169, acc: 0.509766]: [A loss: 0.711643, acc: 0.382812]\n",
      "5510: [D loss: 0.695702, acc: 0.523438]: [A loss: 0.743576, acc: 0.199219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5511: [D loss: 0.689890, acc: 0.537109]: [A loss: 0.675494, acc: 0.562500]\n",
      "5512: [D loss: 0.705558, acc: 0.496094]: [A loss: 0.743874, acc: 0.191406]\n",
      "5513: [D loss: 0.692485, acc: 0.523438]: [A loss: 0.686702, acc: 0.519531]\n",
      "5514: [D loss: 0.695570, acc: 0.519531]: [A loss: 0.712586, acc: 0.359375]\n",
      "5515: [D loss: 0.694619, acc: 0.496094]: [A loss: 0.723330, acc: 0.265625]\n",
      "5516: [D loss: 0.694878, acc: 0.533203]: [A loss: 0.720474, acc: 0.300781]\n",
      "5517: [D loss: 0.697452, acc: 0.472656]: [A loss: 0.709457, acc: 0.375000]\n",
      "5518: [D loss: 0.694521, acc: 0.498047]: [A loss: 0.706703, acc: 0.367188]\n",
      "5519: [D loss: 0.697122, acc: 0.494141]: [A loss: 0.724519, acc: 0.285156]\n",
      "5520: [D loss: 0.698476, acc: 0.500000]: [A loss: 0.719954, acc: 0.320312]\n",
      "5521: [D loss: 0.697901, acc: 0.482422]: [A loss: 0.713619, acc: 0.359375]\n",
      "5522: [D loss: 0.697006, acc: 0.486328]: [A loss: 0.738844, acc: 0.207031]\n",
      "5523: [D loss: 0.693381, acc: 0.498047]: [A loss: 0.706257, acc: 0.394531]\n",
      "5524: [D loss: 0.692458, acc: 0.535156]: [A loss: 0.691696, acc: 0.500000]\n",
      "5525: [D loss: 0.700358, acc: 0.509766]: [A loss: 0.740843, acc: 0.218750]\n",
      "5526: [D loss: 0.697224, acc: 0.490234]: [A loss: 0.724141, acc: 0.296875]\n",
      "5527: [D loss: 0.694173, acc: 0.494141]: [A loss: 0.694902, acc: 0.445312]\n",
      "5528: [D loss: 0.691286, acc: 0.544922]: [A loss: 0.732788, acc: 0.246094]\n",
      "5529: [D loss: 0.693507, acc: 0.505859]: [A loss: 0.701442, acc: 0.421875]\n",
      "5530: [D loss: 0.695592, acc: 0.513672]: [A loss: 0.732978, acc: 0.222656]\n",
      "5531: [D loss: 0.692194, acc: 0.525391]: [A loss: 0.691214, acc: 0.480469]\n",
      "5532: [D loss: 0.703347, acc: 0.498047]: [A loss: 0.796560, acc: 0.058594]\n",
      "5533: [D loss: 0.692964, acc: 0.515625]: [A loss: 0.692631, acc: 0.472656]\n",
      "5534: [D loss: 0.695545, acc: 0.501953]: [A loss: 0.696551, acc: 0.460938]\n",
      "5535: [D loss: 0.694190, acc: 0.496094]: [A loss: 0.715417, acc: 0.351562]\n",
      "5536: [D loss: 0.697934, acc: 0.507812]: [A loss: 0.718546, acc: 0.324219]\n",
      "5537: [D loss: 0.695229, acc: 0.517578]: [A loss: 0.731863, acc: 0.273438]\n",
      "5538: [D loss: 0.695225, acc: 0.492188]: [A loss: 0.717549, acc: 0.320312]\n",
      "5539: [D loss: 0.695837, acc: 0.505859]: [A loss: 0.729326, acc: 0.246094]\n",
      "5540: [D loss: 0.697337, acc: 0.484375]: [A loss: 0.695672, acc: 0.453125]\n",
      "5541: [D loss: 0.706721, acc: 0.507812]: [A loss: 0.766520, acc: 0.085938]\n",
      "5542: [D loss: 0.693503, acc: 0.505859]: [A loss: 0.694785, acc: 0.492188]\n",
      "5543: [D loss: 0.696458, acc: 0.515625]: [A loss: 0.710745, acc: 0.371094]\n",
      "5544: [D loss: 0.695946, acc: 0.515625]: [A loss: 0.712133, acc: 0.320312]\n",
      "5545: [D loss: 0.689648, acc: 0.546875]: [A loss: 0.690766, acc: 0.523438]\n",
      "5546: [D loss: 0.696879, acc: 0.498047]: [A loss: 0.734053, acc: 0.242188]\n",
      "5547: [D loss: 0.696660, acc: 0.501953]: [A loss: 0.705621, acc: 0.394531]\n",
      "5548: [D loss: 0.694294, acc: 0.523438]: [A loss: 0.735556, acc: 0.203125]\n",
      "5549: [D loss: 0.690821, acc: 0.523438]: [A loss: 0.705197, acc: 0.425781]\n",
      "5550: [D loss: 0.686814, acc: 0.541016]: [A loss: 0.698568, acc: 0.429688]\n",
      "5551: [D loss: 0.697726, acc: 0.492188]: [A loss: 0.768978, acc: 0.105469]\n",
      "5552: [D loss: 0.688775, acc: 0.542969]: [A loss: 0.724076, acc: 0.300781]\n",
      "5553: [D loss: 0.689411, acc: 0.537109]: [A loss: 0.722443, acc: 0.304688]\n",
      "5554: [D loss: 0.693630, acc: 0.525391]: [A loss: 0.740228, acc: 0.253906]\n",
      "5555: [D loss: 0.698324, acc: 0.486328]: [A loss: 0.718483, acc: 0.339844]\n",
      "5556: [D loss: 0.691893, acc: 0.507812]: [A loss: 0.708450, acc: 0.386719]\n",
      "5557: [D loss: 0.693339, acc: 0.474609]: [A loss: 0.691145, acc: 0.550781]\n",
      "5558: [D loss: 0.698041, acc: 0.513672]: [A loss: 0.767081, acc: 0.128906]\n",
      "5559: [D loss: 0.693047, acc: 0.490234]: [A loss: 0.716228, acc: 0.363281]\n",
      "5560: [D loss: 0.696376, acc: 0.503906]: [A loss: 0.710373, acc: 0.378906]\n",
      "5561: [D loss: 0.697298, acc: 0.474609]: [A loss: 0.728855, acc: 0.292969]\n",
      "5562: [D loss: 0.697703, acc: 0.503906]: [A loss: 0.722139, acc: 0.300781]\n",
      "5563: [D loss: 0.698380, acc: 0.501953]: [A loss: 0.758630, acc: 0.160156]\n",
      "5564: [D loss: 0.692500, acc: 0.515625]: [A loss: 0.706994, acc: 0.398438]\n",
      "5565: [D loss: 0.696604, acc: 0.509766]: [A loss: 0.752868, acc: 0.152344]\n",
      "5566: [D loss: 0.695679, acc: 0.488281]: [A loss: 0.699265, acc: 0.433594]\n",
      "5567: [D loss: 0.690083, acc: 0.542969]: [A loss: 0.696994, acc: 0.464844]\n",
      "5568: [D loss: 0.698496, acc: 0.500000]: [A loss: 0.729089, acc: 0.300781]\n",
      "5569: [D loss: 0.695381, acc: 0.503906]: [A loss: 0.702739, acc: 0.457031]\n",
      "5570: [D loss: 0.694840, acc: 0.501953]: [A loss: 0.720922, acc: 0.316406]\n",
      "5571: [D loss: 0.701905, acc: 0.478516]: [A loss: 0.747329, acc: 0.175781]\n",
      "5572: [D loss: 0.697579, acc: 0.476562]: [A loss: 0.714925, acc: 0.324219]\n",
      "5573: [D loss: 0.697322, acc: 0.478516]: [A loss: 0.735969, acc: 0.218750]\n",
      "5574: [D loss: 0.694625, acc: 0.529297]: [A loss: 0.747470, acc: 0.171875]\n",
      "5575: [D loss: 0.693924, acc: 0.507812]: [A loss: 0.730261, acc: 0.250000]\n",
      "5576: [D loss: 0.696764, acc: 0.478516]: [A loss: 0.714770, acc: 0.312500]\n",
      "5577: [D loss: 0.693959, acc: 0.509766]: [A loss: 0.711525, acc: 0.343750]\n",
      "5578: [D loss: 0.696759, acc: 0.498047]: [A loss: 0.727090, acc: 0.265625]\n",
      "5579: [D loss: 0.702142, acc: 0.445312]: [A loss: 0.749455, acc: 0.164062]\n",
      "5580: [D loss: 0.694477, acc: 0.517578]: [A loss: 0.706306, acc: 0.382812]\n",
      "5581: [D loss: 0.701514, acc: 0.476562]: [A loss: 0.746122, acc: 0.152344]\n",
      "5582: [D loss: 0.700140, acc: 0.476562]: [A loss: 0.705676, acc: 0.406250]\n",
      "5583: [D loss: 0.698170, acc: 0.484375]: [A loss: 0.746425, acc: 0.132812]\n",
      "5584: [D loss: 0.699065, acc: 0.484375]: [A loss: 0.724290, acc: 0.304688]\n",
      "5585: [D loss: 0.699173, acc: 0.494141]: [A loss: 0.746151, acc: 0.183594]\n",
      "5586: [D loss: 0.704141, acc: 0.421875]: [A loss: 0.734807, acc: 0.230469]\n",
      "5587: [D loss: 0.693346, acc: 0.505859]: [A loss: 0.708461, acc: 0.410156]\n",
      "5588: [D loss: 0.696505, acc: 0.500000]: [A loss: 0.722807, acc: 0.281250]\n",
      "5589: [D loss: 0.688355, acc: 0.542969]: [A loss: 0.704002, acc: 0.421875]\n",
      "5590: [D loss: 0.696342, acc: 0.500000]: [A loss: 0.796536, acc: 0.042969]\n",
      "5591: [D loss: 0.695161, acc: 0.498047]: [A loss: 0.668227, acc: 0.656250]\n",
      "5592: [D loss: 0.696666, acc: 0.501953]: [A loss: 0.752268, acc: 0.156250]\n",
      "5593: [D loss: 0.692335, acc: 0.537109]: [A loss: 0.699964, acc: 0.441406]\n",
      "5594: [D loss: 0.694263, acc: 0.517578]: [A loss: 0.743787, acc: 0.183594]\n",
      "5595: [D loss: 0.690394, acc: 0.546875]: [A loss: 0.685973, acc: 0.519531]\n",
      "5596: [D loss: 0.696095, acc: 0.496094]: [A loss: 0.729828, acc: 0.226562]\n",
      "5597: [D loss: 0.698400, acc: 0.470703]: [A loss: 0.725964, acc: 0.253906]\n",
      "5598: [D loss: 0.697453, acc: 0.500000]: [A loss: 0.721435, acc: 0.304688]\n",
      "5599: [D loss: 0.697622, acc: 0.458984]: [A loss: 0.724048, acc: 0.261719]\n",
      "5600: [D loss: 0.694543, acc: 0.500000]: [A loss: 0.698271, acc: 0.449219]\n",
      "5601: [D loss: 0.698581, acc: 0.478516]: [A loss: 0.720730, acc: 0.300781]\n",
      "5602: [D loss: 0.696913, acc: 0.484375]: [A loss: 0.706407, acc: 0.398438]\n",
      "5603: [D loss: 0.695312, acc: 0.507812]: [A loss: 0.693047, acc: 0.460938]\n",
      "5604: [D loss: 0.697255, acc: 0.521484]: [A loss: 0.720755, acc: 0.320312]\n",
      "5605: [D loss: 0.693663, acc: 0.527344]: [A loss: 0.742736, acc: 0.226562]\n",
      "5606: [D loss: 0.696373, acc: 0.496094]: [A loss: 0.749122, acc: 0.160156]\n",
      "5607: [D loss: 0.694520, acc: 0.507812]: [A loss: 0.726603, acc: 0.273438]\n",
      "5608: [D loss: 0.692892, acc: 0.517578]: [A loss: 0.717770, acc: 0.312500]\n",
      "5609: [D loss: 0.700849, acc: 0.486328]: [A loss: 0.754987, acc: 0.140625]\n",
      "5610: [D loss: 0.693390, acc: 0.509766]: [A loss: 0.710577, acc: 0.367188]\n",
      "5611: [D loss: 0.696832, acc: 0.470703]: [A loss: 0.729934, acc: 0.234375]\n",
      "5612: [D loss: 0.696402, acc: 0.498047]: [A loss: 0.716872, acc: 0.312500]\n",
      "5613: [D loss: 0.691816, acc: 0.505859]: [A loss: 0.700348, acc: 0.441406]\n",
      "5614: [D loss: 0.692268, acc: 0.509766]: [A loss: 0.722641, acc: 0.332031]\n",
      "5615: [D loss: 0.694418, acc: 0.519531]: [A loss: 0.714260, acc: 0.335938]\n",
      "5616: [D loss: 0.693695, acc: 0.503906]: [A loss: 0.695690, acc: 0.460938]\n",
      "5617: [D loss: 0.691540, acc: 0.519531]: [A loss: 0.692896, acc: 0.476562]\n",
      "5618: [D loss: 0.697482, acc: 0.503906]: [A loss: 0.745337, acc: 0.207031]\n",
      "5619: [D loss: 0.695944, acc: 0.500000]: [A loss: 0.727692, acc: 0.273438]\n",
      "5620: [D loss: 0.696647, acc: 0.490234]: [A loss: 0.711464, acc: 0.359375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5621: [D loss: 0.696855, acc: 0.507812]: [A loss: 0.749686, acc: 0.160156]\n",
      "5622: [D loss: 0.692829, acc: 0.529297]: [A loss: 0.705337, acc: 0.386719]\n",
      "5623: [D loss: 0.691891, acc: 0.539062]: [A loss: 0.720311, acc: 0.304688]\n",
      "5624: [D loss: 0.693442, acc: 0.517578]: [A loss: 0.730824, acc: 0.238281]\n",
      "5625: [D loss: 0.704435, acc: 0.431641]: [A loss: 0.728885, acc: 0.269531]\n",
      "5626: [D loss: 0.698492, acc: 0.460938]: [A loss: 0.711831, acc: 0.347656]\n",
      "5627: [D loss: 0.695071, acc: 0.519531]: [A loss: 0.710770, acc: 0.406250]\n",
      "5628: [D loss: 0.699836, acc: 0.501953]: [A loss: 0.752922, acc: 0.152344]\n",
      "5629: [D loss: 0.697393, acc: 0.490234]: [A loss: 0.719230, acc: 0.316406]\n",
      "5630: [D loss: 0.697219, acc: 0.515625]: [A loss: 0.767180, acc: 0.097656]\n",
      "5631: [D loss: 0.697440, acc: 0.484375]: [A loss: 0.721578, acc: 0.332031]\n",
      "5632: [D loss: 0.696156, acc: 0.498047]: [A loss: 0.764190, acc: 0.121094]\n",
      "5633: [D loss: 0.696958, acc: 0.503906]: [A loss: 0.700485, acc: 0.414062]\n",
      "5634: [D loss: 0.696451, acc: 0.486328]: [A loss: 0.707410, acc: 0.382812]\n",
      "5635: [D loss: 0.691466, acc: 0.533203]: [A loss: 0.727819, acc: 0.277344]\n",
      "5636: [D loss: 0.689378, acc: 0.521484]: [A loss: 0.716199, acc: 0.355469]\n",
      "5637: [D loss: 0.693772, acc: 0.501953]: [A loss: 0.728622, acc: 0.281250]\n",
      "5638: [D loss: 0.695301, acc: 0.488281]: [A loss: 0.708070, acc: 0.363281]\n",
      "5639: [D loss: 0.693462, acc: 0.503906]: [A loss: 0.712860, acc: 0.382812]\n",
      "5640: [D loss: 0.692884, acc: 0.525391]: [A loss: 0.711772, acc: 0.390625]\n",
      "5641: [D loss: 0.696551, acc: 0.500000]: [A loss: 0.736772, acc: 0.207031]\n",
      "5642: [D loss: 0.696130, acc: 0.498047]: [A loss: 0.716410, acc: 0.378906]\n",
      "5643: [D loss: 0.689205, acc: 0.537109]: [A loss: 0.738546, acc: 0.199219]\n",
      "5644: [D loss: 0.694794, acc: 0.507812]: [A loss: 0.702732, acc: 0.433594]\n",
      "5645: [D loss: 0.695264, acc: 0.527344]: [A loss: 0.726130, acc: 0.285156]\n",
      "5646: [D loss: 0.690948, acc: 0.521484]: [A loss: 0.688067, acc: 0.488281]\n",
      "5647: [D loss: 0.695722, acc: 0.509766]: [A loss: 0.745659, acc: 0.156250]\n",
      "5648: [D loss: 0.693465, acc: 0.488281]: [A loss: 0.707036, acc: 0.382812]\n",
      "5649: [D loss: 0.699173, acc: 0.517578]: [A loss: 0.759250, acc: 0.144531]\n",
      "5650: [D loss: 0.693990, acc: 0.519531]: [A loss: 0.731701, acc: 0.265625]\n",
      "5651: [D loss: 0.689594, acc: 0.529297]: [A loss: 0.706867, acc: 0.410156]\n",
      "5652: [D loss: 0.694044, acc: 0.517578]: [A loss: 0.705392, acc: 0.386719]\n",
      "5653: [D loss: 0.695899, acc: 0.513672]: [A loss: 0.717955, acc: 0.347656]\n",
      "5654: [D loss: 0.694987, acc: 0.529297]: [A loss: 0.722457, acc: 0.292969]\n",
      "5655: [D loss: 0.692994, acc: 0.513672]: [A loss: 0.731452, acc: 0.265625]\n",
      "5656: [D loss: 0.696701, acc: 0.492188]: [A loss: 0.723917, acc: 0.277344]\n",
      "5657: [D loss: 0.692132, acc: 0.513672]: [A loss: 0.718161, acc: 0.339844]\n",
      "5658: [D loss: 0.695654, acc: 0.513672]: [A loss: 0.723278, acc: 0.312500]\n",
      "5659: [D loss: 0.698798, acc: 0.505859]: [A loss: 0.716228, acc: 0.347656]\n",
      "5660: [D loss: 0.698130, acc: 0.511719]: [A loss: 0.736620, acc: 0.210938]\n",
      "5661: [D loss: 0.693143, acc: 0.507812]: [A loss: 0.724563, acc: 0.292969]\n",
      "5662: [D loss: 0.693435, acc: 0.509766]: [A loss: 0.697688, acc: 0.433594]\n",
      "5663: [D loss: 0.698193, acc: 0.509766]: [A loss: 0.740260, acc: 0.199219]\n",
      "5664: [D loss: 0.700183, acc: 0.484375]: [A loss: 0.723706, acc: 0.281250]\n",
      "5665: [D loss: 0.697380, acc: 0.500000]: [A loss: 0.745395, acc: 0.164062]\n",
      "5666: [D loss: 0.696088, acc: 0.474609]: [A loss: 0.715118, acc: 0.335938]\n",
      "5667: [D loss: 0.696282, acc: 0.486328]: [A loss: 0.749981, acc: 0.128906]\n",
      "5668: [D loss: 0.696296, acc: 0.500000]: [A loss: 0.733451, acc: 0.246094]\n",
      "5669: [D loss: 0.691903, acc: 0.525391]: [A loss: 0.713794, acc: 0.339844]\n",
      "5670: [D loss: 0.704766, acc: 0.453125]: [A loss: 0.740240, acc: 0.187500]\n",
      "5671: [D loss: 0.697468, acc: 0.490234]: [A loss: 0.706423, acc: 0.406250]\n",
      "5672: [D loss: 0.696470, acc: 0.496094]: [A loss: 0.737719, acc: 0.195312]\n",
      "5673: [D loss: 0.695906, acc: 0.503906]: [A loss: 0.705897, acc: 0.375000]\n",
      "5674: [D loss: 0.696563, acc: 0.488281]: [A loss: 0.697369, acc: 0.476562]\n",
      "5675: [D loss: 0.696458, acc: 0.507812]: [A loss: 0.743897, acc: 0.195312]\n",
      "5676: [D loss: 0.692954, acc: 0.486328]: [A loss: 0.702088, acc: 0.425781]\n",
      "5677: [D loss: 0.696980, acc: 0.521484]: [A loss: 0.704743, acc: 0.382812]\n",
      "5678: [D loss: 0.693815, acc: 0.519531]: [A loss: 0.739472, acc: 0.187500]\n",
      "5679: [D loss: 0.694161, acc: 0.517578]: [A loss: 0.708341, acc: 0.363281]\n",
      "5680: [D loss: 0.693252, acc: 0.539062]: [A loss: 0.726260, acc: 0.289062]\n",
      "5681: [D loss: 0.692721, acc: 0.517578]: [A loss: 0.693194, acc: 0.457031]\n",
      "5682: [D loss: 0.691618, acc: 0.546875]: [A loss: 0.716153, acc: 0.328125]\n",
      "5683: [D loss: 0.693664, acc: 0.521484]: [A loss: 0.715652, acc: 0.308594]\n",
      "5684: [D loss: 0.693359, acc: 0.511719]: [A loss: 0.700259, acc: 0.460938]\n",
      "5685: [D loss: 0.697872, acc: 0.484375]: [A loss: 0.725404, acc: 0.257812]\n",
      "5686: [D loss: 0.699185, acc: 0.462891]: [A loss: 0.727187, acc: 0.285156]\n",
      "5687: [D loss: 0.700644, acc: 0.472656]: [A loss: 0.732677, acc: 0.226562]\n",
      "5688: [D loss: 0.693534, acc: 0.505859]: [A loss: 0.723741, acc: 0.242188]\n",
      "5689: [D loss: 0.694569, acc: 0.507812]: [A loss: 0.727619, acc: 0.242188]\n",
      "5690: [D loss: 0.697574, acc: 0.480469]: [A loss: 0.719188, acc: 0.277344]\n",
      "5691: [D loss: 0.697442, acc: 0.488281]: [A loss: 0.742114, acc: 0.187500]\n",
      "5692: [D loss: 0.694429, acc: 0.509766]: [A loss: 0.720299, acc: 0.277344]\n",
      "5693: [D loss: 0.693039, acc: 0.517578]: [A loss: 0.749773, acc: 0.160156]\n",
      "5694: [D loss: 0.695438, acc: 0.515625]: [A loss: 0.730711, acc: 0.234375]\n",
      "5695: [D loss: 0.695186, acc: 0.511719]: [A loss: 0.705328, acc: 0.375000]\n",
      "5696: [D loss: 0.699966, acc: 0.498047]: [A loss: 0.727582, acc: 0.296875]\n",
      "5697: [D loss: 0.697111, acc: 0.511719]: [A loss: 0.706020, acc: 0.386719]\n",
      "5698: [D loss: 0.696632, acc: 0.498047]: [A loss: 0.734296, acc: 0.230469]\n",
      "5699: [D loss: 0.692526, acc: 0.529297]: [A loss: 0.703458, acc: 0.437500]\n",
      "5700: [D loss: 0.697652, acc: 0.521484]: [A loss: 0.750320, acc: 0.160156]\n",
      "5701: [D loss: 0.693449, acc: 0.505859]: [A loss: 0.717860, acc: 0.351562]\n",
      "5702: [D loss: 0.698755, acc: 0.505859]: [A loss: 0.754264, acc: 0.101562]\n",
      "5703: [D loss: 0.700041, acc: 0.466797]: [A loss: 0.704554, acc: 0.398438]\n",
      "5704: [D loss: 0.696416, acc: 0.509766]: [A loss: 0.700404, acc: 0.453125]\n",
      "5705: [D loss: 0.698240, acc: 0.470703]: [A loss: 0.716205, acc: 0.316406]\n",
      "5706: [D loss: 0.692809, acc: 0.500000]: [A loss: 0.709058, acc: 0.351562]\n",
      "5707: [D loss: 0.697928, acc: 0.498047]: [A loss: 0.731147, acc: 0.253906]\n",
      "5708: [D loss: 0.698192, acc: 0.472656]: [A loss: 0.716514, acc: 0.285156]\n",
      "5709: [D loss: 0.694905, acc: 0.492188]: [A loss: 0.694343, acc: 0.441406]\n",
      "5710: [D loss: 0.693146, acc: 0.523438]: [A loss: 0.742602, acc: 0.156250]\n",
      "5711: [D loss: 0.696661, acc: 0.498047]: [A loss: 0.703818, acc: 0.394531]\n",
      "5712: [D loss: 0.698555, acc: 0.496094]: [A loss: 0.747356, acc: 0.148438]\n",
      "5713: [D loss: 0.697290, acc: 0.500000]: [A loss: 0.724636, acc: 0.246094]\n",
      "5714: [D loss: 0.695940, acc: 0.488281]: [A loss: 0.707860, acc: 0.394531]\n",
      "5715: [D loss: 0.696592, acc: 0.492188]: [A loss: 0.749073, acc: 0.164062]\n",
      "5716: [D loss: 0.690012, acc: 0.525391]: [A loss: 0.665209, acc: 0.628906]\n",
      "5717: [D loss: 0.705157, acc: 0.505859]: [A loss: 0.762635, acc: 0.121094]\n",
      "5718: [D loss: 0.694428, acc: 0.501953]: [A loss: 0.686168, acc: 0.539062]\n",
      "5719: [D loss: 0.695734, acc: 0.501953]: [A loss: 0.732954, acc: 0.230469]\n",
      "5720: [D loss: 0.696842, acc: 0.468750]: [A loss: 0.719291, acc: 0.324219]\n",
      "5721: [D loss: 0.693596, acc: 0.523438]: [A loss: 0.720290, acc: 0.320312]\n",
      "5722: [D loss: 0.693820, acc: 0.515625]: [A loss: 0.696501, acc: 0.433594]\n",
      "5723: [D loss: 0.698583, acc: 0.492188]: [A loss: 0.767839, acc: 0.105469]\n",
      "5724: [D loss: 0.697904, acc: 0.455078]: [A loss: 0.705738, acc: 0.378906]\n",
      "5725: [D loss: 0.698976, acc: 0.503906]: [A loss: 0.723111, acc: 0.285156]\n",
      "5726: [D loss: 0.696420, acc: 0.486328]: [A loss: 0.712820, acc: 0.332031]\n",
      "5727: [D loss: 0.697945, acc: 0.501953]: [A loss: 0.714804, acc: 0.324219]\n",
      "5728: [D loss: 0.693744, acc: 0.527344]: [A loss: 0.715248, acc: 0.382812]\n",
      "5729: [D loss: 0.698237, acc: 0.501953]: [A loss: 0.699805, acc: 0.460938]\n",
      "5730: [D loss: 0.699755, acc: 0.500000]: [A loss: 0.751091, acc: 0.148438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5731: [D loss: 0.692469, acc: 0.500000]: [A loss: 0.700146, acc: 0.468750]\n",
      "5732: [D loss: 0.694064, acc: 0.513672]: [A loss: 0.734746, acc: 0.218750]\n",
      "5733: [D loss: 0.692144, acc: 0.511719]: [A loss: 0.715679, acc: 0.343750]\n",
      "5734: [D loss: 0.693697, acc: 0.525391]: [A loss: 0.731160, acc: 0.242188]\n",
      "5735: [D loss: 0.697563, acc: 0.484375]: [A loss: 0.732738, acc: 0.214844]\n",
      "5736: [D loss: 0.694320, acc: 0.519531]: [A loss: 0.706994, acc: 0.386719]\n",
      "5737: [D loss: 0.699007, acc: 0.472656]: [A loss: 0.734700, acc: 0.242188]\n",
      "5738: [D loss: 0.693980, acc: 0.515625]: [A loss: 0.708108, acc: 0.386719]\n",
      "5739: [D loss: 0.693250, acc: 0.521484]: [A loss: 0.692143, acc: 0.488281]\n",
      "5740: [D loss: 0.698158, acc: 0.498047]: [A loss: 0.747379, acc: 0.152344]\n",
      "5741: [D loss: 0.695035, acc: 0.523438]: [A loss: 0.713311, acc: 0.332031]\n",
      "5742: [D loss: 0.694073, acc: 0.544922]: [A loss: 0.726815, acc: 0.289062]\n",
      "5743: [D loss: 0.694997, acc: 0.476562]: [A loss: 0.701667, acc: 0.425781]\n",
      "5744: [D loss: 0.694778, acc: 0.523438]: [A loss: 0.720492, acc: 0.328125]\n",
      "5745: [D loss: 0.691502, acc: 0.519531]: [A loss: 0.712963, acc: 0.339844]\n",
      "5746: [D loss: 0.695572, acc: 0.480469]: [A loss: 0.724833, acc: 0.257812]\n",
      "5747: [D loss: 0.693875, acc: 0.486328]: [A loss: 0.734874, acc: 0.230469]\n",
      "5748: [D loss: 0.696641, acc: 0.492188]: [A loss: 0.735130, acc: 0.210938]\n",
      "5749: [D loss: 0.692729, acc: 0.513672]: [A loss: 0.676647, acc: 0.601562]\n",
      "5750: [D loss: 0.704064, acc: 0.515625]: [A loss: 0.787298, acc: 0.046875]\n",
      "5751: [D loss: 0.695824, acc: 0.498047]: [A loss: 0.692799, acc: 0.472656]\n",
      "5752: [D loss: 0.694915, acc: 0.525391]: [A loss: 0.704416, acc: 0.410156]\n",
      "5753: [D loss: 0.696281, acc: 0.500000]: [A loss: 0.766707, acc: 0.105469]\n",
      "5754: [D loss: 0.693793, acc: 0.519531]: [A loss: 0.687521, acc: 0.519531]\n",
      "5755: [D loss: 0.697229, acc: 0.509766]: [A loss: 0.734591, acc: 0.203125]\n",
      "5756: [D loss: 0.699719, acc: 0.458984]: [A loss: 0.725888, acc: 0.277344]\n",
      "5757: [D loss: 0.693574, acc: 0.529297]: [A loss: 0.703439, acc: 0.398438]\n",
      "5758: [D loss: 0.696457, acc: 0.503906]: [A loss: 0.730862, acc: 0.222656]\n",
      "5759: [D loss: 0.695512, acc: 0.490234]: [A loss: 0.729536, acc: 0.265625]\n",
      "5760: [D loss: 0.690316, acc: 0.539062]: [A loss: 0.719945, acc: 0.332031]\n",
      "5761: [D loss: 0.696358, acc: 0.513672]: [A loss: 0.706720, acc: 0.382812]\n",
      "5762: [D loss: 0.697569, acc: 0.476562]: [A loss: 0.713173, acc: 0.343750]\n",
      "5763: [D loss: 0.691010, acc: 0.529297]: [A loss: 0.706909, acc: 0.367188]\n",
      "5764: [D loss: 0.700390, acc: 0.476562]: [A loss: 0.738526, acc: 0.179688]\n",
      "5765: [D loss: 0.699967, acc: 0.441406]: [A loss: 0.716919, acc: 0.359375]\n",
      "5766: [D loss: 0.701221, acc: 0.492188]: [A loss: 0.722143, acc: 0.265625]\n",
      "5767: [D loss: 0.694251, acc: 0.496094]: [A loss: 0.719727, acc: 0.277344]\n",
      "5768: [D loss: 0.695523, acc: 0.490234]: [A loss: 0.717298, acc: 0.312500]\n",
      "5769: [D loss: 0.695999, acc: 0.482422]: [A loss: 0.729781, acc: 0.257812]\n",
      "5770: [D loss: 0.697197, acc: 0.468750]: [A loss: 0.723986, acc: 0.273438]\n",
      "5771: [D loss: 0.694370, acc: 0.527344]: [A loss: 0.728163, acc: 0.277344]\n",
      "5772: [D loss: 0.694871, acc: 0.488281]: [A loss: 0.710310, acc: 0.402344]\n",
      "5773: [D loss: 0.691712, acc: 0.546875]: [A loss: 0.712112, acc: 0.363281]\n",
      "5774: [D loss: 0.701183, acc: 0.478516]: [A loss: 0.761491, acc: 0.113281]\n",
      "5775: [D loss: 0.698705, acc: 0.466797]: [A loss: 0.726627, acc: 0.257812]\n",
      "5776: [D loss: 0.696261, acc: 0.484375]: [A loss: 0.734214, acc: 0.265625]\n",
      "5777: [D loss: 0.696864, acc: 0.492188]: [A loss: 0.709847, acc: 0.367188]\n",
      "5778: [D loss: 0.696719, acc: 0.496094]: [A loss: 0.759017, acc: 0.140625]\n",
      "5779: [D loss: 0.693258, acc: 0.488281]: [A loss: 0.688513, acc: 0.593750]\n",
      "5780: [D loss: 0.695433, acc: 0.501953]: [A loss: 0.712535, acc: 0.367188]\n",
      "5781: [D loss: 0.694216, acc: 0.513672]: [A loss: 0.687256, acc: 0.503906]\n",
      "5782: [D loss: 0.696726, acc: 0.517578]: [A loss: 0.743438, acc: 0.187500]\n",
      "5783: [D loss: 0.695286, acc: 0.521484]: [A loss: 0.701178, acc: 0.425781]\n",
      "5784: [D loss: 0.698982, acc: 0.488281]: [A loss: 0.750613, acc: 0.132812]\n",
      "5785: [D loss: 0.692304, acc: 0.535156]: [A loss: 0.705274, acc: 0.437500]\n",
      "5786: [D loss: 0.702875, acc: 0.498047]: [A loss: 0.793353, acc: 0.058594]\n",
      "5787: [D loss: 0.695721, acc: 0.505859]: [A loss: 0.703285, acc: 0.378906]\n",
      "5788: [D loss: 0.695658, acc: 0.488281]: [A loss: 0.717540, acc: 0.300781]\n",
      "5789: [D loss: 0.698256, acc: 0.476562]: [A loss: 0.710406, acc: 0.324219]\n",
      "5790: [D loss: 0.701297, acc: 0.453125]: [A loss: 0.728119, acc: 0.242188]\n",
      "5791: [D loss: 0.695902, acc: 0.482422]: [A loss: 0.683432, acc: 0.535156]\n",
      "5792: [D loss: 0.701615, acc: 0.503906]: [A loss: 0.764981, acc: 0.117188]\n",
      "5793: [D loss: 0.703040, acc: 0.464844]: [A loss: 0.731769, acc: 0.207031]\n",
      "5794: [D loss: 0.695293, acc: 0.468750]: [A loss: 0.701570, acc: 0.449219]\n",
      "5795: [D loss: 0.698432, acc: 0.484375]: [A loss: 0.717576, acc: 0.339844]\n",
      "5796: [D loss: 0.701218, acc: 0.464844]: [A loss: 0.741839, acc: 0.183594]\n",
      "5797: [D loss: 0.696363, acc: 0.490234]: [A loss: 0.733188, acc: 0.230469]\n",
      "5798: [D loss: 0.692704, acc: 0.535156]: [A loss: 0.711207, acc: 0.367188]\n",
      "5799: [D loss: 0.700863, acc: 0.500000]: [A loss: 0.736663, acc: 0.207031]\n",
      "5800: [D loss: 0.695860, acc: 0.503906]: [A loss: 0.727303, acc: 0.246094]\n",
      "5801: [D loss: 0.700605, acc: 0.464844]: [A loss: 0.736298, acc: 0.230469]\n",
      "5802: [D loss: 0.700621, acc: 0.453125]: [A loss: 0.718230, acc: 0.292969]\n",
      "5803: [D loss: 0.698082, acc: 0.501953]: [A loss: 0.725658, acc: 0.253906]\n",
      "5804: [D loss: 0.689841, acc: 0.539062]: [A loss: 0.687612, acc: 0.535156]\n",
      "5805: [D loss: 0.697753, acc: 0.511719]: [A loss: 0.717418, acc: 0.335938]\n",
      "5806: [D loss: 0.692857, acc: 0.486328]: [A loss: 0.716489, acc: 0.351562]\n",
      "5807: [D loss: 0.695299, acc: 0.501953]: [A loss: 0.713966, acc: 0.328125]\n",
      "5808: [D loss: 0.693679, acc: 0.521484]: [A loss: 0.714920, acc: 0.335938]\n",
      "5809: [D loss: 0.696756, acc: 0.496094]: [A loss: 0.711019, acc: 0.371094]\n",
      "5810: [D loss: 0.696048, acc: 0.478516]: [A loss: 0.706346, acc: 0.382812]\n",
      "5811: [D loss: 0.699089, acc: 0.500000]: [A loss: 0.786038, acc: 0.050781]\n",
      "5812: [D loss: 0.697009, acc: 0.486328]: [A loss: 0.701505, acc: 0.414062]\n",
      "5813: [D loss: 0.696914, acc: 0.527344]: [A loss: 0.722986, acc: 0.253906]\n",
      "5814: [D loss: 0.692239, acc: 0.515625]: [A loss: 0.698772, acc: 0.429688]\n",
      "5815: [D loss: 0.697074, acc: 0.498047]: [A loss: 0.719549, acc: 0.320312]\n",
      "5816: [D loss: 0.696551, acc: 0.492188]: [A loss: 0.729429, acc: 0.230469]\n",
      "5817: [D loss: 0.694752, acc: 0.494141]: [A loss: 0.718027, acc: 0.285156]\n",
      "5818: [D loss: 0.695461, acc: 0.498047]: [A loss: 0.724544, acc: 0.281250]\n",
      "5819: [D loss: 0.693241, acc: 0.517578]: [A loss: 0.707838, acc: 0.371094]\n",
      "5820: [D loss: 0.692064, acc: 0.527344]: [A loss: 0.734051, acc: 0.242188]\n",
      "5821: [D loss: 0.696904, acc: 0.482422]: [A loss: 0.738586, acc: 0.238281]\n",
      "5822: [D loss: 0.695871, acc: 0.476562]: [A loss: 0.694216, acc: 0.484375]\n",
      "5823: [D loss: 0.692655, acc: 0.542969]: [A loss: 0.715194, acc: 0.335938]\n",
      "5824: [D loss: 0.700283, acc: 0.498047]: [A loss: 0.733357, acc: 0.222656]\n",
      "5825: [D loss: 0.691730, acc: 0.519531]: [A loss: 0.699898, acc: 0.457031]\n",
      "5826: [D loss: 0.700598, acc: 0.490234]: [A loss: 0.773147, acc: 0.058594]\n",
      "5827: [D loss: 0.697170, acc: 0.488281]: [A loss: 0.694618, acc: 0.468750]\n",
      "5828: [D loss: 0.700747, acc: 0.478516]: [A loss: 0.745283, acc: 0.183594]\n",
      "5829: [D loss: 0.694193, acc: 0.478516]: [A loss: 0.723499, acc: 0.281250]\n",
      "5830: [D loss: 0.694146, acc: 0.494141]: [A loss: 0.701170, acc: 0.429688]\n",
      "5831: [D loss: 0.698213, acc: 0.515625]: [A loss: 0.742591, acc: 0.160156]\n",
      "5832: [D loss: 0.698710, acc: 0.470703]: [A loss: 0.715943, acc: 0.312500]\n",
      "5833: [D loss: 0.695046, acc: 0.503906]: [A loss: 0.728796, acc: 0.238281]\n",
      "5834: [D loss: 0.695225, acc: 0.515625]: [A loss: 0.730407, acc: 0.214844]\n",
      "5835: [D loss: 0.694408, acc: 0.501953]: [A loss: 0.709397, acc: 0.351562]\n",
      "5836: [D loss: 0.697571, acc: 0.482422]: [A loss: 0.726378, acc: 0.222656]\n",
      "5837: [D loss: 0.695354, acc: 0.496094]: [A loss: 0.739491, acc: 0.195312]\n",
      "5838: [D loss: 0.690595, acc: 0.537109]: [A loss: 0.717141, acc: 0.351562]\n",
      "5839: [D loss: 0.694287, acc: 0.515625]: [A loss: 0.733878, acc: 0.257812]\n",
      "5840: [D loss: 0.698334, acc: 0.476562]: [A loss: 0.757907, acc: 0.113281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5841: [D loss: 0.691731, acc: 0.527344]: [A loss: 0.690607, acc: 0.523438]\n",
      "5842: [D loss: 0.692400, acc: 0.521484]: [A loss: 0.725541, acc: 0.296875]\n",
      "5843: [D loss: 0.691257, acc: 0.537109]: [A loss: 0.731958, acc: 0.238281]\n",
      "5844: [D loss: 0.694917, acc: 0.529297]: [A loss: 0.731990, acc: 0.218750]\n",
      "5845: [D loss: 0.691670, acc: 0.498047]: [A loss: 0.724376, acc: 0.281250]\n",
      "5846: [D loss: 0.695518, acc: 0.480469]: [A loss: 0.694690, acc: 0.468750]\n",
      "5847: [D loss: 0.698269, acc: 0.486328]: [A loss: 0.773185, acc: 0.050781]\n",
      "5848: [D loss: 0.690673, acc: 0.542969]: [A loss: 0.691493, acc: 0.511719]\n",
      "5849: [D loss: 0.701454, acc: 0.466797]: [A loss: 0.723944, acc: 0.269531]\n",
      "5850: [D loss: 0.690926, acc: 0.527344]: [A loss: 0.714048, acc: 0.347656]\n",
      "5851: [D loss: 0.695412, acc: 0.494141]: [A loss: 0.742917, acc: 0.156250]\n",
      "5852: [D loss: 0.693839, acc: 0.521484]: [A loss: 0.708366, acc: 0.386719]\n",
      "5853: [D loss: 0.697625, acc: 0.507812]: [A loss: 0.706650, acc: 0.375000]\n",
      "5854: [D loss: 0.689412, acc: 0.539062]: [A loss: 0.696496, acc: 0.445312]\n",
      "5855: [D loss: 0.693795, acc: 0.531250]: [A loss: 0.752591, acc: 0.132812]\n",
      "5856: [D loss: 0.697140, acc: 0.458984]: [A loss: 0.726703, acc: 0.304688]\n",
      "5857: [D loss: 0.695405, acc: 0.521484]: [A loss: 0.736764, acc: 0.289062]\n",
      "5858: [D loss: 0.704034, acc: 0.500000]: [A loss: 0.791039, acc: 0.070312]\n",
      "5859: [D loss: 0.696402, acc: 0.500000]: [A loss: 0.695143, acc: 0.468750]\n",
      "5860: [D loss: 0.696990, acc: 0.494141]: [A loss: 0.706152, acc: 0.417969]\n",
      "5861: [D loss: 0.693238, acc: 0.500000]: [A loss: 0.739595, acc: 0.207031]\n",
      "5862: [D loss: 0.692985, acc: 0.472656]: [A loss: 0.704356, acc: 0.429688]\n",
      "5863: [D loss: 0.698877, acc: 0.503906]: [A loss: 0.769654, acc: 0.082031]\n",
      "5864: [D loss: 0.687976, acc: 0.542969]: [A loss: 0.680952, acc: 0.589844]\n",
      "5865: [D loss: 0.702420, acc: 0.480469]: [A loss: 0.748358, acc: 0.187500]\n",
      "5866: [D loss: 0.694635, acc: 0.519531]: [A loss: 0.719916, acc: 0.312500]\n",
      "5867: [D loss: 0.697123, acc: 0.492188]: [A loss: 0.716653, acc: 0.328125]\n",
      "5868: [D loss: 0.699645, acc: 0.486328]: [A loss: 0.735240, acc: 0.207031]\n",
      "5869: [D loss: 0.693766, acc: 0.498047]: [A loss: 0.724101, acc: 0.261719]\n",
      "5870: [D loss: 0.698295, acc: 0.470703]: [A loss: 0.738734, acc: 0.183594]\n",
      "5871: [D loss: 0.689117, acc: 0.498047]: [A loss: 0.727945, acc: 0.226562]\n",
      "5872: [D loss: 0.698537, acc: 0.490234]: [A loss: 0.728787, acc: 0.242188]\n",
      "5873: [D loss: 0.692499, acc: 0.509766]: [A loss: 0.705656, acc: 0.390625]\n",
      "5874: [D loss: 0.693751, acc: 0.513672]: [A loss: 0.737511, acc: 0.226562]\n",
      "5875: [D loss: 0.693297, acc: 0.519531]: [A loss: 0.715120, acc: 0.335938]\n",
      "5876: [D loss: 0.699017, acc: 0.503906]: [A loss: 0.740909, acc: 0.210938]\n",
      "5877: [D loss: 0.694117, acc: 0.503906]: [A loss: 0.685117, acc: 0.511719]\n",
      "5878: [D loss: 0.702348, acc: 0.466797]: [A loss: 0.750547, acc: 0.121094]\n",
      "5879: [D loss: 0.693868, acc: 0.513672]: [A loss: 0.718196, acc: 0.367188]\n",
      "5880: [D loss: 0.704718, acc: 0.480469]: [A loss: 0.758357, acc: 0.105469]\n",
      "5881: [D loss: 0.694925, acc: 0.517578]: [A loss: 0.693275, acc: 0.484375]\n",
      "5882: [D loss: 0.698460, acc: 0.498047]: [A loss: 0.776212, acc: 0.070312]\n",
      "5883: [D loss: 0.691348, acc: 0.505859]: [A loss: 0.681692, acc: 0.554688]\n",
      "5884: [D loss: 0.697218, acc: 0.503906]: [A loss: 0.721152, acc: 0.320312]\n",
      "5885: [D loss: 0.693961, acc: 0.513672]: [A loss: 0.700049, acc: 0.402344]\n",
      "5886: [D loss: 0.700429, acc: 0.519531]: [A loss: 0.722614, acc: 0.281250]\n",
      "5887: [D loss: 0.693621, acc: 0.478516]: [A loss: 0.707950, acc: 0.402344]\n",
      "5888: [D loss: 0.698603, acc: 0.496094]: [A loss: 0.695766, acc: 0.460938]\n",
      "5889: [D loss: 0.701145, acc: 0.515625]: [A loss: 0.748791, acc: 0.164062]\n",
      "5890: [D loss: 0.689288, acc: 0.548828]: [A loss: 0.684453, acc: 0.539062]\n",
      "5891: [D loss: 0.702601, acc: 0.503906]: [A loss: 0.761977, acc: 0.113281]\n",
      "5892: [D loss: 0.695365, acc: 0.484375]: [A loss: 0.697790, acc: 0.441406]\n",
      "5893: [D loss: 0.699961, acc: 0.503906]: [A loss: 0.727234, acc: 0.289062]\n",
      "5894: [D loss: 0.692457, acc: 0.535156]: [A loss: 0.702423, acc: 0.406250]\n",
      "5895: [D loss: 0.693275, acc: 0.492188]: [A loss: 0.716517, acc: 0.320312]\n",
      "5896: [D loss: 0.695260, acc: 0.531250]: [A loss: 0.698348, acc: 0.453125]\n",
      "5897: [D loss: 0.698448, acc: 0.486328]: [A loss: 0.739423, acc: 0.210938]\n",
      "5898: [D loss: 0.691086, acc: 0.511719]: [A loss: 0.683509, acc: 0.593750]\n",
      "5899: [D loss: 0.699324, acc: 0.488281]: [A loss: 0.753024, acc: 0.183594]\n",
      "5900: [D loss: 0.695229, acc: 0.507812]: [A loss: 0.727611, acc: 0.277344]\n",
      "5901: [D loss: 0.693815, acc: 0.505859]: [A loss: 0.756816, acc: 0.167969]\n",
      "5902: [D loss: 0.692967, acc: 0.544922]: [A loss: 0.698580, acc: 0.441406]\n",
      "5903: [D loss: 0.694483, acc: 0.509766]: [A loss: 0.726701, acc: 0.265625]\n",
      "5904: [D loss: 0.687487, acc: 0.535156]: [A loss: 0.694318, acc: 0.515625]\n",
      "5905: [D loss: 0.694024, acc: 0.505859]: [A loss: 0.721121, acc: 0.316406]\n",
      "5906: [D loss: 0.700187, acc: 0.476562]: [A loss: 0.756975, acc: 0.140625]\n",
      "5907: [D loss: 0.693650, acc: 0.494141]: [A loss: 0.716349, acc: 0.371094]\n",
      "5908: [D loss: 0.697390, acc: 0.488281]: [A loss: 0.712102, acc: 0.382812]\n",
      "5909: [D loss: 0.700378, acc: 0.472656]: [A loss: 0.780757, acc: 0.085938]\n",
      "5910: [D loss: 0.692614, acc: 0.496094]: [A loss: 0.683142, acc: 0.570312]\n",
      "5911: [D loss: 0.695236, acc: 0.515625]: [A loss: 0.740050, acc: 0.207031]\n",
      "5912: [D loss: 0.693379, acc: 0.486328]: [A loss: 0.695018, acc: 0.457031]\n",
      "5913: [D loss: 0.690687, acc: 0.525391]: [A loss: 0.705074, acc: 0.445312]\n",
      "5914: [D loss: 0.695765, acc: 0.505859]: [A loss: 0.748420, acc: 0.148438]\n",
      "5915: [D loss: 0.694475, acc: 0.486328]: [A loss: 0.701012, acc: 0.406250]\n",
      "5916: [D loss: 0.699117, acc: 0.490234]: [A loss: 0.752400, acc: 0.156250]\n",
      "5917: [D loss: 0.688548, acc: 0.582031]: [A loss: 0.716137, acc: 0.324219]\n",
      "5918: [D loss: 0.698405, acc: 0.490234]: [A loss: 0.775707, acc: 0.097656]\n",
      "5919: [D loss: 0.696154, acc: 0.500000]: [A loss: 0.702735, acc: 0.414062]\n",
      "5920: [D loss: 0.705470, acc: 0.484375]: [A loss: 0.754544, acc: 0.128906]\n",
      "5921: [D loss: 0.693394, acc: 0.515625]: [A loss: 0.707331, acc: 0.394531]\n",
      "5922: [D loss: 0.698405, acc: 0.500000]: [A loss: 0.731688, acc: 0.238281]\n",
      "5923: [D loss: 0.689548, acc: 0.509766]: [A loss: 0.712344, acc: 0.390625]\n",
      "5924: [D loss: 0.696565, acc: 0.500000]: [A loss: 0.737494, acc: 0.195312]\n",
      "5925: [D loss: 0.692058, acc: 0.515625]: [A loss: 0.703760, acc: 0.417969]\n",
      "5926: [D loss: 0.697821, acc: 0.492188]: [A loss: 0.738222, acc: 0.195312]\n",
      "5927: [D loss: 0.690652, acc: 0.527344]: [A loss: 0.699506, acc: 0.488281]\n",
      "5928: [D loss: 0.700389, acc: 0.500000]: [A loss: 0.756822, acc: 0.199219]\n",
      "5929: [D loss: 0.695146, acc: 0.519531]: [A loss: 0.701359, acc: 0.437500]\n",
      "5930: [D loss: 0.702473, acc: 0.500000]: [A loss: 0.801270, acc: 0.042969]\n",
      "5931: [D loss: 0.693373, acc: 0.523438]: [A loss: 0.669883, acc: 0.582031]\n",
      "5932: [D loss: 0.705273, acc: 0.507812]: [A loss: 0.752246, acc: 0.175781]\n",
      "5933: [D loss: 0.698891, acc: 0.496094]: [A loss: 0.714021, acc: 0.343750]\n",
      "5934: [D loss: 0.691715, acc: 0.542969]: [A loss: 0.719556, acc: 0.347656]\n",
      "5935: [D loss: 0.694683, acc: 0.503906]: [A loss: 0.719652, acc: 0.335938]\n",
      "5936: [D loss: 0.693800, acc: 0.519531]: [A loss: 0.723065, acc: 0.304688]\n",
      "5937: [D loss: 0.700108, acc: 0.472656]: [A loss: 0.747483, acc: 0.175781]\n",
      "5938: [D loss: 0.689625, acc: 0.537109]: [A loss: 0.700503, acc: 0.449219]\n",
      "5939: [D loss: 0.698622, acc: 0.511719]: [A loss: 0.784122, acc: 0.070312]\n",
      "5940: [D loss: 0.689474, acc: 0.544922]: [A loss: 0.682882, acc: 0.562500]\n",
      "5941: [D loss: 0.700157, acc: 0.496094]: [A loss: 0.747317, acc: 0.144531]\n",
      "5942: [D loss: 0.695194, acc: 0.515625]: [A loss: 0.695832, acc: 0.480469]\n",
      "5943: [D loss: 0.690830, acc: 0.544922]: [A loss: 0.706411, acc: 0.390625]\n",
      "5944: [D loss: 0.694802, acc: 0.519531]: [A loss: 0.717571, acc: 0.308594]\n",
      "5945: [D loss: 0.695952, acc: 0.494141]: [A loss: 0.725708, acc: 0.324219]\n",
      "5946: [D loss: 0.694444, acc: 0.513672]: [A loss: 0.724390, acc: 0.289062]\n",
      "5947: [D loss: 0.694380, acc: 0.505859]: [A loss: 0.728229, acc: 0.292969]\n",
      "5948: [D loss: 0.696772, acc: 0.484375]: [A loss: 0.711070, acc: 0.394531]\n",
      "5949: [D loss: 0.693218, acc: 0.533203]: [A loss: 0.728956, acc: 0.261719]\n",
      "5950: [D loss: 0.693079, acc: 0.531250]: [A loss: 0.716348, acc: 0.351562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5951: [D loss: 0.694174, acc: 0.523438]: [A loss: 0.713721, acc: 0.347656]\n",
      "5952: [D loss: 0.693695, acc: 0.525391]: [A loss: 0.727152, acc: 0.308594]\n",
      "5953: [D loss: 0.697987, acc: 0.480469]: [A loss: 0.767456, acc: 0.105469]\n",
      "5954: [D loss: 0.690647, acc: 0.535156]: [A loss: 0.673960, acc: 0.621094]\n",
      "5955: [D loss: 0.702571, acc: 0.500000]: [A loss: 0.751595, acc: 0.160156]\n",
      "5956: [D loss: 0.698513, acc: 0.501953]: [A loss: 0.739820, acc: 0.214844]\n",
      "5957: [D loss: 0.695860, acc: 0.494141]: [A loss: 0.718713, acc: 0.359375]\n",
      "5958: [D loss: 0.693935, acc: 0.515625]: [A loss: 0.745623, acc: 0.195312]\n",
      "5959: [D loss: 0.695391, acc: 0.511719]: [A loss: 0.709877, acc: 0.398438]\n",
      "5960: [D loss: 0.691344, acc: 0.531250]: [A loss: 0.702307, acc: 0.410156]\n",
      "5961: [D loss: 0.698565, acc: 0.490234]: [A loss: 0.739275, acc: 0.226562]\n",
      "5962: [D loss: 0.695243, acc: 0.521484]: [A loss: 0.736984, acc: 0.234375]\n",
      "5963: [D loss: 0.698547, acc: 0.501953]: [A loss: 0.737030, acc: 0.238281]\n",
      "5964: [D loss: 0.695771, acc: 0.515625]: [A loss: 0.700343, acc: 0.433594]\n",
      "5965: [D loss: 0.702647, acc: 0.478516]: [A loss: 0.767162, acc: 0.121094]\n",
      "5966: [D loss: 0.695403, acc: 0.486328]: [A loss: 0.712105, acc: 0.371094]\n",
      "5967: [D loss: 0.698111, acc: 0.498047]: [A loss: 0.717177, acc: 0.312500]\n",
      "5968: [D loss: 0.694140, acc: 0.505859]: [A loss: 0.714808, acc: 0.339844]\n",
      "5969: [D loss: 0.699508, acc: 0.457031]: [A loss: 0.725333, acc: 0.281250]\n",
      "5970: [D loss: 0.692400, acc: 0.523438]: [A loss: 0.740407, acc: 0.210938]\n",
      "5971: [D loss: 0.696827, acc: 0.501953]: [A loss: 0.716981, acc: 0.375000]\n",
      "5972: [D loss: 0.699195, acc: 0.498047]: [A loss: 0.730520, acc: 0.273438]\n",
      "5973: [D loss: 0.694614, acc: 0.494141]: [A loss: 0.724777, acc: 0.296875]\n",
      "5974: [D loss: 0.693893, acc: 0.513672]: [A loss: 0.703044, acc: 0.406250]\n",
      "5975: [D loss: 0.697624, acc: 0.501953]: [A loss: 0.766980, acc: 0.125000]\n",
      "5976: [D loss: 0.689561, acc: 0.525391]: [A loss: 0.699175, acc: 0.425781]\n",
      "5977: [D loss: 0.696412, acc: 0.507812]: [A loss: 0.798012, acc: 0.062500]\n",
      "5978: [D loss: 0.689750, acc: 0.507812]: [A loss: 0.683512, acc: 0.554688]\n",
      "5979: [D loss: 0.695439, acc: 0.515625]: [A loss: 0.779967, acc: 0.066406]\n",
      "5980: [D loss: 0.690356, acc: 0.529297]: [A loss: 0.676716, acc: 0.570312]\n",
      "5981: [D loss: 0.702574, acc: 0.484375]: [A loss: 0.756682, acc: 0.121094]\n",
      "5982: [D loss: 0.697123, acc: 0.517578]: [A loss: 0.709982, acc: 0.371094]\n",
      "5983: [D loss: 0.701266, acc: 0.458984]: [A loss: 0.734076, acc: 0.226562]\n",
      "5984: [D loss: 0.692285, acc: 0.515625]: [A loss: 0.722504, acc: 0.316406]\n",
      "5985: [D loss: 0.692793, acc: 0.521484]: [A loss: 0.742279, acc: 0.207031]\n",
      "5986: [D loss: 0.692506, acc: 0.527344]: [A loss: 0.699631, acc: 0.429688]\n",
      "5987: [D loss: 0.697872, acc: 0.507812]: [A loss: 0.732342, acc: 0.277344]\n",
      "5988: [D loss: 0.694421, acc: 0.478516]: [A loss: 0.703251, acc: 0.375000]\n",
      "5989: [D loss: 0.698628, acc: 0.496094]: [A loss: 0.738249, acc: 0.246094]\n",
      "5990: [D loss: 0.686450, acc: 0.531250]: [A loss: 0.700316, acc: 0.453125]\n",
      "5991: [D loss: 0.699145, acc: 0.494141]: [A loss: 0.765470, acc: 0.105469]\n",
      "5992: [D loss: 0.693845, acc: 0.505859]: [A loss: 0.697501, acc: 0.460938]\n",
      "5993: [D loss: 0.696642, acc: 0.513672]: [A loss: 0.743644, acc: 0.179688]\n",
      "5994: [D loss: 0.692141, acc: 0.496094]: [A loss: 0.691444, acc: 0.515625]\n",
      "5995: [D loss: 0.697717, acc: 0.501953]: [A loss: 0.724110, acc: 0.308594]\n",
      "5996: [D loss: 0.694503, acc: 0.484375]: [A loss: 0.727121, acc: 0.273438]\n",
      "5997: [D loss: 0.692334, acc: 0.523438]: [A loss: 0.715320, acc: 0.382812]\n",
      "5998: [D loss: 0.699974, acc: 0.464844]: [A loss: 0.732199, acc: 0.238281]\n",
      "5999: [D loss: 0.694437, acc: 0.488281]: [A loss: 0.739347, acc: 0.187500]\n",
      "6000: [D loss: 0.695258, acc: 0.482422]: [A loss: 0.717334, acc: 0.320312]\n",
      "6001: [D loss: 0.695956, acc: 0.498047]: [A loss: 0.748847, acc: 0.160156]\n",
      "6002: [D loss: 0.687958, acc: 0.542969]: [A loss: 0.703971, acc: 0.417969]\n",
      "6003: [D loss: 0.702469, acc: 0.486328]: [A loss: 0.760772, acc: 0.093750]\n",
      "6004: [D loss: 0.699357, acc: 0.441406]: [A loss: 0.711060, acc: 0.359375]\n",
      "6005: [D loss: 0.701981, acc: 0.492188]: [A loss: 0.760049, acc: 0.101562]\n",
      "6006: [D loss: 0.693888, acc: 0.490234]: [A loss: 0.713165, acc: 0.386719]\n",
      "6007: [D loss: 0.697529, acc: 0.486328]: [A loss: 0.742813, acc: 0.199219]\n",
      "6008: [D loss: 0.693157, acc: 0.525391]: [A loss: 0.709489, acc: 0.378906]\n",
      "6009: [D loss: 0.697861, acc: 0.509766]: [A loss: 0.754844, acc: 0.152344]\n",
      "6010: [D loss: 0.695819, acc: 0.480469]: [A loss: 0.700037, acc: 0.457031]\n",
      "6011: [D loss: 0.698802, acc: 0.492188]: [A loss: 0.729994, acc: 0.242188]\n",
      "6012: [D loss: 0.695686, acc: 0.486328]: [A loss: 0.706178, acc: 0.398438]\n",
      "6013: [D loss: 0.692111, acc: 0.515625]: [A loss: 0.702095, acc: 0.417969]\n",
      "6014: [D loss: 0.692820, acc: 0.517578]: [A loss: 0.743651, acc: 0.203125]\n",
      "6015: [D loss: 0.691513, acc: 0.505859]: [A loss: 0.740079, acc: 0.191406]\n",
      "6016: [D loss: 0.696698, acc: 0.494141]: [A loss: 0.720261, acc: 0.320312]\n",
      "6017: [D loss: 0.695493, acc: 0.513672]: [A loss: 0.772294, acc: 0.093750]\n",
      "6018: [D loss: 0.696432, acc: 0.505859]: [A loss: 0.714629, acc: 0.351562]\n",
      "6019: [D loss: 0.694900, acc: 0.523438]: [A loss: 0.736847, acc: 0.230469]\n",
      "6020: [D loss: 0.695537, acc: 0.507812]: [A loss: 0.732266, acc: 0.250000]\n",
      "6021: [D loss: 0.696842, acc: 0.525391]: [A loss: 0.711520, acc: 0.347656]\n",
      "6022: [D loss: 0.692631, acc: 0.533203]: [A loss: 0.731788, acc: 0.250000]\n",
      "6023: [D loss: 0.696332, acc: 0.474609]: [A loss: 0.730390, acc: 0.269531]\n",
      "6024: [D loss: 0.691791, acc: 0.519531]: [A loss: 0.716028, acc: 0.343750]\n",
      "6025: [D loss: 0.692958, acc: 0.525391]: [A loss: 0.690034, acc: 0.464844]\n",
      "6026: [D loss: 0.697950, acc: 0.500000]: [A loss: 0.738783, acc: 0.250000]\n",
      "6027: [D loss: 0.697223, acc: 0.482422]: [A loss: 0.715237, acc: 0.355469]\n",
      "6028: [D loss: 0.696322, acc: 0.480469]: [A loss: 0.725190, acc: 0.269531]\n",
      "6029: [D loss: 0.699111, acc: 0.484375]: [A loss: 0.741880, acc: 0.226562]\n",
      "6030: [D loss: 0.688095, acc: 0.546875]: [A loss: 0.710078, acc: 0.382812]\n",
      "6031: [D loss: 0.704134, acc: 0.519531]: [A loss: 0.783406, acc: 0.117188]\n",
      "6032: [D loss: 0.693048, acc: 0.503906]: [A loss: 0.688700, acc: 0.527344]\n",
      "6033: [D loss: 0.699150, acc: 0.505859]: [A loss: 0.757789, acc: 0.132812]\n",
      "6034: [D loss: 0.691049, acc: 0.544922]: [A loss: 0.708016, acc: 0.402344]\n",
      "6035: [D loss: 0.692229, acc: 0.535156]: [A loss: 0.721957, acc: 0.292969]\n",
      "6036: [D loss: 0.693044, acc: 0.509766]: [A loss: 0.729060, acc: 0.273438]\n",
      "6037: [D loss: 0.696013, acc: 0.498047]: [A loss: 0.746698, acc: 0.203125]\n",
      "6038: [D loss: 0.692665, acc: 0.498047]: [A loss: 0.718778, acc: 0.335938]\n",
      "6039: [D loss: 0.697016, acc: 0.501953]: [A loss: 0.719708, acc: 0.312500]\n",
      "6040: [D loss: 0.695055, acc: 0.509766]: [A loss: 0.705707, acc: 0.417969]\n",
      "6041: [D loss: 0.696708, acc: 0.494141]: [A loss: 0.707911, acc: 0.382812]\n",
      "6042: [D loss: 0.692871, acc: 0.531250]: [A loss: 0.727723, acc: 0.238281]\n",
      "6043: [D loss: 0.692813, acc: 0.517578]: [A loss: 0.710035, acc: 0.371094]\n",
      "6044: [D loss: 0.694316, acc: 0.513672]: [A loss: 0.711442, acc: 0.328125]\n",
      "6045: [D loss: 0.693789, acc: 0.519531]: [A loss: 0.711964, acc: 0.347656]\n",
      "6046: [D loss: 0.701123, acc: 0.480469]: [A loss: 0.772587, acc: 0.121094]\n",
      "6047: [D loss: 0.701844, acc: 0.462891]: [A loss: 0.741892, acc: 0.199219]\n",
      "6048: [D loss: 0.694766, acc: 0.515625]: [A loss: 0.706933, acc: 0.410156]\n",
      "6049: [D loss: 0.701928, acc: 0.476562]: [A loss: 0.731406, acc: 0.253906]\n",
      "6050: [D loss: 0.694628, acc: 0.505859]: [A loss: 0.710109, acc: 0.402344]\n",
      "6051: [D loss: 0.702018, acc: 0.500000]: [A loss: 0.772507, acc: 0.093750]\n",
      "6052: [D loss: 0.696707, acc: 0.468750]: [A loss: 0.706905, acc: 0.398438]\n",
      "6053: [D loss: 0.701055, acc: 0.507812]: [A loss: 0.717237, acc: 0.316406]\n",
      "6054: [D loss: 0.698982, acc: 0.498047]: [A loss: 0.731635, acc: 0.242188]\n",
      "6055: [D loss: 0.697268, acc: 0.533203]: [A loss: 0.729439, acc: 0.269531]\n",
      "6056: [D loss: 0.693037, acc: 0.509766]: [A loss: 0.726359, acc: 0.292969]\n",
      "6057: [D loss: 0.695502, acc: 0.492188]: [A loss: 0.748557, acc: 0.230469]\n",
      "6058: [D loss: 0.695869, acc: 0.486328]: [A loss: 0.741386, acc: 0.203125]\n",
      "6059: [D loss: 0.694430, acc: 0.511719]: [A loss: 0.732841, acc: 0.253906]\n",
      "6060: [D loss: 0.692108, acc: 0.535156]: [A loss: 0.734498, acc: 0.285156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6061: [D loss: 0.694759, acc: 0.507812]: [A loss: 0.734918, acc: 0.242188]\n",
      "6062: [D loss: 0.699869, acc: 0.464844]: [A loss: 0.732886, acc: 0.242188]\n",
      "6063: [D loss: 0.693730, acc: 0.500000]: [A loss: 0.724447, acc: 0.289062]\n",
      "6064: [D loss: 0.695701, acc: 0.488281]: [A loss: 0.709942, acc: 0.347656]\n",
      "6065: [D loss: 0.689224, acc: 0.511719]: [A loss: 0.760928, acc: 0.121094]\n",
      "6066: [D loss: 0.697005, acc: 0.500000]: [A loss: 0.713348, acc: 0.390625]\n",
      "6067: [D loss: 0.703356, acc: 0.468750]: [A loss: 0.748655, acc: 0.144531]\n",
      "6068: [D loss: 0.696095, acc: 0.488281]: [A loss: 0.705894, acc: 0.363281]\n",
      "6069: [D loss: 0.699527, acc: 0.488281]: [A loss: 0.725613, acc: 0.265625]\n",
      "6070: [D loss: 0.699999, acc: 0.498047]: [A loss: 0.735951, acc: 0.214844]\n",
      "6071: [D loss: 0.698142, acc: 0.500000]: [A loss: 0.740728, acc: 0.195312]\n",
      "6072: [D loss: 0.695671, acc: 0.492188]: [A loss: 0.711543, acc: 0.398438]\n",
      "6073: [D loss: 0.696023, acc: 0.511719]: [A loss: 0.738392, acc: 0.191406]\n",
      "6074: [D loss: 0.694125, acc: 0.529297]: [A loss: 0.716447, acc: 0.328125]\n",
      "6075: [D loss: 0.694595, acc: 0.517578]: [A loss: 0.707392, acc: 0.386719]\n",
      "6076: [D loss: 0.701819, acc: 0.474609]: [A loss: 0.788787, acc: 0.062500]\n",
      "6077: [D loss: 0.694132, acc: 0.482422]: [A loss: 0.707587, acc: 0.386719]\n",
      "6078: [D loss: 0.697410, acc: 0.505859]: [A loss: 0.780974, acc: 0.089844]\n",
      "6079: [D loss: 0.693589, acc: 0.501953]: [A loss: 0.709542, acc: 0.367188]\n",
      "6080: [D loss: 0.699737, acc: 0.496094]: [A loss: 0.754806, acc: 0.164062]\n",
      "6081: [D loss: 0.691468, acc: 0.513672]: [A loss: 0.742892, acc: 0.210938]\n",
      "6082: [D loss: 0.696545, acc: 0.496094]: [A loss: 0.733103, acc: 0.242188]\n",
      "6083: [D loss: 0.688642, acc: 0.542969]: [A loss: 0.743182, acc: 0.242188]\n",
      "6084: [D loss: 0.693302, acc: 0.513672]: [A loss: 0.711163, acc: 0.394531]\n",
      "6085: [D loss: 0.697106, acc: 0.531250]: [A loss: 0.754661, acc: 0.152344]\n",
      "6086: [D loss: 0.692197, acc: 0.505859]: [A loss: 0.707064, acc: 0.425781]\n",
      "6087: [D loss: 0.700050, acc: 0.486328]: [A loss: 0.725453, acc: 0.285156]\n",
      "6088: [D loss: 0.696603, acc: 0.501953]: [A loss: 0.700057, acc: 0.441406]\n",
      "6089: [D loss: 0.687395, acc: 0.554688]: [A loss: 0.706987, acc: 0.402344]\n",
      "6090: [D loss: 0.692174, acc: 0.531250]: [A loss: 0.743330, acc: 0.171875]\n",
      "6091: [D loss: 0.692064, acc: 0.515625]: [A loss: 0.716820, acc: 0.394531]\n",
      "6092: [D loss: 0.695265, acc: 0.480469]: [A loss: 0.731724, acc: 0.277344]\n",
      "6093: [D loss: 0.695647, acc: 0.539062]: [A loss: 0.709877, acc: 0.414062]\n",
      "6094: [D loss: 0.696231, acc: 0.482422]: [A loss: 0.724067, acc: 0.316406]\n",
      "6095: [D loss: 0.690787, acc: 0.525391]: [A loss: 0.729104, acc: 0.246094]\n",
      "6096: [D loss: 0.690546, acc: 0.521484]: [A loss: 0.699553, acc: 0.453125]\n",
      "6097: [D loss: 0.697506, acc: 0.496094]: [A loss: 0.747549, acc: 0.203125]\n",
      "6098: [D loss: 0.688591, acc: 0.539062]: [A loss: 0.716053, acc: 0.316406]\n",
      "6099: [D loss: 0.696205, acc: 0.531250]: [A loss: 0.735435, acc: 0.250000]\n",
      "6100: [D loss: 0.692895, acc: 0.492188]: [A loss: 0.728374, acc: 0.269531]\n",
      "6101: [D loss: 0.694376, acc: 0.511719]: [A loss: 0.693881, acc: 0.464844]\n",
      "6102: [D loss: 0.696109, acc: 0.472656]: [A loss: 0.702508, acc: 0.429688]\n",
      "6103: [D loss: 0.692147, acc: 0.519531]: [A loss: 0.757802, acc: 0.144531]\n",
      "6104: [D loss: 0.692528, acc: 0.507812]: [A loss: 0.682412, acc: 0.519531]\n",
      "6105: [D loss: 0.700555, acc: 0.496094]: [A loss: 0.793977, acc: 0.050781]\n",
      "6106: [D loss: 0.689223, acc: 0.539062]: [A loss: 0.686392, acc: 0.492188]\n",
      "6107: [D loss: 0.705920, acc: 0.501953]: [A loss: 0.774294, acc: 0.105469]\n",
      "6108: [D loss: 0.699942, acc: 0.462891]: [A loss: 0.719227, acc: 0.324219]\n",
      "6109: [D loss: 0.694609, acc: 0.507812]: [A loss: 0.722657, acc: 0.285156]\n",
      "6110: [D loss: 0.699382, acc: 0.484375]: [A loss: 0.754070, acc: 0.152344]\n",
      "6111: [D loss: 0.694865, acc: 0.484375]: [A loss: 0.711352, acc: 0.355469]\n",
      "6112: [D loss: 0.697622, acc: 0.474609]: [A loss: 0.733713, acc: 0.222656]\n",
      "6113: [D loss: 0.691711, acc: 0.525391]: [A loss: 0.698921, acc: 0.433594]\n",
      "6114: [D loss: 0.699864, acc: 0.496094]: [A loss: 0.742784, acc: 0.183594]\n",
      "6115: [D loss: 0.694781, acc: 0.492188]: [A loss: 0.706240, acc: 0.363281]\n",
      "6116: [D loss: 0.699962, acc: 0.500000]: [A loss: 0.756313, acc: 0.140625]\n",
      "6117: [D loss: 0.694035, acc: 0.517578]: [A loss: 0.683391, acc: 0.542969]\n",
      "6118: [D loss: 0.701716, acc: 0.488281]: [A loss: 0.738990, acc: 0.187500]\n",
      "6119: [D loss: 0.702110, acc: 0.455078]: [A loss: 0.711013, acc: 0.378906]\n",
      "6120: [D loss: 0.696559, acc: 0.521484]: [A loss: 0.721408, acc: 0.277344]\n",
      "6121: [D loss: 0.695039, acc: 0.523438]: [A loss: 0.743222, acc: 0.191406]\n",
      "6122: [D loss: 0.692067, acc: 0.521484]: [A loss: 0.728239, acc: 0.285156]\n",
      "6123: [D loss: 0.694575, acc: 0.505859]: [A loss: 0.717825, acc: 0.324219]\n",
      "6124: [D loss: 0.699844, acc: 0.494141]: [A loss: 0.760642, acc: 0.089844]\n",
      "6125: [D loss: 0.700011, acc: 0.460938]: [A loss: 0.698151, acc: 0.402344]\n",
      "6126: [D loss: 0.700716, acc: 0.486328]: [A loss: 0.710001, acc: 0.335938]\n",
      "6127: [D loss: 0.698285, acc: 0.480469]: [A loss: 0.714550, acc: 0.355469]\n",
      "6128: [D loss: 0.697892, acc: 0.474609]: [A loss: 0.729276, acc: 0.222656]\n",
      "6129: [D loss: 0.698220, acc: 0.511719]: [A loss: 0.699315, acc: 0.441406]\n",
      "6130: [D loss: 0.692203, acc: 0.519531]: [A loss: 0.701693, acc: 0.414062]\n",
      "6131: [D loss: 0.698860, acc: 0.531250]: [A loss: 0.753441, acc: 0.160156]\n",
      "6132: [D loss: 0.692111, acc: 0.531250]: [A loss: 0.740938, acc: 0.195312]\n",
      "6133: [D loss: 0.695406, acc: 0.548828]: [A loss: 0.703858, acc: 0.421875]\n",
      "6134: [D loss: 0.707140, acc: 0.470703]: [A loss: 0.764316, acc: 0.078125]\n",
      "6135: [D loss: 0.689400, acc: 0.548828]: [A loss: 0.705125, acc: 0.414062]\n",
      "6136: [D loss: 0.694914, acc: 0.496094]: [A loss: 0.744675, acc: 0.152344]\n",
      "6137: [D loss: 0.696820, acc: 0.480469]: [A loss: 0.716303, acc: 0.347656]\n",
      "6138: [D loss: 0.694150, acc: 0.503906]: [A loss: 0.712649, acc: 0.347656]\n",
      "6139: [D loss: 0.695882, acc: 0.521484]: [A loss: 0.723650, acc: 0.269531]\n",
      "6140: [D loss: 0.696533, acc: 0.511719]: [A loss: 0.690035, acc: 0.496094]\n",
      "6141: [D loss: 0.703585, acc: 0.494141]: [A loss: 0.765609, acc: 0.093750]\n",
      "6142: [D loss: 0.693153, acc: 0.513672]: [A loss: 0.703405, acc: 0.414062]\n",
      "6143: [D loss: 0.693556, acc: 0.503906]: [A loss: 0.713150, acc: 0.339844]\n",
      "6144: [D loss: 0.693321, acc: 0.521484]: [A loss: 0.716472, acc: 0.339844]\n",
      "6145: [D loss: 0.690076, acc: 0.541016]: [A loss: 0.697457, acc: 0.441406]\n",
      "6146: [D loss: 0.702241, acc: 0.480469]: [A loss: 0.777506, acc: 0.062500]\n",
      "6147: [D loss: 0.698322, acc: 0.492188]: [A loss: 0.708039, acc: 0.351562]\n",
      "6148: [D loss: 0.702371, acc: 0.468750]: [A loss: 0.719287, acc: 0.324219]\n",
      "6149: [D loss: 0.692352, acc: 0.507812]: [A loss: 0.701253, acc: 0.394531]\n",
      "6150: [D loss: 0.696147, acc: 0.505859]: [A loss: 0.693075, acc: 0.476562]\n",
      "6151: [D loss: 0.692818, acc: 0.507812]: [A loss: 0.713077, acc: 0.351562]\n",
      "6152: [D loss: 0.697085, acc: 0.505859]: [A loss: 0.715852, acc: 0.355469]\n",
      "6153: [D loss: 0.696506, acc: 0.525391]: [A loss: 0.709405, acc: 0.347656]\n",
      "6154: [D loss: 0.701578, acc: 0.457031]: [A loss: 0.721919, acc: 0.308594]\n",
      "6155: [D loss: 0.691269, acc: 0.523438]: [A loss: 0.724411, acc: 0.281250]\n",
      "6156: [D loss: 0.700589, acc: 0.462891]: [A loss: 0.763403, acc: 0.140625]\n",
      "6157: [D loss: 0.694554, acc: 0.503906]: [A loss: 0.708941, acc: 0.375000]\n",
      "6158: [D loss: 0.694122, acc: 0.515625]: [A loss: 0.716265, acc: 0.328125]\n",
      "6159: [D loss: 0.690205, acc: 0.509766]: [A loss: 0.715046, acc: 0.324219]\n",
      "6160: [D loss: 0.696339, acc: 0.505859]: [A loss: 0.723616, acc: 0.269531]\n",
      "6161: [D loss: 0.696682, acc: 0.478516]: [A loss: 0.724574, acc: 0.300781]\n",
      "6162: [D loss: 0.689746, acc: 0.531250]: [A loss: 0.713864, acc: 0.304688]\n",
      "6163: [D loss: 0.693849, acc: 0.519531]: [A loss: 0.737771, acc: 0.238281]\n",
      "6164: [D loss: 0.691911, acc: 0.517578]: [A loss: 0.727436, acc: 0.253906]\n",
      "6165: [D loss: 0.699184, acc: 0.503906]: [A loss: 0.724508, acc: 0.289062]\n",
      "6166: [D loss: 0.688338, acc: 0.562500]: [A loss: 0.729262, acc: 0.292969]\n",
      "6167: [D loss: 0.700565, acc: 0.500000]: [A loss: 0.725778, acc: 0.285156]\n",
      "6168: [D loss: 0.691176, acc: 0.511719]: [A loss: 0.709230, acc: 0.367188]\n",
      "6169: [D loss: 0.694447, acc: 0.525391]: [A loss: 0.738711, acc: 0.195312]\n",
      "6170: [D loss: 0.695756, acc: 0.488281]: [A loss: 0.751941, acc: 0.171875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6171: [D loss: 0.692153, acc: 0.505859]: [A loss: 0.699407, acc: 0.460938]\n",
      "6172: [D loss: 0.697940, acc: 0.490234]: [A loss: 0.726906, acc: 0.300781]\n",
      "6173: [D loss: 0.695286, acc: 0.503906]: [A loss: 0.722469, acc: 0.296875]\n",
      "6174: [D loss: 0.691764, acc: 0.531250]: [A loss: 0.732161, acc: 0.250000]\n",
      "6175: [D loss: 0.690055, acc: 0.539062]: [A loss: 0.715918, acc: 0.308594]\n",
      "6176: [D loss: 0.698424, acc: 0.478516]: [A loss: 0.726416, acc: 0.261719]\n",
      "6177: [D loss: 0.693141, acc: 0.505859]: [A loss: 0.697848, acc: 0.441406]\n",
      "6178: [D loss: 0.700184, acc: 0.511719]: [A loss: 0.783726, acc: 0.085938]\n",
      "6179: [D loss: 0.690947, acc: 0.539062]: [A loss: 0.685336, acc: 0.503906]\n",
      "6180: [D loss: 0.702956, acc: 0.501953]: [A loss: 0.753919, acc: 0.167969]\n",
      "6181: [D loss: 0.695545, acc: 0.498047]: [A loss: 0.680365, acc: 0.558594]\n",
      "6182: [D loss: 0.700851, acc: 0.480469]: [A loss: 0.737991, acc: 0.226562]\n",
      "6183: [D loss: 0.691251, acc: 0.539062]: [A loss: 0.714332, acc: 0.351562]\n",
      "6184: [D loss: 0.700806, acc: 0.474609]: [A loss: 0.743241, acc: 0.191406]\n",
      "6185: [D loss: 0.694240, acc: 0.496094]: [A loss: 0.700931, acc: 0.417969]\n",
      "6186: [D loss: 0.701316, acc: 0.478516]: [A loss: 0.735458, acc: 0.250000]\n",
      "6187: [D loss: 0.695981, acc: 0.503906]: [A loss: 0.738881, acc: 0.238281]\n",
      "6188: [D loss: 0.701352, acc: 0.466797]: [A loss: 0.748964, acc: 0.171875]\n",
      "6189: [D loss: 0.695313, acc: 0.496094]: [A loss: 0.710747, acc: 0.351562]\n",
      "6190: [D loss: 0.692381, acc: 0.496094]: [A loss: 0.714087, acc: 0.371094]\n",
      "6191: [D loss: 0.695146, acc: 0.515625]: [A loss: 0.746766, acc: 0.156250]\n",
      "6192: [D loss: 0.695623, acc: 0.527344]: [A loss: 0.734340, acc: 0.230469]\n",
      "6193: [D loss: 0.694248, acc: 0.503906]: [A loss: 0.712321, acc: 0.375000]\n",
      "6194: [D loss: 0.697724, acc: 0.496094]: [A loss: 0.771816, acc: 0.109375]\n",
      "6195: [D loss: 0.693025, acc: 0.484375]: [A loss: 0.677302, acc: 0.582031]\n",
      "6196: [D loss: 0.698731, acc: 0.529297]: [A loss: 0.755721, acc: 0.156250]\n",
      "6197: [D loss: 0.700492, acc: 0.480469]: [A loss: 0.699149, acc: 0.441406]\n",
      "6198: [D loss: 0.695808, acc: 0.474609]: [A loss: 0.702622, acc: 0.433594]\n",
      "6199: [D loss: 0.693612, acc: 0.480469]: [A loss: 0.703890, acc: 0.406250]\n",
      "6200: [D loss: 0.699034, acc: 0.500000]: [A loss: 0.704149, acc: 0.394531]\n",
      "6201: [D loss: 0.693003, acc: 0.542969]: [A loss: 0.708149, acc: 0.351562]\n",
      "6202: [D loss: 0.693459, acc: 0.513672]: [A loss: 0.749323, acc: 0.191406]\n",
      "6203: [D loss: 0.696001, acc: 0.482422]: [A loss: 0.708556, acc: 0.351562]\n",
      "6204: [D loss: 0.699919, acc: 0.482422]: [A loss: 0.729909, acc: 0.250000]\n",
      "6205: [D loss: 0.689552, acc: 0.531250]: [A loss: 0.695828, acc: 0.445312]\n",
      "6206: [D loss: 0.698454, acc: 0.494141]: [A loss: 0.778047, acc: 0.089844]\n",
      "6207: [D loss: 0.693940, acc: 0.503906]: [A loss: 0.713353, acc: 0.343750]\n",
      "6208: [D loss: 0.702213, acc: 0.472656]: [A loss: 0.722489, acc: 0.316406]\n",
      "6209: [D loss: 0.692633, acc: 0.521484]: [A loss: 0.705335, acc: 0.394531]\n",
      "6210: [D loss: 0.696179, acc: 0.480469]: [A loss: 0.703202, acc: 0.433594]\n",
      "6211: [D loss: 0.694007, acc: 0.521484]: [A loss: 0.719738, acc: 0.332031]\n",
      "6212: [D loss: 0.692386, acc: 0.523438]: [A loss: 0.724988, acc: 0.296875]\n",
      "6213: [D loss: 0.697874, acc: 0.503906]: [A loss: 0.719499, acc: 0.308594]\n",
      "6214: [D loss: 0.692451, acc: 0.505859]: [A loss: 0.709099, acc: 0.390625]\n",
      "6215: [D loss: 0.696048, acc: 0.531250]: [A loss: 0.699777, acc: 0.468750]\n",
      "6216: [D loss: 0.696820, acc: 0.513672]: [A loss: 0.751162, acc: 0.148438]\n",
      "6217: [D loss: 0.690804, acc: 0.523438]: [A loss: 0.718948, acc: 0.304688]\n",
      "6218: [D loss: 0.698311, acc: 0.488281]: [A loss: 0.749818, acc: 0.152344]\n",
      "6219: [D loss: 0.692038, acc: 0.498047]: [A loss: 0.724385, acc: 0.285156]\n",
      "6220: [D loss: 0.694409, acc: 0.513672]: [A loss: 0.733942, acc: 0.250000]\n",
      "6221: [D loss: 0.693118, acc: 0.525391]: [A loss: 0.717867, acc: 0.324219]\n",
      "6222: [D loss: 0.697154, acc: 0.492188]: [A loss: 0.734367, acc: 0.257812]\n",
      "6223: [D loss: 0.695679, acc: 0.501953]: [A loss: 0.728691, acc: 0.250000]\n",
      "6224: [D loss: 0.697496, acc: 0.505859]: [A loss: 0.741145, acc: 0.210938]\n",
      "6225: [D loss: 0.693197, acc: 0.500000]: [A loss: 0.735591, acc: 0.242188]\n",
      "6226: [D loss: 0.696953, acc: 0.494141]: [A loss: 0.750804, acc: 0.156250]\n",
      "6227: [D loss: 0.697863, acc: 0.488281]: [A loss: 0.737105, acc: 0.203125]\n",
      "6228: [D loss: 0.696669, acc: 0.511719]: [A loss: 0.702239, acc: 0.414062]\n",
      "6229: [D loss: 0.697637, acc: 0.501953]: [A loss: 0.737317, acc: 0.226562]\n",
      "6230: [D loss: 0.695175, acc: 0.517578]: [A loss: 0.722252, acc: 0.312500]\n",
      "6231: [D loss: 0.696214, acc: 0.501953]: [A loss: 0.764681, acc: 0.105469]\n",
      "6232: [D loss: 0.691701, acc: 0.517578]: [A loss: 0.680094, acc: 0.601562]\n",
      "6233: [D loss: 0.701166, acc: 0.494141]: [A loss: 0.759962, acc: 0.113281]\n",
      "6234: [D loss: 0.696783, acc: 0.490234]: [A loss: 0.715717, acc: 0.351562]\n",
      "6235: [D loss: 0.698708, acc: 0.484375]: [A loss: 0.716676, acc: 0.316406]\n",
      "6236: [D loss: 0.696224, acc: 0.494141]: [A loss: 0.711412, acc: 0.339844]\n",
      "6237: [D loss: 0.696749, acc: 0.494141]: [A loss: 0.709305, acc: 0.402344]\n",
      "6238: [D loss: 0.698676, acc: 0.507812]: [A loss: 0.761352, acc: 0.136719]\n",
      "6239: [D loss: 0.695168, acc: 0.494141]: [A loss: 0.696429, acc: 0.472656]\n",
      "6240: [D loss: 0.696756, acc: 0.476562]: [A loss: 0.715696, acc: 0.308594]\n",
      "6241: [D loss: 0.696728, acc: 0.505859]: [A loss: 0.711890, acc: 0.343750]\n",
      "6242: [D loss: 0.700453, acc: 0.496094]: [A loss: 0.737945, acc: 0.183594]\n",
      "6243: [D loss: 0.693610, acc: 0.509766]: [A loss: 0.732925, acc: 0.234375]\n",
      "6244: [D loss: 0.694140, acc: 0.525391]: [A loss: 0.726809, acc: 0.269531]\n",
      "6245: [D loss: 0.698915, acc: 0.498047]: [A loss: 0.727109, acc: 0.269531]\n",
      "6246: [D loss: 0.694508, acc: 0.509766]: [A loss: 0.730878, acc: 0.261719]\n",
      "6247: [D loss: 0.694224, acc: 0.511719]: [A loss: 0.720963, acc: 0.308594]\n",
      "6248: [D loss: 0.697405, acc: 0.472656]: [A loss: 0.756304, acc: 0.144531]\n",
      "6249: [D loss: 0.693599, acc: 0.478516]: [A loss: 0.703101, acc: 0.433594]\n",
      "6250: [D loss: 0.698364, acc: 0.494141]: [A loss: 0.758532, acc: 0.089844]\n",
      "6251: [D loss: 0.692122, acc: 0.529297]: [A loss: 0.731483, acc: 0.238281]\n",
      "6252: [D loss: 0.694354, acc: 0.507812]: [A loss: 0.726942, acc: 0.300781]\n",
      "6253: [D loss: 0.694918, acc: 0.523438]: [A loss: 0.747958, acc: 0.207031]\n",
      "6254: [D loss: 0.690490, acc: 0.539062]: [A loss: 0.710526, acc: 0.421875]\n",
      "6255: [D loss: 0.695226, acc: 0.503906]: [A loss: 0.728863, acc: 0.273438]\n",
      "6256: [D loss: 0.692565, acc: 0.533203]: [A loss: 0.671979, acc: 0.628906]\n",
      "6257: [D loss: 0.700715, acc: 0.501953]: [A loss: 0.750565, acc: 0.156250]\n",
      "6258: [D loss: 0.691811, acc: 0.537109]: [A loss: 0.686588, acc: 0.488281]\n",
      "6259: [D loss: 0.700608, acc: 0.492188]: [A loss: 0.739798, acc: 0.187500]\n",
      "6260: [D loss: 0.697309, acc: 0.490234]: [A loss: 0.733312, acc: 0.199219]\n",
      "6261: [D loss: 0.695340, acc: 0.505859]: [A loss: 0.728645, acc: 0.265625]\n",
      "6262: [D loss: 0.699252, acc: 0.492188]: [A loss: 0.744608, acc: 0.164062]\n",
      "6263: [D loss: 0.694973, acc: 0.482422]: [A loss: 0.706808, acc: 0.390625]\n",
      "6264: [D loss: 0.692750, acc: 0.519531]: [A loss: 0.757159, acc: 0.148438]\n",
      "6265: [D loss: 0.692397, acc: 0.525391]: [A loss: 0.695988, acc: 0.464844]\n",
      "6266: [D loss: 0.700464, acc: 0.509766]: [A loss: 0.752320, acc: 0.148438]\n",
      "6267: [D loss: 0.696941, acc: 0.470703]: [A loss: 0.691825, acc: 0.515625]\n",
      "6268: [D loss: 0.702962, acc: 0.470703]: [A loss: 0.749798, acc: 0.179688]\n",
      "6269: [D loss: 0.690656, acc: 0.498047]: [A loss: 0.708202, acc: 0.406250]\n",
      "6270: [D loss: 0.696040, acc: 0.535156]: [A loss: 0.725303, acc: 0.265625]\n",
      "6271: [D loss: 0.699984, acc: 0.500000]: [A loss: 0.722900, acc: 0.289062]\n",
      "6272: [D loss: 0.699320, acc: 0.476562]: [A loss: 0.722272, acc: 0.292969]\n",
      "6273: [D loss: 0.694307, acc: 0.517578]: [A loss: 0.702052, acc: 0.445312]\n",
      "6274: [D loss: 0.700445, acc: 0.492188]: [A loss: 0.754047, acc: 0.140625]\n",
      "6275: [D loss: 0.691566, acc: 0.527344]: [A loss: 0.705244, acc: 0.402344]\n",
      "6276: [D loss: 0.704548, acc: 0.468750]: [A loss: 0.752999, acc: 0.160156]\n",
      "6277: [D loss: 0.694380, acc: 0.505859]: [A loss: 0.706324, acc: 0.363281]\n",
      "6278: [D loss: 0.700421, acc: 0.505859]: [A loss: 0.784444, acc: 0.058594]\n",
      "6279: [D loss: 0.692984, acc: 0.515625]: [A loss: 0.692333, acc: 0.492188]\n",
      "6280: [D loss: 0.702597, acc: 0.515625]: [A loss: 0.757192, acc: 0.144531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6281: [D loss: 0.694667, acc: 0.490234]: [A loss: 0.728665, acc: 0.308594]\n",
      "6282: [D loss: 0.697420, acc: 0.501953]: [A loss: 0.744424, acc: 0.164062]\n",
      "6283: [D loss: 0.691262, acc: 0.519531]: [A loss: 0.705938, acc: 0.390625]\n",
      "6284: [D loss: 0.693746, acc: 0.503906]: [A loss: 0.722650, acc: 0.281250]\n",
      "6285: [D loss: 0.697233, acc: 0.500000]: [A loss: 0.710669, acc: 0.359375]\n",
      "6286: [D loss: 0.693886, acc: 0.527344]: [A loss: 0.723200, acc: 0.269531]\n",
      "6287: [D loss: 0.694494, acc: 0.486328]: [A loss: 0.734275, acc: 0.218750]\n",
      "6288: [D loss: 0.698961, acc: 0.509766]: [A loss: 0.736229, acc: 0.203125]\n",
      "6289: [D loss: 0.697371, acc: 0.486328]: [A loss: 0.732140, acc: 0.234375]\n",
      "6290: [D loss: 0.694470, acc: 0.474609]: [A loss: 0.718063, acc: 0.335938]\n",
      "6291: [D loss: 0.693543, acc: 0.529297]: [A loss: 0.728899, acc: 0.238281]\n",
      "6292: [D loss: 0.701815, acc: 0.478516]: [A loss: 0.736748, acc: 0.199219]\n",
      "6293: [D loss: 0.694698, acc: 0.505859]: [A loss: 0.698654, acc: 0.441406]\n",
      "6294: [D loss: 0.695839, acc: 0.521484]: [A loss: 0.717677, acc: 0.328125]\n",
      "6295: [D loss: 0.698115, acc: 0.494141]: [A loss: 0.729616, acc: 0.230469]\n",
      "6296: [D loss: 0.694237, acc: 0.531250]: [A loss: 0.715340, acc: 0.339844]\n",
      "6297: [D loss: 0.693534, acc: 0.541016]: [A loss: 0.708190, acc: 0.363281]\n",
      "6298: [D loss: 0.697469, acc: 0.494141]: [A loss: 0.745258, acc: 0.207031]\n",
      "6299: [D loss: 0.693277, acc: 0.494141]: [A loss: 0.702168, acc: 0.441406]\n",
      "6300: [D loss: 0.701835, acc: 0.472656]: [A loss: 0.754154, acc: 0.109375]\n",
      "6301: [D loss: 0.694330, acc: 0.513672]: [A loss: 0.712730, acc: 0.363281]\n",
      "6302: [D loss: 0.695374, acc: 0.501953]: [A loss: 0.738068, acc: 0.195312]\n",
      "6303: [D loss: 0.693240, acc: 0.535156]: [A loss: 0.725430, acc: 0.273438]\n",
      "6304: [D loss: 0.697105, acc: 0.478516]: [A loss: 0.702990, acc: 0.414062]\n",
      "6305: [D loss: 0.694764, acc: 0.507812]: [A loss: 0.736537, acc: 0.191406]\n",
      "6306: [D loss: 0.692995, acc: 0.525391]: [A loss: 0.703316, acc: 0.406250]\n",
      "6307: [D loss: 0.693605, acc: 0.494141]: [A loss: 0.710519, acc: 0.324219]\n",
      "6308: [D loss: 0.692961, acc: 0.505859]: [A loss: 0.746011, acc: 0.156250]\n",
      "6309: [D loss: 0.695713, acc: 0.482422]: [A loss: 0.711501, acc: 0.355469]\n",
      "6310: [D loss: 0.692191, acc: 0.523438]: [A loss: 0.734843, acc: 0.246094]\n",
      "6311: [D loss: 0.699836, acc: 0.468750]: [A loss: 0.738204, acc: 0.183594]\n",
      "6312: [D loss: 0.693995, acc: 0.496094]: [A loss: 0.726736, acc: 0.214844]\n",
      "6313: [D loss: 0.697898, acc: 0.500000]: [A loss: 0.710956, acc: 0.347656]\n",
      "6314: [D loss: 0.697440, acc: 0.517578]: [A loss: 0.712935, acc: 0.363281]\n",
      "6315: [D loss: 0.694533, acc: 0.513672]: [A loss: 0.728731, acc: 0.246094]\n",
      "6316: [D loss: 0.695553, acc: 0.496094]: [A loss: 0.702477, acc: 0.406250]\n",
      "6317: [D loss: 0.698791, acc: 0.498047]: [A loss: 0.760716, acc: 0.093750]\n",
      "6318: [D loss: 0.689879, acc: 0.529297]: [A loss: 0.699406, acc: 0.472656]\n",
      "6319: [D loss: 0.695165, acc: 0.521484]: [A loss: 0.755611, acc: 0.167969]\n",
      "6320: [D loss: 0.698294, acc: 0.492188]: [A loss: 0.735906, acc: 0.242188]\n",
      "6321: [D loss: 0.689811, acc: 0.546875]: [A loss: 0.704172, acc: 0.437500]\n",
      "6322: [D loss: 0.694571, acc: 0.517578]: [A loss: 0.727977, acc: 0.265625]\n",
      "6323: [D loss: 0.699378, acc: 0.488281]: [A loss: 0.719333, acc: 0.308594]\n",
      "6324: [D loss: 0.695893, acc: 0.488281]: [A loss: 0.745313, acc: 0.210938]\n",
      "6325: [D loss: 0.696145, acc: 0.501953]: [A loss: 0.756992, acc: 0.136719]\n",
      "6326: [D loss: 0.695980, acc: 0.484375]: [A loss: 0.720627, acc: 0.289062]\n",
      "6327: [D loss: 0.696974, acc: 0.498047]: [A loss: 0.711997, acc: 0.375000]\n",
      "6328: [D loss: 0.697461, acc: 0.494141]: [A loss: 0.734307, acc: 0.210938]\n",
      "6329: [D loss: 0.688921, acc: 0.537109]: [A loss: 0.698562, acc: 0.417969]\n",
      "6330: [D loss: 0.695073, acc: 0.517578]: [A loss: 0.698524, acc: 0.429688]\n",
      "6331: [D loss: 0.702249, acc: 0.490234]: [A loss: 0.720162, acc: 0.265625]\n",
      "6332: [D loss: 0.696788, acc: 0.513672]: [A loss: 0.711602, acc: 0.347656]\n",
      "6333: [D loss: 0.700548, acc: 0.480469]: [A loss: 0.767998, acc: 0.093750]\n",
      "6334: [D loss: 0.692745, acc: 0.509766]: [A loss: 0.714072, acc: 0.328125]\n",
      "6335: [D loss: 0.695909, acc: 0.474609]: [A loss: 0.730866, acc: 0.238281]\n",
      "6336: [D loss: 0.693794, acc: 0.500000]: [A loss: 0.724409, acc: 0.304688]\n",
      "6337: [D loss: 0.692268, acc: 0.521484]: [A loss: 0.714067, acc: 0.339844]\n",
      "6338: [D loss: 0.692918, acc: 0.517578]: [A loss: 0.741757, acc: 0.171875]\n",
      "6339: [D loss: 0.697294, acc: 0.458984]: [A loss: 0.746115, acc: 0.183594]\n",
      "6340: [D loss: 0.690340, acc: 0.542969]: [A loss: 0.716619, acc: 0.351562]\n",
      "6341: [D loss: 0.695308, acc: 0.511719]: [A loss: 0.727677, acc: 0.308594]\n",
      "6342: [D loss: 0.694578, acc: 0.541016]: [A loss: 0.706927, acc: 0.406250]\n",
      "6343: [D loss: 0.696167, acc: 0.511719]: [A loss: 0.752509, acc: 0.144531]\n",
      "6344: [D loss: 0.689680, acc: 0.523438]: [A loss: 0.697995, acc: 0.480469]\n",
      "6345: [D loss: 0.700137, acc: 0.501953]: [A loss: 0.765936, acc: 0.128906]\n",
      "6346: [D loss: 0.699225, acc: 0.464844]: [A loss: 0.710003, acc: 0.402344]\n",
      "6347: [D loss: 0.701742, acc: 0.462891]: [A loss: 0.748940, acc: 0.152344]\n",
      "6348: [D loss: 0.691583, acc: 0.523438]: [A loss: 0.697220, acc: 0.449219]\n",
      "6349: [D loss: 0.700218, acc: 0.462891]: [A loss: 0.755239, acc: 0.148438]\n",
      "6350: [D loss: 0.697326, acc: 0.488281]: [A loss: 0.701406, acc: 0.472656]\n",
      "6351: [D loss: 0.695002, acc: 0.513672]: [A loss: 0.694356, acc: 0.472656]\n",
      "6352: [D loss: 0.700712, acc: 0.511719]: [A loss: 0.728451, acc: 0.250000]\n",
      "6353: [D loss: 0.694832, acc: 0.498047]: [A loss: 0.714333, acc: 0.355469]\n",
      "6354: [D loss: 0.698854, acc: 0.466797]: [A loss: 0.705622, acc: 0.402344]\n",
      "6355: [D loss: 0.702190, acc: 0.468750]: [A loss: 0.714454, acc: 0.343750]\n",
      "6356: [D loss: 0.693953, acc: 0.513672]: [A loss: 0.702469, acc: 0.398438]\n",
      "6357: [D loss: 0.700031, acc: 0.490234]: [A loss: 0.738465, acc: 0.203125]\n",
      "6358: [D loss: 0.697769, acc: 0.490234]: [A loss: 0.744101, acc: 0.203125]\n",
      "6359: [D loss: 0.694817, acc: 0.482422]: [A loss: 0.750763, acc: 0.187500]\n",
      "6360: [D loss: 0.695716, acc: 0.496094]: [A loss: 0.735742, acc: 0.234375]\n",
      "6361: [D loss: 0.696039, acc: 0.525391]: [A loss: 0.717567, acc: 0.328125]\n",
      "6362: [D loss: 0.693861, acc: 0.523438]: [A loss: 0.713076, acc: 0.312500]\n",
      "6363: [D loss: 0.691954, acc: 0.527344]: [A loss: 0.724220, acc: 0.304688]\n",
      "6364: [D loss: 0.696625, acc: 0.503906]: [A loss: 0.716324, acc: 0.328125]\n",
      "6365: [D loss: 0.693704, acc: 0.525391]: [A loss: 0.728287, acc: 0.269531]\n",
      "6366: [D loss: 0.693564, acc: 0.498047]: [A loss: 0.720937, acc: 0.296875]\n",
      "6367: [D loss: 0.691935, acc: 0.523438]: [A loss: 0.721067, acc: 0.296875]\n",
      "6368: [D loss: 0.691147, acc: 0.531250]: [A loss: 0.710236, acc: 0.375000]\n",
      "6369: [D loss: 0.696081, acc: 0.511719]: [A loss: 0.730611, acc: 0.250000]\n",
      "6370: [D loss: 0.693138, acc: 0.509766]: [A loss: 0.730057, acc: 0.242188]\n",
      "6371: [D loss: 0.695648, acc: 0.507812]: [A loss: 0.731811, acc: 0.230469]\n",
      "6372: [D loss: 0.696479, acc: 0.509766]: [A loss: 0.693194, acc: 0.476562]\n",
      "6373: [D loss: 0.695198, acc: 0.501953]: [A loss: 0.771236, acc: 0.085938]\n",
      "6374: [D loss: 0.694504, acc: 0.482422]: [A loss: 0.683513, acc: 0.531250]\n",
      "6375: [D loss: 0.702305, acc: 0.472656]: [A loss: 0.747508, acc: 0.148438]\n",
      "6376: [D loss: 0.694148, acc: 0.494141]: [A loss: 0.716660, acc: 0.343750]\n",
      "6377: [D loss: 0.693957, acc: 0.492188]: [A loss: 0.721506, acc: 0.320312]\n",
      "6378: [D loss: 0.698179, acc: 0.494141]: [A loss: 0.732111, acc: 0.238281]\n",
      "6379: [D loss: 0.691120, acc: 0.523438]: [A loss: 0.710879, acc: 0.367188]\n",
      "6380: [D loss: 0.697890, acc: 0.494141]: [A loss: 0.743369, acc: 0.183594]\n",
      "6381: [D loss: 0.698102, acc: 0.470703]: [A loss: 0.710483, acc: 0.406250]\n",
      "6382: [D loss: 0.694429, acc: 0.496094]: [A loss: 0.731248, acc: 0.222656]\n",
      "6383: [D loss: 0.700274, acc: 0.470703]: [A loss: 0.734016, acc: 0.242188]\n",
      "6384: [D loss: 0.694136, acc: 0.500000]: [A loss: 0.735554, acc: 0.207031]\n",
      "6385: [D loss: 0.695719, acc: 0.500000]: [A loss: 0.729346, acc: 0.261719]\n",
      "6386: [D loss: 0.697847, acc: 0.476562]: [A loss: 0.761385, acc: 0.144531]\n",
      "6387: [D loss: 0.695403, acc: 0.496094]: [A loss: 0.704923, acc: 0.421875]\n",
      "6388: [D loss: 0.695762, acc: 0.507812]: [A loss: 0.702279, acc: 0.414062]\n",
      "6389: [D loss: 0.701631, acc: 0.507812]: [A loss: 0.752168, acc: 0.109375]\n",
      "6390: [D loss: 0.692562, acc: 0.515625]: [A loss: 0.704227, acc: 0.414062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6391: [D loss: 0.701486, acc: 0.484375]: [A loss: 0.735399, acc: 0.218750]\n",
      "6392: [D loss: 0.694090, acc: 0.503906]: [A loss: 0.708106, acc: 0.402344]\n",
      "6393: [D loss: 0.688092, acc: 0.515625]: [A loss: 0.746064, acc: 0.160156]\n",
      "6394: [D loss: 0.697915, acc: 0.482422]: [A loss: 0.728198, acc: 0.261719]\n",
      "6395: [D loss: 0.694720, acc: 0.511719]: [A loss: 0.740053, acc: 0.207031]\n",
      "6396: [D loss: 0.692876, acc: 0.494141]: [A loss: 0.714203, acc: 0.343750]\n",
      "6397: [D loss: 0.690270, acc: 0.527344]: [A loss: 0.735857, acc: 0.250000]\n",
      "6398: [D loss: 0.696806, acc: 0.515625]: [A loss: 0.703904, acc: 0.425781]\n",
      "6399: [D loss: 0.694286, acc: 0.511719]: [A loss: 0.719992, acc: 0.328125]\n",
      "6400: [D loss: 0.696840, acc: 0.511719]: [A loss: 0.746008, acc: 0.191406]\n",
      "6401: [D loss: 0.698610, acc: 0.492188]: [A loss: 0.733968, acc: 0.242188]\n",
      "6402: [D loss: 0.689048, acc: 0.529297]: [A loss: 0.712111, acc: 0.414062]\n",
      "6403: [D loss: 0.698119, acc: 0.501953]: [A loss: 0.753166, acc: 0.160156]\n",
      "6404: [D loss: 0.690627, acc: 0.523438]: [A loss: 0.700365, acc: 0.437500]\n",
      "6405: [D loss: 0.696333, acc: 0.533203]: [A loss: 0.764643, acc: 0.105469]\n",
      "6406: [D loss: 0.689944, acc: 0.535156]: [A loss: 0.681687, acc: 0.570312]\n",
      "6407: [D loss: 0.696719, acc: 0.492188]: [A loss: 0.742359, acc: 0.199219]\n",
      "6408: [D loss: 0.693488, acc: 0.484375]: [A loss: 0.714403, acc: 0.324219]\n",
      "6409: [D loss: 0.699673, acc: 0.501953]: [A loss: 0.750969, acc: 0.113281]\n",
      "6410: [D loss: 0.696104, acc: 0.488281]: [A loss: 0.720089, acc: 0.312500]\n",
      "6411: [D loss: 0.693935, acc: 0.509766]: [A loss: 0.711263, acc: 0.332031]\n",
      "6412: [D loss: 0.692471, acc: 0.523438]: [A loss: 0.726167, acc: 0.261719]\n",
      "6413: [D loss: 0.691948, acc: 0.531250]: [A loss: 0.681476, acc: 0.546875]\n",
      "6414: [D loss: 0.699928, acc: 0.496094]: [A loss: 0.754934, acc: 0.125000]\n",
      "6415: [D loss: 0.686770, acc: 0.562500]: [A loss: 0.684308, acc: 0.582031]\n",
      "6416: [D loss: 0.703294, acc: 0.494141]: [A loss: 0.753230, acc: 0.128906]\n",
      "6417: [D loss: 0.696223, acc: 0.488281]: [A loss: 0.737919, acc: 0.199219]\n",
      "6418: [D loss: 0.696635, acc: 0.486328]: [A loss: 0.720809, acc: 0.281250]\n",
      "6419: [D loss: 0.695754, acc: 0.500000]: [A loss: 0.730836, acc: 0.246094]\n",
      "6420: [D loss: 0.696221, acc: 0.505859]: [A loss: 0.725163, acc: 0.277344]\n",
      "6421: [D loss: 0.697808, acc: 0.509766]: [A loss: 0.710626, acc: 0.421875]\n",
      "6422: [D loss: 0.696743, acc: 0.523438]: [A loss: 0.733794, acc: 0.234375]\n",
      "6423: [D loss: 0.693992, acc: 0.501953]: [A loss: 0.744831, acc: 0.199219]\n",
      "6424: [D loss: 0.694795, acc: 0.505859]: [A loss: 0.730755, acc: 0.277344]\n",
      "6425: [D loss: 0.698024, acc: 0.519531]: [A loss: 0.761549, acc: 0.132812]\n",
      "6426: [D loss: 0.689939, acc: 0.539062]: [A loss: 0.700141, acc: 0.398438]\n",
      "6427: [D loss: 0.693590, acc: 0.513672]: [A loss: 0.747163, acc: 0.136719]\n",
      "6428: [D loss: 0.692315, acc: 0.505859]: [A loss: 0.713668, acc: 0.339844]\n",
      "6429: [D loss: 0.695856, acc: 0.490234]: [A loss: 0.761204, acc: 0.113281]\n",
      "6430: [D loss: 0.694251, acc: 0.492188]: [A loss: 0.705172, acc: 0.414062]\n",
      "6431: [D loss: 0.699773, acc: 0.470703]: [A loss: 0.770486, acc: 0.109375]\n",
      "6432: [D loss: 0.699775, acc: 0.474609]: [A loss: 0.724384, acc: 0.296875]\n",
      "6433: [D loss: 0.696541, acc: 0.521484]: [A loss: 0.745795, acc: 0.191406]\n",
      "6434: [D loss: 0.691273, acc: 0.533203]: [A loss: 0.717505, acc: 0.343750]\n",
      "6435: [D loss: 0.693814, acc: 0.498047]: [A loss: 0.726319, acc: 0.289062]\n",
      "6436: [D loss: 0.689748, acc: 0.544922]: [A loss: 0.737264, acc: 0.203125]\n",
      "6437: [D loss: 0.692231, acc: 0.529297]: [A loss: 0.740920, acc: 0.195312]\n",
      "6438: [D loss: 0.689077, acc: 0.531250]: [A loss: 0.713036, acc: 0.355469]\n",
      "6439: [D loss: 0.692377, acc: 0.523438]: [A loss: 0.721817, acc: 0.339844]\n",
      "6440: [D loss: 0.697555, acc: 0.484375]: [A loss: 0.740865, acc: 0.195312]\n",
      "6441: [D loss: 0.692854, acc: 0.505859]: [A loss: 0.697054, acc: 0.449219]\n",
      "6442: [D loss: 0.689601, acc: 0.544922]: [A loss: 0.722214, acc: 0.347656]\n",
      "6443: [D loss: 0.700194, acc: 0.490234]: [A loss: 0.791208, acc: 0.058594]\n",
      "6444: [D loss: 0.695719, acc: 0.486328]: [A loss: 0.720092, acc: 0.308594]\n",
      "6445: [D loss: 0.694129, acc: 0.503906]: [A loss: 0.747232, acc: 0.179688]\n",
      "6446: [D loss: 0.690939, acc: 0.548828]: [A loss: 0.704537, acc: 0.378906]\n",
      "6447: [D loss: 0.695393, acc: 0.484375]: [A loss: 0.728170, acc: 0.281250]\n",
      "6448: [D loss: 0.696380, acc: 0.513672]: [A loss: 0.715853, acc: 0.343750]\n",
      "6449: [D loss: 0.695365, acc: 0.505859]: [A loss: 0.715744, acc: 0.335938]\n",
      "6450: [D loss: 0.700932, acc: 0.486328]: [A loss: 0.727405, acc: 0.238281]\n",
      "6451: [D loss: 0.694100, acc: 0.484375]: [A loss: 0.704465, acc: 0.437500]\n",
      "6452: [D loss: 0.694611, acc: 0.533203]: [A loss: 0.720114, acc: 0.351562]\n",
      "6453: [D loss: 0.693443, acc: 0.542969]: [A loss: 0.740829, acc: 0.261719]\n",
      "6454: [D loss: 0.690505, acc: 0.537109]: [A loss: 0.686844, acc: 0.539062]\n",
      "6455: [D loss: 0.698878, acc: 0.496094]: [A loss: 0.766584, acc: 0.109375]\n",
      "6456: [D loss: 0.694120, acc: 0.517578]: [A loss: 0.707213, acc: 0.410156]\n",
      "6457: [D loss: 0.696410, acc: 0.503906]: [A loss: 0.765531, acc: 0.125000]\n",
      "6458: [D loss: 0.692091, acc: 0.517578]: [A loss: 0.700874, acc: 0.445312]\n",
      "6459: [D loss: 0.695410, acc: 0.507812]: [A loss: 0.725780, acc: 0.292969]\n",
      "6460: [D loss: 0.700195, acc: 0.482422]: [A loss: 0.744733, acc: 0.187500]\n",
      "6461: [D loss: 0.692143, acc: 0.527344]: [A loss: 0.703874, acc: 0.441406]\n",
      "6462: [D loss: 0.693676, acc: 0.501953]: [A loss: 0.734403, acc: 0.218750]\n",
      "6463: [D loss: 0.695094, acc: 0.513672]: [A loss: 0.725056, acc: 0.230469]\n",
      "6464: [D loss: 0.692694, acc: 0.488281]: [A loss: 0.739237, acc: 0.218750]\n",
      "6465: [D loss: 0.696045, acc: 0.507812]: [A loss: 0.730657, acc: 0.238281]\n",
      "6466: [D loss: 0.697962, acc: 0.519531]: [A loss: 0.769229, acc: 0.101562]\n",
      "6467: [D loss: 0.692087, acc: 0.492188]: [A loss: 0.685259, acc: 0.531250]\n",
      "6468: [D loss: 0.702301, acc: 0.501953]: [A loss: 0.745865, acc: 0.210938]\n",
      "6469: [D loss: 0.695171, acc: 0.474609]: [A loss: 0.715241, acc: 0.359375]\n",
      "6470: [D loss: 0.703859, acc: 0.468750]: [A loss: 0.768150, acc: 0.093750]\n",
      "6471: [D loss: 0.694072, acc: 0.505859]: [A loss: 0.701063, acc: 0.425781]\n",
      "6472: [D loss: 0.700744, acc: 0.498047]: [A loss: 0.744542, acc: 0.183594]\n",
      "6473: [D loss: 0.691317, acc: 0.503906]: [A loss: 0.694616, acc: 0.500000]\n",
      "6474: [D loss: 0.701787, acc: 0.492188]: [A loss: 0.760082, acc: 0.136719]\n",
      "6475: [D loss: 0.692760, acc: 0.494141]: [A loss: 0.713111, acc: 0.375000]\n",
      "6476: [D loss: 0.692436, acc: 0.519531]: [A loss: 0.716972, acc: 0.359375]\n",
      "6477: [D loss: 0.688296, acc: 0.521484]: [A loss: 0.723058, acc: 0.335938]\n",
      "6478: [D loss: 0.694434, acc: 0.531250]: [A loss: 0.731940, acc: 0.269531]\n",
      "6479: [D loss: 0.693267, acc: 0.527344]: [A loss: 0.712932, acc: 0.398438]\n",
      "6480: [D loss: 0.691954, acc: 0.505859]: [A loss: 0.769750, acc: 0.128906]\n",
      "6481: [D loss: 0.690197, acc: 0.542969]: [A loss: 0.704573, acc: 0.390625]\n",
      "6482: [D loss: 0.689537, acc: 0.531250]: [A loss: 0.740476, acc: 0.207031]\n",
      "6483: [D loss: 0.687833, acc: 0.525391]: [A loss: 0.694774, acc: 0.453125]\n",
      "6484: [D loss: 0.697749, acc: 0.492188]: [A loss: 0.778557, acc: 0.101562]\n",
      "6485: [D loss: 0.695365, acc: 0.486328]: [A loss: 0.683361, acc: 0.519531]\n",
      "6486: [D loss: 0.699296, acc: 0.500000]: [A loss: 0.774226, acc: 0.105469]\n",
      "6487: [D loss: 0.693510, acc: 0.507812]: [A loss: 0.719214, acc: 0.328125]\n",
      "6488: [D loss: 0.698635, acc: 0.511719]: [A loss: 0.712902, acc: 0.339844]\n",
      "6489: [D loss: 0.692605, acc: 0.521484]: [A loss: 0.709936, acc: 0.378906]\n",
      "6490: [D loss: 0.699668, acc: 0.480469]: [A loss: 0.714357, acc: 0.363281]\n",
      "6491: [D loss: 0.699257, acc: 0.507812]: [A loss: 0.715507, acc: 0.332031]\n",
      "6492: [D loss: 0.700377, acc: 0.488281]: [A loss: 0.765358, acc: 0.109375]\n",
      "6493: [D loss: 0.692021, acc: 0.509766]: [A loss: 0.712242, acc: 0.328125]\n",
      "6494: [D loss: 0.699402, acc: 0.503906]: [A loss: 0.745525, acc: 0.167969]\n",
      "6495: [D loss: 0.693479, acc: 0.527344]: [A loss: 0.705826, acc: 0.402344]\n",
      "6496: [D loss: 0.694086, acc: 0.523438]: [A loss: 0.733391, acc: 0.246094]\n",
      "6497: [D loss: 0.689834, acc: 0.554688]: [A loss: 0.738267, acc: 0.238281]\n",
      "6498: [D loss: 0.693381, acc: 0.503906]: [A loss: 0.714080, acc: 0.335938]\n",
      "6499: [D loss: 0.687451, acc: 0.542969]: [A loss: 0.702401, acc: 0.429688]\n",
      "6500: [D loss: 0.702104, acc: 0.498047]: [A loss: 0.817229, acc: 0.027344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6501: [D loss: 0.693636, acc: 0.533203]: [A loss: 0.683256, acc: 0.562500]\n",
      "6502: [D loss: 0.702991, acc: 0.482422]: [A loss: 0.745550, acc: 0.199219]\n",
      "6503: [D loss: 0.696441, acc: 0.496094]: [A loss: 0.696929, acc: 0.492188]\n",
      "6504: [D loss: 0.693714, acc: 0.503906]: [A loss: 0.717856, acc: 0.324219]\n",
      "6505: [D loss: 0.694046, acc: 0.513672]: [A loss: 0.727534, acc: 0.238281]\n",
      "6506: [D loss: 0.692322, acc: 0.505859]: [A loss: 0.708246, acc: 0.398438]\n",
      "6507: [D loss: 0.689600, acc: 0.525391]: [A loss: 0.702474, acc: 0.425781]\n",
      "6508: [D loss: 0.694980, acc: 0.505859]: [A loss: 0.735366, acc: 0.214844]\n",
      "6509: [D loss: 0.694020, acc: 0.498047]: [A loss: 0.715282, acc: 0.359375]\n",
      "6510: [D loss: 0.701869, acc: 0.490234]: [A loss: 0.744139, acc: 0.175781]\n",
      "6511: [D loss: 0.694879, acc: 0.505859]: [A loss: 0.741504, acc: 0.234375]\n",
      "6512: [D loss: 0.688671, acc: 0.541016]: [A loss: 0.724312, acc: 0.285156]\n",
      "6513: [D loss: 0.691230, acc: 0.501953]: [A loss: 0.719790, acc: 0.312500]\n",
      "6514: [D loss: 0.696202, acc: 0.525391]: [A loss: 0.737799, acc: 0.277344]\n",
      "6515: [D loss: 0.691338, acc: 0.511719]: [A loss: 0.715847, acc: 0.351562]\n",
      "6516: [D loss: 0.697741, acc: 0.513672]: [A loss: 0.713869, acc: 0.371094]\n",
      "6517: [D loss: 0.699050, acc: 0.478516]: [A loss: 0.714136, acc: 0.359375]\n",
      "6518: [D loss: 0.700630, acc: 0.490234]: [A loss: 0.735995, acc: 0.277344]\n",
      "6519: [D loss: 0.695830, acc: 0.498047]: [A loss: 0.778207, acc: 0.128906]\n",
      "6520: [D loss: 0.696793, acc: 0.488281]: [A loss: 0.752721, acc: 0.195312]\n",
      "6521: [D loss: 0.701290, acc: 0.480469]: [A loss: 0.727198, acc: 0.246094]\n",
      "6522: [D loss: 0.701713, acc: 0.494141]: [A loss: 0.766784, acc: 0.113281]\n",
      "6523: [D loss: 0.697030, acc: 0.503906]: [A loss: 0.711555, acc: 0.375000]\n",
      "6524: [D loss: 0.694383, acc: 0.492188]: [A loss: 0.733411, acc: 0.269531]\n",
      "6525: [D loss: 0.702473, acc: 0.474609]: [A loss: 0.779707, acc: 0.089844]\n",
      "6526: [D loss: 0.697920, acc: 0.500000]: [A loss: 0.730572, acc: 0.246094]\n",
      "6527: [D loss: 0.699999, acc: 0.480469]: [A loss: 0.742429, acc: 0.207031]\n",
      "6528: [D loss: 0.694567, acc: 0.492188]: [A loss: 0.716176, acc: 0.355469]\n",
      "6529: [D loss: 0.700029, acc: 0.498047]: [A loss: 0.721695, acc: 0.289062]\n",
      "6530: [D loss: 0.698384, acc: 0.472656]: [A loss: 0.689889, acc: 0.496094]\n",
      "6531: [D loss: 0.694133, acc: 0.519531]: [A loss: 0.724215, acc: 0.281250]\n",
      "6532: [D loss: 0.699172, acc: 0.484375]: [A loss: 0.745295, acc: 0.218750]\n",
      "6533: [D loss: 0.695259, acc: 0.490234]: [A loss: 0.714082, acc: 0.335938]\n",
      "6534: [D loss: 0.697049, acc: 0.486328]: [A loss: 0.748916, acc: 0.195312]\n",
      "6535: [D loss: 0.695121, acc: 0.505859]: [A loss: 0.698366, acc: 0.457031]\n",
      "6536: [D loss: 0.694829, acc: 0.480469]: [A loss: 0.736996, acc: 0.226562]\n",
      "6537: [D loss: 0.694259, acc: 0.509766]: [A loss: 0.719368, acc: 0.304688]\n",
      "6538: [D loss: 0.695277, acc: 0.509766]: [A loss: 0.719524, acc: 0.296875]\n",
      "6539: [D loss: 0.694510, acc: 0.501953]: [A loss: 0.736596, acc: 0.226562]\n",
      "6540: [D loss: 0.692432, acc: 0.554688]: [A loss: 0.744688, acc: 0.222656]\n",
      "6541: [D loss: 0.694614, acc: 0.507812]: [A loss: 0.704641, acc: 0.386719]\n",
      "6542: [D loss: 0.694108, acc: 0.503906]: [A loss: 0.756035, acc: 0.160156]\n",
      "6543: [D loss: 0.699140, acc: 0.476562]: [A loss: 0.722623, acc: 0.316406]\n",
      "6544: [D loss: 0.694587, acc: 0.498047]: [A loss: 0.737391, acc: 0.203125]\n",
      "6545: [D loss: 0.695336, acc: 0.496094]: [A loss: 0.695003, acc: 0.472656]\n",
      "6546: [D loss: 0.701320, acc: 0.486328]: [A loss: 0.730215, acc: 0.246094]\n",
      "6547: [D loss: 0.695490, acc: 0.517578]: [A loss: 0.710848, acc: 0.371094]\n",
      "6548: [D loss: 0.702313, acc: 0.488281]: [A loss: 0.714473, acc: 0.363281]\n",
      "6549: [D loss: 0.699459, acc: 0.486328]: [A loss: 0.728899, acc: 0.238281]\n",
      "6550: [D loss: 0.692045, acc: 0.529297]: [A loss: 0.708448, acc: 0.378906]\n",
      "6551: [D loss: 0.697431, acc: 0.490234]: [A loss: 0.727056, acc: 0.261719]\n",
      "6552: [D loss: 0.695055, acc: 0.500000]: [A loss: 0.708342, acc: 0.421875]\n",
      "6553: [D loss: 0.696937, acc: 0.533203]: [A loss: 0.785847, acc: 0.042969]\n",
      "6554: [D loss: 0.689718, acc: 0.517578]: [A loss: 0.700812, acc: 0.433594]\n",
      "6555: [D loss: 0.697819, acc: 0.507812]: [A loss: 0.699672, acc: 0.472656]\n",
      "6556: [D loss: 0.700260, acc: 0.482422]: [A loss: 0.749203, acc: 0.156250]\n",
      "6557: [D loss: 0.691004, acc: 0.517578]: [A loss: 0.705991, acc: 0.390625]\n",
      "6558: [D loss: 0.701418, acc: 0.505859]: [A loss: 0.724544, acc: 0.285156]\n",
      "6559: [D loss: 0.693370, acc: 0.496094]: [A loss: 0.707590, acc: 0.382812]\n",
      "6560: [D loss: 0.696448, acc: 0.515625]: [A loss: 0.717739, acc: 0.347656]\n",
      "6561: [D loss: 0.700350, acc: 0.472656]: [A loss: 0.739330, acc: 0.207031]\n",
      "6562: [D loss: 0.698370, acc: 0.470703]: [A loss: 0.729324, acc: 0.253906]\n",
      "6563: [D loss: 0.693258, acc: 0.500000]: [A loss: 0.722954, acc: 0.312500]\n",
      "6564: [D loss: 0.695622, acc: 0.503906]: [A loss: 0.746525, acc: 0.210938]\n",
      "6565: [D loss: 0.697577, acc: 0.492188]: [A loss: 0.751059, acc: 0.167969]\n",
      "6566: [D loss: 0.695690, acc: 0.501953]: [A loss: 0.742123, acc: 0.195312]\n",
      "6567: [D loss: 0.690648, acc: 0.548828]: [A loss: 0.693594, acc: 0.476562]\n",
      "6568: [D loss: 0.700369, acc: 0.498047]: [A loss: 0.757196, acc: 0.148438]\n",
      "6569: [D loss: 0.694578, acc: 0.500000]: [A loss: 0.705014, acc: 0.414062]\n",
      "6570: [D loss: 0.698768, acc: 0.492188]: [A loss: 0.734911, acc: 0.261719]\n",
      "6571: [D loss: 0.692772, acc: 0.509766]: [A loss: 0.715338, acc: 0.355469]\n",
      "6572: [D loss: 0.695730, acc: 0.513672]: [A loss: 0.700920, acc: 0.421875]\n",
      "6573: [D loss: 0.704709, acc: 0.498047]: [A loss: 0.783780, acc: 0.058594]\n",
      "6574: [D loss: 0.693880, acc: 0.509766]: [A loss: 0.689896, acc: 0.480469]\n",
      "6575: [D loss: 0.692623, acc: 0.521484]: [A loss: 0.732870, acc: 0.238281]\n",
      "6576: [D loss: 0.691557, acc: 0.515625]: [A loss: 0.719522, acc: 0.285156]\n",
      "6577: [D loss: 0.696655, acc: 0.509766]: [A loss: 0.716849, acc: 0.328125]\n",
      "6578: [D loss: 0.691599, acc: 0.542969]: [A loss: 0.713720, acc: 0.375000]\n",
      "6579: [D loss: 0.700679, acc: 0.492188]: [A loss: 0.731956, acc: 0.230469]\n",
      "6580: [D loss: 0.698511, acc: 0.492188]: [A loss: 0.715604, acc: 0.351562]\n",
      "6581: [D loss: 0.694138, acc: 0.523438]: [A loss: 0.722457, acc: 0.292969]\n",
      "6582: [D loss: 0.693763, acc: 0.523438]: [A loss: 0.721986, acc: 0.308594]\n",
      "6583: [D loss: 0.693691, acc: 0.523438]: [A loss: 0.744087, acc: 0.199219]\n",
      "6584: [D loss: 0.694574, acc: 0.505859]: [A loss: 0.725247, acc: 0.269531]\n",
      "6585: [D loss: 0.696462, acc: 0.500000]: [A loss: 0.719515, acc: 0.277344]\n",
      "6586: [D loss: 0.692654, acc: 0.525391]: [A loss: 0.689975, acc: 0.503906]\n",
      "6587: [D loss: 0.696596, acc: 0.505859]: [A loss: 0.774336, acc: 0.089844]\n",
      "6588: [D loss: 0.694676, acc: 0.490234]: [A loss: 0.723427, acc: 0.332031]\n",
      "6589: [D loss: 0.691420, acc: 0.525391]: [A loss: 0.697148, acc: 0.429688]\n",
      "6590: [D loss: 0.692502, acc: 0.521484]: [A loss: 0.746006, acc: 0.230469]\n",
      "6591: [D loss: 0.700890, acc: 0.460938]: [A loss: 0.726329, acc: 0.304688]\n",
      "6592: [D loss: 0.702905, acc: 0.482422]: [A loss: 0.774624, acc: 0.089844]\n",
      "6593: [D loss: 0.696849, acc: 0.474609]: [A loss: 0.703516, acc: 0.410156]\n",
      "6594: [D loss: 0.703032, acc: 0.462891]: [A loss: 0.725347, acc: 0.261719]\n",
      "6595: [D loss: 0.695043, acc: 0.482422]: [A loss: 0.724400, acc: 0.261719]\n",
      "6596: [D loss: 0.700904, acc: 0.492188]: [A loss: 0.716722, acc: 0.296875]\n",
      "6597: [D loss: 0.695845, acc: 0.507812]: [A loss: 0.729421, acc: 0.281250]\n",
      "6598: [D loss: 0.696300, acc: 0.501953]: [A loss: 0.722298, acc: 0.289062]\n",
      "6599: [D loss: 0.695823, acc: 0.486328]: [A loss: 0.726960, acc: 0.285156]\n",
      "6600: [D loss: 0.698775, acc: 0.500000]: [A loss: 0.745514, acc: 0.226562]\n",
      "6601: [D loss: 0.696307, acc: 0.501953]: [A loss: 0.752743, acc: 0.183594]\n",
      "6602: [D loss: 0.697546, acc: 0.494141]: [A loss: 0.705945, acc: 0.386719]\n",
      "6603: [D loss: 0.698701, acc: 0.476562]: [A loss: 0.744040, acc: 0.171875]\n",
      "6604: [D loss: 0.693374, acc: 0.527344]: [A loss: 0.731463, acc: 0.277344]\n",
      "6605: [D loss: 0.697491, acc: 0.488281]: [A loss: 0.732032, acc: 0.253906]\n",
      "6606: [D loss: 0.696292, acc: 0.509766]: [A loss: 0.732154, acc: 0.277344]\n",
      "6607: [D loss: 0.691928, acc: 0.521484]: [A loss: 0.736967, acc: 0.214844]\n",
      "6608: [D loss: 0.695459, acc: 0.501953]: [A loss: 0.697171, acc: 0.437500]\n",
      "6609: [D loss: 0.695730, acc: 0.515625]: [A loss: 0.736280, acc: 0.230469]\n",
      "6610: [D loss: 0.694805, acc: 0.484375]: [A loss: 0.708110, acc: 0.371094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6611: [D loss: 0.698199, acc: 0.501953]: [A loss: 0.761084, acc: 0.144531]\n",
      "6612: [D loss: 0.697111, acc: 0.492188]: [A loss: 0.730548, acc: 0.238281]\n",
      "6613: [D loss: 0.691168, acc: 0.546875]: [A loss: 0.710969, acc: 0.390625]\n",
      "6614: [D loss: 0.704699, acc: 0.470703]: [A loss: 0.758271, acc: 0.125000]\n",
      "6615: [D loss: 0.692279, acc: 0.542969]: [A loss: 0.733628, acc: 0.226562]\n",
      "6616: [D loss: 0.700874, acc: 0.460938]: [A loss: 0.753754, acc: 0.148438]\n",
      "6617: [D loss: 0.694507, acc: 0.488281]: [A loss: 0.704367, acc: 0.402344]\n",
      "6618: [D loss: 0.699113, acc: 0.498047]: [A loss: 0.744593, acc: 0.152344]\n",
      "6619: [D loss: 0.692009, acc: 0.521484]: [A loss: 0.696075, acc: 0.476562]\n",
      "6620: [D loss: 0.704676, acc: 0.482422]: [A loss: 0.774733, acc: 0.078125]\n",
      "6621: [D loss: 0.694987, acc: 0.509766]: [A loss: 0.713033, acc: 0.363281]\n",
      "6622: [D loss: 0.695426, acc: 0.515625]: [A loss: 0.737736, acc: 0.214844]\n",
      "6623: [D loss: 0.697612, acc: 0.482422]: [A loss: 0.731486, acc: 0.226562]\n",
      "6624: [D loss: 0.697610, acc: 0.501953]: [A loss: 0.725619, acc: 0.261719]\n",
      "6625: [D loss: 0.700979, acc: 0.482422]: [A loss: 0.746330, acc: 0.164062]\n",
      "6626: [D loss: 0.692915, acc: 0.513672]: [A loss: 0.700966, acc: 0.421875]\n",
      "6627: [D loss: 0.697245, acc: 0.511719]: [A loss: 0.734435, acc: 0.238281]\n",
      "6628: [D loss: 0.692173, acc: 0.501953]: [A loss: 0.718578, acc: 0.312500]\n",
      "6629: [D loss: 0.698520, acc: 0.480469]: [A loss: 0.738947, acc: 0.167969]\n",
      "6630: [D loss: 0.695522, acc: 0.492188]: [A loss: 0.715550, acc: 0.339844]\n",
      "6631: [D loss: 0.701128, acc: 0.488281]: [A loss: 0.763682, acc: 0.105469]\n",
      "6632: [D loss: 0.694828, acc: 0.498047]: [A loss: 0.721300, acc: 0.300781]\n",
      "6633: [D loss: 0.700137, acc: 0.470703]: [A loss: 0.778951, acc: 0.054688]\n",
      "6634: [D loss: 0.695533, acc: 0.484375]: [A loss: 0.690859, acc: 0.457031]\n",
      "6635: [D loss: 0.700191, acc: 0.496094]: [A loss: 0.737517, acc: 0.210938]\n",
      "6636: [D loss: 0.696075, acc: 0.476562]: [A loss: 0.725951, acc: 0.246094]\n",
      "6637: [D loss: 0.697373, acc: 0.490234]: [A loss: 0.718126, acc: 0.335938]\n",
      "6638: [D loss: 0.694324, acc: 0.531250]: [A loss: 0.736585, acc: 0.179688]\n",
      "6639: [D loss: 0.693480, acc: 0.515625]: [A loss: 0.694315, acc: 0.488281]\n",
      "6640: [D loss: 0.703052, acc: 0.496094]: [A loss: 0.775901, acc: 0.042969]\n",
      "6641: [D loss: 0.697454, acc: 0.492188]: [A loss: 0.713376, acc: 0.335938]\n",
      "6642: [D loss: 0.695765, acc: 0.501953]: [A loss: 0.724337, acc: 0.281250]\n",
      "6643: [D loss: 0.694439, acc: 0.525391]: [A loss: 0.725483, acc: 0.277344]\n",
      "6644: [D loss: 0.698309, acc: 0.486328]: [A loss: 0.721734, acc: 0.308594]\n",
      "6645: [D loss: 0.697347, acc: 0.480469]: [A loss: 0.729930, acc: 0.242188]\n",
      "6646: [D loss: 0.693969, acc: 0.509766]: [A loss: 0.706347, acc: 0.371094]\n",
      "6647: [D loss: 0.695074, acc: 0.515625]: [A loss: 0.746794, acc: 0.148438]\n",
      "6648: [D loss: 0.695911, acc: 0.519531]: [A loss: 0.692915, acc: 0.441406]\n",
      "6649: [D loss: 0.696317, acc: 0.509766]: [A loss: 0.745121, acc: 0.167969]\n",
      "6650: [D loss: 0.696542, acc: 0.501953]: [A loss: 0.715521, acc: 0.363281]\n",
      "6651: [D loss: 0.698810, acc: 0.484375]: [A loss: 0.708718, acc: 0.367188]\n",
      "6652: [D loss: 0.701074, acc: 0.476562]: [A loss: 0.733245, acc: 0.250000]\n",
      "6653: [D loss: 0.697283, acc: 0.480469]: [A loss: 0.712842, acc: 0.304688]\n",
      "6654: [D loss: 0.697894, acc: 0.496094]: [A loss: 0.714096, acc: 0.343750]\n",
      "6655: [D loss: 0.694926, acc: 0.548828]: [A loss: 0.716725, acc: 0.328125]\n",
      "6656: [D loss: 0.697858, acc: 0.500000]: [A loss: 0.751351, acc: 0.152344]\n",
      "6657: [D loss: 0.694871, acc: 0.464844]: [A loss: 0.717376, acc: 0.312500]\n",
      "6658: [D loss: 0.699658, acc: 0.478516]: [A loss: 0.746801, acc: 0.156250]\n",
      "6659: [D loss: 0.694843, acc: 0.523438]: [A loss: 0.701493, acc: 0.472656]\n",
      "6660: [D loss: 0.695412, acc: 0.515625]: [A loss: 0.745996, acc: 0.167969]\n",
      "6661: [D loss: 0.693002, acc: 0.490234]: [A loss: 0.720854, acc: 0.316406]\n",
      "6662: [D loss: 0.696856, acc: 0.496094]: [A loss: 0.762975, acc: 0.125000]\n",
      "6663: [D loss: 0.691934, acc: 0.529297]: [A loss: 0.679560, acc: 0.562500]\n",
      "6664: [D loss: 0.699708, acc: 0.513672]: [A loss: 0.787000, acc: 0.031250]\n",
      "6665: [D loss: 0.696345, acc: 0.496094]: [A loss: 0.707699, acc: 0.371094]\n",
      "6666: [D loss: 0.704504, acc: 0.478516]: [A loss: 0.756925, acc: 0.089844]\n",
      "6667: [D loss: 0.694739, acc: 0.503906]: [A loss: 0.697312, acc: 0.453125]\n",
      "6668: [D loss: 0.694327, acc: 0.513672]: [A loss: 0.737780, acc: 0.183594]\n",
      "6669: [D loss: 0.693319, acc: 0.521484]: [A loss: 0.701703, acc: 0.417969]\n",
      "6670: [D loss: 0.698135, acc: 0.501953]: [A loss: 0.746109, acc: 0.136719]\n",
      "6671: [D loss: 0.692057, acc: 0.523438]: [A loss: 0.713086, acc: 0.328125]\n",
      "6672: [D loss: 0.697704, acc: 0.501953]: [A loss: 0.742621, acc: 0.187500]\n",
      "6673: [D loss: 0.698585, acc: 0.478516]: [A loss: 0.730329, acc: 0.234375]\n",
      "6674: [D loss: 0.696069, acc: 0.511719]: [A loss: 0.733384, acc: 0.238281]\n",
      "6675: [D loss: 0.692650, acc: 0.486328]: [A loss: 0.743121, acc: 0.191406]\n",
      "6676: [D loss: 0.696020, acc: 0.501953]: [A loss: 0.740605, acc: 0.207031]\n",
      "6677: [D loss: 0.692098, acc: 0.505859]: [A loss: 0.722300, acc: 0.300781]\n",
      "6678: [D loss: 0.696015, acc: 0.484375]: [A loss: 0.717024, acc: 0.320312]\n",
      "6679: [D loss: 0.697081, acc: 0.533203]: [A loss: 0.749466, acc: 0.132812]\n",
      "6680: [D loss: 0.690789, acc: 0.548828]: [A loss: 0.708521, acc: 0.394531]\n",
      "6681: [D loss: 0.696439, acc: 0.501953]: [A loss: 0.753271, acc: 0.167969]\n",
      "6682: [D loss: 0.693734, acc: 0.498047]: [A loss: 0.717693, acc: 0.316406]\n",
      "6683: [D loss: 0.694997, acc: 0.525391]: [A loss: 0.702762, acc: 0.382812]\n",
      "6684: [D loss: 0.699947, acc: 0.490234]: [A loss: 0.749643, acc: 0.171875]\n",
      "6685: [D loss: 0.692548, acc: 0.505859]: [A loss: 0.704917, acc: 0.363281]\n",
      "6686: [D loss: 0.706747, acc: 0.447266]: [A loss: 0.766500, acc: 0.125000]\n",
      "6687: [D loss: 0.692568, acc: 0.482422]: [A loss: 0.701651, acc: 0.410156]\n",
      "6688: [D loss: 0.697133, acc: 0.503906]: [A loss: 0.779437, acc: 0.066406]\n",
      "6689: [D loss: 0.696666, acc: 0.501953]: [A loss: 0.710625, acc: 0.378906]\n",
      "6690: [D loss: 0.696491, acc: 0.498047]: [A loss: 0.730781, acc: 0.242188]\n",
      "6691: [D loss: 0.687860, acc: 0.552734]: [A loss: 0.694839, acc: 0.425781]\n",
      "6692: [D loss: 0.697589, acc: 0.517578]: [A loss: 0.739719, acc: 0.199219]\n",
      "6693: [D loss: 0.697023, acc: 0.474609]: [A loss: 0.725666, acc: 0.261719]\n",
      "6694: [D loss: 0.694930, acc: 0.482422]: [A loss: 0.749129, acc: 0.148438]\n",
      "6695: [D loss: 0.692196, acc: 0.500000]: [A loss: 0.714725, acc: 0.312500]\n",
      "6696: [D loss: 0.693617, acc: 0.521484]: [A loss: 0.739913, acc: 0.218750]\n",
      "6697: [D loss: 0.695809, acc: 0.507812]: [A loss: 0.751498, acc: 0.164062]\n",
      "6698: [D loss: 0.695919, acc: 0.507812]: [A loss: 0.764663, acc: 0.148438]\n",
      "6699: [D loss: 0.688093, acc: 0.548828]: [A loss: 0.676512, acc: 0.585938]\n",
      "6700: [D loss: 0.702966, acc: 0.507812]: [A loss: 0.762345, acc: 0.148438]\n",
      "6701: [D loss: 0.691448, acc: 0.529297]: [A loss: 0.686876, acc: 0.539062]\n",
      "6702: [D loss: 0.692722, acc: 0.531250]: [A loss: 0.700845, acc: 0.433594]\n",
      "6703: [D loss: 0.700723, acc: 0.494141]: [A loss: 0.753147, acc: 0.144531]\n",
      "6704: [D loss: 0.696605, acc: 0.496094]: [A loss: 0.700284, acc: 0.425781]\n",
      "6705: [D loss: 0.706481, acc: 0.462891]: [A loss: 0.776383, acc: 0.058594]\n",
      "6706: [D loss: 0.695799, acc: 0.492188]: [A loss: 0.712300, acc: 0.359375]\n",
      "6707: [D loss: 0.696138, acc: 0.478516]: [A loss: 0.728852, acc: 0.246094]\n",
      "6708: [D loss: 0.690817, acc: 0.519531]: [A loss: 0.694925, acc: 0.453125]\n",
      "6709: [D loss: 0.699464, acc: 0.505859]: [A loss: 0.766185, acc: 0.085938]\n",
      "6710: [D loss: 0.699606, acc: 0.468750]: [A loss: 0.709793, acc: 0.351562]\n",
      "6711: [D loss: 0.690560, acc: 0.533203]: [A loss: 0.717939, acc: 0.296875]\n",
      "6712: [D loss: 0.688964, acc: 0.515625]: [A loss: 0.674433, acc: 0.597656]\n",
      "6713: [D loss: 0.701636, acc: 0.478516]: [A loss: 0.764026, acc: 0.105469]\n",
      "6714: [D loss: 0.696696, acc: 0.478516]: [A loss: 0.698040, acc: 0.472656]\n",
      "6715: [D loss: 0.700155, acc: 0.496094]: [A loss: 0.720537, acc: 0.312500]\n",
      "6716: [D loss: 0.698381, acc: 0.486328]: [A loss: 0.730222, acc: 0.253906]\n",
      "6717: [D loss: 0.694429, acc: 0.503906]: [A loss: 0.724992, acc: 0.285156]\n",
      "6718: [D loss: 0.698987, acc: 0.500000]: [A loss: 0.748481, acc: 0.148438]\n",
      "6719: [D loss: 0.693608, acc: 0.507812]: [A loss: 0.709339, acc: 0.363281]\n",
      "6720: [D loss: 0.700233, acc: 0.509766]: [A loss: 0.742026, acc: 0.167969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6721: [D loss: 0.698469, acc: 0.466797]: [A loss: 0.730282, acc: 0.218750]\n",
      "6722: [D loss: 0.695738, acc: 0.484375]: [A loss: 0.722719, acc: 0.289062]\n",
      "6723: [D loss: 0.694418, acc: 0.486328]: [A loss: 0.714412, acc: 0.320312]\n",
      "6724: [D loss: 0.697902, acc: 0.498047]: [A loss: 0.742615, acc: 0.191406]\n",
      "6725: [D loss: 0.690231, acc: 0.535156]: [A loss: 0.689186, acc: 0.492188]\n",
      "6726: [D loss: 0.705874, acc: 0.482422]: [A loss: 0.782751, acc: 0.054688]\n",
      "6727: [D loss: 0.689351, acc: 0.556641]: [A loss: 0.680754, acc: 0.566406]\n",
      "6728: [D loss: 0.701155, acc: 0.509766]: [A loss: 0.757321, acc: 0.160156]\n",
      "6729: [D loss: 0.691467, acc: 0.509766]: [A loss: 0.693851, acc: 0.457031]\n",
      "6730: [D loss: 0.703599, acc: 0.513672]: [A loss: 0.761760, acc: 0.148438]\n",
      "6731: [D loss: 0.697898, acc: 0.498047]: [A loss: 0.717639, acc: 0.335938]\n",
      "6732: [D loss: 0.696316, acc: 0.476562]: [A loss: 0.728986, acc: 0.230469]\n",
      "6733: [D loss: 0.690267, acc: 0.531250]: [A loss: 0.692204, acc: 0.507812]\n",
      "6734: [D loss: 0.698679, acc: 0.500000]: [A loss: 0.771303, acc: 0.121094]\n",
      "6735: [D loss: 0.692902, acc: 0.507812]: [A loss: 0.689641, acc: 0.507812]\n",
      "6736: [D loss: 0.698419, acc: 0.501953]: [A loss: 0.712327, acc: 0.351562]\n",
      "6737: [D loss: 0.697187, acc: 0.500000]: [A loss: 0.727145, acc: 0.296875]\n",
      "6738: [D loss: 0.695603, acc: 0.476562]: [A loss: 0.718693, acc: 0.304688]\n",
      "6739: [D loss: 0.696126, acc: 0.498047]: [A loss: 0.722835, acc: 0.308594]\n",
      "6740: [D loss: 0.698779, acc: 0.501953]: [A loss: 0.748218, acc: 0.148438]\n",
      "6741: [D loss: 0.696668, acc: 0.505859]: [A loss: 0.712750, acc: 0.328125]\n",
      "6742: [D loss: 0.700286, acc: 0.494141]: [A loss: 0.743900, acc: 0.187500]\n",
      "6743: [D loss: 0.695047, acc: 0.478516]: [A loss: 0.723276, acc: 0.332031]\n",
      "6744: [D loss: 0.701367, acc: 0.513672]: [A loss: 0.779994, acc: 0.066406]\n",
      "6745: [D loss: 0.694516, acc: 0.500000]: [A loss: 0.705362, acc: 0.410156]\n",
      "6746: [D loss: 0.701163, acc: 0.517578]: [A loss: 0.753258, acc: 0.171875]\n",
      "6747: [D loss: 0.693025, acc: 0.505859]: [A loss: 0.705835, acc: 0.417969]\n",
      "6748: [D loss: 0.695456, acc: 0.496094]: [A loss: 0.725911, acc: 0.320312]\n",
      "6749: [D loss: 0.693789, acc: 0.482422]: [A loss: 0.711742, acc: 0.398438]\n",
      "6750: [D loss: 0.693035, acc: 0.546875]: [A loss: 0.730448, acc: 0.210938]\n",
      "6751: [D loss: 0.694510, acc: 0.498047]: [A loss: 0.687087, acc: 0.519531]\n",
      "6752: [D loss: 0.694823, acc: 0.517578]: [A loss: 0.743289, acc: 0.183594]\n",
      "6753: [D loss: 0.694490, acc: 0.527344]: [A loss: 0.692435, acc: 0.496094]\n",
      "6754: [D loss: 0.695758, acc: 0.515625]: [A loss: 0.735319, acc: 0.210938]\n",
      "6755: [D loss: 0.693924, acc: 0.517578]: [A loss: 0.703900, acc: 0.394531]\n",
      "6756: [D loss: 0.697353, acc: 0.511719]: [A loss: 0.763305, acc: 0.089844]\n",
      "6757: [D loss: 0.696137, acc: 0.492188]: [A loss: 0.703344, acc: 0.421875]\n",
      "6758: [D loss: 0.695136, acc: 0.519531]: [A loss: 0.749007, acc: 0.144531]\n",
      "6759: [D loss: 0.696851, acc: 0.496094]: [A loss: 0.696430, acc: 0.468750]\n",
      "6760: [D loss: 0.696603, acc: 0.515625]: [A loss: 0.726346, acc: 0.257812]\n",
      "6761: [D loss: 0.707199, acc: 0.462891]: [A loss: 0.755555, acc: 0.117188]\n",
      "6762: [D loss: 0.690087, acc: 0.523438]: [A loss: 0.696455, acc: 0.445312]\n",
      "6763: [D loss: 0.701926, acc: 0.478516]: [A loss: 0.720178, acc: 0.273438]\n",
      "6764: [D loss: 0.693108, acc: 0.541016]: [A loss: 0.694276, acc: 0.492188]\n",
      "6765: [D loss: 0.698702, acc: 0.509766]: [A loss: 0.715221, acc: 0.355469]\n",
      "6766: [D loss: 0.697482, acc: 0.511719]: [A loss: 0.748856, acc: 0.167969]\n",
      "6767: [D loss: 0.698912, acc: 0.460938]: [A loss: 0.708502, acc: 0.417969]\n",
      "6768: [D loss: 0.694762, acc: 0.511719]: [A loss: 0.725857, acc: 0.269531]\n",
      "6769: [D loss: 0.690838, acc: 0.544922]: [A loss: 0.696126, acc: 0.437500]\n",
      "6770: [D loss: 0.696851, acc: 0.507812]: [A loss: 0.722499, acc: 0.273438]\n",
      "6771: [D loss: 0.695617, acc: 0.494141]: [A loss: 0.731341, acc: 0.257812]\n",
      "6772: [D loss: 0.695468, acc: 0.503906]: [A loss: 0.737788, acc: 0.199219]\n",
      "6773: [D loss: 0.699813, acc: 0.488281]: [A loss: 0.753669, acc: 0.140625]\n",
      "6774: [D loss: 0.693135, acc: 0.501953]: [A loss: 0.703279, acc: 0.453125]\n",
      "6775: [D loss: 0.695717, acc: 0.517578]: [A loss: 0.758909, acc: 0.160156]\n",
      "6776: [D loss: 0.698611, acc: 0.486328]: [A loss: 0.698755, acc: 0.449219]\n",
      "6777: [D loss: 0.703235, acc: 0.492188]: [A loss: 0.751068, acc: 0.140625]\n",
      "6778: [D loss: 0.689996, acc: 0.541016]: [A loss: 0.697259, acc: 0.457031]\n",
      "6779: [D loss: 0.698278, acc: 0.468750]: [A loss: 0.739702, acc: 0.222656]\n",
      "6780: [D loss: 0.701794, acc: 0.476562]: [A loss: 0.744421, acc: 0.164062]\n",
      "6781: [D loss: 0.693516, acc: 0.490234]: [A loss: 0.718586, acc: 0.300781]\n",
      "6782: [D loss: 0.691966, acc: 0.517578]: [A loss: 0.747090, acc: 0.199219]\n",
      "6783: [D loss: 0.694887, acc: 0.498047]: [A loss: 0.709429, acc: 0.359375]\n",
      "6784: [D loss: 0.701975, acc: 0.470703]: [A loss: 0.750563, acc: 0.148438]\n",
      "6785: [D loss: 0.689144, acc: 0.537109]: [A loss: 0.711850, acc: 0.363281]\n",
      "6786: [D loss: 0.694466, acc: 0.490234]: [A loss: 0.729888, acc: 0.246094]\n",
      "6787: [D loss: 0.694229, acc: 0.494141]: [A loss: 0.705179, acc: 0.437500]\n",
      "6788: [D loss: 0.697916, acc: 0.460938]: [A loss: 0.719287, acc: 0.332031]\n",
      "6789: [D loss: 0.695525, acc: 0.523438]: [A loss: 0.744050, acc: 0.175781]\n",
      "6790: [D loss: 0.693287, acc: 0.535156]: [A loss: 0.712586, acc: 0.328125]\n",
      "6791: [D loss: 0.702087, acc: 0.498047]: [A loss: 0.733066, acc: 0.230469]\n",
      "6792: [D loss: 0.696085, acc: 0.511719]: [A loss: 0.707247, acc: 0.394531]\n",
      "6793: [D loss: 0.695808, acc: 0.513672]: [A loss: 0.738274, acc: 0.203125]\n",
      "6794: [D loss: 0.694168, acc: 0.507812]: [A loss: 0.699479, acc: 0.437500]\n",
      "6795: [D loss: 0.697844, acc: 0.517578]: [A loss: 0.724858, acc: 0.308594]\n",
      "6796: [D loss: 0.691884, acc: 0.503906]: [A loss: 0.732791, acc: 0.261719]\n",
      "6797: [D loss: 0.700676, acc: 0.486328]: [A loss: 0.770873, acc: 0.085938]\n",
      "6798: [D loss: 0.698181, acc: 0.490234]: [A loss: 0.710880, acc: 0.375000]\n",
      "6799: [D loss: 0.703275, acc: 0.478516]: [A loss: 0.752607, acc: 0.136719]\n",
      "6800: [D loss: 0.700906, acc: 0.460938]: [A loss: 0.700214, acc: 0.449219]\n",
      "6801: [D loss: 0.695110, acc: 0.515625]: [A loss: 0.720260, acc: 0.324219]\n",
      "6802: [D loss: 0.692014, acc: 0.533203]: [A loss: 0.730962, acc: 0.230469]\n",
      "6803: [D loss: 0.689812, acc: 0.523438]: [A loss: 0.692139, acc: 0.496094]\n",
      "6804: [D loss: 0.701902, acc: 0.521484]: [A loss: 0.784659, acc: 0.054688]\n",
      "6805: [D loss: 0.693012, acc: 0.519531]: [A loss: 0.691957, acc: 0.460938]\n",
      "6806: [D loss: 0.694548, acc: 0.509766]: [A loss: 0.759670, acc: 0.109375]\n",
      "6807: [D loss: 0.695189, acc: 0.513672]: [A loss: 0.708004, acc: 0.339844]\n",
      "6808: [D loss: 0.697176, acc: 0.513672]: [A loss: 0.735725, acc: 0.234375]\n",
      "6809: [D loss: 0.697143, acc: 0.466797]: [A loss: 0.708022, acc: 0.371094]\n",
      "6810: [D loss: 0.695695, acc: 0.519531]: [A loss: 0.711719, acc: 0.375000]\n",
      "6811: [D loss: 0.694156, acc: 0.517578]: [A loss: 0.721048, acc: 0.281250]\n",
      "6812: [D loss: 0.693150, acc: 0.531250]: [A loss: 0.744840, acc: 0.203125]\n",
      "6813: [D loss: 0.695000, acc: 0.501953]: [A loss: 0.729416, acc: 0.222656]\n",
      "6814: [D loss: 0.695802, acc: 0.533203]: [A loss: 0.722159, acc: 0.269531]\n",
      "6815: [D loss: 0.705006, acc: 0.468750]: [A loss: 0.805009, acc: 0.035156]\n",
      "6816: [D loss: 0.696720, acc: 0.498047]: [A loss: 0.706468, acc: 0.390625]\n",
      "6817: [D loss: 0.694691, acc: 0.500000]: [A loss: 0.703105, acc: 0.394531]\n",
      "6818: [D loss: 0.696219, acc: 0.505859]: [A loss: 0.733969, acc: 0.175781]\n",
      "6819: [D loss: 0.697786, acc: 0.476562]: [A loss: 0.716201, acc: 0.308594]\n",
      "6820: [D loss: 0.690569, acc: 0.513672]: [A loss: 0.718181, acc: 0.320312]\n",
      "6821: [D loss: 0.694734, acc: 0.542969]: [A loss: 0.724718, acc: 0.265625]\n",
      "6822: [D loss: 0.699059, acc: 0.474609]: [A loss: 0.720150, acc: 0.300781]\n",
      "6823: [D loss: 0.698407, acc: 0.494141]: [A loss: 0.723837, acc: 0.234375]\n",
      "6824: [D loss: 0.695552, acc: 0.480469]: [A loss: 0.706331, acc: 0.382812]\n",
      "6825: [D loss: 0.694544, acc: 0.500000]: [A loss: 0.727961, acc: 0.230469]\n",
      "6826: [D loss: 0.697061, acc: 0.472656]: [A loss: 0.707170, acc: 0.367188]\n",
      "6827: [D loss: 0.692525, acc: 0.529297]: [A loss: 0.716460, acc: 0.285156]\n",
      "6828: [D loss: 0.696658, acc: 0.517578]: [A loss: 0.773543, acc: 0.078125]\n",
      "6829: [D loss: 0.698021, acc: 0.476562]: [A loss: 0.712366, acc: 0.332031]\n",
      "6830: [D loss: 0.695881, acc: 0.513672]: [A loss: 0.735715, acc: 0.179688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6831: [D loss: 0.692813, acc: 0.519531]: [A loss: 0.679141, acc: 0.535156]\n",
      "6832: [D loss: 0.697489, acc: 0.498047]: [A loss: 0.775052, acc: 0.046875]\n",
      "6833: [D loss: 0.694695, acc: 0.519531]: [A loss: 0.716014, acc: 0.296875]\n",
      "6834: [D loss: 0.694935, acc: 0.511719]: [A loss: 0.736827, acc: 0.199219]\n",
      "6835: [D loss: 0.698592, acc: 0.478516]: [A loss: 0.725703, acc: 0.261719]\n",
      "6836: [D loss: 0.695909, acc: 0.501953]: [A loss: 0.724866, acc: 0.285156]\n",
      "6837: [D loss: 0.693136, acc: 0.513672]: [A loss: 0.726411, acc: 0.269531]\n",
      "6838: [D loss: 0.694896, acc: 0.492188]: [A loss: 0.733321, acc: 0.234375]\n",
      "6839: [D loss: 0.696271, acc: 0.478516]: [A loss: 0.731912, acc: 0.222656]\n",
      "6840: [D loss: 0.692611, acc: 0.505859]: [A loss: 0.717974, acc: 0.308594]\n",
      "6841: [D loss: 0.693478, acc: 0.521484]: [A loss: 0.716743, acc: 0.332031]\n",
      "6842: [D loss: 0.689284, acc: 0.542969]: [A loss: 0.717427, acc: 0.335938]\n",
      "6843: [D loss: 0.698156, acc: 0.498047]: [A loss: 0.750059, acc: 0.144531]\n",
      "6844: [D loss: 0.689950, acc: 0.537109]: [A loss: 0.718229, acc: 0.335938]\n",
      "6845: [D loss: 0.695127, acc: 0.474609]: [A loss: 0.770899, acc: 0.082031]\n",
      "6846: [D loss: 0.697014, acc: 0.490234]: [A loss: 0.713219, acc: 0.332031]\n",
      "6847: [D loss: 0.694449, acc: 0.492188]: [A loss: 0.713303, acc: 0.339844]\n",
      "6848: [D loss: 0.692307, acc: 0.501953]: [A loss: 0.711772, acc: 0.359375]\n",
      "6849: [D loss: 0.696878, acc: 0.515625]: [A loss: 0.721414, acc: 0.300781]\n",
      "6850: [D loss: 0.694122, acc: 0.509766]: [A loss: 0.719721, acc: 0.292969]\n",
      "6851: [D loss: 0.698844, acc: 0.449219]: [A loss: 0.704117, acc: 0.441406]\n",
      "6852: [D loss: 0.695175, acc: 0.521484]: [A loss: 0.718388, acc: 0.304688]\n",
      "6853: [D loss: 0.695517, acc: 0.484375]: [A loss: 0.725339, acc: 0.289062]\n",
      "6854: [D loss: 0.699974, acc: 0.466797]: [A loss: 0.724738, acc: 0.289062]\n",
      "6855: [D loss: 0.692665, acc: 0.513672]: [A loss: 0.735747, acc: 0.199219]\n",
      "6856: [D loss: 0.701001, acc: 0.490234]: [A loss: 0.763473, acc: 0.101562]\n",
      "6857: [D loss: 0.697949, acc: 0.464844]: [A loss: 0.714381, acc: 0.332031]\n",
      "6858: [D loss: 0.700069, acc: 0.507812]: [A loss: 0.745356, acc: 0.152344]\n",
      "6859: [D loss: 0.692537, acc: 0.546875]: [A loss: 0.685136, acc: 0.542969]\n",
      "6860: [D loss: 0.691028, acc: 0.529297]: [A loss: 0.765812, acc: 0.117188]\n",
      "6861: [D loss: 0.694159, acc: 0.486328]: [A loss: 0.725344, acc: 0.304688]\n",
      "6862: [D loss: 0.693669, acc: 0.513672]: [A loss: 0.728606, acc: 0.250000]\n",
      "6863: [D loss: 0.700207, acc: 0.494141]: [A loss: 0.763554, acc: 0.101562]\n",
      "6864: [D loss: 0.695339, acc: 0.488281]: [A loss: 0.717631, acc: 0.281250]\n",
      "6865: [D loss: 0.700141, acc: 0.488281]: [A loss: 0.724653, acc: 0.269531]\n",
      "6866: [D loss: 0.698702, acc: 0.458984]: [A loss: 0.725790, acc: 0.238281]\n",
      "6867: [D loss: 0.692116, acc: 0.505859]: [A loss: 0.704736, acc: 0.394531]\n",
      "6868: [D loss: 0.699988, acc: 0.486328]: [A loss: 0.741743, acc: 0.164062]\n",
      "6869: [D loss: 0.696733, acc: 0.488281]: [A loss: 0.705387, acc: 0.398438]\n",
      "6870: [D loss: 0.697655, acc: 0.472656]: [A loss: 0.725159, acc: 0.273438]\n",
      "6871: [D loss: 0.691944, acc: 0.513672]: [A loss: 0.729446, acc: 0.285156]\n",
      "6872: [D loss: 0.698434, acc: 0.474609]: [A loss: 0.744004, acc: 0.148438]\n",
      "6873: [D loss: 0.691088, acc: 0.511719]: [A loss: 0.689596, acc: 0.511719]\n",
      "6874: [D loss: 0.698365, acc: 0.492188]: [A loss: 0.768031, acc: 0.082031]\n",
      "6875: [D loss: 0.691976, acc: 0.517578]: [A loss: 0.701220, acc: 0.433594]\n",
      "6876: [D loss: 0.697146, acc: 0.523438]: [A loss: 0.714696, acc: 0.320312]\n",
      "6877: [D loss: 0.700157, acc: 0.480469]: [A loss: 0.749809, acc: 0.136719]\n",
      "6878: [D loss: 0.692762, acc: 0.515625]: [A loss: 0.714310, acc: 0.335938]\n",
      "6879: [D loss: 0.698908, acc: 0.498047]: [A loss: 0.754974, acc: 0.136719]\n",
      "6880: [D loss: 0.691340, acc: 0.531250]: [A loss: 0.697601, acc: 0.484375]\n",
      "6881: [D loss: 0.697608, acc: 0.519531]: [A loss: 0.747101, acc: 0.167969]\n",
      "6882: [D loss: 0.695792, acc: 0.488281]: [A loss: 0.695750, acc: 0.429688]\n",
      "6883: [D loss: 0.700087, acc: 0.474609]: [A loss: 0.741876, acc: 0.160156]\n",
      "6884: [D loss: 0.695809, acc: 0.486328]: [A loss: 0.716473, acc: 0.335938]\n",
      "6885: [D loss: 0.695224, acc: 0.525391]: [A loss: 0.715216, acc: 0.320312]\n",
      "6886: [D loss: 0.691916, acc: 0.533203]: [A loss: 0.679885, acc: 0.585938]\n",
      "6887: [D loss: 0.702603, acc: 0.500000]: [A loss: 0.760553, acc: 0.085938]\n",
      "6888: [D loss: 0.696194, acc: 0.492188]: [A loss: 0.714847, acc: 0.355469]\n",
      "6889: [D loss: 0.700839, acc: 0.492188]: [A loss: 0.757795, acc: 0.109375]\n",
      "6890: [D loss: 0.696000, acc: 0.464844]: [A loss: 0.692321, acc: 0.449219]\n",
      "6891: [D loss: 0.697882, acc: 0.505859]: [A loss: 0.767975, acc: 0.128906]\n",
      "6892: [D loss: 0.695613, acc: 0.478516]: [A loss: 0.699087, acc: 0.425781]\n",
      "6893: [D loss: 0.701130, acc: 0.525391]: [A loss: 0.737876, acc: 0.222656]\n",
      "6894: [D loss: 0.697674, acc: 0.507812]: [A loss: 0.726043, acc: 0.226562]\n",
      "6895: [D loss: 0.696463, acc: 0.531250]: [A loss: 0.756539, acc: 0.132812]\n",
      "6896: [D loss: 0.695185, acc: 0.505859]: [A loss: 0.717646, acc: 0.308594]\n",
      "6897: [D loss: 0.701027, acc: 0.480469]: [A loss: 0.765531, acc: 0.070312]\n",
      "6898: [D loss: 0.695483, acc: 0.496094]: [A loss: 0.707470, acc: 0.371094]\n",
      "6899: [D loss: 0.700954, acc: 0.501953]: [A loss: 0.774460, acc: 0.046875]\n",
      "6900: [D loss: 0.689861, acc: 0.527344]: [A loss: 0.705343, acc: 0.402344]\n",
      "6901: [D loss: 0.695015, acc: 0.500000]: [A loss: 0.749064, acc: 0.144531]\n",
      "6902: [D loss: 0.694312, acc: 0.519531]: [A loss: 0.696608, acc: 0.437500]\n",
      "6903: [D loss: 0.697448, acc: 0.501953]: [A loss: 0.719925, acc: 0.265625]\n",
      "6904: [D loss: 0.698326, acc: 0.486328]: [A loss: 0.722220, acc: 0.250000]\n",
      "6905: [D loss: 0.693668, acc: 0.492188]: [A loss: 0.717411, acc: 0.308594]\n",
      "6906: [D loss: 0.693904, acc: 0.539062]: [A loss: 0.714678, acc: 0.312500]\n",
      "6907: [D loss: 0.699323, acc: 0.474609]: [A loss: 0.722500, acc: 0.273438]\n",
      "6908: [D loss: 0.701948, acc: 0.488281]: [A loss: 0.729214, acc: 0.218750]\n",
      "6909: [D loss: 0.695090, acc: 0.505859]: [A loss: 0.720908, acc: 0.335938]\n",
      "6910: [D loss: 0.703024, acc: 0.460938]: [A loss: 0.764821, acc: 0.093750]\n",
      "6911: [D loss: 0.695178, acc: 0.496094]: [A loss: 0.725457, acc: 0.296875]\n",
      "6912: [D loss: 0.695703, acc: 0.500000]: [A loss: 0.714240, acc: 0.371094]\n",
      "6913: [D loss: 0.690079, acc: 0.515625]: [A loss: 0.726836, acc: 0.289062]\n",
      "6914: [D loss: 0.695763, acc: 0.492188]: [A loss: 0.729728, acc: 0.273438]\n",
      "6915: [D loss: 0.692664, acc: 0.523438]: [A loss: 0.738781, acc: 0.195312]\n",
      "6916: [D loss: 0.690171, acc: 0.535156]: [A loss: 0.710000, acc: 0.367188]\n",
      "6917: [D loss: 0.699019, acc: 0.480469]: [A loss: 0.757482, acc: 0.125000]\n",
      "6918: [D loss: 0.694929, acc: 0.496094]: [A loss: 0.687848, acc: 0.507812]\n",
      "6919: [D loss: 0.704552, acc: 0.486328]: [A loss: 0.780988, acc: 0.050781]\n",
      "6920: [D loss: 0.694289, acc: 0.484375]: [A loss: 0.706774, acc: 0.398438]\n",
      "6921: [D loss: 0.695915, acc: 0.484375]: [A loss: 0.734819, acc: 0.179688]\n",
      "6922: [D loss: 0.695583, acc: 0.498047]: [A loss: 0.704277, acc: 0.394531]\n",
      "6923: [D loss: 0.699419, acc: 0.503906]: [A loss: 0.729029, acc: 0.210938]\n",
      "6924: [D loss: 0.697001, acc: 0.505859]: [A loss: 0.717924, acc: 0.281250]\n",
      "6925: [D loss: 0.696745, acc: 0.503906]: [A loss: 0.721149, acc: 0.277344]\n",
      "6926: [D loss: 0.693784, acc: 0.501953]: [A loss: 0.712949, acc: 0.308594]\n",
      "6927: [D loss: 0.698872, acc: 0.527344]: [A loss: 0.750036, acc: 0.121094]\n",
      "6928: [D loss: 0.693790, acc: 0.507812]: [A loss: 0.718644, acc: 0.312500]\n",
      "6929: [D loss: 0.697049, acc: 0.498047]: [A loss: 0.723316, acc: 0.246094]\n",
      "6930: [D loss: 0.696739, acc: 0.511719]: [A loss: 0.739735, acc: 0.175781]\n",
      "6931: [D loss: 0.695390, acc: 0.498047]: [A loss: 0.722430, acc: 0.261719]\n",
      "6932: [D loss: 0.697425, acc: 0.451172]: [A loss: 0.727547, acc: 0.238281]\n",
      "6933: [D loss: 0.701478, acc: 0.472656]: [A loss: 0.744237, acc: 0.156250]\n",
      "6934: [D loss: 0.696251, acc: 0.494141]: [A loss: 0.700173, acc: 0.425781]\n",
      "6935: [D loss: 0.692718, acc: 0.533203]: [A loss: 0.743614, acc: 0.171875]\n",
      "6936: [D loss: 0.691891, acc: 0.503906]: [A loss: 0.699193, acc: 0.406250]\n",
      "6937: [D loss: 0.698600, acc: 0.501953]: [A loss: 0.774185, acc: 0.070312]\n",
      "6938: [D loss: 0.693827, acc: 0.503906]: [A loss: 0.689046, acc: 0.503906]\n",
      "6939: [D loss: 0.697818, acc: 0.503906]: [A loss: 0.742809, acc: 0.164062]\n",
      "6940: [D loss: 0.693434, acc: 0.498047]: [A loss: 0.704792, acc: 0.382812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6941: [D loss: 0.700564, acc: 0.494141]: [A loss: 0.763424, acc: 0.101562]\n",
      "6942: [D loss: 0.695971, acc: 0.498047]: [A loss: 0.703969, acc: 0.406250]\n",
      "6943: [D loss: 0.698423, acc: 0.507812]: [A loss: 0.767115, acc: 0.082031]\n",
      "6944: [D loss: 0.690606, acc: 0.517578]: [A loss: 0.688961, acc: 0.507812]\n",
      "6945: [D loss: 0.702296, acc: 0.500000]: [A loss: 0.774817, acc: 0.082031]\n",
      "6946: [D loss: 0.689397, acc: 0.531250]: [A loss: 0.685536, acc: 0.519531]\n",
      "6947: [D loss: 0.699621, acc: 0.500000]: [A loss: 0.730925, acc: 0.246094]\n",
      "6948: [D loss: 0.695613, acc: 0.494141]: [A loss: 0.685821, acc: 0.542969]\n",
      "6949: [D loss: 0.694403, acc: 0.484375]: [A loss: 0.706785, acc: 0.386719]\n",
      "6950: [D loss: 0.694502, acc: 0.515625]: [A loss: 0.729599, acc: 0.246094]\n",
      "6951: [D loss: 0.694444, acc: 0.542969]: [A loss: 0.710881, acc: 0.371094]\n",
      "6952: [D loss: 0.691612, acc: 0.509766]: [A loss: 0.715596, acc: 0.335938]\n",
      "6953: [D loss: 0.693345, acc: 0.494141]: [A loss: 0.718681, acc: 0.312500]\n",
      "6954: [D loss: 0.695156, acc: 0.490234]: [A loss: 0.729974, acc: 0.226562]\n",
      "6955: [D loss: 0.692387, acc: 0.542969]: [A loss: 0.719292, acc: 0.289062]\n",
      "6956: [D loss: 0.699605, acc: 0.484375]: [A loss: 0.759073, acc: 0.113281]\n",
      "6957: [D loss: 0.694954, acc: 0.500000]: [A loss: 0.698774, acc: 0.445312]\n",
      "6958: [D loss: 0.698601, acc: 0.500000]: [A loss: 0.757546, acc: 0.105469]\n",
      "6959: [D loss: 0.693889, acc: 0.503906]: [A loss: 0.706100, acc: 0.382812]\n",
      "6960: [D loss: 0.697299, acc: 0.503906]: [A loss: 0.742914, acc: 0.179688]\n",
      "6961: [D loss: 0.695543, acc: 0.490234]: [A loss: 0.724154, acc: 0.250000]\n",
      "6962: [D loss: 0.692606, acc: 0.519531]: [A loss: 0.726703, acc: 0.292969]\n",
      "6963: [D loss: 0.694733, acc: 0.507812]: [A loss: 0.742392, acc: 0.210938]\n",
      "6964: [D loss: 0.698826, acc: 0.501953]: [A loss: 0.738030, acc: 0.214844]\n",
      "6965: [D loss: 0.692181, acc: 0.531250]: [A loss: 0.709905, acc: 0.390625]\n",
      "6966: [D loss: 0.695521, acc: 0.517578]: [A loss: 0.743723, acc: 0.203125]\n",
      "6967: [D loss: 0.699638, acc: 0.492188]: [A loss: 0.755302, acc: 0.105469]\n",
      "6968: [D loss: 0.691486, acc: 0.519531]: [A loss: 0.698789, acc: 0.437500]\n",
      "6969: [D loss: 0.698471, acc: 0.498047]: [A loss: 0.757793, acc: 0.089844]\n",
      "6970: [D loss: 0.691316, acc: 0.535156]: [A loss: 0.679536, acc: 0.589844]\n",
      "6971: [D loss: 0.698251, acc: 0.521484]: [A loss: 0.747916, acc: 0.140625]\n",
      "6972: [D loss: 0.696962, acc: 0.470703]: [A loss: 0.713636, acc: 0.308594]\n",
      "6973: [D loss: 0.695450, acc: 0.511719]: [A loss: 0.708307, acc: 0.343750]\n",
      "6974: [D loss: 0.698556, acc: 0.503906]: [A loss: 0.713529, acc: 0.312500]\n",
      "6975: [D loss: 0.695651, acc: 0.498047]: [A loss: 0.749781, acc: 0.144531]\n",
      "6976: [D loss: 0.696289, acc: 0.500000]: [A loss: 0.766194, acc: 0.074219]\n",
      "6977: [D loss: 0.693082, acc: 0.501953]: [A loss: 0.712013, acc: 0.378906]\n",
      "6978: [D loss: 0.697801, acc: 0.501953]: [A loss: 0.800088, acc: 0.054688]\n",
      "6979: [D loss: 0.695668, acc: 0.496094]: [A loss: 0.698881, acc: 0.476562]\n",
      "6980: [D loss: 0.695064, acc: 0.515625]: [A loss: 0.740667, acc: 0.191406]\n",
      "6981: [D loss: 0.693771, acc: 0.503906]: [A loss: 0.712554, acc: 0.343750]\n",
      "6982: [D loss: 0.697437, acc: 0.513672]: [A loss: 0.744590, acc: 0.183594]\n",
      "6983: [D loss: 0.694755, acc: 0.511719]: [A loss: 0.741161, acc: 0.183594]\n",
      "6984: [D loss: 0.694378, acc: 0.498047]: [A loss: 0.713800, acc: 0.339844]\n",
      "6985: [D loss: 0.699447, acc: 0.492188]: [A loss: 0.756511, acc: 0.113281]\n",
      "6986: [D loss: 0.687561, acc: 0.537109]: [A loss: 0.680245, acc: 0.539062]\n",
      "6987: [D loss: 0.698753, acc: 0.500000]: [A loss: 0.771034, acc: 0.062500]\n",
      "6988: [D loss: 0.692094, acc: 0.501953]: [A loss: 0.704660, acc: 0.378906]\n",
      "6989: [D loss: 0.701098, acc: 0.484375]: [A loss: 0.748801, acc: 0.160156]\n",
      "6990: [D loss: 0.692800, acc: 0.519531]: [A loss: 0.685030, acc: 0.519531]\n",
      "6991: [D loss: 0.698694, acc: 0.494141]: [A loss: 0.708345, acc: 0.382812]\n",
      "6992: [D loss: 0.698295, acc: 0.500000]: [A loss: 0.703329, acc: 0.460938]\n",
      "6993: [D loss: 0.692933, acc: 0.500000]: [A loss: 0.725672, acc: 0.277344]\n",
      "6994: [D loss: 0.693527, acc: 0.525391]: [A loss: 0.720271, acc: 0.304688]\n",
      "6995: [D loss: 0.699893, acc: 0.476562]: [A loss: 0.748320, acc: 0.164062]\n",
      "6996: [D loss: 0.692951, acc: 0.505859]: [A loss: 0.711124, acc: 0.347656]\n",
      "6997: [D loss: 0.696526, acc: 0.486328]: [A loss: 0.742746, acc: 0.167969]\n",
      "6998: [D loss: 0.703428, acc: 0.458984]: [A loss: 0.737201, acc: 0.234375]\n",
      "6999: [D loss: 0.697762, acc: 0.519531]: [A loss: 0.702867, acc: 0.382812]\n",
      "7000: [D loss: 0.700895, acc: 0.501953]: [A loss: 0.754774, acc: 0.160156]\n",
      "7001: [D loss: 0.693999, acc: 0.523438]: [A loss: 0.707835, acc: 0.359375]\n",
      "7002: [D loss: 0.693303, acc: 0.519531]: [A loss: 0.744863, acc: 0.167969]\n",
      "7003: [D loss: 0.697188, acc: 0.501953]: [A loss: 0.726433, acc: 0.285156]\n",
      "7004: [D loss: 0.695123, acc: 0.521484]: [A loss: 0.703005, acc: 0.402344]\n",
      "7005: [D loss: 0.696211, acc: 0.519531]: [A loss: 0.738350, acc: 0.164062]\n",
      "7006: [D loss: 0.694762, acc: 0.488281]: [A loss: 0.741157, acc: 0.187500]\n",
      "7007: [D loss: 0.692601, acc: 0.507812]: [A loss: 0.745355, acc: 0.187500]\n",
      "7008: [D loss: 0.690615, acc: 0.529297]: [A loss: 0.718932, acc: 0.343750]\n",
      "7009: [D loss: 0.700561, acc: 0.503906]: [A loss: 0.807198, acc: 0.054688]\n",
      "7010: [D loss: 0.699460, acc: 0.500000]: [A loss: 0.706629, acc: 0.394531]\n",
      "7011: [D loss: 0.697939, acc: 0.480469]: [A loss: 0.751518, acc: 0.156250]\n",
      "7012: [D loss: 0.696280, acc: 0.505859]: [A loss: 0.706736, acc: 0.421875]\n",
      "7013: [D loss: 0.695180, acc: 0.492188]: [A loss: 0.753430, acc: 0.128906]\n",
      "7014: [D loss: 0.691025, acc: 0.501953]: [A loss: 0.734333, acc: 0.261719]\n",
      "7015: [D loss: 0.693095, acc: 0.517578]: [A loss: 0.729434, acc: 0.246094]\n",
      "7016: [D loss: 0.693949, acc: 0.515625]: [A loss: 0.743316, acc: 0.171875]\n",
      "7017: [D loss: 0.692851, acc: 0.494141]: [A loss: 0.701840, acc: 0.453125]\n",
      "7018: [D loss: 0.697385, acc: 0.509766]: [A loss: 0.783246, acc: 0.070312]\n",
      "7019: [D loss: 0.701573, acc: 0.457031]: [A loss: 0.698851, acc: 0.464844]\n",
      "7020: [D loss: 0.696908, acc: 0.498047]: [A loss: 0.715541, acc: 0.316406]\n",
      "7021: [D loss: 0.696775, acc: 0.511719]: [A loss: 0.720864, acc: 0.269531]\n",
      "7022: [D loss: 0.696690, acc: 0.515625]: [A loss: 0.713074, acc: 0.359375]\n",
      "7023: [D loss: 0.697149, acc: 0.521484]: [A loss: 0.738335, acc: 0.214844]\n",
      "7024: [D loss: 0.693409, acc: 0.550781]: [A loss: 0.709708, acc: 0.363281]\n",
      "7025: [D loss: 0.705088, acc: 0.468750]: [A loss: 0.754208, acc: 0.113281]\n",
      "7026: [D loss: 0.694782, acc: 0.513672]: [A loss: 0.726072, acc: 0.250000]\n",
      "7027: [D loss: 0.696753, acc: 0.498047]: [A loss: 0.735771, acc: 0.203125]\n",
      "7028: [D loss: 0.695484, acc: 0.519531]: [A loss: 0.756368, acc: 0.132812]\n",
      "7029: [D loss: 0.695037, acc: 0.509766]: [A loss: 0.760333, acc: 0.167969]\n",
      "7030: [D loss: 0.694292, acc: 0.494141]: [A loss: 0.702712, acc: 0.414062]\n",
      "7031: [D loss: 0.693915, acc: 0.513672]: [A loss: 0.767335, acc: 0.113281]\n",
      "7032: [D loss: 0.694646, acc: 0.486328]: [A loss: 0.686916, acc: 0.519531]\n",
      "7033: [D loss: 0.698259, acc: 0.490234]: [A loss: 0.752166, acc: 0.175781]\n",
      "7034: [D loss: 0.694231, acc: 0.507812]: [A loss: 0.712346, acc: 0.347656]\n",
      "7035: [D loss: 0.691804, acc: 0.560547]: [A loss: 0.722535, acc: 0.292969]\n",
      "7036: [D loss: 0.695973, acc: 0.496094]: [A loss: 0.745023, acc: 0.175781]\n",
      "7037: [D loss: 0.692788, acc: 0.498047]: [A loss: 0.687006, acc: 0.496094]\n",
      "7038: [D loss: 0.700119, acc: 0.476562]: [A loss: 0.769056, acc: 0.093750]\n",
      "7039: [D loss: 0.688773, acc: 0.533203]: [A loss: 0.703477, acc: 0.441406]\n",
      "7040: [D loss: 0.701346, acc: 0.466797]: [A loss: 0.729254, acc: 0.292969]\n",
      "7041: [D loss: 0.694692, acc: 0.523438]: [A loss: 0.714079, acc: 0.347656]\n",
      "7042: [D loss: 0.693711, acc: 0.509766]: [A loss: 0.749051, acc: 0.152344]\n",
      "7043: [D loss: 0.694580, acc: 0.474609]: [A loss: 0.726385, acc: 0.308594]\n",
      "7044: [D loss: 0.690787, acc: 0.515625]: [A loss: 0.723068, acc: 0.304688]\n",
      "7045: [D loss: 0.692153, acc: 0.533203]: [A loss: 0.723479, acc: 0.312500]\n",
      "7046: [D loss: 0.696731, acc: 0.509766]: [A loss: 0.766875, acc: 0.093750]\n",
      "7047: [D loss: 0.691510, acc: 0.507812]: [A loss: 0.723338, acc: 0.316406]\n",
      "7048: [D loss: 0.701298, acc: 0.496094]: [A loss: 0.772171, acc: 0.082031]\n",
      "7049: [D loss: 0.689417, acc: 0.541016]: [A loss: 0.694421, acc: 0.492188]\n",
      "7050: [D loss: 0.695535, acc: 0.501953]: [A loss: 0.763773, acc: 0.109375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7051: [D loss: 0.695663, acc: 0.472656]: [A loss: 0.719201, acc: 0.328125]\n",
      "7052: [D loss: 0.700134, acc: 0.472656]: [A loss: 0.734337, acc: 0.242188]\n",
      "7053: [D loss: 0.699124, acc: 0.500000]: [A loss: 0.718310, acc: 0.312500]\n",
      "7054: [D loss: 0.694147, acc: 0.517578]: [A loss: 0.745848, acc: 0.218750]\n",
      "7055: [D loss: 0.695673, acc: 0.486328]: [A loss: 0.707978, acc: 0.410156]\n",
      "7056: [D loss: 0.697858, acc: 0.503906]: [A loss: 0.739245, acc: 0.218750]\n",
      "7057: [D loss: 0.694450, acc: 0.488281]: [A loss: 0.719070, acc: 0.351562]\n",
      "7058: [D loss: 0.693054, acc: 0.515625]: [A loss: 0.723480, acc: 0.292969]\n",
      "7059: [D loss: 0.697837, acc: 0.484375]: [A loss: 0.744487, acc: 0.210938]\n",
      "7060: [D loss: 0.694773, acc: 0.511719]: [A loss: 0.746563, acc: 0.160156]\n",
      "7061: [D loss: 0.695884, acc: 0.500000]: [A loss: 0.736494, acc: 0.214844]\n",
      "7062: [D loss: 0.697492, acc: 0.521484]: [A loss: 0.741238, acc: 0.199219]\n",
      "7063: [D loss: 0.690961, acc: 0.533203]: [A loss: 0.723388, acc: 0.273438]\n",
      "7064: [D loss: 0.693522, acc: 0.507812]: [A loss: 0.778004, acc: 0.105469]\n",
      "7065: [D loss: 0.692892, acc: 0.482422]: [A loss: 0.677720, acc: 0.589844]\n",
      "7066: [D loss: 0.694883, acc: 0.513672]: [A loss: 0.761866, acc: 0.109375]\n",
      "7067: [D loss: 0.690948, acc: 0.531250]: [A loss: 0.714386, acc: 0.324219]\n",
      "7068: [D loss: 0.696529, acc: 0.488281]: [A loss: 0.763735, acc: 0.105469]\n",
      "7069: [D loss: 0.697427, acc: 0.480469]: [A loss: 0.726833, acc: 0.265625]\n",
      "7070: [D loss: 0.698344, acc: 0.482422]: [A loss: 0.731930, acc: 0.242188]\n",
      "7071: [D loss: 0.698682, acc: 0.496094]: [A loss: 0.777695, acc: 0.058594]\n",
      "7072: [D loss: 0.691995, acc: 0.523438]: [A loss: 0.671993, acc: 0.593750]\n",
      "7073: [D loss: 0.706286, acc: 0.500000]: [A loss: 0.812443, acc: 0.011719]\n",
      "7074: [D loss: 0.695949, acc: 0.519531]: [A loss: 0.702658, acc: 0.421875]\n",
      "7075: [D loss: 0.695985, acc: 0.513672]: [A loss: 0.730434, acc: 0.261719]\n",
      "7076: [D loss: 0.697456, acc: 0.509766]: [A loss: 0.733398, acc: 0.253906]\n",
      "7077: [D loss: 0.698896, acc: 0.494141]: [A loss: 0.754537, acc: 0.128906]\n",
      "7078: [D loss: 0.693756, acc: 0.496094]: [A loss: 0.726285, acc: 0.242188]\n",
      "7079: [D loss: 0.695510, acc: 0.480469]: [A loss: 0.719749, acc: 0.289062]\n",
      "7080: [D loss: 0.700092, acc: 0.460938]: [A loss: 0.749791, acc: 0.144531]\n",
      "7081: [D loss: 0.692576, acc: 0.500000]: [A loss: 0.715134, acc: 0.335938]\n",
      "7082: [D loss: 0.690681, acc: 0.521484]: [A loss: 0.703478, acc: 0.429688]\n",
      "7083: [D loss: 0.698664, acc: 0.501953]: [A loss: 0.737275, acc: 0.226562]\n",
      "7084: [D loss: 0.696480, acc: 0.498047]: [A loss: 0.725585, acc: 0.238281]\n",
      "7085: [D loss: 0.692004, acc: 0.533203]: [A loss: 0.719044, acc: 0.316406]\n",
      "7086: [D loss: 0.689669, acc: 0.515625]: [A loss: 0.725834, acc: 0.285156]\n",
      "7087: [D loss: 0.698338, acc: 0.503906]: [A loss: 0.769601, acc: 0.128906]\n",
      "7088: [D loss: 0.691819, acc: 0.509766]: [A loss: 0.699985, acc: 0.421875]\n",
      "7089: [D loss: 0.699076, acc: 0.500000]: [A loss: 0.749390, acc: 0.167969]\n",
      "7090: [D loss: 0.695888, acc: 0.498047]: [A loss: 0.729543, acc: 0.253906]\n",
      "7091: [D loss: 0.698751, acc: 0.496094]: [A loss: 0.732625, acc: 0.238281]\n",
      "7092: [D loss: 0.697346, acc: 0.496094]: [A loss: 0.742686, acc: 0.222656]\n",
      "7093: [D loss: 0.694873, acc: 0.494141]: [A loss: 0.737067, acc: 0.230469]\n",
      "7094: [D loss: 0.690903, acc: 0.519531]: [A loss: 0.698429, acc: 0.429688]\n",
      "7095: [D loss: 0.699860, acc: 0.503906]: [A loss: 0.773894, acc: 0.066406]\n",
      "7096: [D loss: 0.691384, acc: 0.533203]: [A loss: 0.705419, acc: 0.480469]\n",
      "7097: [D loss: 0.698512, acc: 0.490234]: [A loss: 0.757054, acc: 0.101562]\n",
      "7098: [D loss: 0.693029, acc: 0.529297]: [A loss: 0.713761, acc: 0.324219]\n",
      "7099: [D loss: 0.695169, acc: 0.511719]: [A loss: 0.715444, acc: 0.324219]\n",
      "7100: [D loss: 0.695515, acc: 0.501953]: [A loss: 0.758215, acc: 0.117188]\n",
      "7101: [D loss: 0.693740, acc: 0.503906]: [A loss: 0.710241, acc: 0.355469]\n",
      "7102: [D loss: 0.697436, acc: 0.501953]: [A loss: 0.749543, acc: 0.179688]\n",
      "7103: [D loss: 0.696589, acc: 0.472656]: [A loss: 0.724311, acc: 0.316406]\n",
      "7104: [D loss: 0.700209, acc: 0.476562]: [A loss: 0.759339, acc: 0.125000]\n",
      "7105: [D loss: 0.696319, acc: 0.462891]: [A loss: 0.704299, acc: 0.386719]\n",
      "7106: [D loss: 0.693855, acc: 0.509766]: [A loss: 0.764625, acc: 0.113281]\n",
      "7107: [D loss: 0.693823, acc: 0.498047]: [A loss: 0.707489, acc: 0.371094]\n",
      "7108: [D loss: 0.699273, acc: 0.460938]: [A loss: 0.761802, acc: 0.078125]\n",
      "7109: [D loss: 0.693692, acc: 0.509766]: [A loss: 0.708251, acc: 0.367188]\n",
      "7110: [D loss: 0.694784, acc: 0.511719]: [A loss: 0.758360, acc: 0.101562]\n",
      "7111: [D loss: 0.696101, acc: 0.523438]: [A loss: 0.714456, acc: 0.304688]\n",
      "7112: [D loss: 0.691927, acc: 0.511719]: [A loss: 0.740472, acc: 0.203125]\n",
      "7113: [D loss: 0.693169, acc: 0.515625]: [A loss: 0.742790, acc: 0.164062]\n",
      "7114: [D loss: 0.694719, acc: 0.494141]: [A loss: 0.700664, acc: 0.429688]\n",
      "7115: [D loss: 0.695844, acc: 0.513672]: [A loss: 0.765580, acc: 0.109375]\n",
      "7116: [D loss: 0.694969, acc: 0.515625]: [A loss: 0.718083, acc: 0.316406]\n",
      "7117: [D loss: 0.699317, acc: 0.472656]: [A loss: 0.762860, acc: 0.074219]\n",
      "7118: [D loss: 0.690483, acc: 0.550781]: [A loss: 0.705021, acc: 0.402344]\n",
      "7119: [D loss: 0.693313, acc: 0.533203]: [A loss: 0.732602, acc: 0.250000]\n",
      "7120: [D loss: 0.693618, acc: 0.523438]: [A loss: 0.703040, acc: 0.417969]\n",
      "7121: [D loss: 0.699142, acc: 0.503906]: [A loss: 0.735645, acc: 0.207031]\n",
      "7122: [D loss: 0.692050, acc: 0.539062]: [A loss: 0.711996, acc: 0.351562]\n",
      "7123: [D loss: 0.699335, acc: 0.500000]: [A loss: 0.746177, acc: 0.167969]\n",
      "7124: [D loss: 0.701605, acc: 0.472656]: [A loss: 0.742530, acc: 0.179688]\n",
      "7125: [D loss: 0.695560, acc: 0.507812]: [A loss: 0.708477, acc: 0.359375]\n",
      "7126: [D loss: 0.695247, acc: 0.527344]: [A loss: 0.760414, acc: 0.148438]\n",
      "7127: [D loss: 0.693583, acc: 0.501953]: [A loss: 0.750589, acc: 0.179688]\n",
      "7128: [D loss: 0.698666, acc: 0.486328]: [A loss: 0.745969, acc: 0.179688]\n",
      "7129: [D loss: 0.699604, acc: 0.486328]: [A loss: 0.736261, acc: 0.246094]\n",
      "7130: [D loss: 0.695756, acc: 0.494141]: [A loss: 0.734866, acc: 0.183594]\n",
      "7131: [D loss: 0.692422, acc: 0.521484]: [A loss: 0.730459, acc: 0.234375]\n",
      "7132: [D loss: 0.694137, acc: 0.517578]: [A loss: 0.737067, acc: 0.226562]\n",
      "7133: [D loss: 0.696457, acc: 0.492188]: [A loss: 0.738457, acc: 0.187500]\n",
      "7134: [D loss: 0.695128, acc: 0.509766]: [A loss: 0.754901, acc: 0.148438]\n",
      "7135: [D loss: 0.692778, acc: 0.515625]: [A loss: 0.718500, acc: 0.320312]\n",
      "7136: [D loss: 0.693543, acc: 0.527344]: [A loss: 0.753628, acc: 0.148438]\n",
      "7137: [D loss: 0.687992, acc: 0.544922]: [A loss: 0.686823, acc: 0.492188]\n",
      "7138: [D loss: 0.709335, acc: 0.482422]: [A loss: 0.811093, acc: 0.027344]\n",
      "7139: [D loss: 0.689293, acc: 0.529297]: [A loss: 0.668865, acc: 0.617188]\n",
      "7140: [D loss: 0.706750, acc: 0.488281]: [A loss: 0.798068, acc: 0.054688]\n",
      "7141: [D loss: 0.697576, acc: 0.505859]: [A loss: 0.703314, acc: 0.390625]\n",
      "7142: [D loss: 0.695193, acc: 0.521484]: [A loss: 0.715235, acc: 0.355469]\n",
      "7143: [D loss: 0.697026, acc: 0.507812]: [A loss: 0.723586, acc: 0.277344]\n",
      "7144: [D loss: 0.695420, acc: 0.490234]: [A loss: 0.712737, acc: 0.343750]\n",
      "7145: [D loss: 0.700114, acc: 0.505859]: [A loss: 0.735819, acc: 0.218750]\n",
      "7146: [D loss: 0.698640, acc: 0.478516]: [A loss: 0.715917, acc: 0.316406]\n",
      "7147: [D loss: 0.692154, acc: 0.519531]: [A loss: 0.706222, acc: 0.375000]\n",
      "7148: [D loss: 0.703286, acc: 0.468750]: [A loss: 0.736820, acc: 0.246094]\n",
      "7149: [D loss: 0.689798, acc: 0.521484]: [A loss: 0.728751, acc: 0.250000]\n",
      "7150: [D loss: 0.699763, acc: 0.462891]: [A loss: 0.754176, acc: 0.148438]\n",
      "7151: [D loss: 0.694074, acc: 0.519531]: [A loss: 0.718811, acc: 0.324219]\n",
      "7152: [D loss: 0.696946, acc: 0.513672]: [A loss: 0.741911, acc: 0.195312]\n",
      "7153: [D loss: 0.696154, acc: 0.531250]: [A loss: 0.718231, acc: 0.312500]\n",
      "7154: [D loss: 0.697833, acc: 0.507812]: [A loss: 0.731151, acc: 0.292969]\n",
      "7155: [D loss: 0.698845, acc: 0.484375]: [A loss: 0.733918, acc: 0.234375]\n",
      "7156: [D loss: 0.697509, acc: 0.498047]: [A loss: 0.729595, acc: 0.257812]\n",
      "7157: [D loss: 0.694024, acc: 0.511719]: [A loss: 0.724074, acc: 0.250000]\n",
      "7158: [D loss: 0.694301, acc: 0.490234]: [A loss: 0.757595, acc: 0.144531]\n",
      "7159: [D loss: 0.695166, acc: 0.494141]: [A loss: 0.725757, acc: 0.253906]\n",
      "7160: [D loss: 0.697850, acc: 0.480469]: [A loss: 0.723880, acc: 0.277344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7161: [D loss: 0.696201, acc: 0.535156]: [A loss: 0.739023, acc: 0.199219]\n",
      "7162: [D loss: 0.695572, acc: 0.507812]: [A loss: 0.709638, acc: 0.378906]\n",
      "7163: [D loss: 0.694884, acc: 0.509766]: [A loss: 0.768824, acc: 0.089844]\n",
      "7164: [D loss: 0.697936, acc: 0.492188]: [A loss: 0.726846, acc: 0.261719]\n",
      "7165: [D loss: 0.696997, acc: 0.488281]: [A loss: 0.777321, acc: 0.089844]\n",
      "7166: [D loss: 0.693841, acc: 0.496094]: [A loss: 0.724652, acc: 0.273438]\n",
      "7167: [D loss: 0.688613, acc: 0.558594]: [A loss: 0.734791, acc: 0.246094]\n",
      "7168: [D loss: 0.687405, acc: 0.546875]: [A loss: 0.732930, acc: 0.234375]\n",
      "7169: [D loss: 0.695576, acc: 0.484375]: [A loss: 0.741121, acc: 0.222656]\n",
      "7170: [D loss: 0.696383, acc: 0.513672]: [A loss: 0.715104, acc: 0.355469]\n",
      "7171: [D loss: 0.692470, acc: 0.500000]: [A loss: 0.712850, acc: 0.378906]\n",
      "7172: [D loss: 0.701901, acc: 0.498047]: [A loss: 0.747255, acc: 0.207031]\n",
      "7173: [D loss: 0.698013, acc: 0.500000]: [A loss: 0.725589, acc: 0.285156]\n",
      "7174: [D loss: 0.690377, acc: 0.535156]: [A loss: 0.702760, acc: 0.398438]\n",
      "7175: [D loss: 0.694622, acc: 0.513672]: [A loss: 0.707075, acc: 0.410156]\n",
      "7176: [D loss: 0.695287, acc: 0.515625]: [A loss: 0.738953, acc: 0.238281]\n",
      "7177: [D loss: 0.697088, acc: 0.494141]: [A loss: 0.762306, acc: 0.144531]\n",
      "7178: [D loss: 0.692934, acc: 0.542969]: [A loss: 0.752886, acc: 0.183594]\n",
      "7179: [D loss: 0.696398, acc: 0.513672]: [A loss: 0.768467, acc: 0.136719]\n",
      "7180: [D loss: 0.695149, acc: 0.498047]: [A loss: 0.746813, acc: 0.132812]\n",
      "7181: [D loss: 0.694717, acc: 0.509766]: [A loss: 0.707146, acc: 0.425781]\n",
      "7182: [D loss: 0.696115, acc: 0.521484]: [A loss: 0.772613, acc: 0.132812]\n",
      "7183: [D loss: 0.691364, acc: 0.537109]: [A loss: 0.690591, acc: 0.507812]\n",
      "7184: [D loss: 0.699989, acc: 0.486328]: [A loss: 0.744800, acc: 0.187500]\n",
      "7185: [D loss: 0.697091, acc: 0.500000]: [A loss: 0.711396, acc: 0.375000]\n",
      "7186: [D loss: 0.703258, acc: 0.476562]: [A loss: 0.758823, acc: 0.109375]\n",
      "7187: [D loss: 0.698699, acc: 0.474609]: [A loss: 0.731054, acc: 0.269531]\n",
      "7188: [D loss: 0.697370, acc: 0.503906]: [A loss: 0.729311, acc: 0.269531]\n",
      "7189: [D loss: 0.700372, acc: 0.470703]: [A loss: 0.765369, acc: 0.082031]\n",
      "7190: [D loss: 0.697362, acc: 0.500000]: [A loss: 0.714068, acc: 0.296875]\n",
      "7191: [D loss: 0.697615, acc: 0.498047]: [A loss: 0.735782, acc: 0.269531]\n",
      "7192: [D loss: 0.697633, acc: 0.476562]: [A loss: 0.721037, acc: 0.339844]\n",
      "7193: [D loss: 0.698205, acc: 0.507812]: [A loss: 0.729023, acc: 0.265625]\n",
      "7194: [D loss: 0.690488, acc: 0.544922]: [A loss: 0.731306, acc: 0.250000]\n",
      "7195: [D loss: 0.695757, acc: 0.488281]: [A loss: 0.741439, acc: 0.191406]\n",
      "7196: [D loss: 0.694421, acc: 0.509766]: [A loss: 0.735331, acc: 0.234375]\n",
      "7197: [D loss: 0.697718, acc: 0.503906]: [A loss: 0.764781, acc: 0.093750]\n",
      "7198: [D loss: 0.698840, acc: 0.472656]: [A loss: 0.721287, acc: 0.308594]\n",
      "7199: [D loss: 0.694149, acc: 0.519531]: [A loss: 0.734426, acc: 0.222656]\n",
      "7200: [D loss: 0.694924, acc: 0.496094]: [A loss: 0.731728, acc: 0.246094]\n",
      "7201: [D loss: 0.697880, acc: 0.496094]: [A loss: 0.737155, acc: 0.238281]\n",
      "7202: [D loss: 0.699279, acc: 0.525391]: [A loss: 0.764139, acc: 0.105469]\n",
      "7203: [D loss: 0.690034, acc: 0.523438]: [A loss: 0.707476, acc: 0.351562]\n",
      "7204: [D loss: 0.701542, acc: 0.482422]: [A loss: 0.766743, acc: 0.132812]\n",
      "7205: [D loss: 0.689921, acc: 0.527344]: [A loss: 0.687711, acc: 0.515625]\n",
      "7206: [D loss: 0.704434, acc: 0.484375]: [A loss: 0.794956, acc: 0.039062]\n",
      "7207: [D loss: 0.695192, acc: 0.488281]: [A loss: 0.709503, acc: 0.382812]\n",
      "7208: [D loss: 0.696398, acc: 0.509766]: [A loss: 0.707991, acc: 0.367188]\n",
      "7209: [D loss: 0.698592, acc: 0.482422]: [A loss: 0.728397, acc: 0.234375]\n",
      "7210: [D loss: 0.695803, acc: 0.498047]: [A loss: 0.708332, acc: 0.382812]\n",
      "7211: [D loss: 0.695379, acc: 0.470703]: [A loss: 0.731066, acc: 0.261719]\n",
      "7212: [D loss: 0.698411, acc: 0.488281]: [A loss: 0.742167, acc: 0.175781]\n",
      "7213: [D loss: 0.696086, acc: 0.476562]: [A loss: 0.717050, acc: 0.320312]\n",
      "7214: [D loss: 0.691401, acc: 0.533203]: [A loss: 0.715972, acc: 0.355469]\n",
      "7215: [D loss: 0.692531, acc: 0.535156]: [A loss: 0.720867, acc: 0.296875]\n",
      "7216: [D loss: 0.695786, acc: 0.501953]: [A loss: 0.729423, acc: 0.273438]\n",
      "7217: [D loss: 0.698140, acc: 0.480469]: [A loss: 0.723243, acc: 0.304688]\n",
      "7218: [D loss: 0.694683, acc: 0.515625]: [A loss: 0.754931, acc: 0.148438]\n",
      "7219: [D loss: 0.692188, acc: 0.531250]: [A loss: 0.713594, acc: 0.316406]\n",
      "7220: [D loss: 0.697241, acc: 0.494141]: [A loss: 0.732711, acc: 0.265625]\n",
      "7221: [D loss: 0.692239, acc: 0.490234]: [A loss: 0.716938, acc: 0.335938]\n",
      "7222: [D loss: 0.695550, acc: 0.523438]: [A loss: 0.753227, acc: 0.164062]\n",
      "7223: [D loss: 0.696455, acc: 0.484375]: [A loss: 0.712267, acc: 0.343750]\n",
      "7224: [D loss: 0.697260, acc: 0.488281]: [A loss: 0.733614, acc: 0.246094]\n",
      "7225: [D loss: 0.697610, acc: 0.474609]: [A loss: 0.742811, acc: 0.175781]\n",
      "7226: [D loss: 0.696294, acc: 0.503906]: [A loss: 0.753880, acc: 0.140625]\n",
      "7227: [D loss: 0.689711, acc: 0.515625]: [A loss: 0.733727, acc: 0.257812]\n",
      "7228: [D loss: 0.693835, acc: 0.511719]: [A loss: 0.782335, acc: 0.109375]\n",
      "7229: [D loss: 0.695791, acc: 0.478516]: [A loss: 0.723842, acc: 0.324219]\n",
      "7230: [D loss: 0.695903, acc: 0.500000]: [A loss: 0.720745, acc: 0.320312]\n",
      "7231: [D loss: 0.691774, acc: 0.517578]: [A loss: 0.739688, acc: 0.234375]\n",
      "7232: [D loss: 0.696368, acc: 0.513672]: [A loss: 0.747611, acc: 0.175781]\n",
      "7233: [D loss: 0.690860, acc: 0.507812]: [A loss: 0.714553, acc: 0.367188]\n",
      "7234: [D loss: 0.695512, acc: 0.517578]: [A loss: 0.784553, acc: 0.082031]\n",
      "7235: [D loss: 0.695528, acc: 0.488281]: [A loss: 0.689138, acc: 0.503906]\n",
      "7236: [D loss: 0.694841, acc: 0.496094]: [A loss: 0.755473, acc: 0.121094]\n",
      "7237: [D loss: 0.695340, acc: 0.490234]: [A loss: 0.679730, acc: 0.566406]\n",
      "7238: [D loss: 0.705945, acc: 0.496094]: [A loss: 0.788970, acc: 0.070312]\n",
      "7239: [D loss: 0.696538, acc: 0.488281]: [A loss: 0.708681, acc: 0.355469]\n",
      "7240: [D loss: 0.694417, acc: 0.492188]: [A loss: 0.716299, acc: 0.308594]\n",
      "7241: [D loss: 0.694337, acc: 0.521484]: [A loss: 0.723717, acc: 0.304688]\n",
      "7242: [D loss: 0.701063, acc: 0.490234]: [A loss: 0.742311, acc: 0.136719]\n",
      "7243: [D loss: 0.698924, acc: 0.490234]: [A loss: 0.717379, acc: 0.328125]\n",
      "7244: [D loss: 0.694485, acc: 0.500000]: [A loss: 0.707801, acc: 0.355469]\n",
      "7245: [D loss: 0.695085, acc: 0.496094]: [A loss: 0.734053, acc: 0.191406]\n",
      "7246: [D loss: 0.698747, acc: 0.490234]: [A loss: 0.724828, acc: 0.281250]\n",
      "7247: [D loss: 0.691946, acc: 0.521484]: [A loss: 0.703752, acc: 0.406250]\n",
      "7248: [D loss: 0.698116, acc: 0.501953]: [A loss: 0.799132, acc: 0.042969]\n",
      "7249: [D loss: 0.690513, acc: 0.519531]: [A loss: 0.683429, acc: 0.539062]\n",
      "7250: [D loss: 0.700503, acc: 0.503906]: [A loss: 0.775659, acc: 0.085938]\n",
      "7251: [D loss: 0.693035, acc: 0.498047]: [A loss: 0.684120, acc: 0.546875]\n",
      "7252: [D loss: 0.701735, acc: 0.484375]: [A loss: 0.779838, acc: 0.046875]\n",
      "7253: [D loss: 0.696809, acc: 0.482422]: [A loss: 0.709375, acc: 0.351562]\n",
      "7254: [D loss: 0.699882, acc: 0.498047]: [A loss: 0.740567, acc: 0.210938]\n",
      "7255: [D loss: 0.695187, acc: 0.486328]: [A loss: 0.711424, acc: 0.347656]\n",
      "7256: [D loss: 0.690571, acc: 0.521484]: [A loss: 0.713837, acc: 0.359375]\n",
      "7257: [D loss: 0.701162, acc: 0.480469]: [A loss: 0.764159, acc: 0.082031]\n",
      "7258: [D loss: 0.693189, acc: 0.484375]: [A loss: 0.709316, acc: 0.343750]\n",
      "7259: [D loss: 0.696428, acc: 0.498047]: [A loss: 0.729962, acc: 0.230469]\n",
      "7260: [D loss: 0.694687, acc: 0.511719]: [A loss: 0.719201, acc: 0.292969]\n",
      "7261: [D loss: 0.692601, acc: 0.519531]: [A loss: 0.713524, acc: 0.343750]\n",
      "7262: [D loss: 0.694969, acc: 0.494141]: [A loss: 0.705586, acc: 0.414062]\n",
      "7263: [D loss: 0.694869, acc: 0.496094]: [A loss: 0.731689, acc: 0.234375]\n",
      "7264: [D loss: 0.694520, acc: 0.496094]: [A loss: 0.704215, acc: 0.382812]\n",
      "7265: [D loss: 0.694362, acc: 0.533203]: [A loss: 0.728350, acc: 0.230469]\n",
      "7266: [D loss: 0.693803, acc: 0.511719]: [A loss: 0.725096, acc: 0.265625]\n",
      "7267: [D loss: 0.695526, acc: 0.509766]: [A loss: 0.709859, acc: 0.351562]\n",
      "7268: [D loss: 0.694498, acc: 0.503906]: [A loss: 0.751403, acc: 0.156250]\n",
      "7269: [D loss: 0.692169, acc: 0.535156]: [A loss: 0.697604, acc: 0.453125]\n",
      "7270: [D loss: 0.696170, acc: 0.515625]: [A loss: 0.733244, acc: 0.238281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7271: [D loss: 0.693818, acc: 0.521484]: [A loss: 0.712274, acc: 0.363281]\n",
      "7272: [D loss: 0.698421, acc: 0.511719]: [A loss: 0.741841, acc: 0.175781]\n",
      "7273: [D loss: 0.694423, acc: 0.519531]: [A loss: 0.734013, acc: 0.226562]\n",
      "7274: [D loss: 0.697931, acc: 0.494141]: [A loss: 0.742580, acc: 0.175781]\n",
      "7275: [D loss: 0.696311, acc: 0.501953]: [A loss: 0.696219, acc: 0.484375]\n",
      "7276: [D loss: 0.700735, acc: 0.500000]: [A loss: 0.791544, acc: 0.031250]\n",
      "7277: [D loss: 0.695892, acc: 0.488281]: [A loss: 0.715883, acc: 0.335938]\n",
      "7278: [D loss: 0.690772, acc: 0.527344]: [A loss: 0.713834, acc: 0.347656]\n",
      "7279: [D loss: 0.693640, acc: 0.527344]: [A loss: 0.709488, acc: 0.367188]\n",
      "7280: [D loss: 0.694141, acc: 0.515625]: [A loss: 0.712572, acc: 0.367188]\n",
      "7281: [D loss: 0.694999, acc: 0.519531]: [A loss: 0.741691, acc: 0.187500]\n",
      "7282: [D loss: 0.688694, acc: 0.552734]: [A loss: 0.716499, acc: 0.328125]\n",
      "7283: [D loss: 0.697813, acc: 0.515625]: [A loss: 0.723748, acc: 0.292969]\n",
      "7284: [D loss: 0.693116, acc: 0.523438]: [A loss: 0.717609, acc: 0.316406]\n",
      "7285: [D loss: 0.692291, acc: 0.531250]: [A loss: 0.696707, acc: 0.457031]\n",
      "7286: [D loss: 0.700989, acc: 0.500000]: [A loss: 0.776668, acc: 0.054688]\n",
      "7287: [D loss: 0.696553, acc: 0.492188]: [A loss: 0.724005, acc: 0.304688]\n",
      "7288: [D loss: 0.689404, acc: 0.519531]: [A loss: 0.702865, acc: 0.371094]\n",
      "7289: [D loss: 0.693648, acc: 0.511719]: [A loss: 0.741425, acc: 0.218750]\n",
      "7290: [D loss: 0.692363, acc: 0.544922]: [A loss: 0.706969, acc: 0.375000]\n",
      "7291: [D loss: 0.699602, acc: 0.503906]: [A loss: 0.754775, acc: 0.191406]\n",
      "7292: [D loss: 0.697158, acc: 0.486328]: [A loss: 0.758348, acc: 0.140625]\n",
      "7293: [D loss: 0.689176, acc: 0.544922]: [A loss: 0.687275, acc: 0.523438]\n",
      "7294: [D loss: 0.696160, acc: 0.507812]: [A loss: 0.779351, acc: 0.093750]\n",
      "7295: [D loss: 0.692774, acc: 0.500000]: [A loss: 0.703472, acc: 0.421875]\n",
      "7296: [D loss: 0.696689, acc: 0.515625]: [A loss: 0.738488, acc: 0.210938]\n",
      "7297: [D loss: 0.688693, acc: 0.511719]: [A loss: 0.687981, acc: 0.542969]\n",
      "7298: [D loss: 0.700768, acc: 0.501953]: [A loss: 0.786414, acc: 0.093750]\n",
      "7299: [D loss: 0.695824, acc: 0.494141]: [A loss: 0.706753, acc: 0.386719]\n",
      "7300: [D loss: 0.692300, acc: 0.509766]: [A loss: 0.738545, acc: 0.191406]\n",
      "7301: [D loss: 0.695112, acc: 0.490234]: [A loss: 0.723667, acc: 0.300781]\n",
      "7302: [D loss: 0.700672, acc: 0.474609]: [A loss: 0.761786, acc: 0.144531]\n",
      "7303: [D loss: 0.696797, acc: 0.480469]: [A loss: 0.708601, acc: 0.398438]\n",
      "7304: [D loss: 0.699680, acc: 0.476562]: [A loss: 0.712373, acc: 0.355469]\n",
      "7305: [D loss: 0.699849, acc: 0.509766]: [A loss: 0.745406, acc: 0.203125]\n",
      "7306: [D loss: 0.694214, acc: 0.503906]: [A loss: 0.726134, acc: 0.316406]\n",
      "7307: [D loss: 0.690873, acc: 0.511719]: [A loss: 0.730878, acc: 0.257812]\n",
      "7308: [D loss: 0.691334, acc: 0.513672]: [A loss: 0.718889, acc: 0.324219]\n",
      "7309: [D loss: 0.698834, acc: 0.513672]: [A loss: 0.758285, acc: 0.156250]\n",
      "7310: [D loss: 0.695327, acc: 0.476562]: [A loss: 0.706773, acc: 0.410156]\n",
      "7311: [D loss: 0.695234, acc: 0.511719]: [A loss: 0.761261, acc: 0.152344]\n",
      "7312: [D loss: 0.699141, acc: 0.472656]: [A loss: 0.748212, acc: 0.199219]\n",
      "7313: [D loss: 0.692725, acc: 0.509766]: [A loss: 0.729404, acc: 0.218750]\n",
      "7314: [D loss: 0.699468, acc: 0.488281]: [A loss: 0.778269, acc: 0.074219]\n",
      "7315: [D loss: 0.689519, acc: 0.544922]: [A loss: 0.689922, acc: 0.531250]\n",
      "7316: [D loss: 0.696415, acc: 0.492188]: [A loss: 0.769008, acc: 0.117188]\n",
      "7317: [D loss: 0.693945, acc: 0.484375]: [A loss: 0.698665, acc: 0.445312]\n",
      "7318: [D loss: 0.694719, acc: 0.501953]: [A loss: 0.712229, acc: 0.378906]\n",
      "7319: [D loss: 0.699760, acc: 0.492188]: [A loss: 0.748118, acc: 0.167969]\n",
      "7320: [D loss: 0.698438, acc: 0.484375]: [A loss: 0.731212, acc: 0.242188]\n",
      "7321: [D loss: 0.702258, acc: 0.490234]: [A loss: 0.749043, acc: 0.164062]\n",
      "7322: [D loss: 0.693984, acc: 0.505859]: [A loss: 0.706295, acc: 0.410156]\n",
      "7323: [D loss: 0.699114, acc: 0.509766]: [A loss: 0.776675, acc: 0.058594]\n",
      "7324: [D loss: 0.696474, acc: 0.501953]: [A loss: 0.727726, acc: 0.273438]\n",
      "7325: [D loss: 0.695273, acc: 0.492188]: [A loss: 0.730308, acc: 0.230469]\n",
      "7326: [D loss: 0.693419, acc: 0.525391]: [A loss: 0.723049, acc: 0.285156]\n",
      "7327: [D loss: 0.694306, acc: 0.529297]: [A loss: 0.792814, acc: 0.042969]\n",
      "7328: [D loss: 0.692414, acc: 0.513672]: [A loss: 0.692251, acc: 0.484375]\n",
      "7329: [D loss: 0.699358, acc: 0.509766]: [A loss: 0.791165, acc: 0.066406]\n",
      "7330: [D loss: 0.694672, acc: 0.500000]: [A loss: 0.690943, acc: 0.527344]\n",
      "7331: [D loss: 0.696294, acc: 0.511719]: [A loss: 0.725846, acc: 0.265625]\n",
      "7332: [D loss: 0.694231, acc: 0.519531]: [A loss: 0.712382, acc: 0.347656]\n",
      "7333: [D loss: 0.698874, acc: 0.484375]: [A loss: 0.738450, acc: 0.179688]\n",
      "7334: [D loss: 0.694957, acc: 0.503906]: [A loss: 0.726008, acc: 0.281250]\n",
      "7335: [D loss: 0.689521, acc: 0.523438]: [A loss: 0.695740, acc: 0.457031]\n",
      "7336: [D loss: 0.700315, acc: 0.503906]: [A loss: 0.799025, acc: 0.035156]\n",
      "7337: [D loss: 0.696899, acc: 0.509766]: [A loss: 0.693565, acc: 0.488281]\n",
      "7338: [D loss: 0.696501, acc: 0.503906]: [A loss: 0.750726, acc: 0.117188]\n",
      "7339: [D loss: 0.692556, acc: 0.533203]: [A loss: 0.726020, acc: 0.261719]\n",
      "7340: [D loss: 0.690385, acc: 0.535156]: [A loss: 0.716923, acc: 0.304688]\n",
      "7341: [D loss: 0.693872, acc: 0.515625]: [A loss: 0.729604, acc: 0.242188]\n",
      "7342: [D loss: 0.706567, acc: 0.437500]: [A loss: 0.736013, acc: 0.218750]\n",
      "7343: [D loss: 0.692702, acc: 0.523438]: [A loss: 0.729077, acc: 0.246094]\n",
      "7344: [D loss: 0.697279, acc: 0.486328]: [A loss: 0.724146, acc: 0.269531]\n",
      "7345: [D loss: 0.697806, acc: 0.472656]: [A loss: 0.746946, acc: 0.128906]\n",
      "7346: [D loss: 0.692980, acc: 0.539062]: [A loss: 0.708249, acc: 0.363281]\n",
      "7347: [D loss: 0.695030, acc: 0.511719]: [A loss: 0.737217, acc: 0.214844]\n",
      "7348: [D loss: 0.692962, acc: 0.519531]: [A loss: 0.699739, acc: 0.421875]\n",
      "7349: [D loss: 0.698396, acc: 0.511719]: [A loss: 0.775271, acc: 0.074219]\n",
      "7350: [D loss: 0.693174, acc: 0.509766]: [A loss: 0.700856, acc: 0.402344]\n",
      "7351: [D loss: 0.703809, acc: 0.500000]: [A loss: 0.789358, acc: 0.035156]\n",
      "7352: [D loss: 0.694656, acc: 0.484375]: [A loss: 0.707284, acc: 0.378906]\n",
      "7353: [D loss: 0.695634, acc: 0.511719]: [A loss: 0.739133, acc: 0.207031]\n",
      "7354: [D loss: 0.696893, acc: 0.494141]: [A loss: 0.729219, acc: 0.246094]\n",
      "7355: [D loss: 0.694901, acc: 0.531250]: [A loss: 0.683450, acc: 0.558594]\n",
      "7356: [D loss: 0.700337, acc: 0.501953]: [A loss: 0.746455, acc: 0.167969]\n",
      "7357: [D loss: 0.691986, acc: 0.488281]: [A loss: 0.698472, acc: 0.429688]\n",
      "7358: [D loss: 0.697755, acc: 0.492188]: [A loss: 0.767107, acc: 0.089844]\n",
      "7359: [D loss: 0.695570, acc: 0.509766]: [A loss: 0.708297, acc: 0.378906]\n",
      "7360: [D loss: 0.694796, acc: 0.503906]: [A loss: 0.729577, acc: 0.265625]\n",
      "7361: [D loss: 0.692879, acc: 0.517578]: [A loss: 0.739349, acc: 0.183594]\n",
      "7362: [D loss: 0.695859, acc: 0.488281]: [A loss: 0.722275, acc: 0.273438]\n",
      "7363: [D loss: 0.698059, acc: 0.488281]: [A loss: 0.748073, acc: 0.164062]\n",
      "7364: [D loss: 0.687047, acc: 0.558594]: [A loss: 0.674106, acc: 0.625000]\n",
      "7365: [D loss: 0.692132, acc: 0.527344]: [A loss: 0.750443, acc: 0.183594]\n",
      "7366: [D loss: 0.695318, acc: 0.496094]: [A loss: 0.702990, acc: 0.453125]\n",
      "7367: [D loss: 0.691996, acc: 0.519531]: [A loss: 0.749967, acc: 0.179688]\n",
      "7368: [D loss: 0.692465, acc: 0.513672]: [A loss: 0.714391, acc: 0.355469]\n",
      "7369: [D loss: 0.693742, acc: 0.519531]: [A loss: 0.776705, acc: 0.058594]\n",
      "7370: [D loss: 0.691331, acc: 0.519531]: [A loss: 0.718385, acc: 0.347656]\n",
      "7371: [D loss: 0.695747, acc: 0.496094]: [A loss: 0.753467, acc: 0.167969]\n",
      "7372: [D loss: 0.696888, acc: 0.486328]: [A loss: 0.707300, acc: 0.390625]\n",
      "7373: [D loss: 0.693975, acc: 0.527344]: [A loss: 0.708619, acc: 0.402344]\n",
      "7374: [D loss: 0.695350, acc: 0.513672]: [A loss: 0.724553, acc: 0.312500]\n",
      "7375: [D loss: 0.689043, acc: 0.515625]: [A loss: 0.729089, acc: 0.273438]\n",
      "7376: [D loss: 0.691239, acc: 0.531250]: [A loss: 0.722845, acc: 0.300781]\n",
      "7377: [D loss: 0.690515, acc: 0.529297]: [A loss: 0.686076, acc: 0.542969]\n",
      "7378: [D loss: 0.700061, acc: 0.486328]: [A loss: 0.804992, acc: 0.035156]\n",
      "7379: [D loss: 0.693072, acc: 0.513672]: [A loss: 0.691431, acc: 0.472656]\n",
      "7380: [D loss: 0.705051, acc: 0.511719]: [A loss: 0.769476, acc: 0.109375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7381: [D loss: 0.696618, acc: 0.478516]: [A loss: 0.701504, acc: 0.453125]\n",
      "7382: [D loss: 0.702440, acc: 0.500000]: [A loss: 0.722489, acc: 0.269531]\n",
      "7383: [D loss: 0.695545, acc: 0.472656]: [A loss: 0.693411, acc: 0.480469]\n",
      "7384: [D loss: 0.697740, acc: 0.511719]: [A loss: 0.722994, acc: 0.273438]\n",
      "7385: [D loss: 0.696951, acc: 0.490234]: [A loss: 0.703774, acc: 0.425781]\n",
      "7386: [D loss: 0.699681, acc: 0.474609]: [A loss: 0.758126, acc: 0.101562]\n",
      "7387: [D loss: 0.695594, acc: 0.480469]: [A loss: 0.738440, acc: 0.187500]\n",
      "7388: [D loss: 0.694279, acc: 0.531250]: [A loss: 0.719412, acc: 0.304688]\n",
      "7389: [D loss: 0.696460, acc: 0.488281]: [A loss: 0.739449, acc: 0.222656]\n",
      "7390: [D loss: 0.692090, acc: 0.542969]: [A loss: 0.719605, acc: 0.277344]\n",
      "7391: [D loss: 0.700002, acc: 0.509766]: [A loss: 0.772136, acc: 0.082031]\n",
      "7392: [D loss: 0.691880, acc: 0.535156]: [A loss: 0.695208, acc: 0.480469]\n",
      "7393: [D loss: 0.697178, acc: 0.496094]: [A loss: 0.774262, acc: 0.085938]\n",
      "7394: [D loss: 0.695673, acc: 0.503906]: [A loss: 0.728060, acc: 0.269531]\n",
      "7395: [D loss: 0.696536, acc: 0.505859]: [A loss: 0.747430, acc: 0.136719]\n",
      "7396: [D loss: 0.691541, acc: 0.525391]: [A loss: 0.691588, acc: 0.503906]\n",
      "7397: [D loss: 0.705052, acc: 0.478516]: [A loss: 0.810055, acc: 0.015625]\n",
      "7398: [D loss: 0.695165, acc: 0.503906]: [A loss: 0.700869, acc: 0.472656]\n",
      "7399: [D loss: 0.695034, acc: 0.523438]: [A loss: 0.725949, acc: 0.253906]\n",
      "7400: [D loss: 0.693961, acc: 0.515625]: [A loss: 0.713660, acc: 0.296875]\n",
      "7401: [D loss: 0.695128, acc: 0.496094]: [A loss: 0.741363, acc: 0.195312]\n",
      "7402: [D loss: 0.694528, acc: 0.492188]: [A loss: 0.711793, acc: 0.320312]\n",
      "7403: [D loss: 0.694747, acc: 0.511719]: [A loss: 0.729156, acc: 0.250000]\n",
      "7404: [D loss: 0.695851, acc: 0.503906]: [A loss: 0.737581, acc: 0.226562]\n",
      "7405: [D loss: 0.693225, acc: 0.501953]: [A loss: 0.714599, acc: 0.359375]\n",
      "7406: [D loss: 0.695871, acc: 0.517578]: [A loss: 0.736680, acc: 0.214844]\n",
      "7407: [D loss: 0.693811, acc: 0.505859]: [A loss: 0.709326, acc: 0.378906]\n",
      "7408: [D loss: 0.693719, acc: 0.513672]: [A loss: 0.767209, acc: 0.089844]\n",
      "7409: [D loss: 0.692278, acc: 0.539062]: [A loss: 0.671669, acc: 0.628906]\n",
      "7410: [D loss: 0.707709, acc: 0.490234]: [A loss: 0.782299, acc: 0.035156]\n",
      "7411: [D loss: 0.693277, acc: 0.529297]: [A loss: 0.692859, acc: 0.476562]\n",
      "7412: [D loss: 0.695858, acc: 0.503906]: [A loss: 0.728936, acc: 0.269531]\n",
      "7413: [D loss: 0.694632, acc: 0.529297]: [A loss: 0.725841, acc: 0.304688]\n",
      "7414: [D loss: 0.694171, acc: 0.527344]: [A loss: 0.729512, acc: 0.242188]\n",
      "7415: [D loss: 0.697441, acc: 0.474609]: [A loss: 0.721038, acc: 0.296875]\n",
      "7416: [D loss: 0.694226, acc: 0.492188]: [A loss: 0.735115, acc: 0.222656]\n",
      "7417: [D loss: 0.692162, acc: 0.533203]: [A loss: 0.710325, acc: 0.355469]\n",
      "7418: [D loss: 0.700781, acc: 0.476562]: [A loss: 0.787500, acc: 0.062500]\n",
      "7419: [D loss: 0.696827, acc: 0.494141]: [A loss: 0.722749, acc: 0.281250]\n",
      "7420: [D loss: 0.695386, acc: 0.488281]: [A loss: 0.764048, acc: 0.097656]\n",
      "7421: [D loss: 0.690835, acc: 0.533203]: [A loss: 0.715253, acc: 0.359375]\n",
      "7422: [D loss: 0.696003, acc: 0.503906]: [A loss: 0.728599, acc: 0.242188]\n",
      "7423: [D loss: 0.695285, acc: 0.486328]: [A loss: 0.739958, acc: 0.242188]\n",
      "7424: [D loss: 0.694737, acc: 0.503906]: [A loss: 0.701937, acc: 0.441406]\n",
      "7425: [D loss: 0.696137, acc: 0.503906]: [A loss: 0.753184, acc: 0.183594]\n",
      "7426: [D loss: 0.696288, acc: 0.511719]: [A loss: 0.722445, acc: 0.339844]\n",
      "7427: [D loss: 0.699214, acc: 0.480469]: [A loss: 0.735724, acc: 0.234375]\n",
      "7428: [D loss: 0.688960, acc: 0.560547]: [A loss: 0.691182, acc: 0.539062]\n",
      "7429: [D loss: 0.706126, acc: 0.472656]: [A loss: 0.789910, acc: 0.074219]\n",
      "7430: [D loss: 0.695518, acc: 0.539062]: [A loss: 0.709769, acc: 0.382812]\n",
      "7431: [D loss: 0.699657, acc: 0.482422]: [A loss: 0.746288, acc: 0.195312]\n",
      "7432: [D loss: 0.697636, acc: 0.486328]: [A loss: 0.718063, acc: 0.328125]\n",
      "7433: [D loss: 0.695590, acc: 0.521484]: [A loss: 0.723823, acc: 0.292969]\n",
      "7434: [D loss: 0.693182, acc: 0.529297]: [A loss: 0.723372, acc: 0.277344]\n",
      "7435: [D loss: 0.696383, acc: 0.515625]: [A loss: 0.714644, acc: 0.320312]\n",
      "7436: [D loss: 0.700717, acc: 0.470703]: [A loss: 0.740150, acc: 0.179688]\n",
      "7437: [D loss: 0.694443, acc: 0.484375]: [A loss: 0.702425, acc: 0.421875]\n",
      "7438: [D loss: 0.697163, acc: 0.505859]: [A loss: 0.748119, acc: 0.164062]\n",
      "7439: [D loss: 0.694954, acc: 0.488281]: [A loss: 0.717288, acc: 0.300781]\n",
      "7440: [D loss: 0.696073, acc: 0.509766]: [A loss: 0.734214, acc: 0.242188]\n",
      "7441: [D loss: 0.695832, acc: 0.494141]: [A loss: 0.716718, acc: 0.308594]\n",
      "7442: [D loss: 0.692339, acc: 0.531250]: [A loss: 0.697941, acc: 0.421875]\n",
      "7443: [D loss: 0.699807, acc: 0.492188]: [A loss: 0.787761, acc: 0.046875]\n",
      "7444: [D loss: 0.692729, acc: 0.511719]: [A loss: 0.678959, acc: 0.574219]\n",
      "7445: [D loss: 0.699671, acc: 0.523438]: [A loss: 0.769256, acc: 0.125000]\n",
      "7446: [D loss: 0.691832, acc: 0.527344]: [A loss: 0.715804, acc: 0.332031]\n",
      "7447: [D loss: 0.696755, acc: 0.500000]: [A loss: 0.734049, acc: 0.230469]\n",
      "7448: [D loss: 0.691742, acc: 0.527344]: [A loss: 0.722303, acc: 0.300781]\n",
      "7449: [D loss: 0.698167, acc: 0.521484]: [A loss: 0.749273, acc: 0.222656]\n",
      "7450: [D loss: 0.693162, acc: 0.505859]: [A loss: 0.669515, acc: 0.636719]\n",
      "7451: [D loss: 0.703120, acc: 0.488281]: [A loss: 0.755628, acc: 0.156250]\n",
      "7452: [D loss: 0.687867, acc: 0.558594]: [A loss: 0.682470, acc: 0.554688]\n",
      "7453: [D loss: 0.701559, acc: 0.492188]: [A loss: 0.786547, acc: 0.082031]\n",
      "7454: [D loss: 0.693135, acc: 0.523438]: [A loss: 0.712583, acc: 0.371094]\n",
      "7455: [D loss: 0.690629, acc: 0.558594]: [A loss: 0.695572, acc: 0.484375]\n",
      "7456: [D loss: 0.705614, acc: 0.472656]: [A loss: 0.773718, acc: 0.078125]\n",
      "7457: [D loss: 0.693640, acc: 0.529297]: [A loss: 0.700803, acc: 0.402344]\n",
      "7458: [D loss: 0.696606, acc: 0.500000]: [A loss: 0.707702, acc: 0.363281]\n",
      "7459: [D loss: 0.697805, acc: 0.496094]: [A loss: 0.716266, acc: 0.300781]\n",
      "7460: [D loss: 0.696238, acc: 0.488281]: [A loss: 0.714849, acc: 0.343750]\n",
      "7461: [D loss: 0.695291, acc: 0.515625]: [A loss: 0.729840, acc: 0.246094]\n",
      "7462: [D loss: 0.696187, acc: 0.501953]: [A loss: 0.745650, acc: 0.164062]\n",
      "7463: [D loss: 0.696004, acc: 0.509766]: [A loss: 0.739846, acc: 0.183594]\n",
      "7464: [D loss: 0.697179, acc: 0.525391]: [A loss: 0.742722, acc: 0.210938]\n",
      "7465: [D loss: 0.692559, acc: 0.511719]: [A loss: 0.762688, acc: 0.128906]\n",
      "7466: [D loss: 0.692111, acc: 0.501953]: [A loss: 0.694445, acc: 0.519531]\n",
      "7467: [D loss: 0.696965, acc: 0.519531]: [A loss: 0.803884, acc: 0.042969]\n",
      "7468: [D loss: 0.696299, acc: 0.476562]: [A loss: 0.683068, acc: 0.539062]\n",
      "7469: [D loss: 0.696960, acc: 0.501953]: [A loss: 0.741240, acc: 0.191406]\n",
      "7470: [D loss: 0.688939, acc: 0.527344]: [A loss: 0.701819, acc: 0.410156]\n",
      "7471: [D loss: 0.696722, acc: 0.517578]: [A loss: 0.749869, acc: 0.203125]\n",
      "7472: [D loss: 0.697984, acc: 0.494141]: [A loss: 0.727921, acc: 0.277344]\n",
      "7473: [D loss: 0.693002, acc: 0.525391]: [A loss: 0.715440, acc: 0.335938]\n",
      "7474: [D loss: 0.695087, acc: 0.503906]: [A loss: 0.703101, acc: 0.433594]\n",
      "7475: [D loss: 0.694635, acc: 0.541016]: [A loss: 0.743830, acc: 0.199219]\n",
      "7476: [D loss: 0.693186, acc: 0.517578]: [A loss: 0.719054, acc: 0.332031]\n",
      "7477: [D loss: 0.696483, acc: 0.533203]: [A loss: 0.777100, acc: 0.070312]\n",
      "7478: [D loss: 0.691546, acc: 0.517578]: [A loss: 0.685504, acc: 0.531250]\n",
      "7479: [D loss: 0.700067, acc: 0.509766]: [A loss: 0.775814, acc: 0.070312]\n",
      "7480: [D loss: 0.690278, acc: 0.535156]: [A loss: 0.702149, acc: 0.421875]\n",
      "7481: [D loss: 0.696661, acc: 0.505859]: [A loss: 0.711429, acc: 0.351562]\n",
      "7482: [D loss: 0.693171, acc: 0.517578]: [A loss: 0.710916, acc: 0.394531]\n",
      "7483: [D loss: 0.695791, acc: 0.519531]: [A loss: 0.735725, acc: 0.230469]\n",
      "7484: [D loss: 0.697676, acc: 0.511719]: [A loss: 0.702604, acc: 0.437500]\n",
      "7485: [D loss: 0.692812, acc: 0.539062]: [A loss: 0.755069, acc: 0.113281]\n",
      "7486: [D loss: 0.695812, acc: 0.492188]: [A loss: 0.744147, acc: 0.179688]\n",
      "7487: [D loss: 0.693461, acc: 0.503906]: [A loss: 0.709940, acc: 0.359375]\n",
      "7488: [D loss: 0.694356, acc: 0.509766]: [A loss: 0.739372, acc: 0.203125]\n",
      "7489: [D loss: 0.699577, acc: 0.478516]: [A loss: 0.739752, acc: 0.214844]\n",
      "7490: [D loss: 0.694150, acc: 0.501953]: [A loss: 0.728777, acc: 0.234375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7491: [D loss: 0.700969, acc: 0.523438]: [A loss: 0.744327, acc: 0.171875]\n",
      "7492: [D loss: 0.693034, acc: 0.527344]: [A loss: 0.739017, acc: 0.210938]\n",
      "7493: [D loss: 0.697738, acc: 0.482422]: [A loss: 0.721148, acc: 0.316406]\n",
      "7494: [D loss: 0.696378, acc: 0.462891]: [A loss: 0.756025, acc: 0.156250]\n",
      "7495: [D loss: 0.697315, acc: 0.494141]: [A loss: 0.723933, acc: 0.261719]\n",
      "7496: [D loss: 0.695628, acc: 0.498047]: [A loss: 0.736989, acc: 0.246094]\n",
      "7497: [D loss: 0.694880, acc: 0.527344]: [A loss: 0.747014, acc: 0.179688]\n",
      "7498: [D loss: 0.695227, acc: 0.470703]: [A loss: 0.726233, acc: 0.281250]\n",
      "7499: [D loss: 0.700459, acc: 0.470703]: [A loss: 0.735127, acc: 0.230469]\n",
      "7500: [D loss: 0.695436, acc: 0.492188]: [A loss: 0.721858, acc: 0.328125]\n",
      "7501: [D loss: 0.696993, acc: 0.503906]: [A loss: 0.722656, acc: 0.289062]\n",
      "7502: [D loss: 0.701178, acc: 0.501953]: [A loss: 0.750009, acc: 0.171875]\n",
      "7503: [D loss: 0.689379, acc: 0.521484]: [A loss: 0.710919, acc: 0.355469]\n",
      "7504: [D loss: 0.696850, acc: 0.509766]: [A loss: 0.769292, acc: 0.089844]\n",
      "7505: [D loss: 0.694526, acc: 0.515625]: [A loss: 0.722455, acc: 0.328125]\n",
      "7506: [D loss: 0.693642, acc: 0.537109]: [A loss: 0.765701, acc: 0.121094]\n",
      "7507: [D loss: 0.694700, acc: 0.517578]: [A loss: 0.745146, acc: 0.191406]\n",
      "7508: [D loss: 0.695886, acc: 0.511719]: [A loss: 0.742126, acc: 0.179688]\n",
      "7509: [D loss: 0.690419, acc: 0.539062]: [A loss: 0.737876, acc: 0.242188]\n",
      "7510: [D loss: 0.695159, acc: 0.517578]: [A loss: 0.752329, acc: 0.164062]\n",
      "7511: [D loss: 0.695745, acc: 0.498047]: [A loss: 0.749163, acc: 0.183594]\n",
      "7512: [D loss: 0.695908, acc: 0.513672]: [A loss: 0.754215, acc: 0.136719]\n",
      "7513: [D loss: 0.693019, acc: 0.505859]: [A loss: 0.728883, acc: 0.269531]\n",
      "7514: [D loss: 0.699664, acc: 0.486328]: [A loss: 0.773938, acc: 0.054688]\n",
      "7515: [D loss: 0.697099, acc: 0.472656]: [A loss: 0.703961, acc: 0.429688]\n",
      "7516: [D loss: 0.690922, acc: 0.533203]: [A loss: 0.726035, acc: 0.253906]\n",
      "7517: [D loss: 0.695793, acc: 0.531250]: [A loss: 0.729067, acc: 0.250000]\n",
      "7518: [D loss: 0.695926, acc: 0.529297]: [A loss: 0.714765, acc: 0.363281]\n",
      "7519: [D loss: 0.695934, acc: 0.505859]: [A loss: 0.738127, acc: 0.250000]\n",
      "7520: [D loss: 0.695146, acc: 0.494141]: [A loss: 0.736675, acc: 0.269531]\n",
      "7521: [D loss: 0.698444, acc: 0.494141]: [A loss: 0.786046, acc: 0.066406]\n",
      "7522: [D loss: 0.690611, acc: 0.533203]: [A loss: 0.679607, acc: 0.574219]\n",
      "7523: [D loss: 0.706743, acc: 0.500000]: [A loss: 0.822934, acc: 0.000000]\n",
      "7524: [D loss: 0.691982, acc: 0.525391]: [A loss: 0.678605, acc: 0.562500]\n",
      "7525: [D loss: 0.704473, acc: 0.486328]: [A loss: 0.768055, acc: 0.070312]\n",
      "7526: [D loss: 0.692921, acc: 0.535156]: [A loss: 0.702002, acc: 0.417969]\n",
      "7527: [D loss: 0.693813, acc: 0.509766]: [A loss: 0.700486, acc: 0.445312]\n",
      "7528: [D loss: 0.697823, acc: 0.501953]: [A loss: 0.738619, acc: 0.183594]\n",
      "7529: [D loss: 0.691635, acc: 0.509766]: [A loss: 0.691604, acc: 0.476562]\n",
      "7530: [D loss: 0.693511, acc: 0.511719]: [A loss: 0.744567, acc: 0.226562]\n",
      "7531: [D loss: 0.692851, acc: 0.515625]: [A loss: 0.699092, acc: 0.437500]\n",
      "7532: [D loss: 0.693537, acc: 0.523438]: [A loss: 0.773225, acc: 0.101562]\n",
      "7533: [D loss: 0.693153, acc: 0.503906]: [A loss: 0.705641, acc: 0.386719]\n",
      "7534: [D loss: 0.702588, acc: 0.498047]: [A loss: 0.777705, acc: 0.042969]\n",
      "7535: [D loss: 0.689197, acc: 0.539062]: [A loss: 0.674333, acc: 0.644531]\n",
      "7536: [D loss: 0.697498, acc: 0.507812]: [A loss: 0.767952, acc: 0.117188]\n",
      "7537: [D loss: 0.688878, acc: 0.533203]: [A loss: 0.688657, acc: 0.496094]\n",
      "7538: [D loss: 0.695714, acc: 0.490234]: [A loss: 0.733518, acc: 0.257812]\n",
      "7539: [D loss: 0.695885, acc: 0.501953]: [A loss: 0.719368, acc: 0.320312]\n",
      "7540: [D loss: 0.690434, acc: 0.544922]: [A loss: 0.700760, acc: 0.457031]\n",
      "7541: [D loss: 0.696935, acc: 0.494141]: [A loss: 0.758299, acc: 0.136719]\n",
      "7542: [D loss: 0.696180, acc: 0.478516]: [A loss: 0.705150, acc: 0.421875]\n",
      "7543: [D loss: 0.693150, acc: 0.509766]: [A loss: 0.755855, acc: 0.175781]\n",
      "7544: [D loss: 0.696444, acc: 0.478516]: [A loss: 0.707799, acc: 0.343750]\n",
      "7545: [D loss: 0.696928, acc: 0.521484]: [A loss: 0.752524, acc: 0.171875]\n",
      "7546: [D loss: 0.691103, acc: 0.513672]: [A loss: 0.698333, acc: 0.429688]\n",
      "7547: [D loss: 0.693564, acc: 0.521484]: [A loss: 0.738993, acc: 0.207031]\n",
      "7548: [D loss: 0.700383, acc: 0.462891]: [A loss: 0.754888, acc: 0.148438]\n",
      "7549: [D loss: 0.696736, acc: 0.494141]: [A loss: 0.702896, acc: 0.417969]\n",
      "7550: [D loss: 0.691887, acc: 0.544922]: [A loss: 0.726601, acc: 0.230469]\n",
      "7551: [D loss: 0.694694, acc: 0.507812]: [A loss: 0.713512, acc: 0.339844]\n",
      "7552: [D loss: 0.696417, acc: 0.496094]: [A loss: 0.765504, acc: 0.117188]\n",
      "7553: [D loss: 0.694870, acc: 0.498047]: [A loss: 0.702941, acc: 0.410156]\n",
      "7554: [D loss: 0.696337, acc: 0.511719]: [A loss: 0.747531, acc: 0.171875]\n",
      "7555: [D loss: 0.692362, acc: 0.544922]: [A loss: 0.695150, acc: 0.472656]\n",
      "7556: [D loss: 0.692359, acc: 0.521484]: [A loss: 0.752711, acc: 0.128906]\n",
      "7557: [D loss: 0.693898, acc: 0.498047]: [A loss: 0.710375, acc: 0.351562]\n",
      "7558: [D loss: 0.696438, acc: 0.521484]: [A loss: 0.782405, acc: 0.050781]\n",
      "7559: [D loss: 0.695807, acc: 0.490234]: [A loss: 0.683604, acc: 0.582031]\n",
      "7560: [D loss: 0.701913, acc: 0.501953]: [A loss: 0.764034, acc: 0.093750]\n",
      "7561: [D loss: 0.690548, acc: 0.513672]: [A loss: 0.689192, acc: 0.496094]\n",
      "7562: [D loss: 0.697394, acc: 0.490234]: [A loss: 0.737366, acc: 0.191406]\n",
      "7563: [D loss: 0.699220, acc: 0.449219]: [A loss: 0.732497, acc: 0.203125]\n",
      "7564: [D loss: 0.694648, acc: 0.509766]: [A loss: 0.713330, acc: 0.300781]\n",
      "7565: [D loss: 0.699077, acc: 0.500000]: [A loss: 0.757852, acc: 0.113281]\n",
      "7566: [D loss: 0.696081, acc: 0.519531]: [A loss: 0.729124, acc: 0.289062]\n",
      "7567: [D loss: 0.694028, acc: 0.492188]: [A loss: 0.712256, acc: 0.335938]\n",
      "7568: [D loss: 0.695174, acc: 0.509766]: [A loss: 0.752203, acc: 0.144531]\n",
      "7569: [D loss: 0.693959, acc: 0.517578]: [A loss: 0.686492, acc: 0.468750]\n",
      "7570: [D loss: 0.698444, acc: 0.507812]: [A loss: 0.790139, acc: 0.050781]\n",
      "7571: [D loss: 0.693827, acc: 0.517578]: [A loss: 0.694859, acc: 0.503906]\n",
      "7572: [D loss: 0.704326, acc: 0.501953]: [A loss: 0.797434, acc: 0.035156]\n",
      "7573: [D loss: 0.694472, acc: 0.494141]: [A loss: 0.696371, acc: 0.445312]\n",
      "7574: [D loss: 0.696922, acc: 0.507812]: [A loss: 0.730982, acc: 0.230469]\n",
      "7575: [D loss: 0.696403, acc: 0.476562]: [A loss: 0.721397, acc: 0.296875]\n",
      "7576: [D loss: 0.697829, acc: 0.486328]: [A loss: 0.722653, acc: 0.277344]\n",
      "7577: [D loss: 0.694494, acc: 0.517578]: [A loss: 0.730800, acc: 0.218750]\n",
      "7578: [D loss: 0.698003, acc: 0.464844]: [A loss: 0.746443, acc: 0.156250]\n",
      "7579: [D loss: 0.693565, acc: 0.533203]: [A loss: 0.706640, acc: 0.378906]\n",
      "7580: [D loss: 0.695036, acc: 0.505859]: [A loss: 0.785610, acc: 0.062500]\n",
      "7581: [D loss: 0.691618, acc: 0.519531]: [A loss: 0.693677, acc: 0.500000]\n",
      "7582: [D loss: 0.702308, acc: 0.507812]: [A loss: 0.755094, acc: 0.160156]\n",
      "7583: [D loss: 0.697863, acc: 0.500000]: [A loss: 0.709754, acc: 0.367188]\n",
      "7584: [D loss: 0.695288, acc: 0.507812]: [A loss: 0.719611, acc: 0.277344]\n",
      "7585: [D loss: 0.696648, acc: 0.505859]: [A loss: 0.723367, acc: 0.277344]\n",
      "7586: [D loss: 0.697104, acc: 0.501953]: [A loss: 0.691578, acc: 0.476562]\n",
      "7587: [D loss: 0.700332, acc: 0.503906]: [A loss: 0.766745, acc: 0.078125]\n",
      "7588: [D loss: 0.695359, acc: 0.511719]: [A loss: 0.697073, acc: 0.449219]\n",
      "7589: [D loss: 0.700444, acc: 0.490234]: [A loss: 0.741022, acc: 0.175781]\n",
      "7590: [D loss: 0.692455, acc: 0.509766]: [A loss: 0.688229, acc: 0.468750]\n",
      "7591: [D loss: 0.693674, acc: 0.519531]: [A loss: 0.742993, acc: 0.167969]\n",
      "7592: [D loss: 0.693503, acc: 0.531250]: [A loss: 0.706642, acc: 0.371094]\n",
      "7593: [D loss: 0.694126, acc: 0.490234]: [A loss: 0.736524, acc: 0.242188]\n",
      "7594: [D loss: 0.691519, acc: 0.544922]: [A loss: 0.708008, acc: 0.347656]\n",
      "7595: [D loss: 0.699253, acc: 0.490234]: [A loss: 0.772322, acc: 0.074219]\n",
      "7596: [D loss: 0.690288, acc: 0.537109]: [A loss: 0.690539, acc: 0.507812]\n",
      "7597: [D loss: 0.704989, acc: 0.496094]: [A loss: 0.798356, acc: 0.031250]\n",
      "7598: [D loss: 0.701586, acc: 0.492188]: [A loss: 0.710179, acc: 0.359375]\n",
      "7599: [D loss: 0.697084, acc: 0.478516]: [A loss: 0.702188, acc: 0.382812]\n",
      "7600: [D loss: 0.699302, acc: 0.468750]: [A loss: 0.719419, acc: 0.320312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7601: [D loss: 0.692116, acc: 0.541016]: [A loss: 0.724816, acc: 0.277344]\n",
      "7602: [D loss: 0.699033, acc: 0.480469]: [A loss: 0.713862, acc: 0.324219]\n",
      "7603: [D loss: 0.697141, acc: 0.476562]: [A loss: 0.763702, acc: 0.105469]\n",
      "7604: [D loss: 0.694379, acc: 0.523438]: [A loss: 0.716495, acc: 0.300781]\n",
      "7605: [D loss: 0.693910, acc: 0.519531]: [A loss: 0.736460, acc: 0.199219]\n",
      "7606: [D loss: 0.692784, acc: 0.513672]: [A loss: 0.711513, acc: 0.371094]\n",
      "7607: [D loss: 0.695132, acc: 0.513672]: [A loss: 0.787138, acc: 0.054688]\n",
      "7608: [D loss: 0.694123, acc: 0.498047]: [A loss: 0.692248, acc: 0.484375]\n",
      "7609: [D loss: 0.700696, acc: 0.517578]: [A loss: 0.739196, acc: 0.175781]\n",
      "7610: [D loss: 0.690678, acc: 0.511719]: [A loss: 0.709192, acc: 0.382812]\n",
      "7611: [D loss: 0.694305, acc: 0.486328]: [A loss: 0.730718, acc: 0.210938]\n",
      "7612: [D loss: 0.692074, acc: 0.517578]: [A loss: 0.691172, acc: 0.480469]\n",
      "7613: [D loss: 0.696081, acc: 0.505859]: [A loss: 0.759423, acc: 0.117188]\n",
      "7614: [D loss: 0.692049, acc: 0.550781]: [A loss: 0.709184, acc: 0.363281]\n",
      "7615: [D loss: 0.695650, acc: 0.507812]: [A loss: 0.748234, acc: 0.136719]\n",
      "7616: [D loss: 0.691836, acc: 0.541016]: [A loss: 0.719459, acc: 0.320312]\n",
      "7617: [D loss: 0.693703, acc: 0.517578]: [A loss: 0.738532, acc: 0.214844]\n",
      "7618: [D loss: 0.697262, acc: 0.509766]: [A loss: 0.732771, acc: 0.226562]\n",
      "7619: [D loss: 0.696926, acc: 0.486328]: [A loss: 0.736421, acc: 0.222656]\n",
      "7620: [D loss: 0.696956, acc: 0.494141]: [A loss: 0.738364, acc: 0.222656]\n",
      "7621: [D loss: 0.690448, acc: 0.546875]: [A loss: 0.768288, acc: 0.117188]\n",
      "7622: [D loss: 0.695238, acc: 0.513672]: [A loss: 0.703370, acc: 0.414062]\n",
      "7623: [D loss: 0.698083, acc: 0.535156]: [A loss: 0.768024, acc: 0.109375]\n",
      "7624: [D loss: 0.696552, acc: 0.482422]: [A loss: 0.714751, acc: 0.375000]\n",
      "7625: [D loss: 0.700099, acc: 0.478516]: [A loss: 0.792861, acc: 0.078125]\n",
      "7626: [D loss: 0.697184, acc: 0.492188]: [A loss: 0.701530, acc: 0.406250]\n",
      "7627: [D loss: 0.692886, acc: 0.531250]: [A loss: 0.771912, acc: 0.074219]\n",
      "7628: [D loss: 0.693504, acc: 0.529297]: [A loss: 0.703535, acc: 0.398438]\n",
      "7629: [D loss: 0.697998, acc: 0.511719]: [A loss: 0.785618, acc: 0.050781]\n",
      "7630: [D loss: 0.693271, acc: 0.519531]: [A loss: 0.677925, acc: 0.582031]\n",
      "7631: [D loss: 0.697562, acc: 0.521484]: [A loss: 0.797768, acc: 0.023438]\n",
      "7632: [D loss: 0.690987, acc: 0.525391]: [A loss: 0.694541, acc: 0.445312]\n",
      "7633: [D loss: 0.695541, acc: 0.488281]: [A loss: 0.745878, acc: 0.175781]\n",
      "7634: [D loss: 0.692039, acc: 0.531250]: [A loss: 0.701778, acc: 0.378906]\n",
      "7635: [D loss: 0.698993, acc: 0.503906]: [A loss: 0.742157, acc: 0.179688]\n",
      "7636: [D loss: 0.689880, acc: 0.554688]: [A loss: 0.699537, acc: 0.417969]\n",
      "7637: [D loss: 0.699971, acc: 0.501953]: [A loss: 0.736359, acc: 0.191406]\n",
      "7638: [D loss: 0.694239, acc: 0.503906]: [A loss: 0.701902, acc: 0.417969]\n",
      "7639: [D loss: 0.691541, acc: 0.513672]: [A loss: 0.718210, acc: 0.324219]\n",
      "7640: [D loss: 0.690519, acc: 0.537109]: [A loss: 0.694538, acc: 0.484375]\n",
      "7641: [D loss: 0.696520, acc: 0.517578]: [A loss: 0.758297, acc: 0.136719]\n",
      "7642: [D loss: 0.693987, acc: 0.517578]: [A loss: 0.713494, acc: 0.335938]\n",
      "7643: [D loss: 0.692527, acc: 0.517578]: [A loss: 0.717339, acc: 0.339844]\n",
      "7644: [D loss: 0.691987, acc: 0.527344]: [A loss: 0.733041, acc: 0.261719]\n",
      "7645: [D loss: 0.697491, acc: 0.482422]: [A loss: 0.750284, acc: 0.136719]\n",
      "7646: [D loss: 0.690811, acc: 0.546875]: [A loss: 0.707449, acc: 0.386719]\n",
      "7647: [D loss: 0.691960, acc: 0.523438]: [A loss: 0.763833, acc: 0.085938]\n",
      "7648: [D loss: 0.697725, acc: 0.503906]: [A loss: 0.721188, acc: 0.285156]\n",
      "7649: [D loss: 0.697933, acc: 0.496094]: [A loss: 0.776689, acc: 0.085938]\n",
      "7650: [D loss: 0.694852, acc: 0.478516]: [A loss: 0.698924, acc: 0.441406]\n",
      "7651: [D loss: 0.700440, acc: 0.490234]: [A loss: 0.781056, acc: 0.078125]\n",
      "7652: [D loss: 0.691234, acc: 0.533203]: [A loss: 0.694854, acc: 0.496094]\n",
      "7653: [D loss: 0.694292, acc: 0.531250]: [A loss: 0.768251, acc: 0.125000]\n",
      "7654: [D loss: 0.697039, acc: 0.501953]: [A loss: 0.719861, acc: 0.304688]\n",
      "7655: [D loss: 0.696097, acc: 0.500000]: [A loss: 0.725661, acc: 0.277344]\n",
      "7656: [D loss: 0.697648, acc: 0.507812]: [A loss: 0.752191, acc: 0.117188]\n",
      "7657: [D loss: 0.689814, acc: 0.544922]: [A loss: 0.722910, acc: 0.308594]\n",
      "7658: [D loss: 0.695933, acc: 0.498047]: [A loss: 0.761039, acc: 0.148438]\n",
      "7659: [D loss: 0.692700, acc: 0.521484]: [A loss: 0.689403, acc: 0.542969]\n",
      "7660: [D loss: 0.696360, acc: 0.509766]: [A loss: 0.801512, acc: 0.023438]\n",
      "7661: [D loss: 0.696331, acc: 0.464844]: [A loss: 0.688664, acc: 0.523438]\n",
      "7662: [D loss: 0.696237, acc: 0.523438]: [A loss: 0.759414, acc: 0.105469]\n",
      "7663: [D loss: 0.695986, acc: 0.513672]: [A loss: 0.708530, acc: 0.386719]\n",
      "7664: [D loss: 0.695239, acc: 0.507812]: [A loss: 0.729403, acc: 0.250000]\n",
      "7665: [D loss: 0.696899, acc: 0.470703]: [A loss: 0.718560, acc: 0.316406]\n",
      "7666: [D loss: 0.697418, acc: 0.515625]: [A loss: 0.741561, acc: 0.203125]\n",
      "7667: [D loss: 0.697975, acc: 0.488281]: [A loss: 0.741441, acc: 0.203125]\n",
      "7668: [D loss: 0.693480, acc: 0.513672]: [A loss: 0.714820, acc: 0.328125]\n",
      "7669: [D loss: 0.689042, acc: 0.525391]: [A loss: 0.697112, acc: 0.453125]\n",
      "7670: [D loss: 0.699182, acc: 0.501953]: [A loss: 0.806540, acc: 0.027344]\n",
      "7671: [D loss: 0.691933, acc: 0.517578]: [A loss: 0.693474, acc: 0.464844]\n",
      "7672: [D loss: 0.701818, acc: 0.482422]: [A loss: 0.754571, acc: 0.128906]\n",
      "7673: [D loss: 0.695336, acc: 0.486328]: [A loss: 0.715295, acc: 0.332031]\n",
      "7674: [D loss: 0.694477, acc: 0.498047]: [A loss: 0.729692, acc: 0.242188]\n",
      "7675: [D loss: 0.693885, acc: 0.511719]: [A loss: 0.732942, acc: 0.242188]\n",
      "7676: [D loss: 0.690708, acc: 0.496094]: [A loss: 0.725936, acc: 0.253906]\n",
      "7677: [D loss: 0.695394, acc: 0.507812]: [A loss: 0.747479, acc: 0.226562]\n",
      "7678: [D loss: 0.693388, acc: 0.501953]: [A loss: 0.723284, acc: 0.324219]\n",
      "7679: [D loss: 0.695220, acc: 0.517578]: [A loss: 0.734973, acc: 0.253906]\n",
      "7680: [D loss: 0.693621, acc: 0.511719]: [A loss: 0.703107, acc: 0.406250]\n",
      "7681: [D loss: 0.703634, acc: 0.498047]: [A loss: 0.784814, acc: 0.042969]\n",
      "7682: [D loss: 0.697028, acc: 0.503906]: [A loss: 0.698082, acc: 0.433594]\n",
      "7683: [D loss: 0.690946, acc: 0.537109]: [A loss: 0.719736, acc: 0.304688]\n",
      "7684: [D loss: 0.693260, acc: 0.533203]: [A loss: 0.716297, acc: 0.312500]\n",
      "7685: [D loss: 0.697173, acc: 0.498047]: [A loss: 0.736665, acc: 0.203125]\n",
      "7686: [D loss: 0.694177, acc: 0.505859]: [A loss: 0.712642, acc: 0.351562]\n",
      "7687: [D loss: 0.700088, acc: 0.468750]: [A loss: 0.762045, acc: 0.113281]\n",
      "7688: [D loss: 0.692075, acc: 0.513672]: [A loss: 0.691308, acc: 0.515625]\n",
      "7689: [D loss: 0.699316, acc: 0.517578]: [A loss: 0.773259, acc: 0.097656]\n",
      "7690: [D loss: 0.690331, acc: 0.513672]: [A loss: 0.696709, acc: 0.472656]\n",
      "7691: [D loss: 0.700967, acc: 0.515625]: [A loss: 0.766640, acc: 0.097656]\n",
      "7692: [D loss: 0.692576, acc: 0.517578]: [A loss: 0.689497, acc: 0.511719]\n",
      "7693: [D loss: 0.702578, acc: 0.476562]: [A loss: 0.795265, acc: 0.050781]\n",
      "7694: [D loss: 0.693511, acc: 0.496094]: [A loss: 0.712968, acc: 0.320312]\n",
      "7695: [D loss: 0.699872, acc: 0.490234]: [A loss: 0.742277, acc: 0.207031]\n",
      "7696: [D loss: 0.690515, acc: 0.509766]: [A loss: 0.727965, acc: 0.265625]\n",
      "7697: [D loss: 0.698476, acc: 0.500000]: [A loss: 0.751934, acc: 0.167969]\n",
      "7698: [D loss: 0.699135, acc: 0.482422]: [A loss: 0.737124, acc: 0.234375]\n",
      "7699: [D loss: 0.695102, acc: 0.515625]: [A loss: 0.744107, acc: 0.167969]\n",
      "7700: [D loss: 0.691345, acc: 0.531250]: [A loss: 0.713002, acc: 0.386719]\n",
      "7701: [D loss: 0.700885, acc: 0.501953]: [A loss: 0.798429, acc: 0.011719]\n",
      "7702: [D loss: 0.691793, acc: 0.513672]: [A loss: 0.674260, acc: 0.628906]\n",
      "7703: [D loss: 0.703854, acc: 0.496094]: [A loss: 0.776862, acc: 0.062500]\n",
      "7704: [D loss: 0.695953, acc: 0.486328]: [A loss: 0.706807, acc: 0.398438]\n",
      "7705: [D loss: 0.695660, acc: 0.525391]: [A loss: 0.698640, acc: 0.449219]\n",
      "7706: [D loss: 0.697197, acc: 0.511719]: [A loss: 0.773996, acc: 0.078125]\n",
      "7707: [D loss: 0.692548, acc: 0.509766]: [A loss: 0.698017, acc: 0.441406]\n",
      "7708: [D loss: 0.699099, acc: 0.468750]: [A loss: 0.746437, acc: 0.171875]\n",
      "7709: [D loss: 0.690287, acc: 0.544922]: [A loss: 0.704641, acc: 0.414062]\n",
      "7710: [D loss: 0.698042, acc: 0.515625]: [A loss: 0.749816, acc: 0.132812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7711: [D loss: 0.692410, acc: 0.525391]: [A loss: 0.697819, acc: 0.457031]\n",
      "7712: [D loss: 0.698934, acc: 0.484375]: [A loss: 0.747336, acc: 0.195312]\n",
      "7713: [D loss: 0.690716, acc: 0.519531]: [A loss: 0.687550, acc: 0.515625]\n",
      "7714: [D loss: 0.701023, acc: 0.484375]: [A loss: 0.752526, acc: 0.156250]\n",
      "7715: [D loss: 0.696402, acc: 0.527344]: [A loss: 0.688636, acc: 0.503906]\n",
      "7716: [D loss: 0.698441, acc: 0.486328]: [A loss: 0.779868, acc: 0.078125]\n",
      "7717: [D loss: 0.692900, acc: 0.511719]: [A loss: 0.707991, acc: 0.339844]\n",
      "7718: [D loss: 0.692689, acc: 0.537109]: [A loss: 0.718783, acc: 0.320312]\n",
      "7719: [D loss: 0.701567, acc: 0.509766]: [A loss: 0.801710, acc: 0.039062]\n",
      "7720: [D loss: 0.688280, acc: 0.542969]: [A loss: 0.672226, acc: 0.613281]\n",
      "7721: [D loss: 0.706312, acc: 0.492188]: [A loss: 0.799982, acc: 0.039062]\n",
      "7722: [D loss: 0.688262, acc: 0.533203]: [A loss: 0.698464, acc: 0.437500]\n",
      "7723: [D loss: 0.693156, acc: 0.537109]: [A loss: 0.713695, acc: 0.378906]\n",
      "7724: [D loss: 0.700166, acc: 0.500000]: [A loss: 0.738142, acc: 0.218750]\n",
      "7725: [D loss: 0.693879, acc: 0.541016]: [A loss: 0.727671, acc: 0.285156]\n",
      "7726: [D loss: 0.697687, acc: 0.509766]: [A loss: 0.722679, acc: 0.312500]\n",
      "7727: [D loss: 0.701867, acc: 0.507812]: [A loss: 0.764505, acc: 0.167969]\n",
      "7728: [D loss: 0.695152, acc: 0.482422]: [A loss: 0.692037, acc: 0.500000]\n",
      "7729: [D loss: 0.698354, acc: 0.521484]: [A loss: 0.739079, acc: 0.199219]\n",
      "7730: [D loss: 0.691854, acc: 0.527344]: [A loss: 0.695282, acc: 0.492188]\n",
      "7731: [D loss: 0.699702, acc: 0.494141]: [A loss: 0.723968, acc: 0.304688]\n",
      "7732: [D loss: 0.696609, acc: 0.500000]: [A loss: 0.717748, acc: 0.328125]\n",
      "7733: [D loss: 0.697044, acc: 0.480469]: [A loss: 0.739673, acc: 0.199219]\n",
      "7734: [D loss: 0.694132, acc: 0.509766]: [A loss: 0.731052, acc: 0.242188]\n",
      "7735: [D loss: 0.695283, acc: 0.513672]: [A loss: 0.723910, acc: 0.277344]\n",
      "7736: [D loss: 0.696231, acc: 0.521484]: [A loss: 0.719859, acc: 0.296875]\n",
      "7737: [D loss: 0.690108, acc: 0.552734]: [A loss: 0.741174, acc: 0.218750]\n",
      "7738: [D loss: 0.695636, acc: 0.507812]: [A loss: 0.723393, acc: 0.316406]\n",
      "7739: [D loss: 0.697412, acc: 0.482422]: [A loss: 0.756277, acc: 0.128906]\n",
      "7740: [D loss: 0.692014, acc: 0.531250]: [A loss: 0.693619, acc: 0.468750]\n",
      "7741: [D loss: 0.702451, acc: 0.503906]: [A loss: 0.789441, acc: 0.027344]\n",
      "7742: [D loss: 0.691155, acc: 0.529297]: [A loss: 0.702465, acc: 0.449219]\n",
      "7743: [D loss: 0.695998, acc: 0.507812]: [A loss: 0.754270, acc: 0.183594]\n",
      "7744: [D loss: 0.688701, acc: 0.531250]: [A loss: 0.676554, acc: 0.589844]\n",
      "7745: [D loss: 0.700086, acc: 0.511719]: [A loss: 0.802014, acc: 0.039062]\n",
      "7746: [D loss: 0.696499, acc: 0.498047]: [A loss: 0.715403, acc: 0.402344]\n",
      "7747: [D loss: 0.691444, acc: 0.527344]: [A loss: 0.746325, acc: 0.199219]\n",
      "7748: [D loss: 0.703832, acc: 0.458984]: [A loss: 0.747599, acc: 0.222656]\n",
      "7749: [D loss: 0.693619, acc: 0.525391]: [A loss: 0.730568, acc: 0.285156]\n",
      "7750: [D loss: 0.699266, acc: 0.525391]: [A loss: 0.777320, acc: 0.148438]\n",
      "7751: [D loss: 0.694889, acc: 0.476562]: [A loss: 0.713052, acc: 0.398438]\n",
      "7752: [D loss: 0.698913, acc: 0.492188]: [A loss: 0.750652, acc: 0.199219]\n",
      "7753: [D loss: 0.690178, acc: 0.519531]: [A loss: 0.704190, acc: 0.414062]\n",
      "7754: [D loss: 0.696234, acc: 0.486328]: [A loss: 0.750093, acc: 0.140625]\n",
      "7755: [D loss: 0.693312, acc: 0.539062]: [A loss: 0.691131, acc: 0.503906]\n",
      "7756: [D loss: 0.693388, acc: 0.511719]: [A loss: 0.774785, acc: 0.097656]\n",
      "7757: [D loss: 0.697630, acc: 0.511719]: [A loss: 0.689928, acc: 0.511719]\n",
      "7758: [D loss: 0.693565, acc: 0.500000]: [A loss: 0.742770, acc: 0.199219]\n",
      "7759: [D loss: 0.693933, acc: 0.523438]: [A loss: 0.710340, acc: 0.382812]\n",
      "7760: [D loss: 0.701612, acc: 0.496094]: [A loss: 0.730132, acc: 0.289062]\n",
      "7761: [D loss: 0.693342, acc: 0.507812]: [A loss: 0.706814, acc: 0.406250]\n",
      "7762: [D loss: 0.692652, acc: 0.515625]: [A loss: 0.760703, acc: 0.132812]\n",
      "7763: [D loss: 0.691058, acc: 0.527344]: [A loss: 0.715264, acc: 0.347656]\n",
      "7764: [D loss: 0.692202, acc: 0.509766]: [A loss: 0.739046, acc: 0.203125]\n",
      "7765: [D loss: 0.694604, acc: 0.505859]: [A loss: 0.729080, acc: 0.269531]\n",
      "7766: [D loss: 0.692647, acc: 0.525391]: [A loss: 0.733772, acc: 0.273438]\n",
      "7767: [D loss: 0.691790, acc: 0.501953]: [A loss: 0.737974, acc: 0.257812]\n",
      "7768: [D loss: 0.696354, acc: 0.509766]: [A loss: 0.716397, acc: 0.367188]\n",
      "7769: [D loss: 0.691328, acc: 0.542969]: [A loss: 0.752013, acc: 0.136719]\n",
      "7770: [D loss: 0.690093, acc: 0.523438]: [A loss: 0.718979, acc: 0.347656]\n",
      "7771: [D loss: 0.690358, acc: 0.537109]: [A loss: 0.755217, acc: 0.183594]\n",
      "7772: [D loss: 0.695942, acc: 0.468750]: [A loss: 0.753967, acc: 0.195312]\n",
      "7773: [D loss: 0.690934, acc: 0.525391]: [A loss: 0.732350, acc: 0.285156]\n",
      "7774: [D loss: 0.695187, acc: 0.507812]: [A loss: 0.731109, acc: 0.253906]\n",
      "7775: [D loss: 0.696659, acc: 0.482422]: [A loss: 0.721146, acc: 0.324219]\n",
      "7776: [D loss: 0.695473, acc: 0.490234]: [A loss: 0.736230, acc: 0.191406]\n",
      "7777: [D loss: 0.699425, acc: 0.490234]: [A loss: 0.740704, acc: 0.210938]\n",
      "7778: [D loss: 0.698106, acc: 0.490234]: [A loss: 0.745160, acc: 0.183594]\n",
      "7779: [D loss: 0.694426, acc: 0.533203]: [A loss: 0.734467, acc: 0.234375]\n",
      "7780: [D loss: 0.696650, acc: 0.494141]: [A loss: 0.716409, acc: 0.371094]\n",
      "7781: [D loss: 0.693402, acc: 0.525391]: [A loss: 0.743948, acc: 0.199219]\n",
      "7782: [D loss: 0.694789, acc: 0.500000]: [A loss: 0.737964, acc: 0.242188]\n",
      "7783: [D loss: 0.690871, acc: 0.521484]: [A loss: 0.723453, acc: 0.316406]\n",
      "7784: [D loss: 0.693130, acc: 0.503906]: [A loss: 0.741204, acc: 0.210938]\n",
      "7785: [D loss: 0.698264, acc: 0.498047]: [A loss: 0.723261, acc: 0.343750]\n",
      "7786: [D loss: 0.693151, acc: 0.501953]: [A loss: 0.754556, acc: 0.199219]\n",
      "7787: [D loss: 0.681279, acc: 0.580078]: [A loss: 0.714813, acc: 0.367188]\n",
      "7788: [D loss: 0.701147, acc: 0.513672]: [A loss: 0.841323, acc: 0.031250]\n",
      "7789: [D loss: 0.704461, acc: 0.480469]: [A loss: 0.705777, acc: 0.390625]\n",
      "7790: [D loss: 0.694665, acc: 0.523438]: [A loss: 0.730409, acc: 0.304688]\n",
      "7791: [D loss: 0.700803, acc: 0.486328]: [A loss: 0.746001, acc: 0.171875]\n",
      "7792: [D loss: 0.695345, acc: 0.503906]: [A loss: 0.727327, acc: 0.304688]\n",
      "7793: [D loss: 0.693757, acc: 0.525391]: [A loss: 0.711178, acc: 0.394531]\n",
      "7794: [D loss: 0.700900, acc: 0.500000]: [A loss: 0.762090, acc: 0.136719]\n",
      "7795: [D loss: 0.691515, acc: 0.503906]: [A loss: 0.694148, acc: 0.531250]\n",
      "7796: [D loss: 0.698288, acc: 0.511719]: [A loss: 0.770778, acc: 0.128906]\n",
      "7797: [D loss: 0.692677, acc: 0.531250]: [A loss: 0.715288, acc: 0.339844]\n",
      "7798: [D loss: 0.694126, acc: 0.498047]: [A loss: 0.734460, acc: 0.277344]\n",
      "7799: [D loss: 0.697234, acc: 0.496094]: [A loss: 0.781256, acc: 0.070312]\n",
      "7800: [D loss: 0.693306, acc: 0.519531]: [A loss: 0.692382, acc: 0.488281]\n",
      "7801: [D loss: 0.703526, acc: 0.482422]: [A loss: 0.790786, acc: 0.062500]\n",
      "7802: [D loss: 0.695836, acc: 0.482422]: [A loss: 0.713159, acc: 0.332031]\n",
      "7803: [D loss: 0.697268, acc: 0.486328]: [A loss: 0.730409, acc: 0.277344]\n",
      "7804: [D loss: 0.695575, acc: 0.509766]: [A loss: 0.736672, acc: 0.246094]\n",
      "7805: [D loss: 0.696941, acc: 0.511719]: [A loss: 0.738607, acc: 0.238281]\n",
      "7806: [D loss: 0.691983, acc: 0.505859]: [A loss: 0.710049, acc: 0.382812]\n",
      "7807: [D loss: 0.698634, acc: 0.496094]: [A loss: 0.790311, acc: 0.082031]\n",
      "7808: [D loss: 0.696141, acc: 0.517578]: [A loss: 0.688912, acc: 0.519531]\n",
      "7809: [D loss: 0.696286, acc: 0.500000]: [A loss: 0.734402, acc: 0.253906]\n",
      "7810: [D loss: 0.695861, acc: 0.511719]: [A loss: 0.718637, acc: 0.328125]\n",
      "7811: [D loss: 0.702134, acc: 0.480469]: [A loss: 0.775382, acc: 0.070312]\n",
      "7812: [D loss: 0.693709, acc: 0.541016]: [A loss: 0.705113, acc: 0.414062]\n",
      "7813: [D loss: 0.697260, acc: 0.515625]: [A loss: 0.702332, acc: 0.433594]\n",
      "7814: [D loss: 0.699130, acc: 0.503906]: [A loss: 0.733157, acc: 0.285156]\n",
      "7815: [D loss: 0.688894, acc: 0.527344]: [A loss: 0.714311, acc: 0.332031]\n",
      "7816: [D loss: 0.692103, acc: 0.525391]: [A loss: 0.729264, acc: 0.292969]\n",
      "7817: [D loss: 0.691940, acc: 0.507812]: [A loss: 0.708013, acc: 0.441406]\n",
      "7818: [D loss: 0.702286, acc: 0.492188]: [A loss: 0.766922, acc: 0.144531]\n",
      "7819: [D loss: 0.694354, acc: 0.498047]: [A loss: 0.736990, acc: 0.222656]\n",
      "7820: [D loss: 0.699586, acc: 0.505859]: [A loss: 0.742758, acc: 0.257812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7821: [D loss: 0.695331, acc: 0.505859]: [A loss: 0.716070, acc: 0.375000]\n",
      "7822: [D loss: 0.698529, acc: 0.488281]: [A loss: 0.798534, acc: 0.082031]\n",
      "7823: [D loss: 0.692083, acc: 0.492188]: [A loss: 0.726569, acc: 0.296875]\n",
      "7824: [D loss: 0.689750, acc: 0.531250]: [A loss: 0.717211, acc: 0.371094]\n",
      "7825: [D loss: 0.699638, acc: 0.507812]: [A loss: 0.752352, acc: 0.152344]\n",
      "7826: [D loss: 0.690123, acc: 0.505859]: [A loss: 0.702377, acc: 0.437500]\n",
      "7827: [D loss: 0.692765, acc: 0.527344]: [A loss: 0.791209, acc: 0.046875]\n",
      "7828: [D loss: 0.698615, acc: 0.494141]: [A loss: 0.695541, acc: 0.492188]\n",
      "7829: [D loss: 0.694974, acc: 0.521484]: [A loss: 0.755495, acc: 0.183594]\n",
      "7830: [D loss: 0.693722, acc: 0.519531]: [A loss: 0.733865, acc: 0.281250]\n",
      "7831: [D loss: 0.695751, acc: 0.490234]: [A loss: 0.766179, acc: 0.140625]\n",
      "7832: [D loss: 0.695585, acc: 0.507812]: [A loss: 0.702039, acc: 0.429688]\n",
      "7833: [D loss: 0.701716, acc: 0.486328]: [A loss: 0.789268, acc: 0.082031]\n",
      "7834: [D loss: 0.693188, acc: 0.517578]: [A loss: 0.698787, acc: 0.468750]\n",
      "7835: [D loss: 0.697787, acc: 0.515625]: [A loss: 0.760218, acc: 0.167969]\n",
      "7836: [D loss: 0.699176, acc: 0.498047]: [A loss: 0.735896, acc: 0.253906]\n",
      "7837: [D loss: 0.697342, acc: 0.492188]: [A loss: 0.692539, acc: 0.476562]\n",
      "7838: [D loss: 0.696942, acc: 0.523438]: [A loss: 0.748230, acc: 0.171875]\n",
      "7839: [D loss: 0.694068, acc: 0.482422]: [A loss: 0.726066, acc: 0.304688]\n",
      "7840: [D loss: 0.691045, acc: 0.535156]: [A loss: 0.706542, acc: 0.406250]\n",
      "7841: [D loss: 0.691241, acc: 0.523438]: [A loss: 0.743177, acc: 0.246094]\n",
      "7842: [D loss: 0.686422, acc: 0.537109]: [A loss: 0.695323, acc: 0.437500]\n",
      "7843: [D loss: 0.695532, acc: 0.492188]: [A loss: 0.753360, acc: 0.164062]\n",
      "7844: [D loss: 0.692468, acc: 0.531250]: [A loss: 0.705717, acc: 0.402344]\n",
      "7845: [D loss: 0.698187, acc: 0.505859]: [A loss: 0.754930, acc: 0.199219]\n",
      "7846: [D loss: 0.694453, acc: 0.505859]: [A loss: 0.657144, acc: 0.664062]\n",
      "7847: [D loss: 0.711349, acc: 0.501953]: [A loss: 0.799330, acc: 0.042969]\n",
      "7848: [D loss: 0.696836, acc: 0.503906]: [A loss: 0.717479, acc: 0.335938]\n",
      "7849: [D loss: 0.696109, acc: 0.511719]: [A loss: 0.712844, acc: 0.351562]\n",
      "7850: [D loss: 0.699656, acc: 0.503906]: [A loss: 0.714447, acc: 0.339844]\n",
      "7851: [D loss: 0.696928, acc: 0.517578]: [A loss: 0.738334, acc: 0.242188]\n",
      "7852: [D loss: 0.699565, acc: 0.460938]: [A loss: 0.743399, acc: 0.191406]\n",
      "7853: [D loss: 0.695589, acc: 0.480469]: [A loss: 0.736100, acc: 0.226562]\n",
      "7854: [D loss: 0.692666, acc: 0.525391]: [A loss: 0.749550, acc: 0.195312]\n",
      "7855: [D loss: 0.698651, acc: 0.488281]: [A loss: 0.731662, acc: 0.253906]\n",
      "7856: [D loss: 0.695996, acc: 0.498047]: [A loss: 0.751501, acc: 0.171875]\n",
      "7857: [D loss: 0.691681, acc: 0.533203]: [A loss: 0.735030, acc: 0.257812]\n",
      "7858: [D loss: 0.692967, acc: 0.519531]: [A loss: 0.712359, acc: 0.363281]\n",
      "7859: [D loss: 0.700439, acc: 0.490234]: [A loss: 0.771888, acc: 0.132812]\n",
      "7860: [D loss: 0.697195, acc: 0.498047]: [A loss: 0.704062, acc: 0.417969]\n",
      "7861: [D loss: 0.700331, acc: 0.501953]: [A loss: 0.761776, acc: 0.097656]\n",
      "7862: [D loss: 0.698866, acc: 0.458984]: [A loss: 0.696501, acc: 0.523438]\n",
      "7863: [D loss: 0.701506, acc: 0.466797]: [A loss: 0.751255, acc: 0.105469]\n",
      "7864: [D loss: 0.693639, acc: 0.509766]: [A loss: 0.710353, acc: 0.359375]\n",
      "7865: [D loss: 0.697305, acc: 0.496094]: [A loss: 0.708419, acc: 0.390625]\n",
      "7866: [D loss: 0.705757, acc: 0.462891]: [A loss: 0.768281, acc: 0.105469]\n",
      "7867: [D loss: 0.698585, acc: 0.478516]: [A loss: 0.701603, acc: 0.394531]\n",
      "7868: [D loss: 0.699089, acc: 0.503906]: [A loss: 0.713562, acc: 0.351562]\n",
      "7869: [D loss: 0.701609, acc: 0.498047]: [A loss: 0.731130, acc: 0.281250]\n",
      "7870: [D loss: 0.691772, acc: 0.531250]: [A loss: 0.717920, acc: 0.328125]\n",
      "7871: [D loss: 0.703513, acc: 0.453125]: [A loss: 0.739152, acc: 0.222656]\n",
      "7872: [D loss: 0.697082, acc: 0.494141]: [A loss: 0.753075, acc: 0.164062]\n",
      "7873: [D loss: 0.696407, acc: 0.492188]: [A loss: 0.713630, acc: 0.339844]\n",
      "7874: [D loss: 0.695569, acc: 0.486328]: [A loss: 0.744353, acc: 0.210938]\n",
      "7875: [D loss: 0.696108, acc: 0.500000]: [A loss: 0.730874, acc: 0.242188]\n",
      "7876: [D loss: 0.699844, acc: 0.476562]: [A loss: 0.746621, acc: 0.179688]\n",
      "7877: [D loss: 0.692456, acc: 0.519531]: [A loss: 0.700568, acc: 0.441406]\n",
      "7878: [D loss: 0.699445, acc: 0.498047]: [A loss: 0.735886, acc: 0.214844]\n",
      "7879: [D loss: 0.698129, acc: 0.492188]: [A loss: 0.709866, acc: 0.406250]\n",
      "7880: [D loss: 0.704175, acc: 0.474609]: [A loss: 0.772605, acc: 0.132812]\n",
      "7881: [D loss: 0.697523, acc: 0.496094]: [A loss: 0.728588, acc: 0.281250]\n",
      "7882: [D loss: 0.701107, acc: 0.484375]: [A loss: 0.747958, acc: 0.207031]\n",
      "7883: [D loss: 0.692471, acc: 0.505859]: [A loss: 0.745424, acc: 0.195312]\n",
      "7884: [D loss: 0.697638, acc: 0.523438]: [A loss: 0.726833, acc: 0.269531]\n",
      "7885: [D loss: 0.699867, acc: 0.474609]: [A loss: 0.750122, acc: 0.156250]\n",
      "7886: [D loss: 0.697115, acc: 0.484375]: [A loss: 0.730424, acc: 0.253906]\n",
      "7887: [D loss: 0.700993, acc: 0.460938]: [A loss: 0.746185, acc: 0.167969]\n",
      "7888: [D loss: 0.694862, acc: 0.507812]: [A loss: 0.715575, acc: 0.363281]\n",
      "7889: [D loss: 0.706025, acc: 0.455078]: [A loss: 0.761492, acc: 0.121094]\n",
      "7890: [D loss: 0.693937, acc: 0.478516]: [A loss: 0.680647, acc: 0.562500]\n",
      "7891: [D loss: 0.707843, acc: 0.490234]: [A loss: 0.811739, acc: 0.023438]\n",
      "7892: [D loss: 0.693576, acc: 0.492188]: [A loss: 0.702300, acc: 0.394531]\n",
      "7893: [D loss: 0.702821, acc: 0.498047]: [A loss: 0.741837, acc: 0.175781]\n",
      "7894: [D loss: 0.701311, acc: 0.462891]: [A loss: 0.720990, acc: 0.273438]\n",
      "7895: [D loss: 0.698474, acc: 0.482422]: [A loss: 0.729118, acc: 0.265625]\n",
      "7896: [D loss: 0.690579, acc: 0.513672]: [A loss: 0.694424, acc: 0.488281]\n",
      "7897: [D loss: 0.707261, acc: 0.457031]: [A loss: 0.767684, acc: 0.089844]\n",
      "7898: [D loss: 0.694190, acc: 0.523438]: [A loss: 0.705722, acc: 0.394531]\n",
      "7899: [D loss: 0.699152, acc: 0.488281]: [A loss: 0.746458, acc: 0.160156]\n",
      "7900: [D loss: 0.695046, acc: 0.482422]: [A loss: 0.706643, acc: 0.394531]\n",
      "7901: [D loss: 0.697353, acc: 0.503906]: [A loss: 0.767781, acc: 0.101562]\n",
      "7902: [D loss: 0.696382, acc: 0.527344]: [A loss: 0.718274, acc: 0.343750]\n",
      "7903: [D loss: 0.696849, acc: 0.490234]: [A loss: 0.752758, acc: 0.136719]\n",
      "7904: [D loss: 0.697505, acc: 0.468750]: [A loss: 0.718035, acc: 0.335938]\n",
      "7905: [D loss: 0.696529, acc: 0.525391]: [A loss: 0.732873, acc: 0.238281]\n",
      "7906: [D loss: 0.696450, acc: 0.490234]: [A loss: 0.718750, acc: 0.328125]\n",
      "7907: [D loss: 0.696788, acc: 0.501953]: [A loss: 0.715615, acc: 0.328125]\n",
      "7908: [D loss: 0.700951, acc: 0.500000]: [A loss: 0.761690, acc: 0.160156]\n",
      "7909: [D loss: 0.698731, acc: 0.492188]: [A loss: 0.699390, acc: 0.425781]\n",
      "7910: [D loss: 0.696310, acc: 0.480469]: [A loss: 0.719314, acc: 0.308594]\n",
      "7911: [D loss: 0.694891, acc: 0.503906]: [A loss: 0.728802, acc: 0.300781]\n",
      "7912: [D loss: 0.697328, acc: 0.501953]: [A loss: 0.760037, acc: 0.164062]\n",
      "7913: [D loss: 0.701496, acc: 0.453125]: [A loss: 0.732921, acc: 0.246094]\n",
      "7914: [D loss: 0.699780, acc: 0.478516]: [A loss: 0.753424, acc: 0.140625]\n",
      "7915: [D loss: 0.696651, acc: 0.478516]: [A loss: 0.751190, acc: 0.144531]\n",
      "7916: [D loss: 0.694384, acc: 0.509766]: [A loss: 0.720112, acc: 0.300781]\n",
      "7917: [D loss: 0.703802, acc: 0.496094]: [A loss: 0.756723, acc: 0.156250]\n",
      "7918: [D loss: 0.693373, acc: 0.523438]: [A loss: 0.700591, acc: 0.406250]\n",
      "7919: [D loss: 0.699713, acc: 0.498047]: [A loss: 0.766866, acc: 0.121094]\n",
      "7920: [D loss: 0.698702, acc: 0.478516]: [A loss: 0.701088, acc: 0.445312]\n",
      "7921: [D loss: 0.697905, acc: 0.501953]: [A loss: 0.757669, acc: 0.125000]\n",
      "7922: [D loss: 0.694975, acc: 0.484375]: [A loss: 0.706784, acc: 0.378906]\n",
      "7923: [D loss: 0.694894, acc: 0.525391]: [A loss: 0.714290, acc: 0.359375]\n",
      "7924: [D loss: 0.698506, acc: 0.494141]: [A loss: 0.739836, acc: 0.199219]\n",
      "7925: [D loss: 0.699812, acc: 0.488281]: [A loss: 0.738768, acc: 0.250000]\n",
      "7926: [D loss: 0.697524, acc: 0.494141]: [A loss: 0.728061, acc: 0.292969]\n",
      "7927: [D loss: 0.695529, acc: 0.501953]: [A loss: 0.738343, acc: 0.234375]\n",
      "7928: [D loss: 0.694421, acc: 0.507812]: [A loss: 0.763691, acc: 0.101562]\n",
      "7929: [D loss: 0.695931, acc: 0.517578]: [A loss: 0.725889, acc: 0.300781]\n",
      "7930: [D loss: 0.699492, acc: 0.498047]: [A loss: 0.745121, acc: 0.144531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7931: [D loss: 0.693085, acc: 0.515625]: [A loss: 0.706659, acc: 0.402344]\n",
      "7932: [D loss: 0.698102, acc: 0.494141]: [A loss: 0.749416, acc: 0.191406]\n",
      "7933: [D loss: 0.695329, acc: 0.488281]: [A loss: 0.730332, acc: 0.273438]\n",
      "7934: [D loss: 0.700025, acc: 0.482422]: [A loss: 0.762059, acc: 0.125000]\n",
      "7935: [D loss: 0.699154, acc: 0.482422]: [A loss: 0.741612, acc: 0.199219]\n",
      "7936: [D loss: 0.693388, acc: 0.507812]: [A loss: 0.767397, acc: 0.097656]\n",
      "7937: [D loss: 0.692951, acc: 0.494141]: [A loss: 0.706928, acc: 0.417969]\n",
      "7938: [D loss: 0.701698, acc: 0.490234]: [A loss: 0.780756, acc: 0.074219]\n",
      "7939: [D loss: 0.691668, acc: 0.531250]: [A loss: 0.708411, acc: 0.359375]\n",
      "7940: [D loss: 0.695726, acc: 0.498047]: [A loss: 0.755128, acc: 0.140625]\n",
      "7941: [D loss: 0.696973, acc: 0.503906]: [A loss: 0.708613, acc: 0.382812]\n",
      "7942: [D loss: 0.696410, acc: 0.500000]: [A loss: 0.716295, acc: 0.359375]\n",
      "7943: [D loss: 0.699704, acc: 0.490234]: [A loss: 0.745343, acc: 0.203125]\n",
      "7944: [D loss: 0.695875, acc: 0.482422]: [A loss: 0.713841, acc: 0.347656]\n",
      "7945: [D loss: 0.698228, acc: 0.511719]: [A loss: 0.728130, acc: 0.269531]\n",
      "7946: [D loss: 0.697868, acc: 0.488281]: [A loss: 0.766405, acc: 0.125000]\n",
      "7947: [D loss: 0.695645, acc: 0.496094]: [A loss: 0.746821, acc: 0.226562]\n",
      "7948: [D loss: 0.690827, acc: 0.523438]: [A loss: 0.727633, acc: 0.304688]\n",
      "7949: [D loss: 0.696307, acc: 0.505859]: [A loss: 0.724661, acc: 0.312500]\n",
      "7950: [D loss: 0.699696, acc: 0.476562]: [A loss: 0.754286, acc: 0.144531]\n",
      "7951: [D loss: 0.691020, acc: 0.529297]: [A loss: 0.676615, acc: 0.574219]\n",
      "7952: [D loss: 0.697344, acc: 0.511719]: [A loss: 0.800576, acc: 0.035156]\n",
      "7953: [D loss: 0.697714, acc: 0.501953]: [A loss: 0.699289, acc: 0.441406]\n",
      "7954: [D loss: 0.692773, acc: 0.527344]: [A loss: 0.728039, acc: 0.269531]\n",
      "7955: [D loss: 0.700921, acc: 0.478516]: [A loss: 0.752108, acc: 0.164062]\n",
      "7956: [D loss: 0.689829, acc: 0.535156]: [A loss: 0.699706, acc: 0.441406]\n",
      "7957: [D loss: 0.695740, acc: 0.552734]: [A loss: 0.779899, acc: 0.082031]\n",
      "7958: [D loss: 0.693153, acc: 0.529297]: [A loss: 0.717472, acc: 0.347656]\n",
      "7959: [D loss: 0.689783, acc: 0.527344]: [A loss: 0.724949, acc: 0.300781]\n",
      "7960: [D loss: 0.695393, acc: 0.525391]: [A loss: 0.733152, acc: 0.281250]\n",
      "7961: [D loss: 0.696732, acc: 0.501953]: [A loss: 0.749805, acc: 0.195312]\n",
      "7962: [D loss: 0.696635, acc: 0.513672]: [A loss: 0.746253, acc: 0.210938]\n",
      "7963: [D loss: 0.692833, acc: 0.541016]: [A loss: 0.719202, acc: 0.359375]\n",
      "7964: [D loss: 0.694239, acc: 0.496094]: [A loss: 0.748549, acc: 0.167969]\n",
      "7965: [D loss: 0.693542, acc: 0.515625]: [A loss: 0.697756, acc: 0.429688]\n",
      "7966: [D loss: 0.692576, acc: 0.511719]: [A loss: 0.772815, acc: 0.121094]\n",
      "7967: [D loss: 0.692384, acc: 0.531250]: [A loss: 0.677361, acc: 0.570312]\n",
      "7968: [D loss: 0.698572, acc: 0.503906]: [A loss: 0.761427, acc: 0.160156]\n",
      "7969: [D loss: 0.696229, acc: 0.500000]: [A loss: 0.712219, acc: 0.343750]\n",
      "7970: [D loss: 0.699227, acc: 0.484375]: [A loss: 0.716463, acc: 0.351562]\n",
      "7971: [D loss: 0.692240, acc: 0.513672]: [A loss: 0.728642, acc: 0.300781]\n",
      "7972: [D loss: 0.694759, acc: 0.500000]: [A loss: 0.724142, acc: 0.324219]\n",
      "7973: [D loss: 0.689697, acc: 0.542969]: [A loss: 0.675621, acc: 0.589844]\n",
      "7974: [D loss: 0.702409, acc: 0.505859]: [A loss: 0.787550, acc: 0.101562]\n",
      "7975: [D loss: 0.695048, acc: 0.490234]: [A loss: 0.714766, acc: 0.363281]\n",
      "7976: [D loss: 0.697802, acc: 0.503906]: [A loss: 0.712947, acc: 0.390625]\n",
      "7977: [D loss: 0.694437, acc: 0.501953]: [A loss: 0.729582, acc: 0.312500]\n",
      "7978: [D loss: 0.699515, acc: 0.472656]: [A loss: 0.755520, acc: 0.171875]\n",
      "7979: [D loss: 0.692894, acc: 0.519531]: [A loss: 0.696956, acc: 0.433594]\n",
      "7980: [D loss: 0.695018, acc: 0.484375]: [A loss: 0.772100, acc: 0.113281]\n",
      "7981: [D loss: 0.695239, acc: 0.505859]: [A loss: 0.695123, acc: 0.488281]\n",
      "7982: [D loss: 0.697238, acc: 0.519531]: [A loss: 0.787427, acc: 0.058594]\n",
      "7983: [D loss: 0.692753, acc: 0.509766]: [A loss: 0.692642, acc: 0.496094]\n",
      "7984: [D loss: 0.693572, acc: 0.521484]: [A loss: 0.764618, acc: 0.109375]\n",
      "7985: [D loss: 0.687898, acc: 0.539062]: [A loss: 0.692475, acc: 0.496094]\n",
      "7986: [D loss: 0.700119, acc: 0.521484]: [A loss: 0.764405, acc: 0.117188]\n",
      "7987: [D loss: 0.697397, acc: 0.494141]: [A loss: 0.705076, acc: 0.441406]\n",
      "7988: [D loss: 0.699556, acc: 0.501953]: [A loss: 0.733634, acc: 0.218750]\n",
      "7989: [D loss: 0.692387, acc: 0.513672]: [A loss: 0.701207, acc: 0.406250]\n",
      "7990: [D loss: 0.699203, acc: 0.486328]: [A loss: 0.724612, acc: 0.285156]\n",
      "7991: [D loss: 0.699185, acc: 0.478516]: [A loss: 0.728698, acc: 0.273438]\n",
      "7992: [D loss: 0.697207, acc: 0.507812]: [A loss: 0.744873, acc: 0.195312]\n",
      "7993: [D loss: 0.700584, acc: 0.476562]: [A loss: 0.728355, acc: 0.285156]\n",
      "7994: [D loss: 0.699944, acc: 0.484375]: [A loss: 0.767383, acc: 0.132812]\n",
      "7995: [D loss: 0.693560, acc: 0.500000]: [A loss: 0.712345, acc: 0.367188]\n",
      "7996: [D loss: 0.697472, acc: 0.492188]: [A loss: 0.737593, acc: 0.222656]\n",
      "7997: [D loss: 0.696066, acc: 0.521484]: [A loss: 0.708744, acc: 0.386719]\n",
      "7998: [D loss: 0.693748, acc: 0.515625]: [A loss: 0.788565, acc: 0.082031]\n",
      "7999: [D loss: 0.695358, acc: 0.505859]: [A loss: 0.700706, acc: 0.433594]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_dcgan.train(train_steps=8000, batch_size=256, save_interval=500)\n",
    "mnist_dcgan.plot_images(fake=True)\n",
    "mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(4).reshape((2, 2))\n",
    "x2 = np.ones(6).reshape((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[None, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones([2,3,2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2,1) (1,3,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6d35106e7697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2,1) (1,3,2) "
     ]
    }
   ],
   "source": [
    "x1[..., None] + x2[None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
